{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler\n",
    "from itertools import chain\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, logging\n",
    "\n",
    "# Setup\n",
    "diffusion_model_id = 'runwayml/stable-diffusion-v1-5'\n",
    "text_encoder_model_id = 'openai/clip-vit-large-patch14'\n",
    "device = 'cuda'\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Textual inversion settings\n",
    "property_name = 'bloodborne'  # Name of property to learn\n",
    "property_type = 'style'  # Type of property to learn (object, style)\n",
    "placeholder_token = f'<{property_name.replace(\"_\", \"-\")}>'  # Token that represents new property\n",
    "initializer_token = 'fantasy'  # Initial embedding for new property\n",
    "\n",
    "# Hugging Face access token\n",
    "token = ''\n",
    "with open('hugging_face_token.txt', 'r') as secret:\n",
    "    token = secret.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model components\n",
    "\n",
    "# Text Encoder + Tokenizer\n",
    "tokenizer = CLIPTokenizer.from_pretrained(text_encoder_model_id)\n",
    "text_encoder = CLIPTextModel.from_pretrained(text_encoder_model_id, torch_dtype=torch.float16)\n",
    "text_encoder.to(device)\n",
    "\n",
    "# Variational Autoencoder\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    diffusion_model_id, subfolder='vae', torch_dtype=torch.float16,\n",
    "    revision='fp16', use_auth_token=token)\n",
    "vae.to(device)\n",
    "\n",
    "# U-Net Model\n",
    "u_net = UNet2DConditionModel.from_pretrained(\n",
    "    diffusion_model_id, subfolder='unet', torch_dtype=torch.float16,\n",
    "    revision='fp16', use_auth_token=token)\n",
    "u_net.to(device)\n",
    "\n",
    "# Noise Scheduler\n",
    "noise_scheduler = DDPMScheduler.from_config(diffusion_model_id, subfolder='scheduler', use_auth_token=token)\n",
    "\n",
    "# Freeze parameters for a model\n",
    "def freeze_params(params):\n",
    "    for param in params:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Freeze all pre-trained models except for token embeddings in the text encoder\n",
    "freeze_params(vae.parameters())\n",
    "freeze_params(u_net.parameters())\n",
    "encoder_params_to_freeze = itertools.chain(\n",
    "        text_encoder.text_model.encoder.parameters(),\n",
    "        text_encoder.text_model.final_layer_norm.parameters(),\n",
    "        text_encoder.text_model.embeddings.position_embedding.parameters(),\n",
    ")\n",
    "freeze_params(encoder_params_to_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer and text encoder\n",
    "\n",
    "# Add the placeholder token in tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(placeholder_token)\n",
    "\n",
    "# Convert the initializer token and placeholder token to ids\n",
    "token_ids = tokenizer.encode(initializer_token, add_special_tokens=False)\n",
    "initializer_token_id = token_ids[0]\n",
    "placeholder_token_id = tokenizer.convert_tokens_to_ids(placeholder_token)\n",
    "\n",
    "# Resize the token embeddings as we are adding new special tokens to the tokenizer\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Initialize the newly added placeholder token with the embeddings of the initializer token\n",
    "token_embeds = text_encoder.get_input_embeddings().weight.data\n",
    "token_embeds[placeholder_token_id] = token_embeds[initializer_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates\n",
    "\n",
    "# Object\n",
    "object_templates = [\n",
    "    'a photo of a {}',\n",
    "    'a rendering of a {}',\n",
    "    'a cropped photo of the {}',\n",
    "    'the photo of a {}',\n",
    "    'a photo of a clean {}',\n",
    "    'a photo of a dirty {}',\n",
    "    'a dark photo of the {}',\n",
    "    'a photo of my {}',\n",
    "    'a photo of the cool {}',\n",
    "    'a close-up photo of a {}',\n",
    "    'a bright photo of the {}',\n",
    "    'a cropped photo of a {}',\n",
    "    'a photo of the {}',\n",
    "    'a good photo of the {}',\n",
    "    'a photo of one {}',\n",
    "    'a close-up photo of the {}',\n",
    "    'a rendition of the {}',\n",
    "    'a photo of the clean {}',\n",
    "    'a rendition of a {}',\n",
    "    'a photo of a nice {}',\n",
    "    'a good photo of a {}',\n",
    "    'a photo of the nice {}',\n",
    "    'a photo of the small {}',\n",
    "    'a photo of the weird {}',\n",
    "    'a photo of the large {}',\n",
    "    'a photo of a cool {}',\n",
    "    'a photo of a small {}',\n",
    "]\n",
    "\n",
    "# Style\n",
    "style_templates = [\n",
    "    'a painting in the style of {}',\n",
    "    'a rendering in the style of {}',\n",
    "    'a cropped painting in the style of {}',\n",
    "    'the painting in the style of {}',\n",
    "    'a clean painting in the style of {}',\n",
    "    'a dirty painting in the style of {}',\n",
    "    'a dark painting in the style of {}',\n",
    "    'a picture in the style of {}',\n",
    "    'a cool painting in the style of {}',\n",
    "    'a close-up painting in the style of {}',\n",
    "    'a bright painting in the style of {}',\n",
    "    'a cropped painting in the style of {}',\n",
    "    'a good painting in the style of {}',\n",
    "    'a close-up painting in the style of {}',\n",
    "    'a rendition in the style of {}',\n",
    "    'a nice painting in the style of {}',\n",
    "    'a small painting in the style of {}',\n",
    "    'a weird painting in the style of {}',\n",
    "    'a large painting in the style of {}',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class TextualInversionDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root,\n",
    "        learnable_property,\n",
    "        placeholder_token,\n",
    "        repeats=100,\n",
    "        flip_p=0.5,\n",
    "    ):\n",
    "        self.data_root = data_root\n",
    "        self.learnable_property = learnable_property\n",
    "        self.placeholder_token = placeholder_token\n",
    "        self.flip_p = flip_p\n",
    "        self.flip_transform = RandomHorizontalFlip(p=self.flip_p)\n",
    "\n",
    "        # Data settings\n",
    "        self.image_paths = [os.path.join(self.data_root, file_path) for file_path in os.listdir(self.data_root)]\n",
    "        self.num_images = len(self.image_paths)\n",
    "        self._length = self.num_images * repeats\n",
    "        self.templates = object_templates if property_type == 'object' else style_templates\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Get and prepare image\n",
    "        image = Image.open(self.image_paths[i % self.num_images])\n",
    "        image = self.flip_transform(image)\n",
    "        image = np.array(image).astype(np.uint8)\n",
    "        image = (image / 127.5 - 1.0).astype(np.float16)\n",
    "\n",
    "        # Get text prompt\n",
    "        text = random.choice(self.templates).format(self.placeholder_token)\n",
    "\n",
    "        # Create example\n",
    "        example = {}\n",
    "        example['input_prompt'] = text\n",
    "        example['pixel_values'] = torch.from_numpy(image).permute(2, 0, 1).to(device)\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "# Encode input prompt\n",
    "def encode_prompt(prompt):\n",
    "    text_inputs = tokenizer(\n",
    "        prompt, padding='max_length', max_length=tokenizer.model_max_length,\n",
    "        truncation=True, return_tensors='pt')\n",
    "    text_embeddings = text_encoder(text_inputs.input_ids.to(device))[0]\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to a pytorch file\n",
    "def save_model(path_dir, filename):\n",
    "    if not os.path.isdir(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    learned_embeddings = text_encoder.get_input_embeddings().weight[placeholder_token_id]\n",
    "    torch.save({placeholder_token: learned_embeddings.detach().cpu()}, os.path.join(path_dir, filename))\n",
    "\n",
    "# Model training\n",
    "def train_model(property, data_root, optimizer, max_train_steps=3000, batch_size=1):\n",
    "    # Initialize dataset\n",
    "    train_dataset = TextualInversionDataset(data_root, property_type, placeholder_token)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Set frozen models to eval\n",
    "    vae.eval()\n",
    "    u_net.eval()\n",
    "\n",
    "    # Calculate number of training epochs\n",
    "    num_train_epochs = math.ceil(max_train_steps / len(train_dataloader))\n",
    "\n",
    "    # Training loop\n",
    "    print('***** Running Training *****')\n",
    "    print(f'  Num. Examples = {len(train_dataset)}')\n",
    "    print(f'  Num. Epochs = {num_train_epochs}')\n",
    "    for epoch in range(num_train_epochs):\n",
    "        # Save current model\n",
    "        save_model(f'saved_models/textual_inversion/{property}', f'{property}_{epoch}.pt')\n",
    "\n",
    "        # Train for another epoch\n",
    "        text_encoder.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Convert images to latent space\n",
    "            latents = vae.encode(batch['pixel_values']).latent_dist.sample()\n",
    "            latents *= 0.18215\n",
    "\n",
    "            # Sample noise that we'll add to the latents\n",
    "            noise = torch.randn(latents.shape, dtype=torch.float16).to(latents.device)\n",
    "            bsz = latents.shape[0]\n",
    "\n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device\n",
    "            ).long()\n",
    "\n",
    "            # Add noise to the latents according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "            # Get the text embedding for conditioning\n",
    "            encoder_hidden_states = encode_prompt(batch['input_prompt'])\n",
    "\n",
    "            # Predict the noise residual\n",
    "            noise_pred = u_net(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "\n",
    "            # Backwards pass\n",
    "            loss = F.mse_loss(noise_pred, noise, reduction='none').mean([1, 2, 3]).mean()\n",
    "            loss.backward()\n",
    "\n",
    "            # Zero out the gradients for all token embeddings except the placeholder token\n",
    "            grads = text_encoder.get_input_embeddings().weight.grad\n",
    "            index_grads_to_zero = torch.arange(len(tokenizer)) != placeholder_token_id\n",
    "            grads.data[index_grads_to_zero, :] = grads.data[index_grads_to_zero, :].fill_(0)\n",
    "\n",
    "            # Optimizer pass\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Print logs\n",
    "            current_loss = round(loss.detach().item(), 4)\n",
    "            print(f'loss: {current_loss}, lr: {optimizer.param_groups[0][\"lr\"]}, '\n",
    "                  f'epoch: {epoch + 1}/{num_train_epochs}, step: {step + 1}/{len(train_dataloader)}')\n",
    "    print('***** Training Completed *****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running Training *****\n",
      "  Num. Examples = 600\n",
      "  Num. Epochs = 9\n",
      "loss: 0.0765, lr: 0.0005, epoch: 1/9, step: 1/600\n",
      "loss: 0.468, lr: 0.0005, epoch: 1/9, step: 2/600\n",
      "loss: 0.036, lr: 0.0005, epoch: 1/9, step: 3/600\n",
      "loss: 0.2474, lr: 0.0005, epoch: 1/9, step: 4/600\n",
      "loss: 0.0977, lr: 0.0005, epoch: 1/9, step: 5/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 1/9, step: 6/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 1/9, step: 7/600\n",
      "loss: 0.0421, lr: 0.0005, epoch: 1/9, step: 8/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 1/9, step: 9/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 1/9, step: 10/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 1/9, step: 11/600\n",
      "loss: 0.0157, lr: 0.0005, epoch: 1/9, step: 12/600\n",
      "loss: 0.2542, lr: 0.0005, epoch: 1/9, step: 13/600\n",
      "loss: 0.8105, lr: 0.0005, epoch: 1/9, step: 14/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 1/9, step: 15/600\n",
      "loss: 0.5576, lr: 0.0005, epoch: 1/9, step: 16/600\n",
      "loss: 0.1816, lr: 0.0005, epoch: 1/9, step: 17/600\n",
      "loss: 0.0666, lr: 0.0005, epoch: 1/9, step: 18/600\n",
      "loss: 0.2512, lr: 0.0005, epoch: 1/9, step: 19/600\n",
      "loss: 0.1487, lr: 0.0005, epoch: 1/9, step: 20/600\n",
      "loss: 0.177, lr: 0.0005, epoch: 1/9, step: 21/600\n",
      "loss: 0.2224, lr: 0.0005, epoch: 1/9, step: 22/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 1/9, step: 23/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 1/9, step: 24/600\n",
      "loss: 0.4104, lr: 0.0005, epoch: 1/9, step: 25/600\n",
      "loss: 0.2776, lr: 0.0005, epoch: 1/9, step: 26/600\n",
      "loss: 0.0338, lr: 0.0005, epoch: 1/9, step: 27/600\n",
      "loss: 0.0156, lr: 0.0005, epoch: 1/9, step: 28/600\n",
      "loss: 0.0459, lr: 0.0005, epoch: 1/9, step: 29/600\n",
      "loss: 0.4661, lr: 0.0005, epoch: 1/9, step: 30/600\n",
      "loss: 0.3796, lr: 0.0005, epoch: 1/9, step: 31/600\n",
      "loss: 0.0919, lr: 0.0005, epoch: 1/9, step: 32/600\n",
      "loss: 0.7363, lr: 0.0005, epoch: 1/9, step: 33/600\n",
      "loss: 0.0139, lr: 0.0005, epoch: 1/9, step: 34/600\n",
      "loss: 0.5923, lr: 0.0005, epoch: 1/9, step: 35/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 1/9, step: 36/600\n",
      "loss: 0.2734, lr: 0.0005, epoch: 1/9, step: 37/600\n",
      "loss: 0.3201, lr: 0.0005, epoch: 1/9, step: 38/600\n",
      "loss: 0.17, lr: 0.0005, epoch: 1/9, step: 39/600\n",
      "loss: 0.1913, lr: 0.0005, epoch: 1/9, step: 40/600\n",
      "loss: 0.087, lr: 0.0005, epoch: 1/9, step: 41/600\n",
      "loss: 0.0231, lr: 0.0005, epoch: 1/9, step: 42/600\n",
      "loss: 0.0243, lr: 0.0005, epoch: 1/9, step: 43/600\n",
      "loss: 0.2432, lr: 0.0005, epoch: 1/9, step: 44/600\n",
      "loss: 0.0662, lr: 0.0005, epoch: 1/9, step: 45/600\n",
      "loss: 0.0417, lr: 0.0005, epoch: 1/9, step: 46/600\n",
      "loss: 0.0499, lr: 0.0005, epoch: 1/9, step: 47/600\n",
      "loss: 0.22, lr: 0.0005, epoch: 1/9, step: 48/600\n",
      "loss: 0.4058, lr: 0.0005, epoch: 1/9, step: 49/600\n",
      "loss: 0.0301, lr: 0.0005, epoch: 1/9, step: 50/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 1/9, step: 51/600\n",
      "loss: 0.7134, lr: 0.0005, epoch: 1/9, step: 52/600\n",
      "loss: 0.3127, lr: 0.0005, epoch: 1/9, step: 53/600\n",
      "loss: 0.4524, lr: 0.0005, epoch: 1/9, step: 54/600\n",
      "loss: 0.3276, lr: 0.0005, epoch: 1/9, step: 55/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 1/9, step: 56/600\n",
      "loss: 0.049, lr: 0.0005, epoch: 1/9, step: 57/600\n",
      "loss: 0.2593, lr: 0.0005, epoch: 1/9, step: 58/600\n",
      "loss: 0.3416, lr: 0.0005, epoch: 1/9, step: 59/600\n",
      "loss: 0.3948, lr: 0.0005, epoch: 1/9, step: 60/600\n",
      "loss: 0.0365, lr: 0.0005, epoch: 1/9, step: 61/600\n",
      "loss: 0.0931, lr: 0.0005, epoch: 1/9, step: 62/600\n",
      "loss: 0.5171, lr: 0.0005, epoch: 1/9, step: 63/600\n",
      "loss: 0.3232, lr: 0.0005, epoch: 1/9, step: 64/600\n",
      "loss: 0.0769, lr: 0.0005, epoch: 1/9, step: 65/600\n",
      "loss: 0.0206, lr: 0.0005, epoch: 1/9, step: 66/600\n",
      "loss: 0.0384, lr: 0.0005, epoch: 1/9, step: 67/600\n",
      "loss: 0.1292, lr: 0.0005, epoch: 1/9, step: 68/600\n",
      "loss: 0.4968, lr: 0.0005, epoch: 1/9, step: 69/600\n",
      "loss: 0.1561, lr: 0.0005, epoch: 1/9, step: 70/600\n",
      "loss: 0.0972, lr: 0.0005, epoch: 1/9, step: 71/600\n",
      "loss: 0.017, lr: 0.0005, epoch: 1/9, step: 72/600\n",
      "loss: 0.2708, lr: 0.0005, epoch: 1/9, step: 73/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 1/9, step: 74/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 1/9, step: 75/600\n",
      "loss: 0.0485, lr: 0.0005, epoch: 1/9, step: 76/600\n",
      "loss: 0.2454, lr: 0.0005, epoch: 1/9, step: 77/600\n",
      "loss: 0.2881, lr: 0.0005, epoch: 1/9, step: 78/600\n",
      "loss: 0.0232, lr: 0.0005, epoch: 1/9, step: 79/600\n",
      "loss: 0.3069, lr: 0.0005, epoch: 1/9, step: 80/600\n",
      "loss: 0.1917, lr: 0.0005, epoch: 1/9, step: 81/600\n",
      "loss: 0.0503, lr: 0.0005, epoch: 1/9, step: 82/600\n",
      "loss: 0.0872, lr: 0.0005, epoch: 1/9, step: 83/600\n",
      "loss: 0.0507, lr: 0.0005, epoch: 1/9, step: 84/600\n",
      "loss: 0.2625, lr: 0.0005, epoch: 1/9, step: 85/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 1/9, step: 86/600\n",
      "loss: 0.5278, lr: 0.0005, epoch: 1/9, step: 87/600\n",
      "loss: 0.2428, lr: 0.0005, epoch: 1/9, step: 88/600\n",
      "loss: 0.3032, lr: 0.0005, epoch: 1/9, step: 89/600\n",
      "loss: 0.0486, lr: 0.0005, epoch: 1/9, step: 90/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 1/9, step: 91/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 1/9, step: 92/600\n",
      "loss: 0.7812, lr: 0.0005, epoch: 1/9, step: 93/600\n",
      "loss: 0.1661, lr: 0.0005, epoch: 1/9, step: 94/600\n",
      "loss: 0.3716, lr: 0.0005, epoch: 1/9, step: 95/600\n",
      "loss: 0.0342, lr: 0.0005, epoch: 1/9, step: 96/600\n",
      "loss: 0.5884, lr: 0.0005, epoch: 1/9, step: 97/600\n",
      "loss: 0.3201, lr: 0.0005, epoch: 1/9, step: 98/600\n",
      "loss: 0.022, lr: 0.0005, epoch: 1/9, step: 99/600\n",
      "loss: 0.6416, lr: 0.0005, epoch: 1/9, step: 100/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 1/9, step: 101/600\n",
      "loss: 0.7534, lr: 0.0005, epoch: 1/9, step: 102/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 1/9, step: 103/600\n",
      "loss: 0.0137, lr: 0.0005, epoch: 1/9, step: 104/600\n",
      "loss: 0.2664, lr: 0.0005, epoch: 1/9, step: 105/600\n",
      "loss: 0.1065, lr: 0.0005, epoch: 1/9, step: 106/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 1/9, step: 107/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 1/9, step: 108/600\n",
      "loss: 0.6597, lr: 0.0005, epoch: 1/9, step: 109/600\n",
      "loss: 0.1061, lr: 0.0005, epoch: 1/9, step: 110/600\n",
      "loss: 0.1801, lr: 0.0005, epoch: 1/9, step: 111/600\n",
      "loss: 0.0168, lr: 0.0005, epoch: 1/9, step: 112/600\n",
      "loss: 0.1296, lr: 0.0005, epoch: 1/9, step: 113/600\n",
      "loss: 0.6006, lr: 0.0005, epoch: 1/9, step: 114/600\n",
      "loss: 0.1985, lr: 0.0005, epoch: 1/9, step: 115/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 1/9, step: 116/600\n",
      "loss: 0.4287, lr: 0.0005, epoch: 1/9, step: 117/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 1/9, step: 118/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 1/9, step: 119/600\n",
      "loss: 0.1465, lr: 0.0005, epoch: 1/9, step: 120/600\n",
      "loss: 0.0832, lr: 0.0005, epoch: 1/9, step: 121/600\n",
      "loss: 0.3374, lr: 0.0005, epoch: 1/9, step: 122/600\n",
      "loss: 0.0218, lr: 0.0005, epoch: 1/9, step: 123/600\n",
      "loss: 0.1831, lr: 0.0005, epoch: 1/9, step: 124/600\n",
      "loss: 0.2261, lr: 0.0005, epoch: 1/9, step: 125/600\n",
      "loss: 0.3369, lr: 0.0005, epoch: 1/9, step: 126/600\n",
      "loss: 0.0631, lr: 0.0005, epoch: 1/9, step: 127/600\n",
      "loss: 0.0239, lr: 0.0005, epoch: 1/9, step: 128/600\n",
      "loss: 0.1281, lr: 0.0005, epoch: 1/9, step: 129/600\n",
      "loss: 0.031, lr: 0.0005, epoch: 1/9, step: 130/600\n",
      "loss: 0.1317, lr: 0.0005, epoch: 1/9, step: 131/600\n",
      "loss: 0.6567, lr: 0.0005, epoch: 1/9, step: 132/600\n",
      "loss: 0.1742, lr: 0.0005, epoch: 1/9, step: 133/600\n",
      "loss: 0.385, lr: 0.0005, epoch: 1/9, step: 134/600\n",
      "loss: 0.5508, lr: 0.0005, epoch: 1/9, step: 135/600\n",
      "loss: 0.0883, lr: 0.0005, epoch: 1/9, step: 136/600\n",
      "loss: 0.0375, lr: 0.0005, epoch: 1/9, step: 137/600\n",
      "loss: 0.0216, lr: 0.0005, epoch: 1/9, step: 138/600\n",
      "loss: 0.1121, lr: 0.0005, epoch: 1/9, step: 139/600\n",
      "loss: 0.3762, lr: 0.0005, epoch: 1/9, step: 140/600\n",
      "loss: 0.1146, lr: 0.0005, epoch: 1/9, step: 141/600\n",
      "loss: 0.1255, lr: 0.0005, epoch: 1/9, step: 142/600\n",
      "loss: 0.0886, lr: 0.0005, epoch: 1/9, step: 143/600\n",
      "loss: 0.4575, lr: 0.0005, epoch: 1/9, step: 144/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 1/9, step: 145/600\n",
      "loss: 0.1532, lr: 0.0005, epoch: 1/9, step: 146/600\n",
      "loss: 0.0352, lr: 0.0005, epoch: 1/9, step: 147/600\n",
      "loss: 0.0163, lr: 0.0005, epoch: 1/9, step: 148/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 1/9, step: 149/600\n",
      "loss: 0.0302, lr: 0.0005, epoch: 1/9, step: 150/600\n",
      "loss: 0.0744, lr: 0.0005, epoch: 1/9, step: 151/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 1/9, step: 152/600\n",
      "loss: 0.6138, lr: 0.0005, epoch: 1/9, step: 153/600\n",
      "loss: 0.0024, lr: 0.0005, epoch: 1/9, step: 154/600\n",
      "loss: 0.4456, lr: 0.0005, epoch: 1/9, step: 155/600\n",
      "loss: 0.1222, lr: 0.0005, epoch: 1/9, step: 156/600\n",
      "loss: 0.252, lr: 0.0005, epoch: 1/9, step: 157/600\n",
      "loss: 0.0203, lr: 0.0005, epoch: 1/9, step: 158/600\n",
      "loss: 0.0858, lr: 0.0005, epoch: 1/9, step: 159/600\n",
      "loss: 0.2666, lr: 0.0005, epoch: 1/9, step: 160/600\n",
      "loss: 0.2588, lr: 0.0005, epoch: 1/9, step: 161/600\n",
      "loss: 0.0413, lr: 0.0005, epoch: 1/9, step: 162/600\n",
      "loss: 0.353, lr: 0.0005, epoch: 1/9, step: 163/600\n",
      "loss: 0.0232, lr: 0.0005, epoch: 1/9, step: 164/600\n",
      "loss: 0.0414, lr: 0.0005, epoch: 1/9, step: 165/600\n",
      "loss: 0.0795, lr: 0.0005, epoch: 1/9, step: 166/600\n",
      "loss: 0.4353, lr: 0.0005, epoch: 1/9, step: 167/600\n",
      "loss: 0.0198, lr: 0.0005, epoch: 1/9, step: 168/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 1/9, step: 169/600\n",
      "loss: 0.2817, lr: 0.0005, epoch: 1/9, step: 170/600\n",
      "loss: 0.2314, lr: 0.0005, epoch: 1/9, step: 171/600\n",
      "loss: 0.356, lr: 0.0005, epoch: 1/9, step: 172/600\n",
      "loss: 0.0342, lr: 0.0005, epoch: 1/9, step: 173/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 1/9, step: 174/600\n",
      "loss: 0.0162, lr: 0.0005, epoch: 1/9, step: 175/600\n",
      "loss: 0.2751, lr: 0.0005, epoch: 1/9, step: 176/600\n",
      "loss: 0.4766, lr: 0.0005, epoch: 1/9, step: 177/600\n",
      "loss: 0.0188, lr: 0.0005, epoch: 1/9, step: 178/600\n",
      "loss: 0.0309, lr: 0.0005, epoch: 1/9, step: 179/600\n",
      "loss: 0.0091, lr: 0.0005, epoch: 1/9, step: 180/600\n",
      "loss: 0.364, lr: 0.0005, epoch: 1/9, step: 181/600\n",
      "loss: 0.2773, lr: 0.0005, epoch: 1/9, step: 182/600\n",
      "loss: 0.0293, lr: 0.0005, epoch: 1/9, step: 183/600\n",
      "loss: 0.0869, lr: 0.0005, epoch: 1/9, step: 184/600\n",
      "loss: 0.155, lr: 0.0005, epoch: 1/9, step: 185/600\n",
      "loss: 0.218, lr: 0.0005, epoch: 1/9, step: 186/600\n",
      "loss: 0.0312, lr: 0.0005, epoch: 1/9, step: 187/600\n",
      "loss: 0.064, lr: 0.0005, epoch: 1/9, step: 188/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 1/9, step: 189/600\n",
      "loss: 0.009, lr: 0.0005, epoch: 1/9, step: 190/600\n",
      "loss: 0.0229, lr: 0.0005, epoch: 1/9, step: 191/600\n",
      "loss: 0.007, lr: 0.0005, epoch: 1/9, step: 192/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 1/9, step: 193/600\n",
      "loss: 0.0481, lr: 0.0005, epoch: 1/9, step: 194/600\n",
      "loss: 0.127, lr: 0.0005, epoch: 1/9, step: 195/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 1/9, step: 196/600\n",
      "loss: 0.1202, lr: 0.0005, epoch: 1/9, step: 197/600\n",
      "loss: 0.0055, lr: 0.0005, epoch: 1/9, step: 198/600\n",
      "loss: 0.0298, lr: 0.0005, epoch: 1/9, step: 199/600\n",
      "loss: 0.6938, lr: 0.0005, epoch: 1/9, step: 200/600\n",
      "loss: 0.4851, lr: 0.0005, epoch: 1/9, step: 201/600\n",
      "loss: 0.1018, lr: 0.0005, epoch: 1/9, step: 202/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 1/9, step: 203/600\n",
      "loss: 0.0879, lr: 0.0005, epoch: 1/9, step: 204/600\n",
      "loss: 0.4407, lr: 0.0005, epoch: 1/9, step: 205/600\n",
      "loss: 0.3286, lr: 0.0005, epoch: 1/9, step: 206/600\n",
      "loss: 0.0338, lr: 0.0005, epoch: 1/9, step: 207/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 1/9, step: 208/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 1/9, step: 209/600\n",
      "loss: 0.5645, lr: 0.0005, epoch: 1/9, step: 210/600\n",
      "loss: 0.1899, lr: 0.0005, epoch: 1/9, step: 211/600\n",
      "loss: 0.4895, lr: 0.0005, epoch: 1/9, step: 212/600\n",
      "loss: 0.0021, lr: 0.0005, epoch: 1/9, step: 213/600\n",
      "loss: 0.0668, lr: 0.0005, epoch: 1/9, step: 214/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 1/9, step: 215/600\n",
      "loss: 0.2218, lr: 0.0005, epoch: 1/9, step: 216/600\n",
      "loss: 0.3662, lr: 0.0005, epoch: 1/9, step: 217/600\n",
      "loss: 0.4905, lr: 0.0005, epoch: 1/9, step: 218/600\n",
      "loss: 0.5366, lr: 0.0005, epoch: 1/9, step: 219/600\n",
      "loss: 0.3389, lr: 0.0005, epoch: 1/9, step: 220/600\n",
      "loss: 0.0576, lr: 0.0005, epoch: 1/9, step: 221/600\n",
      "loss: 0.0824, lr: 0.0005, epoch: 1/9, step: 222/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 1/9, step: 223/600\n",
      "loss: 0.1265, lr: 0.0005, epoch: 1/9, step: 224/600\n",
      "loss: 0.3853, lr: 0.0005, epoch: 1/9, step: 225/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 1/9, step: 226/600\n",
      "loss: 0.0706, lr: 0.0005, epoch: 1/9, step: 227/600\n",
      "loss: 0.0113, lr: 0.0005, epoch: 1/9, step: 228/600\n",
      "loss: 0.0858, lr: 0.0005, epoch: 1/9, step: 229/600\n",
      "loss: 0.1115, lr: 0.0005, epoch: 1/9, step: 230/600\n",
      "loss: 0.0373, lr: 0.0005, epoch: 1/9, step: 231/600\n",
      "loss: 0.041, lr: 0.0005, epoch: 1/9, step: 232/600\n",
      "loss: 0.1201, lr: 0.0005, epoch: 1/9, step: 233/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 1/9, step: 234/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 1/9, step: 235/600\n",
      "loss: 0.5864, lr: 0.0005, epoch: 1/9, step: 236/600\n",
      "loss: 0.0965, lr: 0.0005, epoch: 1/9, step: 237/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 1/9, step: 238/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 1/9, step: 239/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 1/9, step: 240/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 1/9, step: 241/600\n",
      "loss: 0.3074, lr: 0.0005, epoch: 1/9, step: 242/600\n",
      "loss: 0.1382, lr: 0.0005, epoch: 1/9, step: 243/600\n",
      "loss: 0.334, lr: 0.0005, epoch: 1/9, step: 244/600\n",
      "loss: 0.626, lr: 0.0005, epoch: 1/9, step: 245/600\n",
      "loss: 0.5508, lr: 0.0005, epoch: 1/9, step: 246/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 1/9, step: 247/600\n",
      "loss: 0.0446, lr: 0.0005, epoch: 1/9, step: 248/600\n",
      "loss: 0.161, lr: 0.0005, epoch: 1/9, step: 249/600\n",
      "loss: 0.8301, lr: 0.0005, epoch: 1/9, step: 250/600\n",
      "loss: 0.226, lr: 0.0005, epoch: 1/9, step: 251/600\n",
      "loss: 0.1423, lr: 0.0005, epoch: 1/9, step: 252/600\n",
      "loss: 0.2649, lr: 0.0005, epoch: 1/9, step: 253/600\n",
      "loss: 0.4287, lr: 0.0005, epoch: 1/9, step: 254/600\n",
      "loss: 0.0887, lr: 0.0005, epoch: 1/9, step: 255/600\n",
      "loss: 0.5708, lr: 0.0005, epoch: 1/9, step: 256/600\n",
      "loss: 0.0267, lr: 0.0005, epoch: 1/9, step: 257/600\n",
      "loss: 0.3679, lr: 0.0005, epoch: 1/9, step: 258/600\n",
      "loss: 0.0624, lr: 0.0005, epoch: 1/9, step: 259/600\n",
      "loss: 0.6074, lr: 0.0005, epoch: 1/9, step: 260/600\n",
      "loss: 0.1501, lr: 0.0005, epoch: 1/9, step: 261/600\n",
      "loss: 0.4692, lr: 0.0005, epoch: 1/9, step: 262/600\n",
      "loss: 0.2537, lr: 0.0005, epoch: 1/9, step: 263/600\n",
      "loss: 0.1941, lr: 0.0005, epoch: 1/9, step: 264/600\n",
      "loss: 0.5664, lr: 0.0005, epoch: 1/9, step: 265/600\n",
      "loss: 0.0235, lr: 0.0005, epoch: 1/9, step: 266/600\n",
      "loss: 0.1401, lr: 0.0005, epoch: 1/9, step: 267/600\n",
      "loss: 0.5649, lr: 0.0005, epoch: 1/9, step: 268/600\n",
      "loss: 0.958, lr: 0.0005, epoch: 1/9, step: 269/600\n",
      "loss: 0.4487, lr: 0.0005, epoch: 1/9, step: 270/600\n",
      "loss: 0.0267, lr: 0.0005, epoch: 1/9, step: 271/600\n",
      "loss: 0.063, lr: 0.0005, epoch: 1/9, step: 272/600\n",
      "loss: 0.2089, lr: 0.0005, epoch: 1/9, step: 273/600\n",
      "loss: 0.0748, lr: 0.0005, epoch: 1/9, step: 274/600\n",
      "loss: 0.017, lr: 0.0005, epoch: 1/9, step: 275/600\n",
      "loss: 0.3013, lr: 0.0005, epoch: 1/9, step: 276/600\n",
      "loss: 0.1266, lr: 0.0005, epoch: 1/9, step: 277/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 1/9, step: 278/600\n",
      "loss: 0.0803, lr: 0.0005, epoch: 1/9, step: 279/600\n",
      "loss: 0.1671, lr: 0.0005, epoch: 1/9, step: 280/600\n",
      "loss: 0.2072, lr: 0.0005, epoch: 1/9, step: 281/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 1/9, step: 282/600\n",
      "loss: 0.0996, lr: 0.0005, epoch: 1/9, step: 283/600\n",
      "loss: 0.0923, lr: 0.0005, epoch: 1/9, step: 284/600\n",
      "loss: 0.645, lr: 0.0005, epoch: 1/9, step: 285/600\n",
      "loss: 0.4946, lr: 0.0005, epoch: 1/9, step: 286/600\n",
      "loss: 0.0315, lr: 0.0005, epoch: 1/9, step: 287/600\n",
      "loss: 0.4924, lr: 0.0005, epoch: 1/9, step: 288/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 1/9, step: 289/600\n",
      "loss: 0.0124, lr: 0.0005, epoch: 1/9, step: 290/600\n",
      "loss: 0.0587, lr: 0.0005, epoch: 1/9, step: 291/600\n",
      "loss: 0.3645, lr: 0.0005, epoch: 1/9, step: 292/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 1/9, step: 293/600\n",
      "loss: 0.2771, lr: 0.0005, epoch: 1/9, step: 294/600\n",
      "loss: 0.2434, lr: 0.0005, epoch: 1/9, step: 295/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 1/9, step: 296/600\n",
      "loss: 0.4438, lr: 0.0005, epoch: 1/9, step: 297/600\n",
      "loss: 0.0884, lr: 0.0005, epoch: 1/9, step: 298/600\n",
      "loss: 0.0105, lr: 0.0005, epoch: 1/9, step: 299/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 1/9, step: 300/600\n",
      "loss: 0.2177, lr: 0.0005, epoch: 1/9, step: 301/600\n",
      "loss: 0.3594, lr: 0.0005, epoch: 1/9, step: 302/600\n",
      "loss: 0.3215, lr: 0.0005, epoch: 1/9, step: 303/600\n",
      "loss: 0.1069, lr: 0.0005, epoch: 1/9, step: 304/600\n",
      "loss: 0.4167, lr: 0.0005, epoch: 1/9, step: 305/600\n",
      "loss: 0.2411, lr: 0.0005, epoch: 1/9, step: 306/600\n",
      "loss: 0.1835, lr: 0.0005, epoch: 1/9, step: 307/600\n",
      "loss: 0.0334, lr: 0.0005, epoch: 1/9, step: 308/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 1/9, step: 309/600\n",
      "loss: 0.0922, lr: 0.0005, epoch: 1/9, step: 310/600\n",
      "loss: 0.5259, lr: 0.0005, epoch: 1/9, step: 311/600\n",
      "loss: 0.1859, lr: 0.0005, epoch: 1/9, step: 312/600\n",
      "loss: 0.3445, lr: 0.0005, epoch: 1/9, step: 313/600\n",
      "loss: 0.019, lr: 0.0005, epoch: 1/9, step: 314/600\n",
      "loss: 0.282, lr: 0.0005, epoch: 1/9, step: 315/600\n",
      "loss: 0.0302, lr: 0.0005, epoch: 1/9, step: 316/600\n",
      "loss: 0.438, lr: 0.0005, epoch: 1/9, step: 317/600\n",
      "loss: 0.582, lr: 0.0005, epoch: 1/9, step: 318/600\n",
      "loss: 0.0377, lr: 0.0005, epoch: 1/9, step: 319/600\n",
      "loss: 0.3748, lr: 0.0005, epoch: 1/9, step: 320/600\n",
      "loss: 0.1586, lr: 0.0005, epoch: 1/9, step: 321/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 1/9, step: 322/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 1/9, step: 323/600\n",
      "loss: 0.6372, lr: 0.0005, epoch: 1/9, step: 324/600\n",
      "loss: 0.0646, lr: 0.0005, epoch: 1/9, step: 325/600\n",
      "loss: 0.0118, lr: 0.0005, epoch: 1/9, step: 326/600\n",
      "loss: 0.2969, lr: 0.0005, epoch: 1/9, step: 327/600\n",
      "loss: 0.08, lr: 0.0005, epoch: 1/9, step: 328/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 1/9, step: 329/600\n",
      "loss: 0.0159, lr: 0.0005, epoch: 1/9, step: 330/600\n",
      "loss: 0.2087, lr: 0.0005, epoch: 1/9, step: 331/600\n",
      "loss: 0.1317, lr: 0.0005, epoch: 1/9, step: 332/600\n",
      "loss: 0.0118, lr: 0.0005, epoch: 1/9, step: 333/600\n",
      "loss: 0.0427, lr: 0.0005, epoch: 1/9, step: 334/600\n",
      "loss: 0.0634, lr: 0.0005, epoch: 1/9, step: 335/600\n",
      "loss: 0.007, lr: 0.0005, epoch: 1/9, step: 336/600\n",
      "loss: 0.0345, lr: 0.0005, epoch: 1/9, step: 337/600\n",
      "loss: 0.522, lr: 0.0005, epoch: 1/9, step: 338/600\n",
      "loss: 0.5171, lr: 0.0005, epoch: 1/9, step: 339/600\n",
      "loss: 0.3613, lr: 0.0005, epoch: 1/9, step: 340/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 1/9, step: 341/600\n",
      "loss: 0.22, lr: 0.0005, epoch: 1/9, step: 342/600\n",
      "loss: 0.08, lr: 0.0005, epoch: 1/9, step: 343/600\n",
      "loss: 0.0113, lr: 0.0005, epoch: 1/9, step: 344/600\n",
      "loss: 0.0121, lr: 0.0005, epoch: 1/9, step: 345/600\n",
      "loss: 0.0382, lr: 0.0005, epoch: 1/9, step: 346/600\n",
      "loss: 0.7671, lr: 0.0005, epoch: 1/9, step: 347/600\n",
      "loss: 0.0991, lr: 0.0005, epoch: 1/9, step: 348/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 1/9, step: 349/600\n",
      "loss: 0.3235, lr: 0.0005, epoch: 1/9, step: 350/600\n",
      "loss: 0.4011, lr: 0.0005, epoch: 1/9, step: 351/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 1/9, step: 352/600\n",
      "loss: 0.0906, lr: 0.0005, epoch: 1/9, step: 353/600\n",
      "loss: 0.8013, lr: 0.0005, epoch: 1/9, step: 354/600\n",
      "loss: 0.0241, lr: 0.0005, epoch: 1/9, step: 355/600\n",
      "loss: 0.2583, lr: 0.0005, epoch: 1/9, step: 356/600\n",
      "loss: 0.1932, lr: 0.0005, epoch: 1/9, step: 357/600\n",
      "loss: 0.3096, lr: 0.0005, epoch: 1/9, step: 358/600\n",
      "loss: 0.1277, lr: 0.0005, epoch: 1/9, step: 359/600\n",
      "loss: 0.2737, lr: 0.0005, epoch: 1/9, step: 360/600\n",
      "loss: 0.0582, lr: 0.0005, epoch: 1/9, step: 361/600\n",
      "loss: 0.0158, lr: 0.0005, epoch: 1/9, step: 362/600\n",
      "loss: 0.1775, lr: 0.0005, epoch: 1/9, step: 363/600\n",
      "loss: 0.8838, lr: 0.0005, epoch: 1/9, step: 364/600\n",
      "loss: 0.0526, lr: 0.0005, epoch: 1/9, step: 365/600\n",
      "loss: 0.0389, lr: 0.0005, epoch: 1/9, step: 366/600\n",
      "loss: 0.3003, lr: 0.0005, epoch: 1/9, step: 367/600\n",
      "loss: 0.2114, lr: 0.0005, epoch: 1/9, step: 368/600\n",
      "loss: 0.0421, lr: 0.0005, epoch: 1/9, step: 369/600\n",
      "loss: 0.0093, lr: 0.0005, epoch: 1/9, step: 370/600\n",
      "loss: 0.1337, lr: 0.0005, epoch: 1/9, step: 371/600\n",
      "loss: 0.0654, lr: 0.0005, epoch: 1/9, step: 372/600\n",
      "loss: 0.4319, lr: 0.0005, epoch: 1/9, step: 373/600\n",
      "loss: 0.4128, lr: 0.0005, epoch: 1/9, step: 374/600\n",
      "loss: 0.5889, lr: 0.0005, epoch: 1/9, step: 375/600\n",
      "loss: 0.8765, lr: 0.0005, epoch: 1/9, step: 376/600\n",
      "loss: 0.2527, lr: 0.0005, epoch: 1/9, step: 377/600\n",
      "loss: 0.1394, lr: 0.0005, epoch: 1/9, step: 378/600\n",
      "loss: 0.4973, lr: 0.0005, epoch: 1/9, step: 379/600\n",
      "loss: 0.0278, lr: 0.0005, epoch: 1/9, step: 380/600\n",
      "loss: 0.2325, lr: 0.0005, epoch: 1/9, step: 381/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 1/9, step: 382/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 1/9, step: 383/600\n",
      "loss: 0.2705, lr: 0.0005, epoch: 1/9, step: 384/600\n",
      "loss: 0.4814, lr: 0.0005, epoch: 1/9, step: 385/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 1/9, step: 386/600\n",
      "loss: 0.4736, lr: 0.0005, epoch: 1/9, step: 387/600\n",
      "loss: 0.2568, lr: 0.0005, epoch: 1/9, step: 388/600\n",
      "loss: 0.1366, lr: 0.0005, epoch: 1/9, step: 389/600\n",
      "loss: 0.1926, lr: 0.0005, epoch: 1/9, step: 390/600\n",
      "loss: 0.0361, lr: 0.0005, epoch: 1/9, step: 391/600\n",
      "loss: 0.2942, lr: 0.0005, epoch: 1/9, step: 392/600\n",
      "loss: 0.0974, lr: 0.0005, epoch: 1/9, step: 393/600\n",
      "loss: 0.0111, lr: 0.0005, epoch: 1/9, step: 394/600\n",
      "loss: 0.1335, lr: 0.0005, epoch: 1/9, step: 395/600\n",
      "loss: 0.179, lr: 0.0005, epoch: 1/9, step: 396/600\n",
      "loss: 0.3833, lr: 0.0005, epoch: 1/9, step: 397/600\n",
      "loss: 0.3521, lr: 0.0005, epoch: 1/9, step: 398/600\n",
      "loss: 0.7324, lr: 0.0005, epoch: 1/9, step: 399/600\n",
      "loss: 0.1389, lr: 0.0005, epoch: 1/9, step: 400/600\n",
      "loss: 0.3577, lr: 0.0005, epoch: 1/9, step: 401/600\n",
      "loss: 0.2876, lr: 0.0005, epoch: 1/9, step: 402/600\n",
      "loss: 0.3459, lr: 0.0005, epoch: 1/9, step: 403/600\n",
      "loss: 0.0637, lr: 0.0005, epoch: 1/9, step: 404/600\n",
      "loss: 0.5815, lr: 0.0005, epoch: 1/9, step: 405/600\n",
      "loss: 0.2795, lr: 0.0005, epoch: 1/9, step: 406/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 1/9, step: 407/600\n",
      "loss: 0.0507, lr: 0.0005, epoch: 1/9, step: 408/600\n",
      "loss: 0.4187, lr: 0.0005, epoch: 1/9, step: 409/600\n",
      "loss: 0.017, lr: 0.0005, epoch: 1/9, step: 410/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 1/9, step: 411/600\n",
      "loss: 0.1982, lr: 0.0005, epoch: 1/9, step: 412/600\n",
      "loss: 0.0162, lr: 0.0005, epoch: 1/9, step: 413/600\n",
      "loss: 0.198, lr: 0.0005, epoch: 1/9, step: 414/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 1/9, step: 415/600\n",
      "loss: 0.5371, lr: 0.0005, epoch: 1/9, step: 416/600\n",
      "loss: 0.0911, lr: 0.0005, epoch: 1/9, step: 417/600\n",
      "loss: 0.0655, lr: 0.0005, epoch: 1/9, step: 418/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 1/9, step: 419/600\n",
      "loss: 0.2008, lr: 0.0005, epoch: 1/9, step: 420/600\n",
      "loss: 0.1547, lr: 0.0005, epoch: 1/9, step: 421/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 1/9, step: 422/600\n",
      "loss: 0.3896, lr: 0.0005, epoch: 1/9, step: 423/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 1/9, step: 424/600\n",
      "loss: 0.7148, lr: 0.0005, epoch: 1/9, step: 425/600\n",
      "loss: 0.0568, lr: 0.0005, epoch: 1/9, step: 426/600\n",
      "loss: 0.0812, lr: 0.0005, epoch: 1/9, step: 427/600\n",
      "loss: 0.0231, lr: 0.0005, epoch: 1/9, step: 428/600\n",
      "loss: 0.0233, lr: 0.0005, epoch: 1/9, step: 429/600\n",
      "loss: 0.6787, lr: 0.0005, epoch: 1/9, step: 430/600\n",
      "loss: 0.0126, lr: 0.0005, epoch: 1/9, step: 431/600\n",
      "loss: 0.0421, lr: 0.0005, epoch: 1/9, step: 432/600\n",
      "loss: 0.0276, lr: 0.0005, epoch: 1/9, step: 433/600\n",
      "loss: 0.4929, lr: 0.0005, epoch: 1/9, step: 434/600\n",
      "loss: 0.6035, lr: 0.0005, epoch: 1/9, step: 435/600\n",
      "loss: 0.2959, lr: 0.0005, epoch: 1/9, step: 436/600\n",
      "loss: 0.1378, lr: 0.0005, epoch: 1/9, step: 437/600\n",
      "loss: 0.4246, lr: 0.0005, epoch: 1/9, step: 438/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 1/9, step: 439/600\n",
      "loss: 0.1132, lr: 0.0005, epoch: 1/9, step: 440/600\n",
      "loss: 0.2438, lr: 0.0005, epoch: 1/9, step: 441/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 1/9, step: 442/600\n",
      "loss: 0.3486, lr: 0.0005, epoch: 1/9, step: 443/600\n",
      "loss: 0.4507, lr: 0.0005, epoch: 1/9, step: 444/600\n",
      "loss: 0.2454, lr: 0.0005, epoch: 1/9, step: 445/600\n",
      "loss: 0.3591, lr: 0.0005, epoch: 1/9, step: 446/600\n",
      "loss: 0.0154, lr: 0.0005, epoch: 1/9, step: 447/600\n",
      "loss: 0.0172, lr: 0.0005, epoch: 1/9, step: 448/600\n",
      "loss: 0.2097, lr: 0.0005, epoch: 1/9, step: 449/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 1/9, step: 450/600\n",
      "loss: 0.0311, lr: 0.0005, epoch: 1/9, step: 451/600\n",
      "loss: 0.2406, lr: 0.0005, epoch: 1/9, step: 452/600\n",
      "loss: 0.0166, lr: 0.0005, epoch: 1/9, step: 453/600\n",
      "loss: 0.3611, lr: 0.0005, epoch: 1/9, step: 454/600\n",
      "loss: 0.2515, lr: 0.0005, epoch: 1/9, step: 455/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 1/9, step: 456/600\n",
      "loss: 0.028, lr: 0.0005, epoch: 1/9, step: 457/600\n",
      "loss: 0.0337, lr: 0.0005, epoch: 1/9, step: 458/600\n",
      "loss: 0.0298, lr: 0.0005, epoch: 1/9, step: 459/600\n",
      "loss: 0.1041, lr: 0.0005, epoch: 1/9, step: 460/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 1/9, step: 461/600\n",
      "loss: 0.1174, lr: 0.0005, epoch: 1/9, step: 462/600\n",
      "loss: 0.7168, lr: 0.0005, epoch: 1/9, step: 463/600\n",
      "loss: 0.0108, lr: 0.0005, epoch: 1/9, step: 464/600\n",
      "loss: 0.0117, lr: 0.0005, epoch: 1/9, step: 465/600\n",
      "loss: 0.0718, lr: 0.0005, epoch: 1/9, step: 466/600\n",
      "loss: 0.0423, lr: 0.0005, epoch: 1/9, step: 467/600\n",
      "loss: 0.2428, lr: 0.0005, epoch: 1/9, step: 468/600\n",
      "loss: 0.0743, lr: 0.0005, epoch: 1/9, step: 469/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 1/9, step: 470/600\n",
      "loss: 0.1173, lr: 0.0005, epoch: 1/9, step: 471/600\n",
      "loss: 0.3752, lr: 0.0005, epoch: 1/9, step: 472/600\n",
      "loss: 0.1803, lr: 0.0005, epoch: 1/9, step: 473/600\n",
      "loss: 0.2279, lr: 0.0005, epoch: 1/9, step: 474/600\n",
      "loss: 0.0797, lr: 0.0005, epoch: 1/9, step: 475/600\n",
      "loss: 0.8916, lr: 0.0005, epoch: 1/9, step: 476/600\n",
      "loss: 0.3813, lr: 0.0005, epoch: 1/9, step: 477/600\n",
      "loss: 0.1204, lr: 0.0005, epoch: 1/9, step: 478/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 1/9, step: 479/600\n",
      "loss: 0.26, lr: 0.0005, epoch: 1/9, step: 480/600\n",
      "loss: 0.2881, lr: 0.0005, epoch: 1/9, step: 481/600\n",
      "loss: 0.021, lr: 0.0005, epoch: 1/9, step: 482/600\n",
      "loss: 0.0369, lr: 0.0005, epoch: 1/9, step: 483/600\n",
      "loss: 0.1608, lr: 0.0005, epoch: 1/9, step: 484/600\n",
      "loss: 0.0396, lr: 0.0005, epoch: 1/9, step: 485/600\n",
      "loss: 0.0383, lr: 0.0005, epoch: 1/9, step: 486/600\n",
      "loss: 0.1998, lr: 0.0005, epoch: 1/9, step: 487/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 1/9, step: 488/600\n",
      "loss: 0.0404, lr: 0.0005, epoch: 1/9, step: 489/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 1/9, step: 490/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 1/9, step: 491/600\n",
      "loss: 0.7148, lr: 0.0005, epoch: 1/9, step: 492/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 1/9, step: 493/600\n",
      "loss: 0.416, lr: 0.0005, epoch: 1/9, step: 494/600\n",
      "loss: 0.1614, lr: 0.0005, epoch: 1/9, step: 495/600\n",
      "loss: 0.5356, lr: 0.0005, epoch: 1/9, step: 496/600\n",
      "loss: 0.3044, lr: 0.0005, epoch: 1/9, step: 497/600\n",
      "loss: 0.4995, lr: 0.0005, epoch: 1/9, step: 498/600\n",
      "loss: 0.0383, lr: 0.0005, epoch: 1/9, step: 499/600\n",
      "loss: 0.017, lr: 0.0005, epoch: 1/9, step: 500/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 1/9, step: 501/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 1/9, step: 502/600\n",
      "loss: 0.0921, lr: 0.0005, epoch: 1/9, step: 503/600\n",
      "loss: 0.3225, lr: 0.0005, epoch: 1/9, step: 504/600\n",
      "loss: 0.4146, lr: 0.0005, epoch: 1/9, step: 505/600\n",
      "loss: 0.1315, lr: 0.0005, epoch: 1/9, step: 506/600\n",
      "loss: 0.22, lr: 0.0005, epoch: 1/9, step: 507/600\n",
      "loss: 0.2107, lr: 0.0005, epoch: 1/9, step: 508/600\n",
      "loss: 0.0532, lr: 0.0005, epoch: 1/9, step: 509/600\n",
      "loss: 0.0193, lr: 0.0005, epoch: 1/9, step: 510/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 1/9, step: 511/600\n",
      "loss: 0.1368, lr: 0.0005, epoch: 1/9, step: 512/600\n",
      "loss: 0.1115, lr: 0.0005, epoch: 1/9, step: 513/600\n",
      "loss: 0.0396, lr: 0.0005, epoch: 1/9, step: 514/600\n",
      "loss: 0.4199, lr: 0.0005, epoch: 1/9, step: 515/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 1/9, step: 516/600\n",
      "loss: 0.0141, lr: 0.0005, epoch: 1/9, step: 517/600\n",
      "loss: 0.0854, lr: 0.0005, epoch: 1/9, step: 518/600\n",
      "loss: 0.0368, lr: 0.0005, epoch: 1/9, step: 519/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 1/9, step: 520/600\n",
      "loss: 0.1615, lr: 0.0005, epoch: 1/9, step: 521/600\n",
      "loss: 0.0975, lr: 0.0005, epoch: 1/9, step: 522/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 1/9, step: 523/600\n",
      "loss: 0.0992, lr: 0.0005, epoch: 1/9, step: 524/600\n",
      "loss: 0.2739, lr: 0.0005, epoch: 1/9, step: 525/600\n",
      "loss: 0.0894, lr: 0.0005, epoch: 1/9, step: 526/600\n",
      "loss: 0.0021, lr: 0.0005, epoch: 1/9, step: 527/600\n",
      "loss: 0.1409, lr: 0.0005, epoch: 1/9, step: 528/600\n",
      "loss: 0.0069, lr: 0.0005, epoch: 1/9, step: 529/600\n",
      "loss: 0.114, lr: 0.0005, epoch: 1/9, step: 530/600\n",
      "loss: 0.0441, lr: 0.0005, epoch: 1/9, step: 531/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 1/9, step: 532/600\n",
      "loss: 0.071, lr: 0.0005, epoch: 1/9, step: 533/600\n",
      "loss: 0.041, lr: 0.0005, epoch: 1/9, step: 534/600\n",
      "loss: 0.0922, lr: 0.0005, epoch: 1/9, step: 535/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 1/9, step: 536/600\n",
      "loss: 0.3076, lr: 0.0005, epoch: 1/9, step: 537/600\n",
      "loss: 0.4797, lr: 0.0005, epoch: 1/9, step: 538/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 1/9, step: 539/600\n",
      "loss: 0.0117, lr: 0.0005, epoch: 1/9, step: 540/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 1/9, step: 541/600\n",
      "loss: 0.1147, lr: 0.0005, epoch: 1/9, step: 542/600\n",
      "loss: 0.2448, lr: 0.0005, epoch: 1/9, step: 543/600\n",
      "loss: 0.2197, lr: 0.0005, epoch: 1/9, step: 544/600\n",
      "loss: 0.4753, lr: 0.0005, epoch: 1/9, step: 545/600\n",
      "loss: 0.1311, lr: 0.0005, epoch: 1/9, step: 546/600\n",
      "loss: 0.0079, lr: 0.0005, epoch: 1/9, step: 547/600\n",
      "loss: 0.5425, lr: 0.0005, epoch: 1/9, step: 548/600\n",
      "loss: 0.0804, lr: 0.0005, epoch: 1/9, step: 549/600\n",
      "loss: 0.0374, lr: 0.0005, epoch: 1/9, step: 550/600\n",
      "loss: 0.1827, lr: 0.0005, epoch: 1/9, step: 551/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 1/9, step: 552/600\n",
      "loss: 0.0317, lr: 0.0005, epoch: 1/9, step: 553/600\n",
      "loss: 0.0184, lr: 0.0005, epoch: 1/9, step: 554/600\n",
      "loss: 0.0383, lr: 0.0005, epoch: 1/9, step: 555/600\n",
      "loss: 0.0753, lr: 0.0005, epoch: 1/9, step: 556/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 1/9, step: 557/600\n",
      "loss: 0.3008, lr: 0.0005, epoch: 1/9, step: 558/600\n",
      "loss: 0.029, lr: 0.0005, epoch: 1/9, step: 559/600\n",
      "loss: 0.2905, lr: 0.0005, epoch: 1/9, step: 560/600\n",
      "loss: 0.1348, lr: 0.0005, epoch: 1/9, step: 561/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 1/9, step: 562/600\n",
      "loss: 0.0609, lr: 0.0005, epoch: 1/9, step: 563/600\n",
      "loss: 0.7422, lr: 0.0005, epoch: 1/9, step: 564/600\n",
      "loss: 0.0185, lr: 0.0005, epoch: 1/9, step: 565/600\n",
      "loss: 0.0735, lr: 0.0005, epoch: 1/9, step: 566/600\n",
      "loss: 0.0125, lr: 0.0005, epoch: 1/9, step: 567/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 1/9, step: 568/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 1/9, step: 569/600\n",
      "loss: 0.0112, lr: 0.0005, epoch: 1/9, step: 570/600\n",
      "loss: 0.2238, lr: 0.0005, epoch: 1/9, step: 571/600\n",
      "loss: 0.1523, lr: 0.0005, epoch: 1/9, step: 572/600\n",
      "loss: 0.5103, lr: 0.0005, epoch: 1/9, step: 573/600\n",
      "loss: 0.0188, lr: 0.0005, epoch: 1/9, step: 574/600\n",
      "loss: 0.0825, lr: 0.0005, epoch: 1/9, step: 575/600\n",
      "loss: 0.2247, lr: 0.0005, epoch: 1/9, step: 576/600\n",
      "loss: 0.0703, lr: 0.0005, epoch: 1/9, step: 577/600\n",
      "loss: 0.0558, lr: 0.0005, epoch: 1/9, step: 578/600\n",
      "loss: 0.4485, lr: 0.0005, epoch: 1/9, step: 579/600\n",
      "loss: 0.2686, lr: 0.0005, epoch: 1/9, step: 580/600\n",
      "loss: 0.1951, lr: 0.0005, epoch: 1/9, step: 581/600\n",
      "loss: 0.1385, lr: 0.0005, epoch: 1/9, step: 582/600\n",
      "loss: 0.04, lr: 0.0005, epoch: 1/9, step: 583/600\n",
      "loss: 0.3518, lr: 0.0005, epoch: 1/9, step: 584/600\n",
      "loss: 0.0491, lr: 0.0005, epoch: 1/9, step: 585/600\n",
      "loss: 0.0393, lr: 0.0005, epoch: 1/9, step: 586/600\n",
      "loss: 0.397, lr: 0.0005, epoch: 1/9, step: 587/600\n",
      "loss: 0.1566, lr: 0.0005, epoch: 1/9, step: 588/600\n",
      "loss: 0.0138, lr: 0.0005, epoch: 1/9, step: 589/600\n",
      "loss: 0.0228, lr: 0.0005, epoch: 1/9, step: 590/600\n",
      "loss: 0.29, lr: 0.0005, epoch: 1/9, step: 591/600\n",
      "loss: 0.0972, lr: 0.0005, epoch: 1/9, step: 592/600\n",
      "loss: 0.2198, lr: 0.0005, epoch: 1/9, step: 593/600\n",
      "loss: 0.041, lr: 0.0005, epoch: 1/9, step: 594/600\n",
      "loss: 0.1332, lr: 0.0005, epoch: 1/9, step: 595/600\n",
      "loss: 0.0137, lr: 0.0005, epoch: 1/9, step: 596/600\n",
      "loss: 0.2947, lr: 0.0005, epoch: 1/9, step: 597/600\n",
      "loss: 0.179, lr: 0.0005, epoch: 1/9, step: 598/600\n",
      "loss: 0.1515, lr: 0.0005, epoch: 1/9, step: 599/600\n",
      "loss: 0.0913, lr: 0.0005, epoch: 1/9, step: 600/600\n",
      "loss: 0.1768, lr: 0.0005, epoch: 2/9, step: 1/600\n",
      "loss: 0.4199, lr: 0.0005, epoch: 2/9, step: 2/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 2/9, step: 3/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 2/9, step: 4/600\n",
      "loss: 0.1661, lr: 0.0005, epoch: 2/9, step: 5/600\n",
      "loss: 0.1038, lr: 0.0005, epoch: 2/9, step: 6/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 2/9, step: 7/600\n",
      "loss: 0.1318, lr: 0.0005, epoch: 2/9, step: 8/600\n",
      "loss: 0.0876, lr: 0.0005, epoch: 2/9, step: 9/600\n",
      "loss: 0.177, lr: 0.0005, epoch: 2/9, step: 10/600\n",
      "loss: 0.0857, lr: 0.0005, epoch: 2/9, step: 11/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 2/9, step: 12/600\n",
      "loss: 0.4495, lr: 0.0005, epoch: 2/9, step: 13/600\n",
      "loss: 0.0999, lr: 0.0005, epoch: 2/9, step: 14/600\n",
      "loss: 0.0444, lr: 0.0005, epoch: 2/9, step: 15/600\n",
      "loss: 0.043, lr: 0.0005, epoch: 2/9, step: 16/600\n",
      "loss: 0.521, lr: 0.0005, epoch: 2/9, step: 17/600\n",
      "loss: 0.0161, lr: 0.0005, epoch: 2/9, step: 18/600\n",
      "loss: 0.1089, lr: 0.0005, epoch: 2/9, step: 19/600\n",
      "loss: 0.5327, lr: 0.0005, epoch: 2/9, step: 20/600\n",
      "loss: 0.5522, lr: 0.0005, epoch: 2/9, step: 21/600\n",
      "loss: 0.3667, lr: 0.0005, epoch: 2/9, step: 22/600\n",
      "loss: 0.2632, lr: 0.0005, epoch: 2/9, step: 23/600\n",
      "loss: 0.3613, lr: 0.0005, epoch: 2/9, step: 24/600\n",
      "loss: 0.0673, lr: 0.0005, epoch: 2/9, step: 25/600\n",
      "loss: 0.0209, lr: 0.0005, epoch: 2/9, step: 26/600\n",
      "loss: 0.0748, lr: 0.0005, epoch: 2/9, step: 27/600\n",
      "loss: 0.1555, lr: 0.0005, epoch: 2/9, step: 28/600\n",
      "loss: 0.0121, lr: 0.0005, epoch: 2/9, step: 29/600\n",
      "loss: 0.0137, lr: 0.0005, epoch: 2/9, step: 30/600\n",
      "loss: 0.25, lr: 0.0005, epoch: 2/9, step: 31/600\n",
      "loss: 0.0228, lr: 0.0005, epoch: 2/9, step: 32/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 2/9, step: 33/600\n",
      "loss: 0.0088, lr: 0.0005, epoch: 2/9, step: 34/600\n",
      "loss: 0.0142, lr: 0.0005, epoch: 2/9, step: 35/600\n",
      "loss: 0.3855, lr: 0.0005, epoch: 2/9, step: 36/600\n",
      "loss: 0.0107, lr: 0.0005, epoch: 2/9, step: 37/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 2/9, step: 38/600\n",
      "loss: 0.1414, lr: 0.0005, epoch: 2/9, step: 39/600\n",
      "loss: 0.0731, lr: 0.0005, epoch: 2/9, step: 40/600\n",
      "loss: 0.2849, lr: 0.0005, epoch: 2/9, step: 41/600\n",
      "loss: 0.1891, lr: 0.0005, epoch: 2/9, step: 42/600\n",
      "loss: 0.0228, lr: 0.0005, epoch: 2/9, step: 43/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 2/9, step: 44/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 2/9, step: 45/600\n",
      "loss: 0.3394, lr: 0.0005, epoch: 2/9, step: 46/600\n",
      "loss: 0.0853, lr: 0.0005, epoch: 2/9, step: 47/600\n",
      "loss: 0.4927, lr: 0.0005, epoch: 2/9, step: 48/600\n",
      "loss: 0.2822, lr: 0.0005, epoch: 2/9, step: 49/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 2/9, step: 50/600\n",
      "loss: 0.1232, lr: 0.0005, epoch: 2/9, step: 51/600\n",
      "loss: 0.0238, lr: 0.0005, epoch: 2/9, step: 52/600\n",
      "loss: 0.4822, lr: 0.0005, epoch: 2/9, step: 53/600\n",
      "loss: 0.4746, lr: 0.0005, epoch: 2/9, step: 54/600\n",
      "loss: 0.0329, lr: 0.0005, epoch: 2/9, step: 55/600\n",
      "loss: 0.25, lr: 0.0005, epoch: 2/9, step: 56/600\n",
      "loss: 0.314, lr: 0.0005, epoch: 2/9, step: 57/600\n",
      "loss: 0.376, lr: 0.0005, epoch: 2/9, step: 58/600\n",
      "loss: 0.2189, lr: 0.0005, epoch: 2/9, step: 59/600\n",
      "loss: 0.0205, lr: 0.0005, epoch: 2/9, step: 60/600\n",
      "loss: 0.3518, lr: 0.0005, epoch: 2/9, step: 61/600\n",
      "loss: 0.9541, lr: 0.0005, epoch: 2/9, step: 62/600\n",
      "loss: 0.7026, lr: 0.0005, epoch: 2/9, step: 63/600\n",
      "loss: 0.2371, lr: 0.0005, epoch: 2/9, step: 64/600\n",
      "loss: 0.6245, lr: 0.0005, epoch: 2/9, step: 65/600\n",
      "loss: 0.1377, lr: 0.0005, epoch: 2/9, step: 66/600\n",
      "loss: 0.0411, lr: 0.0005, epoch: 2/9, step: 67/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 2/9, step: 68/600\n",
      "loss: 0.1825, lr: 0.0005, epoch: 2/9, step: 69/600\n",
      "loss: 0.0886, lr: 0.0005, epoch: 2/9, step: 70/600\n",
      "loss: 0.0137, lr: 0.0005, epoch: 2/9, step: 71/600\n",
      "loss: 0.0425, lr: 0.0005, epoch: 2/9, step: 72/600\n",
      "loss: 0.2554, lr: 0.0005, epoch: 2/9, step: 73/600\n",
      "loss: 0.3105, lr: 0.0005, epoch: 2/9, step: 74/600\n",
      "loss: 0.0792, lr: 0.0005, epoch: 2/9, step: 75/600\n",
      "loss: 0.3228, lr: 0.0005, epoch: 2/9, step: 76/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 2/9, step: 77/600\n",
      "loss: 0.0069, lr: 0.0005, epoch: 2/9, step: 78/600\n",
      "loss: 0.0617, lr: 0.0005, epoch: 2/9, step: 79/600\n",
      "loss: 0.1941, lr: 0.0005, epoch: 2/9, step: 80/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 2/9, step: 81/600\n",
      "loss: 0.2917, lr: 0.0005, epoch: 2/9, step: 82/600\n",
      "loss: 0.2228, lr: 0.0005, epoch: 2/9, step: 83/600\n",
      "loss: 0.0266, lr: 0.0005, epoch: 2/9, step: 84/600\n",
      "loss: 0.1455, lr: 0.0005, epoch: 2/9, step: 85/600\n",
      "loss: 0.3689, lr: 0.0005, epoch: 2/9, step: 86/600\n",
      "loss: 0.0886, lr: 0.0005, epoch: 2/9, step: 87/600\n",
      "loss: 0.52, lr: 0.0005, epoch: 2/9, step: 88/600\n",
      "loss: 0.7241, lr: 0.0005, epoch: 2/9, step: 89/600\n",
      "loss: 0.563, lr: 0.0005, epoch: 2/9, step: 90/600\n",
      "loss: 0.7256, lr: 0.0005, epoch: 2/9, step: 91/600\n",
      "loss: 0.049, lr: 0.0005, epoch: 2/9, step: 92/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 2/9, step: 93/600\n",
      "loss: 0.0457, lr: 0.0005, epoch: 2/9, step: 94/600\n",
      "loss: 0.1187, lr: 0.0005, epoch: 2/9, step: 95/600\n",
      "loss: 0.3501, lr: 0.0005, epoch: 2/9, step: 96/600\n",
      "loss: 0.0534, lr: 0.0005, epoch: 2/9, step: 97/600\n",
      "loss: 0.1942, lr: 0.0005, epoch: 2/9, step: 98/600\n",
      "loss: 0.0146, lr: 0.0005, epoch: 2/9, step: 99/600\n",
      "loss: 0.0182, lr: 0.0005, epoch: 2/9, step: 100/600\n",
      "loss: 0.8071, lr: 0.0005, epoch: 2/9, step: 101/600\n",
      "loss: 0.3955, lr: 0.0005, epoch: 2/9, step: 102/600\n",
      "loss: 0.0322, lr: 0.0005, epoch: 2/9, step: 103/600\n",
      "loss: 0.2612, lr: 0.0005, epoch: 2/9, step: 104/600\n",
      "loss: 0.0209, lr: 0.0005, epoch: 2/9, step: 105/600\n",
      "loss: 0.564, lr: 0.0005, epoch: 2/9, step: 106/600\n",
      "loss: 0.2457, lr: 0.0005, epoch: 2/9, step: 107/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 2/9, step: 108/600\n",
      "loss: 0.2158, lr: 0.0005, epoch: 2/9, step: 109/600\n",
      "loss: 0.1519, lr: 0.0005, epoch: 2/9, step: 110/600\n",
      "loss: 0.2172, lr: 0.0005, epoch: 2/9, step: 111/600\n",
      "loss: 0.1405, lr: 0.0005, epoch: 2/9, step: 112/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 2/9, step: 113/600\n",
      "loss: 0.0247, lr: 0.0005, epoch: 2/9, step: 114/600\n",
      "loss: 0.073, lr: 0.0005, epoch: 2/9, step: 115/600\n",
      "loss: 0.0342, lr: 0.0005, epoch: 2/9, step: 116/600\n",
      "loss: 0.1028, lr: 0.0005, epoch: 2/9, step: 117/600\n",
      "loss: 0.4375, lr: 0.0005, epoch: 2/9, step: 118/600\n",
      "loss: 0.1215, lr: 0.0005, epoch: 2/9, step: 119/600\n",
      "loss: 0.5562, lr: 0.0005, epoch: 2/9, step: 120/600\n",
      "loss: 0.4561, lr: 0.0005, epoch: 2/9, step: 121/600\n",
      "loss: 0.3135, lr: 0.0005, epoch: 2/9, step: 122/600\n",
      "loss: 0.3398, lr: 0.0005, epoch: 2/9, step: 123/600\n",
      "loss: 0.1669, lr: 0.0005, epoch: 2/9, step: 124/600\n",
      "loss: 0.394, lr: 0.0005, epoch: 2/9, step: 125/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 2/9, step: 126/600\n",
      "loss: 0.0418, lr: 0.0005, epoch: 2/9, step: 127/600\n",
      "loss: 0.1691, lr: 0.0005, epoch: 2/9, step: 128/600\n",
      "loss: 0.5347, lr: 0.0005, epoch: 2/9, step: 129/600\n",
      "loss: 0.0055, lr: 0.0005, epoch: 2/9, step: 130/600\n",
      "loss: 0.0839, lr: 0.0005, epoch: 2/9, step: 131/600\n",
      "loss: 0.0184, lr: 0.0005, epoch: 2/9, step: 132/600\n",
      "loss: 0.1094, lr: 0.0005, epoch: 2/9, step: 133/600\n",
      "loss: 0.3354, lr: 0.0005, epoch: 2/9, step: 134/600\n",
      "loss: 0.3093, lr: 0.0005, epoch: 2/9, step: 135/600\n",
      "loss: 0.4878, lr: 0.0005, epoch: 2/9, step: 136/600\n",
      "loss: 0.1877, lr: 0.0005, epoch: 2/9, step: 137/600\n",
      "loss: 0.0287, lr: 0.0005, epoch: 2/9, step: 138/600\n",
      "loss: 0.0216, lr: 0.0005, epoch: 2/9, step: 139/600\n",
      "loss: 0.5796, lr: 0.0005, epoch: 2/9, step: 140/600\n",
      "loss: 0.1516, lr: 0.0005, epoch: 2/9, step: 141/600\n",
      "loss: 0.4773, lr: 0.0005, epoch: 2/9, step: 142/600\n",
      "loss: 0.0426, lr: 0.0005, epoch: 2/9, step: 143/600\n",
      "loss: 0.3203, lr: 0.0005, epoch: 2/9, step: 144/600\n",
      "loss: 0.2566, lr: 0.0005, epoch: 2/9, step: 145/600\n",
      "loss: 0.0677, lr: 0.0005, epoch: 2/9, step: 146/600\n",
      "loss: 0.3108, lr: 0.0005, epoch: 2/9, step: 147/600\n",
      "loss: 0.0145, lr: 0.0005, epoch: 2/9, step: 148/600\n",
      "loss: 0.1353, lr: 0.0005, epoch: 2/9, step: 149/600\n",
      "loss: 0.2842, lr: 0.0005, epoch: 2/9, step: 150/600\n",
      "loss: 0.5654, lr: 0.0005, epoch: 2/9, step: 151/600\n",
      "loss: 0.2756, lr: 0.0005, epoch: 2/9, step: 152/600\n",
      "loss: 0.271, lr: 0.0005, epoch: 2/9, step: 153/600\n",
      "loss: 0.0346, lr: 0.0005, epoch: 2/9, step: 154/600\n",
      "loss: 0.0327, lr: 0.0005, epoch: 2/9, step: 155/600\n",
      "loss: 0.3665, lr: 0.0005, epoch: 2/9, step: 156/600\n",
      "loss: 0.0617, lr: 0.0005, epoch: 2/9, step: 157/600\n",
      "loss: 0.396, lr: 0.0005, epoch: 2/9, step: 158/600\n",
      "loss: 0.7246, lr: 0.0005, epoch: 2/9, step: 159/600\n",
      "loss: 0.0756, lr: 0.0005, epoch: 2/9, step: 160/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 2/9, step: 161/600\n",
      "loss: 0.0915, lr: 0.0005, epoch: 2/9, step: 162/600\n",
      "loss: 0.017, lr: 0.0005, epoch: 2/9, step: 163/600\n",
      "loss: 0.1222, lr: 0.0005, epoch: 2/9, step: 164/600\n",
      "loss: 0.0464, lr: 0.0005, epoch: 2/9, step: 165/600\n",
      "loss: 0.0836, lr: 0.0005, epoch: 2/9, step: 166/600\n",
      "loss: 0.1587, lr: 0.0005, epoch: 2/9, step: 167/600\n",
      "loss: 0.1154, lr: 0.0005, epoch: 2/9, step: 168/600\n",
      "loss: 0.6177, lr: 0.0005, epoch: 2/9, step: 169/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 2/9, step: 170/600\n",
      "loss: 0.163, lr: 0.0005, epoch: 2/9, step: 171/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 2/9, step: 172/600\n",
      "loss: 0.1242, lr: 0.0005, epoch: 2/9, step: 173/600\n",
      "loss: 0.2001, lr: 0.0005, epoch: 2/9, step: 174/600\n",
      "loss: 0.3279, lr: 0.0005, epoch: 2/9, step: 175/600\n",
      "loss: 0.4609, lr: 0.0005, epoch: 2/9, step: 176/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 2/9, step: 177/600\n",
      "loss: 0.0272, lr: 0.0005, epoch: 2/9, step: 178/600\n",
      "loss: 0.0205, lr: 0.0005, epoch: 2/9, step: 179/600\n",
      "loss: 0.0808, lr: 0.0005, epoch: 2/9, step: 180/600\n",
      "loss: 0.8433, lr: 0.0005, epoch: 2/9, step: 181/600\n",
      "loss: 0.4194, lr: 0.0005, epoch: 2/9, step: 182/600\n",
      "loss: 0.0844, lr: 0.0005, epoch: 2/9, step: 183/600\n",
      "loss: 0.2129, lr: 0.0005, epoch: 2/9, step: 184/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 2/9, step: 185/600\n",
      "loss: 0.2407, lr: 0.0005, epoch: 2/9, step: 186/600\n",
      "loss: 0.3589, lr: 0.0005, epoch: 2/9, step: 187/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 2/9, step: 188/600\n",
      "loss: 0.0704, lr: 0.0005, epoch: 2/9, step: 189/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 2/9, step: 190/600\n",
      "loss: 0.0481, lr: 0.0005, epoch: 2/9, step: 191/600\n",
      "loss: 0.0437, lr: 0.0005, epoch: 2/9, step: 192/600\n",
      "loss: 0.0377, lr: 0.0005, epoch: 2/9, step: 193/600\n",
      "loss: 0.1976, lr: 0.0005, epoch: 2/9, step: 194/600\n",
      "loss: 0.2568, lr: 0.0005, epoch: 2/9, step: 195/600\n",
      "loss: 0.0174, lr: 0.0005, epoch: 2/9, step: 196/600\n",
      "loss: 0.0354, lr: 0.0005, epoch: 2/9, step: 197/600\n",
      "loss: 0.0133, lr: 0.0005, epoch: 2/9, step: 198/600\n",
      "loss: 0.1724, lr: 0.0005, epoch: 2/9, step: 199/600\n",
      "loss: 0.0908, lr: 0.0005, epoch: 2/9, step: 200/600\n",
      "loss: 0.0573, lr: 0.0005, epoch: 2/9, step: 201/600\n",
      "loss: 0.1733, lr: 0.0005, epoch: 2/9, step: 202/600\n",
      "loss: 0.4741, lr: 0.0005, epoch: 2/9, step: 203/600\n",
      "loss: 0.0312, lr: 0.0005, epoch: 2/9, step: 204/600\n",
      "loss: 0.0416, lr: 0.0005, epoch: 2/9, step: 205/600\n",
      "loss: 0.0149, lr: 0.0005, epoch: 2/9, step: 206/600\n",
      "loss: 0.1638, lr: 0.0005, epoch: 2/9, step: 207/600\n",
      "loss: 0.4946, lr: 0.0005, epoch: 2/9, step: 208/600\n",
      "loss: 0.7573, lr: 0.0005, epoch: 2/9, step: 209/600\n",
      "loss: 0.2656, lr: 0.0005, epoch: 2/9, step: 210/600\n",
      "loss: 0.3696, lr: 0.0005, epoch: 2/9, step: 211/600\n",
      "loss: 0.0107, lr: 0.0005, epoch: 2/9, step: 212/600\n",
      "loss: 0.2754, lr: 0.0005, epoch: 2/9, step: 213/600\n",
      "loss: 0.0352, lr: 0.0005, epoch: 2/9, step: 214/600\n",
      "loss: 0.0354, lr: 0.0005, epoch: 2/9, step: 215/600\n",
      "loss: 0.246, lr: 0.0005, epoch: 2/9, step: 216/600\n",
      "loss: 0.0641, lr: 0.0005, epoch: 2/9, step: 217/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 2/9, step: 218/600\n",
      "loss: 0.4146, lr: 0.0005, epoch: 2/9, step: 219/600\n",
      "loss: 0.0673, lr: 0.0005, epoch: 2/9, step: 220/600\n",
      "loss: 0.4141, lr: 0.0005, epoch: 2/9, step: 221/600\n",
      "loss: 0.321, lr: 0.0005, epoch: 2/9, step: 222/600\n",
      "loss: 0.0515, lr: 0.0005, epoch: 2/9, step: 223/600\n",
      "loss: 0.1436, lr: 0.0005, epoch: 2/9, step: 224/600\n",
      "loss: 0.5894, lr: 0.0005, epoch: 2/9, step: 225/600\n",
      "loss: 0.0917, lr: 0.0005, epoch: 2/9, step: 226/600\n",
      "loss: 0.3979, lr: 0.0005, epoch: 2/9, step: 227/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 2/9, step: 228/600\n",
      "loss: 0.7104, lr: 0.0005, epoch: 2/9, step: 229/600\n",
      "loss: 0.4124, lr: 0.0005, epoch: 2/9, step: 230/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 2/9, step: 231/600\n",
      "loss: 0.0158, lr: 0.0005, epoch: 2/9, step: 232/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 2/9, step: 233/600\n",
      "loss: 0.2761, lr: 0.0005, epoch: 2/9, step: 234/600\n",
      "loss: 0.4402, lr: 0.0005, epoch: 2/9, step: 235/600\n",
      "loss: 0.3855, lr: 0.0005, epoch: 2/9, step: 236/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 2/9, step: 237/600\n",
      "loss: 0.1039, lr: 0.0005, epoch: 2/9, step: 238/600\n",
      "loss: 0.1062, lr: 0.0005, epoch: 2/9, step: 239/600\n",
      "loss: 0.4087, lr: 0.0005, epoch: 2/9, step: 240/600\n",
      "loss: 0.3137, lr: 0.0005, epoch: 2/9, step: 241/600\n",
      "loss: 0.0514, lr: 0.0005, epoch: 2/9, step: 242/600\n",
      "loss: 0.1236, lr: 0.0005, epoch: 2/9, step: 243/600\n",
      "loss: 0.0977, lr: 0.0005, epoch: 2/9, step: 244/600\n",
      "loss: 0.0196, lr: 0.0005, epoch: 2/9, step: 245/600\n",
      "loss: 0.0301, lr: 0.0005, epoch: 2/9, step: 246/600\n",
      "loss: 0.2844, lr: 0.0005, epoch: 2/9, step: 247/600\n",
      "loss: 0.1526, lr: 0.0005, epoch: 2/9, step: 248/600\n",
      "loss: 0.5527, lr: 0.0005, epoch: 2/9, step: 249/600\n",
      "loss: 0.3647, lr: 0.0005, epoch: 2/9, step: 250/600\n",
      "loss: 0.387, lr: 0.0005, epoch: 2/9, step: 251/600\n",
      "loss: 0.0402, lr: 0.0005, epoch: 2/9, step: 252/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 2/9, step: 253/600\n",
      "loss: 0.7959, lr: 0.0005, epoch: 2/9, step: 254/600\n",
      "loss: 0.0759, lr: 0.0005, epoch: 2/9, step: 255/600\n",
      "loss: 0.0847, lr: 0.0005, epoch: 2/9, step: 256/600\n",
      "loss: 0.2034, lr: 0.0005, epoch: 2/9, step: 257/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 2/9, step: 258/600\n",
      "loss: 0.0509, lr: 0.0005, epoch: 2/9, step: 259/600\n",
      "loss: 0.4922, lr: 0.0005, epoch: 2/9, step: 260/600\n",
      "loss: 0.2495, lr: 0.0005, epoch: 2/9, step: 261/600\n",
      "loss: 0.3779, lr: 0.0005, epoch: 2/9, step: 262/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 2/9, step: 263/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 2/9, step: 264/600\n",
      "loss: 0.2644, lr: 0.0005, epoch: 2/9, step: 265/600\n",
      "loss: 0.3508, lr: 0.0005, epoch: 2/9, step: 266/600\n",
      "loss: 0.0452, lr: 0.0005, epoch: 2/9, step: 267/600\n",
      "loss: 0.0124, lr: 0.0005, epoch: 2/9, step: 268/600\n",
      "loss: 0.0146, lr: 0.0005, epoch: 2/9, step: 269/600\n",
      "loss: 0.0095, lr: 0.0005, epoch: 2/9, step: 270/600\n",
      "loss: 0.3372, lr: 0.0005, epoch: 2/9, step: 271/600\n",
      "loss: 0.02, lr: 0.0005, epoch: 2/9, step: 272/600\n",
      "loss: 0.0111, lr: 0.0005, epoch: 2/9, step: 273/600\n",
      "loss: 0.3027, lr: 0.0005, epoch: 2/9, step: 274/600\n",
      "loss: 0.3093, lr: 0.0005, epoch: 2/9, step: 275/600\n",
      "loss: 0.1915, lr: 0.0005, epoch: 2/9, step: 276/600\n",
      "loss: 0.4082, lr: 0.0005, epoch: 2/9, step: 277/600\n",
      "loss: 0.436, lr: 0.0005, epoch: 2/9, step: 278/600\n",
      "loss: 0.0771, lr: 0.0005, epoch: 2/9, step: 279/600\n",
      "loss: 0.0079, lr: 0.0005, epoch: 2/9, step: 280/600\n",
      "loss: 0.1882, lr: 0.0005, epoch: 2/9, step: 281/600\n",
      "loss: 0.2296, lr: 0.0005, epoch: 2/9, step: 282/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 2/9, step: 283/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 2/9, step: 284/600\n",
      "loss: 0.0592, lr: 0.0005, epoch: 2/9, step: 285/600\n",
      "loss: 0.0732, lr: 0.0005, epoch: 2/9, step: 286/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 2/9, step: 287/600\n",
      "loss: 0.0415, lr: 0.0005, epoch: 2/9, step: 288/600\n",
      "loss: 0.0262, lr: 0.0005, epoch: 2/9, step: 289/600\n",
      "loss: 0.3884, lr: 0.0005, epoch: 2/9, step: 290/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 2/9, step: 291/600\n",
      "loss: 0.5796, lr: 0.0005, epoch: 2/9, step: 292/600\n",
      "loss: 0.1993, lr: 0.0005, epoch: 2/9, step: 293/600\n",
      "loss: 0.3853, lr: 0.0005, epoch: 2/9, step: 294/600\n",
      "loss: 0.0159, lr: 0.0005, epoch: 2/9, step: 295/600\n",
      "loss: 0.076, lr: 0.0005, epoch: 2/9, step: 296/600\n",
      "loss: 0.101, lr: 0.0005, epoch: 2/9, step: 297/600\n",
      "loss: 0.0596, lr: 0.0005, epoch: 2/9, step: 298/600\n",
      "loss: 0.6265, lr: 0.0005, epoch: 2/9, step: 299/600\n",
      "loss: 0.1182, lr: 0.0005, epoch: 2/9, step: 300/600\n",
      "loss: 0.0108, lr: 0.0005, epoch: 2/9, step: 301/600\n",
      "loss: 0.2524, lr: 0.0005, epoch: 2/9, step: 302/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 2/9, step: 303/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 2/9, step: 304/600\n",
      "loss: 0.4404, lr: 0.0005, epoch: 2/9, step: 305/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 2/9, step: 306/600\n",
      "loss: 0.3396, lr: 0.0005, epoch: 2/9, step: 307/600\n",
      "loss: 0.1661, lr: 0.0005, epoch: 2/9, step: 308/600\n",
      "loss: 0.1796, lr: 0.0005, epoch: 2/9, step: 309/600\n",
      "loss: 0.0389, lr: 0.0005, epoch: 2/9, step: 310/600\n",
      "loss: 0.4915, lr: 0.0005, epoch: 2/9, step: 311/600\n",
      "loss: 0.2479, lr: 0.0005, epoch: 2/9, step: 312/600\n",
      "loss: 0.0288, lr: 0.0005, epoch: 2/9, step: 313/600\n",
      "loss: 0.0317, lr: 0.0005, epoch: 2/9, step: 314/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 2/9, step: 315/600\n",
      "loss: 0.0363, lr: 0.0005, epoch: 2/9, step: 316/600\n",
      "loss: 0.1526, lr: 0.0005, epoch: 2/9, step: 317/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 2/9, step: 318/600\n",
      "loss: 0.0168, lr: 0.0005, epoch: 2/9, step: 319/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 2/9, step: 320/600\n",
      "loss: 0.4041, lr: 0.0005, epoch: 2/9, step: 321/600\n",
      "loss: 0.0112, lr: 0.0005, epoch: 2/9, step: 322/600\n",
      "loss: 0.584, lr: 0.0005, epoch: 2/9, step: 323/600\n",
      "loss: 0.0915, lr: 0.0005, epoch: 2/9, step: 324/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 2/9, step: 325/600\n",
      "loss: 0.205, lr: 0.0005, epoch: 2/9, step: 326/600\n",
      "loss: 0.0236, lr: 0.0005, epoch: 2/9, step: 327/600\n",
      "loss: 0.171, lr: 0.0005, epoch: 2/9, step: 328/600\n",
      "loss: 0.4363, lr: 0.0005, epoch: 2/9, step: 329/600\n",
      "loss: 0.1683, lr: 0.0005, epoch: 2/9, step: 330/600\n",
      "loss: 0.0147, lr: 0.0005, epoch: 2/9, step: 331/600\n",
      "loss: 0.1096, lr: 0.0005, epoch: 2/9, step: 332/600\n",
      "loss: 0.3359, lr: 0.0005, epoch: 2/9, step: 333/600\n",
      "loss: 0.7275, lr: 0.0005, epoch: 2/9, step: 334/600\n",
      "loss: 0.0243, lr: 0.0005, epoch: 2/9, step: 335/600\n",
      "loss: 0.1353, lr: 0.0005, epoch: 2/9, step: 336/600\n",
      "loss: 0.1619, lr: 0.0005, epoch: 2/9, step: 337/600\n",
      "loss: 0.3667, lr: 0.0005, epoch: 2/9, step: 338/600\n",
      "loss: 0.2128, lr: 0.0005, epoch: 2/9, step: 339/600\n",
      "loss: 0.2671, lr: 0.0005, epoch: 2/9, step: 340/600\n",
      "loss: 0.0751, lr: 0.0005, epoch: 2/9, step: 341/600\n",
      "loss: 0.3452, lr: 0.0005, epoch: 2/9, step: 342/600\n",
      "loss: 0.026, lr: 0.0005, epoch: 2/9, step: 343/600\n",
      "loss: 0.0105, lr: 0.0005, epoch: 2/9, step: 344/600\n",
      "loss: 0.4026, lr: 0.0005, epoch: 2/9, step: 345/600\n",
      "loss: 0.0254, lr: 0.0005, epoch: 2/9, step: 346/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 2/9, step: 347/600\n",
      "loss: 0.1382, lr: 0.0005, epoch: 2/9, step: 348/600\n",
      "loss: 0.0515, lr: 0.0005, epoch: 2/9, step: 349/600\n",
      "loss: 0.3157, lr: 0.0005, epoch: 2/9, step: 350/600\n",
      "loss: 0.1907, lr: 0.0005, epoch: 2/9, step: 351/600\n",
      "loss: 0.1193, lr: 0.0005, epoch: 2/9, step: 352/600\n",
      "loss: 0.1155, lr: 0.0005, epoch: 2/9, step: 353/600\n",
      "loss: 0.0677, lr: 0.0005, epoch: 2/9, step: 354/600\n",
      "loss: 0.1411, lr: 0.0005, epoch: 2/9, step: 355/600\n",
      "loss: 0.0742, lr: 0.0005, epoch: 2/9, step: 356/600\n",
      "loss: 0.0207, lr: 0.0005, epoch: 2/9, step: 357/600\n",
      "loss: 0.3074, lr: 0.0005, epoch: 2/9, step: 358/600\n",
      "loss: 0.0451, lr: 0.0005, epoch: 2/9, step: 359/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 2/9, step: 360/600\n",
      "loss: 0.0786, lr: 0.0005, epoch: 2/9, step: 361/600\n",
      "loss: 0.0826, lr: 0.0005, epoch: 2/9, step: 362/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 2/9, step: 363/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 2/9, step: 364/600\n",
      "loss: 0.0264, lr: 0.0005, epoch: 2/9, step: 365/600\n",
      "loss: 0.1637, lr: 0.0005, epoch: 2/9, step: 366/600\n",
      "loss: 0.1538, lr: 0.0005, epoch: 2/9, step: 367/600\n",
      "loss: 0.0399, lr: 0.0005, epoch: 2/9, step: 368/600\n",
      "loss: 0.8135, lr: 0.0005, epoch: 2/9, step: 369/600\n",
      "loss: 0.2773, lr: 0.0005, epoch: 2/9, step: 370/600\n",
      "loss: 0.7676, lr: 0.0005, epoch: 2/9, step: 371/600\n",
      "loss: 0.0388, lr: 0.0005, epoch: 2/9, step: 372/600\n",
      "loss: 0.0348, lr: 0.0005, epoch: 2/9, step: 373/600\n",
      "loss: 0.7627, lr: 0.0005, epoch: 2/9, step: 374/600\n",
      "loss: 0.2034, lr: 0.0005, epoch: 2/9, step: 375/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 2/9, step: 376/600\n",
      "loss: 0.0842, lr: 0.0005, epoch: 2/9, step: 377/600\n",
      "loss: 0.1451, lr: 0.0005, epoch: 2/9, step: 378/600\n",
      "loss: 0.1849, lr: 0.0005, epoch: 2/9, step: 379/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 2/9, step: 380/600\n",
      "loss: 0.2971, lr: 0.0005, epoch: 2/9, step: 381/600\n",
      "loss: 0.0086, lr: 0.0005, epoch: 2/9, step: 382/600\n",
      "loss: 0.2301, lr: 0.0005, epoch: 2/9, step: 383/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 2/9, step: 384/600\n",
      "loss: 0.062, lr: 0.0005, epoch: 2/9, step: 385/600\n",
      "loss: 0.1332, lr: 0.0005, epoch: 2/9, step: 386/600\n",
      "loss: 0.0091, lr: 0.0005, epoch: 2/9, step: 387/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 2/9, step: 388/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 2/9, step: 389/600\n",
      "loss: 0.3442, lr: 0.0005, epoch: 2/9, step: 390/600\n",
      "loss: 0.3088, lr: 0.0005, epoch: 2/9, step: 391/600\n",
      "loss: 0.0859, lr: 0.0005, epoch: 2/9, step: 392/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 2/9, step: 393/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 2/9, step: 394/600\n",
      "loss: 0.1655, lr: 0.0005, epoch: 2/9, step: 395/600\n",
      "loss: 0.5156, lr: 0.0005, epoch: 2/9, step: 396/600\n",
      "loss: 0.1967, lr: 0.0005, epoch: 2/9, step: 397/600\n",
      "loss: 0.0163, lr: 0.0005, epoch: 2/9, step: 398/600\n",
      "loss: 0.3176, lr: 0.0005, epoch: 2/9, step: 399/600\n",
      "loss: 0.1506, lr: 0.0005, epoch: 2/9, step: 400/600\n",
      "loss: 0.0176, lr: 0.0005, epoch: 2/9, step: 401/600\n",
      "loss: 0.4614, lr: 0.0005, epoch: 2/9, step: 402/600\n",
      "loss: 0.096, lr: 0.0005, epoch: 2/9, step: 403/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 2/9, step: 404/600\n",
      "loss: 0.4319, lr: 0.0005, epoch: 2/9, step: 405/600\n",
      "loss: 0.0198, lr: 0.0005, epoch: 2/9, step: 406/600\n",
      "loss: 0.0177, lr: 0.0005, epoch: 2/9, step: 407/600\n",
      "loss: 0.0861, lr: 0.0005, epoch: 2/9, step: 408/600\n",
      "loss: 0.029, lr: 0.0005, epoch: 2/9, step: 409/600\n",
      "loss: 0.1029, lr: 0.0005, epoch: 2/9, step: 410/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 2/9, step: 411/600\n",
      "loss: 0.0424, lr: 0.0005, epoch: 2/9, step: 412/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 2/9, step: 413/600\n",
      "loss: 0.0335, lr: 0.0005, epoch: 2/9, step: 414/600\n",
      "loss: 0.3984, lr: 0.0005, epoch: 2/9, step: 415/600\n",
      "loss: 0.3245, lr: 0.0005, epoch: 2/9, step: 416/600\n",
      "loss: 0.0293, lr: 0.0005, epoch: 2/9, step: 417/600\n",
      "loss: 0.0856, lr: 0.0005, epoch: 2/9, step: 418/600\n",
      "loss: 0.0775, lr: 0.0005, epoch: 2/9, step: 419/600\n",
      "loss: 0.4756, lr: 0.0005, epoch: 2/9, step: 420/600\n",
      "loss: 0.0176, lr: 0.0005, epoch: 2/9, step: 421/600\n",
      "loss: 0.0573, lr: 0.0005, epoch: 2/9, step: 422/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 2/9, step: 423/600\n",
      "loss: 0.5156, lr: 0.0005, epoch: 2/9, step: 424/600\n",
      "loss: 0.0116, lr: 0.0005, epoch: 2/9, step: 425/600\n",
      "loss: 0.4961, lr: 0.0005, epoch: 2/9, step: 426/600\n",
      "loss: 0.1763, lr: 0.0005, epoch: 2/9, step: 427/600\n",
      "loss: 0.0208, lr: 0.0005, epoch: 2/9, step: 428/600\n",
      "loss: 0.0452, lr: 0.0005, epoch: 2/9, step: 429/600\n",
      "loss: 0.5054, lr: 0.0005, epoch: 2/9, step: 430/600\n",
      "loss: 0.667, lr: 0.0005, epoch: 2/9, step: 431/600\n",
      "loss: 0.0545, lr: 0.0005, epoch: 2/9, step: 432/600\n",
      "loss: 0.3821, lr: 0.0005, epoch: 2/9, step: 433/600\n",
      "loss: 0.0199, lr: 0.0005, epoch: 2/9, step: 434/600\n",
      "loss: 0.2661, lr: 0.0005, epoch: 2/9, step: 435/600\n",
      "loss: 0.0571, lr: 0.0005, epoch: 2/9, step: 436/600\n",
      "loss: 0.0853, lr: 0.0005, epoch: 2/9, step: 437/600\n",
      "loss: 0.1372, lr: 0.0005, epoch: 2/9, step: 438/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 2/9, step: 439/600\n",
      "loss: 0.0976, lr: 0.0005, epoch: 2/9, step: 440/600\n",
      "loss: 0.1143, lr: 0.0005, epoch: 2/9, step: 441/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 2/9, step: 442/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 2/9, step: 443/600\n",
      "loss: 0.106, lr: 0.0005, epoch: 2/9, step: 444/600\n",
      "loss: 0.077, lr: 0.0005, epoch: 2/9, step: 445/600\n",
      "loss: 0.1796, lr: 0.0005, epoch: 2/9, step: 446/600\n",
      "loss: 0.2966, lr: 0.0005, epoch: 2/9, step: 447/600\n",
      "loss: 0.1942, lr: 0.0005, epoch: 2/9, step: 448/600\n",
      "loss: 0.4878, lr: 0.0005, epoch: 2/9, step: 449/600\n",
      "loss: 0.0998, lr: 0.0005, epoch: 2/9, step: 450/600\n",
      "loss: 0.8188, lr: 0.0005, epoch: 2/9, step: 451/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 2/9, step: 452/600\n",
      "loss: 0.0567, lr: 0.0005, epoch: 2/9, step: 453/600\n",
      "loss: 0.1134, lr: 0.0005, epoch: 2/9, step: 454/600\n",
      "loss: 0.1843, lr: 0.0005, epoch: 2/9, step: 455/600\n",
      "loss: 0.17, lr: 0.0005, epoch: 2/9, step: 456/600\n",
      "loss: 0.3066, lr: 0.0005, epoch: 2/9, step: 457/600\n",
      "loss: 0.0285, lr: 0.0005, epoch: 2/9, step: 458/600\n",
      "loss: 0.0256, lr: 0.0005, epoch: 2/9, step: 459/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 2/9, step: 460/600\n",
      "loss: 0.0631, lr: 0.0005, epoch: 2/9, step: 461/600\n",
      "loss: 0.1149, lr: 0.0005, epoch: 2/9, step: 462/600\n",
      "loss: 0.152, lr: 0.0005, epoch: 2/9, step: 463/600\n",
      "loss: 0.0386, lr: 0.0005, epoch: 2/9, step: 464/600\n",
      "loss: 0.1231, lr: 0.0005, epoch: 2/9, step: 465/600\n",
      "loss: 0.0226, lr: 0.0005, epoch: 2/9, step: 466/600\n",
      "loss: 0.0463, lr: 0.0005, epoch: 2/9, step: 467/600\n",
      "loss: 0.3074, lr: 0.0005, epoch: 2/9, step: 468/600\n",
      "loss: 0.4219, lr: 0.0005, epoch: 2/9, step: 469/600\n",
      "loss: 0.0467, lr: 0.0005, epoch: 2/9, step: 470/600\n",
      "loss: 0.1163, lr: 0.0005, epoch: 2/9, step: 471/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 2/9, step: 472/600\n",
      "loss: 0.0637, lr: 0.0005, epoch: 2/9, step: 473/600\n",
      "loss: 0.1263, lr: 0.0005, epoch: 2/9, step: 474/600\n",
      "loss: 0.2578, lr: 0.0005, epoch: 2/9, step: 475/600\n",
      "loss: 0.3516, lr: 0.0005, epoch: 2/9, step: 476/600\n",
      "loss: 0.0302, lr: 0.0005, epoch: 2/9, step: 477/600\n",
      "loss: 0.103, lr: 0.0005, epoch: 2/9, step: 478/600\n",
      "loss: 0.1431, lr: 0.0005, epoch: 2/9, step: 479/600\n",
      "loss: 0.3169, lr: 0.0005, epoch: 2/9, step: 480/600\n",
      "loss: 0.1389, lr: 0.0005, epoch: 2/9, step: 481/600\n",
      "loss: 0.2988, lr: 0.0005, epoch: 2/9, step: 482/600\n",
      "loss: 0.4561, lr: 0.0005, epoch: 2/9, step: 483/600\n",
      "loss: 0.1776, lr: 0.0005, epoch: 2/9, step: 484/600\n",
      "loss: 0.1487, lr: 0.0005, epoch: 2/9, step: 485/600\n",
      "loss: 0.5415, lr: 0.0005, epoch: 2/9, step: 486/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 2/9, step: 487/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 2/9, step: 488/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 2/9, step: 489/600\n",
      "loss: 0.0485, lr: 0.0005, epoch: 2/9, step: 490/600\n",
      "loss: 0.0693, lr: 0.0005, epoch: 2/9, step: 491/600\n",
      "loss: 0.0122, lr: 0.0005, epoch: 2/9, step: 492/600\n",
      "loss: 0.0307, lr: 0.0005, epoch: 2/9, step: 493/600\n",
      "loss: 0.665, lr: 0.0005, epoch: 2/9, step: 494/600\n",
      "loss: 0.5752, lr: 0.0005, epoch: 2/9, step: 495/600\n",
      "loss: 0.0504, lr: 0.0005, epoch: 2/9, step: 496/600\n",
      "loss: 0.2294, lr: 0.0005, epoch: 2/9, step: 497/600\n",
      "loss: 0.1019, lr: 0.0005, epoch: 2/9, step: 498/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 2/9, step: 499/600\n",
      "loss: 0.2332, lr: 0.0005, epoch: 2/9, step: 500/600\n",
      "loss: 0.0504, lr: 0.0005, epoch: 2/9, step: 501/600\n",
      "loss: 0.6216, lr: 0.0005, epoch: 2/9, step: 502/600\n",
      "loss: 0.2739, lr: 0.0005, epoch: 2/9, step: 503/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 2/9, step: 504/600\n",
      "loss: 0.1053, lr: 0.0005, epoch: 2/9, step: 505/600\n",
      "loss: 0.0346, lr: 0.0005, epoch: 2/9, step: 506/600\n",
      "loss: 0.3525, lr: 0.0005, epoch: 2/9, step: 507/600\n",
      "loss: 0.0258, lr: 0.0005, epoch: 2/9, step: 508/600\n",
      "loss: 0.3296, lr: 0.0005, epoch: 2/9, step: 509/600\n",
      "loss: 0.4109, lr: 0.0005, epoch: 2/9, step: 510/600\n",
      "loss: 0.0093, lr: 0.0005, epoch: 2/9, step: 511/600\n",
      "loss: 0.3257, lr: 0.0005, epoch: 2/9, step: 512/600\n",
      "loss: 0.1565, lr: 0.0005, epoch: 2/9, step: 513/600\n",
      "loss: 0.1246, lr: 0.0005, epoch: 2/9, step: 514/600\n",
      "loss: 0.115, lr: 0.0005, epoch: 2/9, step: 515/600\n",
      "loss: 0.0602, lr: 0.0005, epoch: 2/9, step: 516/600\n",
      "loss: 0.0288, lr: 0.0005, epoch: 2/9, step: 517/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 2/9, step: 518/600\n",
      "loss: 0.3801, lr: 0.0005, epoch: 2/9, step: 519/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 2/9, step: 520/600\n",
      "loss: 0.3271, lr: 0.0005, epoch: 2/9, step: 521/600\n",
      "loss: 0.0394, lr: 0.0005, epoch: 2/9, step: 522/600\n",
      "loss: 0.3333, lr: 0.0005, epoch: 2/9, step: 523/600\n",
      "loss: 0.5078, lr: 0.0005, epoch: 2/9, step: 524/600\n",
      "loss: 0.229, lr: 0.0005, epoch: 2/9, step: 525/600\n",
      "loss: 0.0836, lr: 0.0005, epoch: 2/9, step: 526/600\n",
      "loss: 0.2148, lr: 0.0005, epoch: 2/9, step: 527/600\n",
      "loss: 0.0782, lr: 0.0005, epoch: 2/9, step: 528/600\n",
      "loss: 0.4253, lr: 0.0005, epoch: 2/9, step: 529/600\n",
      "loss: 0.3198, lr: 0.0005, epoch: 2/9, step: 530/600\n",
      "loss: 0.04, lr: 0.0005, epoch: 2/9, step: 531/600\n",
      "loss: 0.045, lr: 0.0005, epoch: 2/9, step: 532/600\n",
      "loss: 0.3262, lr: 0.0005, epoch: 2/9, step: 533/600\n",
      "loss: 0.0403, lr: 0.0005, epoch: 2/9, step: 534/600\n",
      "loss: 0.4246, lr: 0.0005, epoch: 2/9, step: 535/600\n",
      "loss: 0.7305, lr: 0.0005, epoch: 2/9, step: 536/600\n",
      "loss: 0.3157, lr: 0.0005, epoch: 2/9, step: 537/600\n",
      "loss: 0.2084, lr: 0.0005, epoch: 2/9, step: 538/600\n",
      "loss: 0.0874, lr: 0.0005, epoch: 2/9, step: 539/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 2/9, step: 540/600\n",
      "loss: 0.3767, lr: 0.0005, epoch: 2/9, step: 541/600\n",
      "loss: 0.2502, lr: 0.0005, epoch: 2/9, step: 542/600\n",
      "loss: 0.2744, lr: 0.0005, epoch: 2/9, step: 543/600\n",
      "loss: 0.0119, lr: 0.0005, epoch: 2/9, step: 544/600\n",
      "loss: 0.0961, lr: 0.0005, epoch: 2/9, step: 545/600\n",
      "loss: 0.46, lr: 0.0005, epoch: 2/9, step: 546/600\n",
      "loss: 0.2043, lr: 0.0005, epoch: 2/9, step: 547/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 2/9, step: 548/600\n",
      "loss: 0.3647, lr: 0.0005, epoch: 2/9, step: 549/600\n",
      "loss: 0.2756, lr: 0.0005, epoch: 2/9, step: 550/600\n",
      "loss: 0.1141, lr: 0.0005, epoch: 2/9, step: 551/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 2/9, step: 552/600\n",
      "loss: 0.0129, lr: 0.0005, epoch: 2/9, step: 553/600\n",
      "loss: 0.54, lr: 0.0005, epoch: 2/9, step: 554/600\n",
      "loss: 0.2426, lr: 0.0005, epoch: 2/9, step: 555/600\n",
      "loss: 0.0668, lr: 0.0005, epoch: 2/9, step: 556/600\n",
      "loss: 0.0603, lr: 0.0005, epoch: 2/9, step: 557/600\n",
      "loss: 0.0576, lr: 0.0005, epoch: 2/9, step: 558/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 2/9, step: 559/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 2/9, step: 560/600\n",
      "loss: 0.2661, lr: 0.0005, epoch: 2/9, step: 561/600\n",
      "loss: 0.5669, lr: 0.0005, epoch: 2/9, step: 562/600\n",
      "loss: 0.007, lr: 0.0005, epoch: 2/9, step: 563/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 2/9, step: 564/600\n",
      "loss: 0.1091, lr: 0.0005, epoch: 2/9, step: 565/600\n",
      "loss: 0.0182, lr: 0.0005, epoch: 2/9, step: 566/600\n",
      "loss: 0.1332, lr: 0.0005, epoch: 2/9, step: 567/600\n",
      "loss: 0.1324, lr: 0.0005, epoch: 2/9, step: 568/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 2/9, step: 569/600\n",
      "loss: 0.0565, lr: 0.0005, epoch: 2/9, step: 570/600\n",
      "loss: 0.0152, lr: 0.0005, epoch: 2/9, step: 571/600\n",
      "loss: 0.1212, lr: 0.0005, epoch: 2/9, step: 572/600\n",
      "loss: 0.035, lr: 0.0005, epoch: 2/9, step: 573/600\n",
      "loss: 0.0686, lr: 0.0005, epoch: 2/9, step: 574/600\n",
      "loss: 0.7588, lr: 0.0005, epoch: 2/9, step: 575/600\n",
      "loss: 0.0395, lr: 0.0005, epoch: 2/9, step: 576/600\n",
      "loss: 0.0536, lr: 0.0005, epoch: 2/9, step: 577/600\n",
      "loss: 0.0849, lr: 0.0005, epoch: 2/9, step: 578/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 2/9, step: 579/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 2/9, step: 580/600\n",
      "loss: 0.0324, lr: 0.0005, epoch: 2/9, step: 581/600\n",
      "loss: 0.1844, lr: 0.0005, epoch: 2/9, step: 582/600\n",
      "loss: 0.1376, lr: 0.0005, epoch: 2/9, step: 583/600\n",
      "loss: 0.4658, lr: 0.0005, epoch: 2/9, step: 584/600\n",
      "loss: 0.0101, lr: 0.0005, epoch: 2/9, step: 585/600\n",
      "loss: 0.107, lr: 0.0005, epoch: 2/9, step: 586/600\n",
      "loss: 0.1014, lr: 0.0005, epoch: 2/9, step: 587/600\n",
      "loss: 0.5547, lr: 0.0005, epoch: 2/9, step: 588/600\n",
      "loss: 0.0232, lr: 0.0005, epoch: 2/9, step: 589/600\n",
      "loss: 0.0556, lr: 0.0005, epoch: 2/9, step: 590/600\n",
      "loss: 0.4695, lr: 0.0005, epoch: 2/9, step: 591/600\n",
      "loss: 0.1438, lr: 0.0005, epoch: 2/9, step: 592/600\n",
      "loss: 0.2595, lr: 0.0005, epoch: 2/9, step: 593/600\n",
      "loss: 0.0179, lr: 0.0005, epoch: 2/9, step: 594/600\n",
      "loss: 0.1832, lr: 0.0005, epoch: 2/9, step: 595/600\n",
      "loss: 0.5234, lr: 0.0005, epoch: 2/9, step: 596/600\n",
      "loss: 0.0486, lr: 0.0005, epoch: 2/9, step: 597/600\n",
      "loss: 0.1688, lr: 0.0005, epoch: 2/9, step: 598/600\n",
      "loss: 0.0107, lr: 0.0005, epoch: 2/9, step: 599/600\n",
      "loss: 0.3494, lr: 0.0005, epoch: 2/9, step: 600/600\n",
      "loss: 0.0199, lr: 0.0005, epoch: 3/9, step: 1/600\n",
      "loss: 0.0224, lr: 0.0005, epoch: 3/9, step: 2/600\n",
      "loss: 0.2079, lr: 0.0005, epoch: 3/9, step: 3/600\n",
      "loss: 0.0319, lr: 0.0005, epoch: 3/9, step: 4/600\n",
      "loss: 0.0516, lr: 0.0005, epoch: 3/9, step: 5/600\n",
      "loss: 0.1512, lr: 0.0005, epoch: 3/9, step: 6/600\n",
      "loss: 0.0156, lr: 0.0005, epoch: 3/9, step: 7/600\n",
      "loss: 0.0153, lr: 0.0005, epoch: 3/9, step: 8/600\n",
      "loss: 0.2379, lr: 0.0005, epoch: 3/9, step: 9/600\n",
      "loss: 0.2428, lr: 0.0005, epoch: 3/9, step: 10/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 3/9, step: 11/600\n",
      "loss: 0.1081, lr: 0.0005, epoch: 3/9, step: 12/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 3/9, step: 13/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 3/9, step: 14/600\n",
      "loss: 0.2286, lr: 0.0005, epoch: 3/9, step: 15/600\n",
      "loss: 0.0423, lr: 0.0005, epoch: 3/9, step: 16/600\n",
      "loss: 0.072, lr: 0.0005, epoch: 3/9, step: 17/600\n",
      "loss: 0.0266, lr: 0.0005, epoch: 3/9, step: 18/600\n",
      "loss: 0.1343, lr: 0.0005, epoch: 3/9, step: 19/600\n",
      "loss: 0.04, lr: 0.0005, epoch: 3/9, step: 20/600\n",
      "loss: 0.0231, lr: 0.0005, epoch: 3/9, step: 21/600\n",
      "loss: 0.3013, lr: 0.0005, epoch: 3/9, step: 22/600\n",
      "loss: 0.1371, lr: 0.0005, epoch: 3/9, step: 23/600\n",
      "loss: 0.7109, lr: 0.0005, epoch: 3/9, step: 24/600\n",
      "loss: 0.2098, lr: 0.0005, epoch: 3/9, step: 25/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 3/9, step: 26/600\n",
      "loss: 0.406, lr: 0.0005, epoch: 3/9, step: 27/600\n",
      "loss: 0.2715, lr: 0.0005, epoch: 3/9, step: 28/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 3/9, step: 29/600\n",
      "loss: 0.1802, lr: 0.0005, epoch: 3/9, step: 30/600\n",
      "loss: 0.3872, lr: 0.0005, epoch: 3/9, step: 31/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 3/9, step: 32/600\n",
      "loss: 0.2878, lr: 0.0005, epoch: 3/9, step: 33/600\n",
      "loss: 0.2524, lr: 0.0005, epoch: 3/9, step: 34/600\n",
      "loss: 0.0051, lr: 0.0005, epoch: 3/9, step: 35/600\n",
      "loss: 0.0512, lr: 0.0005, epoch: 3/9, step: 36/600\n",
      "loss: 0.0232, lr: 0.0005, epoch: 3/9, step: 37/600\n",
      "loss: 0.0398, lr: 0.0005, epoch: 3/9, step: 38/600\n",
      "loss: 0.1486, lr: 0.0005, epoch: 3/9, step: 39/600\n",
      "loss: 0.311, lr: 0.0005, epoch: 3/9, step: 40/600\n",
      "loss: 0.6978, lr: 0.0005, epoch: 3/9, step: 41/600\n",
      "loss: 0.0437, lr: 0.0005, epoch: 3/9, step: 42/600\n",
      "loss: 0.353, lr: 0.0005, epoch: 3/9, step: 43/600\n",
      "loss: 0.3843, lr: 0.0005, epoch: 3/9, step: 44/600\n",
      "loss: 0.0312, lr: 0.0005, epoch: 3/9, step: 45/600\n",
      "loss: 0.8516, lr: 0.0005, epoch: 3/9, step: 46/600\n",
      "loss: 0.1571, lr: 0.0005, epoch: 3/9, step: 47/600\n",
      "loss: 0.0809, lr: 0.0005, epoch: 3/9, step: 48/600\n",
      "loss: 0.1616, lr: 0.0005, epoch: 3/9, step: 49/600\n",
      "loss: 0.4014, lr: 0.0005, epoch: 3/9, step: 50/600\n",
      "loss: 0.0248, lr: 0.0005, epoch: 3/9, step: 51/600\n",
      "loss: 0.0574, lr: 0.0005, epoch: 3/9, step: 52/600\n",
      "loss: 0.2522, lr: 0.0005, epoch: 3/9, step: 53/600\n",
      "loss: 0.0163, lr: 0.0005, epoch: 3/9, step: 54/600\n",
      "loss: 0.0515, lr: 0.0005, epoch: 3/9, step: 55/600\n",
      "loss: 0.7046, lr: 0.0005, epoch: 3/9, step: 56/600\n",
      "loss: 0.0973, lr: 0.0005, epoch: 3/9, step: 57/600\n",
      "loss: 0.1539, lr: 0.0005, epoch: 3/9, step: 58/600\n",
      "loss: 0.4451, lr: 0.0005, epoch: 3/9, step: 59/600\n",
      "loss: 0.2319, lr: 0.0005, epoch: 3/9, step: 60/600\n",
      "loss: 0.3174, lr: 0.0005, epoch: 3/9, step: 61/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 3/9, step: 62/600\n",
      "loss: 0.1422, lr: 0.0005, epoch: 3/9, step: 63/600\n",
      "loss: 0.5679, lr: 0.0005, epoch: 3/9, step: 64/600\n",
      "loss: 0.1823, lr: 0.0005, epoch: 3/9, step: 65/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 3/9, step: 66/600\n",
      "loss: 0.0789, lr: 0.0005, epoch: 3/9, step: 67/600\n",
      "loss: 0.5093, lr: 0.0005, epoch: 3/9, step: 68/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 3/9, step: 69/600\n",
      "loss: 0.353, lr: 0.0005, epoch: 3/9, step: 70/600\n",
      "loss: 0.0978, lr: 0.0005, epoch: 3/9, step: 71/600\n",
      "loss: 0.2411, lr: 0.0005, epoch: 3/9, step: 72/600\n",
      "loss: 0.2549, lr: 0.0005, epoch: 3/9, step: 73/600\n",
      "loss: 0.1768, lr: 0.0005, epoch: 3/9, step: 74/600\n",
      "loss: 0.0235, lr: 0.0005, epoch: 3/9, step: 75/600\n",
      "loss: 0.0998, lr: 0.0005, epoch: 3/9, step: 76/600\n",
      "loss: 0.0108, lr: 0.0005, epoch: 3/9, step: 77/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 3/9, step: 78/600\n",
      "loss: 0.0293, lr: 0.0005, epoch: 3/9, step: 79/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 3/9, step: 80/600\n",
      "loss: 0.0389, lr: 0.0005, epoch: 3/9, step: 81/600\n",
      "loss: 0.1364, lr: 0.0005, epoch: 3/9, step: 82/600\n",
      "loss: 0.0576, lr: 0.0005, epoch: 3/9, step: 83/600\n",
      "loss: 0.1262, lr: 0.0005, epoch: 3/9, step: 84/600\n",
      "loss: 0.2494, lr: 0.0005, epoch: 3/9, step: 85/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 3/9, step: 86/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 3/9, step: 87/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 3/9, step: 88/600\n",
      "loss: 0.1132, lr: 0.0005, epoch: 3/9, step: 89/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 3/9, step: 90/600\n",
      "loss: 0.3999, lr: 0.0005, epoch: 3/9, step: 91/600\n",
      "loss: 0.0055, lr: 0.0005, epoch: 3/9, step: 92/600\n",
      "loss: 0.2593, lr: 0.0005, epoch: 3/9, step: 93/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 3/9, step: 94/600\n",
      "loss: 0.0378, lr: 0.0005, epoch: 3/9, step: 95/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 3/9, step: 96/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 3/9, step: 97/600\n",
      "loss: 0.292, lr: 0.0005, epoch: 3/9, step: 98/600\n",
      "loss: 0.1278, lr: 0.0005, epoch: 3/9, step: 99/600\n",
      "loss: 0.3958, lr: 0.0005, epoch: 3/9, step: 100/600\n",
      "loss: 0.0103, lr: 0.0005, epoch: 3/9, step: 101/600\n",
      "loss: 0.1833, lr: 0.0005, epoch: 3/9, step: 102/600\n",
      "loss: 0.0199, lr: 0.0005, epoch: 3/9, step: 103/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 3/9, step: 104/600\n",
      "loss: 0.1978, lr: 0.0005, epoch: 3/9, step: 105/600\n",
      "loss: 0.1182, lr: 0.0005, epoch: 3/9, step: 106/600\n",
      "loss: 0.0191, lr: 0.0005, epoch: 3/9, step: 107/600\n",
      "loss: 0.4651, lr: 0.0005, epoch: 3/9, step: 108/600\n",
      "loss: 0.5776, lr: 0.0005, epoch: 3/9, step: 109/600\n",
      "loss: 0.2551, lr: 0.0005, epoch: 3/9, step: 110/600\n",
      "loss: 0.1628, lr: 0.0005, epoch: 3/9, step: 111/600\n",
      "loss: 0.332, lr: 0.0005, epoch: 3/9, step: 112/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 3/9, step: 113/600\n",
      "loss: 0.0418, lr: 0.0005, epoch: 3/9, step: 114/600\n",
      "loss: 0.3369, lr: 0.0005, epoch: 3/9, step: 115/600\n",
      "loss: 0.032, lr: 0.0005, epoch: 3/9, step: 116/600\n",
      "loss: 0.1433, lr: 0.0005, epoch: 3/9, step: 117/600\n",
      "loss: 0.2473, lr: 0.0005, epoch: 3/9, step: 118/600\n",
      "loss: 0.093, lr: 0.0005, epoch: 3/9, step: 119/600\n",
      "loss: 0.4211, lr: 0.0005, epoch: 3/9, step: 120/600\n",
      "loss: 0.0939, lr: 0.0005, epoch: 3/9, step: 121/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 3/9, step: 122/600\n",
      "loss: 0.1665, lr: 0.0005, epoch: 3/9, step: 123/600\n",
      "loss: 0.0192, lr: 0.0005, epoch: 3/9, step: 124/600\n",
      "loss: 0.025, lr: 0.0005, epoch: 3/9, step: 125/600\n",
      "loss: 0.0105, lr: 0.0005, epoch: 3/9, step: 126/600\n",
      "loss: 0.0402, lr: 0.0005, epoch: 3/9, step: 127/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 3/9, step: 128/600\n",
      "loss: 0.6113, lr: 0.0005, epoch: 3/9, step: 129/600\n",
      "loss: 0.0113, lr: 0.0005, epoch: 3/9, step: 130/600\n",
      "loss: 0.0574, lr: 0.0005, epoch: 3/9, step: 131/600\n",
      "loss: 0.1103, lr: 0.0005, epoch: 3/9, step: 132/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 3/9, step: 133/600\n",
      "loss: 0.0414, lr: 0.0005, epoch: 3/9, step: 134/600\n",
      "loss: 0.0824, lr: 0.0005, epoch: 3/9, step: 135/600\n",
      "loss: 0.4175, lr: 0.0005, epoch: 3/9, step: 136/600\n",
      "loss: 0.2056, lr: 0.0005, epoch: 3/9, step: 137/600\n",
      "loss: 0.3638, lr: 0.0005, epoch: 3/9, step: 138/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 3/9, step: 139/600\n",
      "loss: 0.0255, lr: 0.0005, epoch: 3/9, step: 140/600\n",
      "loss: 0.2649, lr: 0.0005, epoch: 3/9, step: 141/600\n",
      "loss: 0.017, lr: 0.0005, epoch: 3/9, step: 142/600\n",
      "loss: 0.4011, lr: 0.0005, epoch: 3/9, step: 143/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 3/9, step: 144/600\n",
      "loss: 0.0119, lr: 0.0005, epoch: 3/9, step: 145/600\n",
      "loss: 0.0288, lr: 0.0005, epoch: 3/9, step: 146/600\n",
      "loss: 0.302, lr: 0.0005, epoch: 3/9, step: 147/600\n",
      "loss: 0.21, lr: 0.0005, epoch: 3/9, step: 148/600\n",
      "loss: 0.141, lr: 0.0005, epoch: 3/9, step: 149/600\n",
      "loss: 0.0138, lr: 0.0005, epoch: 3/9, step: 150/600\n",
      "loss: 0.2969, lr: 0.0005, epoch: 3/9, step: 151/600\n",
      "loss: 0.174, lr: 0.0005, epoch: 3/9, step: 152/600\n",
      "loss: 0.5127, lr: 0.0005, epoch: 3/9, step: 153/600\n",
      "loss: 0.1569, lr: 0.0005, epoch: 3/9, step: 154/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 3/9, step: 155/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 3/9, step: 156/600\n",
      "loss: 0.2656, lr: 0.0005, epoch: 3/9, step: 157/600\n",
      "loss: 0.6299, lr: 0.0005, epoch: 3/9, step: 158/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 3/9, step: 159/600\n",
      "loss: 0.4163, lr: 0.0005, epoch: 3/9, step: 160/600\n",
      "loss: 0.0687, lr: 0.0005, epoch: 3/9, step: 161/600\n",
      "loss: 0.7959, lr: 0.0005, epoch: 3/9, step: 162/600\n",
      "loss: 0.1688, lr: 0.0005, epoch: 3/9, step: 163/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 3/9, step: 164/600\n",
      "loss: 0.0258, lr: 0.0005, epoch: 3/9, step: 165/600\n",
      "loss: 0.2172, lr: 0.0005, epoch: 3/9, step: 166/600\n",
      "loss: 0.1393, lr: 0.0005, epoch: 3/9, step: 167/600\n",
      "loss: 0.0178, lr: 0.0005, epoch: 3/9, step: 168/600\n",
      "loss: 0.1266, lr: 0.0005, epoch: 3/9, step: 169/600\n",
      "loss: 0.3906, lr: 0.0005, epoch: 3/9, step: 170/600\n",
      "loss: 0.0267, lr: 0.0005, epoch: 3/9, step: 171/600\n",
      "loss: 0.4109, lr: 0.0005, epoch: 3/9, step: 172/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 3/9, step: 173/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 3/9, step: 174/600\n",
      "loss: 0.54, lr: 0.0005, epoch: 3/9, step: 175/600\n",
      "loss: 0.8394, lr: 0.0005, epoch: 3/9, step: 176/600\n",
      "loss: 0.0571, lr: 0.0005, epoch: 3/9, step: 177/600\n",
      "loss: 0.2695, lr: 0.0005, epoch: 3/9, step: 178/600\n",
      "loss: 0.041, lr: 0.0005, epoch: 3/9, step: 179/600\n",
      "loss: 0.0427, lr: 0.0005, epoch: 3/9, step: 180/600\n",
      "loss: 0.2612, lr: 0.0005, epoch: 3/9, step: 181/600\n",
      "loss: 0.0168, lr: 0.0005, epoch: 3/9, step: 182/600\n",
      "loss: 0.2944, lr: 0.0005, epoch: 3/9, step: 183/600\n",
      "loss: 0.3828, lr: 0.0005, epoch: 3/9, step: 184/600\n",
      "loss: 0.666, lr: 0.0005, epoch: 3/9, step: 185/600\n",
      "loss: 0.5918, lr: 0.0005, epoch: 3/9, step: 186/600\n",
      "loss: 0.522, lr: 0.0005, epoch: 3/9, step: 187/600\n",
      "loss: 0.6592, lr: 0.0005, epoch: 3/9, step: 188/600\n",
      "loss: 0.2059, lr: 0.0005, epoch: 3/9, step: 189/600\n",
      "loss: 0.013, lr: 0.0005, epoch: 3/9, step: 190/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 3/9, step: 191/600\n",
      "loss: 0.151, lr: 0.0005, epoch: 3/9, step: 192/600\n",
      "loss: 0.0292, lr: 0.0005, epoch: 3/9, step: 193/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 3/9, step: 194/600\n",
      "loss: 0.1956, lr: 0.0005, epoch: 3/9, step: 195/600\n",
      "loss: 0.0117, lr: 0.0005, epoch: 3/9, step: 196/600\n",
      "loss: 0.0596, lr: 0.0005, epoch: 3/9, step: 197/600\n",
      "loss: 0.0197, lr: 0.0005, epoch: 3/9, step: 198/600\n",
      "loss: 0.0556, lr: 0.0005, epoch: 3/9, step: 199/600\n",
      "loss: 0.2433, lr: 0.0005, epoch: 3/9, step: 200/600\n",
      "loss: 0.1328, lr: 0.0005, epoch: 3/9, step: 201/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 3/9, step: 202/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 3/9, step: 203/600\n",
      "loss: 0.249, lr: 0.0005, epoch: 3/9, step: 204/600\n",
      "loss: 0.1746, lr: 0.0005, epoch: 3/9, step: 205/600\n",
      "loss: 0.1273, lr: 0.0005, epoch: 3/9, step: 206/600\n",
      "loss: 0.0116, lr: 0.0005, epoch: 3/9, step: 207/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 3/9, step: 208/600\n",
      "loss: 0.8696, lr: 0.0005, epoch: 3/9, step: 209/600\n",
      "loss: 0.0122, lr: 0.0005, epoch: 3/9, step: 210/600\n",
      "loss: 0.1052, lr: 0.0005, epoch: 3/9, step: 211/600\n",
      "loss: 0.0069, lr: 0.0005, epoch: 3/9, step: 212/600\n",
      "loss: 0.2815, lr: 0.0005, epoch: 3/9, step: 213/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 3/9, step: 214/600\n",
      "loss: 0.2485, lr: 0.0005, epoch: 3/9, step: 215/600\n",
      "loss: 0.0207, lr: 0.0005, epoch: 3/9, step: 216/600\n",
      "loss: 0.0739, lr: 0.0005, epoch: 3/9, step: 217/600\n",
      "loss: 0.2671, lr: 0.0005, epoch: 3/9, step: 218/600\n",
      "loss: 0.4009, lr: 0.0005, epoch: 3/9, step: 219/600\n",
      "loss: 0.2881, lr: 0.0005, epoch: 3/9, step: 220/600\n",
      "loss: 0.2937, lr: 0.0005, epoch: 3/9, step: 221/600\n",
      "loss: 0.2462, lr: 0.0005, epoch: 3/9, step: 222/600\n",
      "loss: 0.085, lr: 0.0005, epoch: 3/9, step: 223/600\n",
      "loss: 0.4221, lr: 0.0005, epoch: 3/9, step: 224/600\n",
      "loss: 0.2556, lr: 0.0005, epoch: 3/9, step: 225/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 3/9, step: 226/600\n",
      "loss: 0.3594, lr: 0.0005, epoch: 3/9, step: 227/600\n",
      "loss: 0.4697, lr: 0.0005, epoch: 3/9, step: 228/600\n",
      "loss: 0.418, lr: 0.0005, epoch: 3/9, step: 229/600\n",
      "loss: 0.0921, lr: 0.0005, epoch: 3/9, step: 230/600\n",
      "loss: 0.2467, lr: 0.0005, epoch: 3/9, step: 231/600\n",
      "loss: 0.3047, lr: 0.0005, epoch: 3/9, step: 232/600\n",
      "loss: 0.2463, lr: 0.0005, epoch: 3/9, step: 233/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 3/9, step: 234/600\n",
      "loss: 0.0138, lr: 0.0005, epoch: 3/9, step: 235/600\n",
      "loss: 0.5845, lr: 0.0005, epoch: 3/9, step: 236/600\n",
      "loss: 0.5552, lr: 0.0005, epoch: 3/9, step: 237/600\n",
      "loss: 0.0138, lr: 0.0005, epoch: 3/9, step: 238/600\n",
      "loss: 0.4705, lr: 0.0005, epoch: 3/9, step: 239/600\n",
      "loss: 0.3274, lr: 0.0005, epoch: 3/9, step: 240/600\n",
      "loss: 0.0366, lr: 0.0005, epoch: 3/9, step: 241/600\n",
      "loss: 0.1044, lr: 0.0005, epoch: 3/9, step: 242/600\n",
      "loss: 0.0162, lr: 0.0005, epoch: 3/9, step: 243/600\n",
      "loss: 0.007, lr: 0.0005, epoch: 3/9, step: 244/600\n",
      "loss: 0.093, lr: 0.0005, epoch: 3/9, step: 245/600\n",
      "loss: 0.1719, lr: 0.0005, epoch: 3/9, step: 246/600\n",
      "loss: 0.7314, lr: 0.0005, epoch: 3/9, step: 247/600\n",
      "loss: 0.0213, lr: 0.0005, epoch: 3/9, step: 248/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 3/9, step: 249/600\n",
      "loss: 0.6357, lr: 0.0005, epoch: 3/9, step: 250/600\n",
      "loss: 0.0196, lr: 0.0005, epoch: 3/9, step: 251/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 3/9, step: 252/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 3/9, step: 253/600\n",
      "loss: 0.3184, lr: 0.0005, epoch: 3/9, step: 254/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 3/9, step: 255/600\n",
      "loss: 0.1187, lr: 0.0005, epoch: 3/9, step: 256/600\n",
      "loss: 0.4531, lr: 0.0005, epoch: 3/9, step: 257/600\n",
      "loss: 0.0848, lr: 0.0005, epoch: 3/9, step: 258/600\n",
      "loss: 0.2179, lr: 0.0005, epoch: 3/9, step: 259/600\n",
      "loss: 0.5635, lr: 0.0005, epoch: 3/9, step: 260/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 3/9, step: 261/600\n",
      "loss: 0.0481, lr: 0.0005, epoch: 3/9, step: 262/600\n",
      "loss: 0.8237, lr: 0.0005, epoch: 3/9, step: 263/600\n",
      "loss: 0.1, lr: 0.0005, epoch: 3/9, step: 264/600\n",
      "loss: 0.0279, lr: 0.0005, epoch: 3/9, step: 265/600\n",
      "loss: 0.1112, lr: 0.0005, epoch: 3/9, step: 266/600\n",
      "loss: 0.2186, lr: 0.0005, epoch: 3/9, step: 267/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 3/9, step: 268/600\n",
      "loss: 0.046, lr: 0.0005, epoch: 3/9, step: 269/600\n",
      "loss: 0.11, lr: 0.0005, epoch: 3/9, step: 270/600\n",
      "loss: 0.0495, lr: 0.0005, epoch: 3/9, step: 271/600\n",
      "loss: 0.0211, lr: 0.0005, epoch: 3/9, step: 272/600\n",
      "loss: 0.0241, lr: 0.0005, epoch: 3/9, step: 273/600\n",
      "loss: 0.0735, lr: 0.0005, epoch: 3/9, step: 274/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 3/9, step: 275/600\n",
      "loss: 0.0281, lr: 0.0005, epoch: 3/9, step: 276/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 3/9, step: 277/600\n",
      "loss: 0.0894, lr: 0.0005, epoch: 3/9, step: 278/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 3/9, step: 279/600\n",
      "loss: 0.3367, lr: 0.0005, epoch: 3/9, step: 280/600\n",
      "loss: 0.1947, lr: 0.0005, epoch: 3/9, step: 281/600\n",
      "loss: 0.0563, lr: 0.0005, epoch: 3/9, step: 282/600\n",
      "loss: 0.0121, lr: 0.0005, epoch: 3/9, step: 283/600\n",
      "loss: 0.1809, lr: 0.0005, epoch: 3/9, step: 284/600\n",
      "loss: 0.2883, lr: 0.0005, epoch: 3/9, step: 285/600\n",
      "loss: 0.1224, lr: 0.0005, epoch: 3/9, step: 286/600\n",
      "loss: 0.2097, lr: 0.0005, epoch: 3/9, step: 287/600\n",
      "loss: 0.3059, lr: 0.0005, epoch: 3/9, step: 288/600\n",
      "loss: 0.2834, lr: 0.0005, epoch: 3/9, step: 289/600\n",
      "loss: 0.0824, lr: 0.0005, epoch: 3/9, step: 290/600\n",
      "loss: 0.0413, lr: 0.0005, epoch: 3/9, step: 291/600\n",
      "loss: 0.0574, lr: 0.0005, epoch: 3/9, step: 292/600\n",
      "loss: 0.2834, lr: 0.0005, epoch: 3/9, step: 293/600\n",
      "loss: 0.0369, lr: 0.0005, epoch: 3/9, step: 294/600\n",
      "loss: 0.4724, lr: 0.0005, epoch: 3/9, step: 295/600\n",
      "loss: 0.1604, lr: 0.0005, epoch: 3/9, step: 296/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 3/9, step: 297/600\n",
      "loss: 0.1842, lr: 0.0005, epoch: 3/9, step: 298/600\n",
      "loss: 0.4993, lr: 0.0005, epoch: 3/9, step: 299/600\n",
      "loss: 0.0216, lr: 0.0005, epoch: 3/9, step: 300/600\n",
      "loss: 0.0176, lr: 0.0005, epoch: 3/9, step: 301/600\n",
      "loss: 0.1469, lr: 0.0005, epoch: 3/9, step: 302/600\n",
      "loss: 0.0294, lr: 0.0005, epoch: 3/9, step: 303/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 3/9, step: 304/600\n",
      "loss: 0.4404, lr: 0.0005, epoch: 3/9, step: 305/600\n",
      "loss: 0.0571, lr: 0.0005, epoch: 3/9, step: 306/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 3/9, step: 307/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 3/9, step: 308/600\n",
      "loss: 0.0635, lr: 0.0005, epoch: 3/9, step: 309/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 3/9, step: 310/600\n",
      "loss: 0.0083, lr: 0.0005, epoch: 3/9, step: 311/600\n",
      "loss: 0.0486, lr: 0.0005, epoch: 3/9, step: 312/600\n",
      "loss: 0.2935, lr: 0.0005, epoch: 3/9, step: 313/600\n",
      "loss: 0.0187, lr: 0.0005, epoch: 3/9, step: 314/600\n",
      "loss: 0.1256, lr: 0.0005, epoch: 3/9, step: 315/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 3/9, step: 316/600\n",
      "loss: 0.0441, lr: 0.0005, epoch: 3/9, step: 317/600\n",
      "loss: 0.1443, lr: 0.0005, epoch: 3/9, step: 318/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 3/9, step: 319/600\n",
      "loss: 0.054, lr: 0.0005, epoch: 3/9, step: 320/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 3/9, step: 321/600\n",
      "loss: 0.2197, lr: 0.0005, epoch: 3/9, step: 322/600\n",
      "loss: 0.0202, lr: 0.0005, epoch: 3/9, step: 323/600\n",
      "loss: 0.6606, lr: 0.0005, epoch: 3/9, step: 324/600\n",
      "loss: 0.5742, lr: 0.0005, epoch: 3/9, step: 325/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 3/9, step: 326/600\n",
      "loss: 0.3684, lr: 0.0005, epoch: 3/9, step: 327/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 3/9, step: 328/600\n",
      "loss: 0.271, lr: 0.0005, epoch: 3/9, step: 329/600\n",
      "loss: 0.3137, lr: 0.0005, epoch: 3/9, step: 330/600\n",
      "loss: 0.0123, lr: 0.0005, epoch: 3/9, step: 331/600\n",
      "loss: 0.0613, lr: 0.0005, epoch: 3/9, step: 332/600\n",
      "loss: 0.0147, lr: 0.0005, epoch: 3/9, step: 333/600\n",
      "loss: 0.0848, lr: 0.0005, epoch: 3/9, step: 334/600\n",
      "loss: 0.0403, lr: 0.0005, epoch: 3/9, step: 335/600\n",
      "loss: 0.6484, lr: 0.0005, epoch: 3/9, step: 336/600\n",
      "loss: 0.0749, lr: 0.0005, epoch: 3/9, step: 337/600\n",
      "loss: 0.0839, lr: 0.0005, epoch: 3/9, step: 338/600\n",
      "loss: 0.1088, lr: 0.0005, epoch: 3/9, step: 339/600\n",
      "loss: 0.0677, lr: 0.0005, epoch: 3/9, step: 340/600\n",
      "loss: 0.6616, lr: 0.0005, epoch: 3/9, step: 341/600\n",
      "loss: 0.2695, lr: 0.0005, epoch: 3/9, step: 342/600\n",
      "loss: 0.4829, lr: 0.0005, epoch: 3/9, step: 343/600\n",
      "loss: 0.9434, lr: 0.0005, epoch: 3/9, step: 344/600\n",
      "loss: 0.0344, lr: 0.0005, epoch: 3/9, step: 345/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 3/9, step: 346/600\n",
      "loss: 0.0375, lr: 0.0005, epoch: 3/9, step: 347/600\n",
      "loss: 0.5215, lr: 0.0005, epoch: 3/9, step: 348/600\n",
      "loss: 0.3037, lr: 0.0005, epoch: 3/9, step: 349/600\n",
      "loss: 0.1844, lr: 0.0005, epoch: 3/9, step: 350/600\n",
      "loss: 0.114, lr: 0.0005, epoch: 3/9, step: 351/600\n",
      "loss: 0.0513, lr: 0.0005, epoch: 3/9, step: 352/600\n",
      "loss: 0.0237, lr: 0.0005, epoch: 3/9, step: 353/600\n",
      "loss: 0.0611, lr: 0.0005, epoch: 3/9, step: 354/600\n",
      "loss: 0.3394, lr: 0.0005, epoch: 3/9, step: 355/600\n",
      "loss: 0.1072, lr: 0.0005, epoch: 3/9, step: 356/600\n",
      "loss: 0.0376, lr: 0.0005, epoch: 3/9, step: 357/600\n",
      "loss: 0.3606, lr: 0.0005, epoch: 3/9, step: 358/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 3/9, step: 359/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 3/9, step: 360/600\n",
      "loss: 0.6611, lr: 0.0005, epoch: 3/9, step: 361/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 3/9, step: 362/600\n",
      "loss: 0.021, lr: 0.0005, epoch: 3/9, step: 363/600\n",
      "loss: 0.011, lr: 0.0005, epoch: 3/9, step: 364/600\n",
      "loss: 0.0191, lr: 0.0005, epoch: 3/9, step: 365/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 3/9, step: 366/600\n",
      "loss: 0.0079, lr: 0.0005, epoch: 3/9, step: 367/600\n",
      "loss: 0.4202, lr: 0.0005, epoch: 3/9, step: 368/600\n",
      "loss: 0.1267, lr: 0.0005, epoch: 3/9, step: 369/600\n",
      "loss: 0.5889, lr: 0.0005, epoch: 3/9, step: 370/600\n",
      "loss: 0.3857, lr: 0.0005, epoch: 3/9, step: 371/600\n",
      "loss: 0.0851, lr: 0.0005, epoch: 3/9, step: 372/600\n",
      "loss: 0.0222, lr: 0.0005, epoch: 3/9, step: 373/600\n",
      "loss: 0.024, lr: 0.0005, epoch: 3/9, step: 374/600\n",
      "loss: 0.1694, lr: 0.0005, epoch: 3/9, step: 375/600\n",
      "loss: 0.2585, lr: 0.0005, epoch: 3/9, step: 376/600\n",
      "loss: 0.5747, lr: 0.0005, epoch: 3/9, step: 377/600\n",
      "loss: 0.2311, lr: 0.0005, epoch: 3/9, step: 378/600\n",
      "loss: 0.2932, lr: 0.0005, epoch: 3/9, step: 379/600\n",
      "loss: 0.0909, lr: 0.0005, epoch: 3/9, step: 380/600\n",
      "loss: 0.1945, lr: 0.0005, epoch: 3/9, step: 381/600\n",
      "loss: 0.1975, lr: 0.0005, epoch: 3/9, step: 382/600\n",
      "loss: 0.6665, lr: 0.0005, epoch: 3/9, step: 383/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 3/9, step: 384/600\n",
      "loss: 0.1561, lr: 0.0005, epoch: 3/9, step: 385/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 3/9, step: 386/600\n",
      "loss: 0.0839, lr: 0.0005, epoch: 3/9, step: 387/600\n",
      "loss: 0.0447, lr: 0.0005, epoch: 3/9, step: 388/600\n",
      "loss: 0.5732, lr: 0.0005, epoch: 3/9, step: 389/600\n",
      "loss: 0.2434, lr: 0.0005, epoch: 3/9, step: 390/600\n",
      "loss: 0.1799, lr: 0.0005, epoch: 3/9, step: 391/600\n",
      "loss: 0.1901, lr: 0.0005, epoch: 3/9, step: 392/600\n",
      "loss: 0.071, lr: 0.0005, epoch: 3/9, step: 393/600\n",
      "loss: 0.0128, lr: 0.0005, epoch: 3/9, step: 394/600\n",
      "loss: 0.0367, lr: 0.0005, epoch: 3/9, step: 395/600\n",
      "loss: 0.1979, lr: 0.0005, epoch: 3/9, step: 396/600\n",
      "loss: 0.4482, lr: 0.0005, epoch: 3/9, step: 397/600\n",
      "loss: 0.2903, lr: 0.0005, epoch: 3/9, step: 398/600\n",
      "loss: 0.3105, lr: 0.0005, epoch: 3/9, step: 399/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 3/9, step: 400/600\n",
      "loss: 0.1007, lr: 0.0005, epoch: 3/9, step: 401/600\n",
      "loss: 0.0988, lr: 0.0005, epoch: 3/9, step: 402/600\n",
      "loss: 0.1766, lr: 0.0005, epoch: 3/9, step: 403/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 3/9, step: 404/600\n",
      "loss: 0.0119, lr: 0.0005, epoch: 3/9, step: 405/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 3/9, step: 406/600\n",
      "loss: 0.1415, lr: 0.0005, epoch: 3/9, step: 407/600\n",
      "loss: 0.4216, lr: 0.0005, epoch: 3/9, step: 408/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 3/9, step: 409/600\n",
      "loss: 0.2301, lr: 0.0005, epoch: 3/9, step: 410/600\n",
      "loss: 0.0079, lr: 0.0005, epoch: 3/9, step: 411/600\n",
      "loss: 0.0586, lr: 0.0005, epoch: 3/9, step: 412/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 3/9, step: 413/600\n",
      "loss: 0.1335, lr: 0.0005, epoch: 3/9, step: 414/600\n",
      "loss: 0.0205, lr: 0.0005, epoch: 3/9, step: 415/600\n",
      "loss: 0.0233, lr: 0.0005, epoch: 3/9, step: 416/600\n",
      "loss: 0.2216, lr: 0.0005, epoch: 3/9, step: 417/600\n",
      "loss: 0.0296, lr: 0.0005, epoch: 3/9, step: 418/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 3/9, step: 419/600\n",
      "loss: 0.3127, lr: 0.0005, epoch: 3/9, step: 420/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 3/9, step: 421/600\n",
      "loss: 0.0547, lr: 0.0005, epoch: 3/9, step: 422/600\n",
      "loss: 0.2474, lr: 0.0005, epoch: 3/9, step: 423/600\n",
      "loss: 0.0255, lr: 0.0005, epoch: 3/9, step: 424/600\n",
      "loss: 0.0089, lr: 0.0005, epoch: 3/9, step: 425/600\n",
      "loss: 0.0658, lr: 0.0005, epoch: 3/9, step: 426/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 3/9, step: 427/600\n",
      "loss: 0.0534, lr: 0.0005, epoch: 3/9, step: 428/600\n",
      "loss: 0.244, lr: 0.0005, epoch: 3/9, step: 429/600\n",
      "loss: 0.0324, lr: 0.0005, epoch: 3/9, step: 430/600\n",
      "loss: 0.0147, lr: 0.0005, epoch: 3/9, step: 431/600\n",
      "loss: 0.6538, lr: 0.0005, epoch: 3/9, step: 432/600\n",
      "loss: 0.0864, lr: 0.0005, epoch: 3/9, step: 433/600\n",
      "loss: 0.6812, lr: 0.0005, epoch: 3/9, step: 434/600\n",
      "loss: 0.0191, lr: 0.0005, epoch: 3/9, step: 435/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 3/9, step: 436/600\n",
      "loss: 0.2089, lr: 0.0005, epoch: 3/9, step: 437/600\n",
      "loss: 0.3547, lr: 0.0005, epoch: 3/9, step: 438/600\n",
      "loss: 0.5767, lr: 0.0005, epoch: 3/9, step: 439/600\n",
      "loss: 0.028, lr: 0.0005, epoch: 3/9, step: 440/600\n",
      "loss: 0.2686, lr: 0.0005, epoch: 3/9, step: 441/600\n",
      "loss: 0.7285, lr: 0.0005, epoch: 3/9, step: 442/600\n",
      "loss: 0.582, lr: 0.0005, epoch: 3/9, step: 443/600\n",
      "loss: 0.0051, lr: 0.0005, epoch: 3/9, step: 444/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 3/9, step: 445/600\n",
      "loss: 0.0533, lr: 0.0005, epoch: 3/9, step: 446/600\n",
      "loss: 0.1125, lr: 0.0005, epoch: 3/9, step: 447/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 3/9, step: 448/600\n",
      "loss: 0.1804, lr: 0.0005, epoch: 3/9, step: 449/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 3/9, step: 450/600\n",
      "loss: 0.0074, lr: 0.0005, epoch: 3/9, step: 451/600\n",
      "loss: 0.1255, lr: 0.0005, epoch: 3/9, step: 452/600\n",
      "loss: 0.7153, lr: 0.0005, epoch: 3/9, step: 453/600\n",
      "loss: 0.4045, lr: 0.0005, epoch: 3/9, step: 454/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 3/9, step: 455/600\n",
      "loss: 0.0472, lr: 0.0005, epoch: 3/9, step: 456/600\n",
      "loss: 0.344, lr: 0.0005, epoch: 3/9, step: 457/600\n",
      "loss: 0.1372, lr: 0.0005, epoch: 3/9, step: 458/600\n",
      "loss: 0.0725, lr: 0.0005, epoch: 3/9, step: 459/600\n",
      "loss: 0.2042, lr: 0.0005, epoch: 3/9, step: 460/600\n",
      "loss: 0.0225, lr: 0.0005, epoch: 3/9, step: 461/600\n",
      "loss: 0.6909, lr: 0.0005, epoch: 3/9, step: 462/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 3/9, step: 463/600\n",
      "loss: 0.03, lr: 0.0005, epoch: 3/9, step: 464/600\n",
      "loss: 0.0837, lr: 0.0005, epoch: 3/9, step: 465/600\n",
      "loss: 0.7134, lr: 0.0005, epoch: 3/9, step: 466/600\n",
      "loss: 0.1066, lr: 0.0005, epoch: 3/9, step: 467/600\n",
      "loss: 0.0094, lr: 0.0005, epoch: 3/9, step: 468/600\n",
      "loss: 0.0174, lr: 0.0005, epoch: 3/9, step: 469/600\n",
      "loss: 0.3025, lr: 0.0005, epoch: 3/9, step: 470/600\n",
      "loss: 0.0595, lr: 0.0005, epoch: 3/9, step: 471/600\n",
      "loss: 0.2212, lr: 0.0005, epoch: 3/9, step: 472/600\n",
      "loss: 0.1234, lr: 0.0005, epoch: 3/9, step: 473/600\n",
      "loss: 0.1437, lr: 0.0005, epoch: 3/9, step: 474/600\n",
      "loss: 0.3247, lr: 0.0005, epoch: 3/9, step: 475/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 3/9, step: 476/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 3/9, step: 477/600\n",
      "loss: 0.021, lr: 0.0005, epoch: 3/9, step: 478/600\n",
      "loss: 0.1027, lr: 0.0005, epoch: 3/9, step: 479/600\n",
      "loss: 0.1849, lr: 0.0005, epoch: 3/9, step: 480/600\n",
      "loss: 0.0733, lr: 0.0005, epoch: 3/9, step: 481/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 3/9, step: 482/600\n",
      "loss: 0.6978, lr: 0.0005, epoch: 3/9, step: 483/600\n",
      "loss: 0.0497, lr: 0.0005, epoch: 3/9, step: 484/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 3/9, step: 485/600\n",
      "loss: 0.0748, lr: 0.0005, epoch: 3/9, step: 486/600\n",
      "loss: 0.1691, lr: 0.0005, epoch: 3/9, step: 487/600\n",
      "loss: 0.0961, lr: 0.0005, epoch: 3/9, step: 488/600\n",
      "loss: 0.0927, lr: 0.0005, epoch: 3/9, step: 489/600\n",
      "loss: 0.2452, lr: 0.0005, epoch: 3/9, step: 490/600\n",
      "loss: 0.3123, lr: 0.0005, epoch: 3/9, step: 491/600\n",
      "loss: 0.2059, lr: 0.0005, epoch: 3/9, step: 492/600\n",
      "loss: 0.155, lr: 0.0005, epoch: 3/9, step: 493/600\n",
      "loss: 0.0318, lr: 0.0005, epoch: 3/9, step: 494/600\n",
      "loss: 0.0239, lr: 0.0005, epoch: 3/9, step: 495/600\n",
      "loss: 0.2102, lr: 0.0005, epoch: 3/9, step: 496/600\n",
      "loss: 0.0208, lr: 0.0005, epoch: 3/9, step: 497/600\n",
      "loss: 0.012, lr: 0.0005, epoch: 3/9, step: 498/600\n",
      "loss: 0.0505, lr: 0.0005, epoch: 3/9, step: 499/600\n",
      "loss: 0.2245, lr: 0.0005, epoch: 3/9, step: 500/600\n",
      "loss: 0.024, lr: 0.0005, epoch: 3/9, step: 501/600\n",
      "loss: 0.0435, lr: 0.0005, epoch: 3/9, step: 502/600\n",
      "loss: 0.4421, lr: 0.0005, epoch: 3/9, step: 503/600\n",
      "loss: 0.0914, lr: 0.0005, epoch: 3/9, step: 504/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 3/9, step: 505/600\n",
      "loss: 0.4504, lr: 0.0005, epoch: 3/9, step: 506/600\n",
      "loss: 0.2181, lr: 0.0005, epoch: 3/9, step: 507/600\n",
      "loss: 0.2368, lr: 0.0005, epoch: 3/9, step: 508/600\n",
      "loss: 0.0419, lr: 0.0005, epoch: 3/9, step: 509/600\n",
      "loss: 0.4534, lr: 0.0005, epoch: 3/9, step: 510/600\n",
      "loss: 0.5259, lr: 0.0005, epoch: 3/9, step: 511/600\n",
      "loss: 0.1104, lr: 0.0005, epoch: 3/9, step: 512/600\n",
      "loss: 0.163, lr: 0.0005, epoch: 3/9, step: 513/600\n",
      "loss: 0.0247, lr: 0.0005, epoch: 3/9, step: 514/600\n",
      "loss: 0.2664, lr: 0.0005, epoch: 3/9, step: 515/600\n",
      "loss: 0.7788, lr: 0.0005, epoch: 3/9, step: 516/600\n",
      "loss: 0.6104, lr: 0.0005, epoch: 3/9, step: 517/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 3/9, step: 518/600\n",
      "loss: 0.3433, lr: 0.0005, epoch: 3/9, step: 519/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 3/9, step: 520/600\n",
      "loss: 0.2742, lr: 0.0005, epoch: 3/9, step: 521/600\n",
      "loss: 0.4045, lr: 0.0005, epoch: 3/9, step: 522/600\n",
      "loss: 0.4675, lr: 0.0005, epoch: 3/9, step: 523/600\n",
      "loss: 0.7271, lr: 0.0005, epoch: 3/9, step: 524/600\n",
      "loss: 0.0298, lr: 0.0005, epoch: 3/9, step: 525/600\n",
      "loss: 0.1461, lr: 0.0005, epoch: 3/9, step: 526/600\n",
      "loss: 0.0901, lr: 0.0005, epoch: 3/9, step: 527/600\n",
      "loss: 0.334, lr: 0.0005, epoch: 3/9, step: 528/600\n",
      "loss: 0.0284, lr: 0.0005, epoch: 3/9, step: 529/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 3/9, step: 530/600\n",
      "loss: 0.2266, lr: 0.0005, epoch: 3/9, step: 531/600\n",
      "loss: 0.3137, lr: 0.0005, epoch: 3/9, step: 532/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 3/9, step: 533/600\n",
      "loss: 0.5015, lr: 0.0005, epoch: 3/9, step: 534/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 3/9, step: 535/600\n",
      "loss: 0.1033, lr: 0.0005, epoch: 3/9, step: 536/600\n",
      "loss: 0.0275, lr: 0.0005, epoch: 3/9, step: 537/600\n",
      "loss: 0.3413, lr: 0.0005, epoch: 3/9, step: 538/600\n",
      "loss: 0.2576, lr: 0.0005, epoch: 3/9, step: 539/600\n",
      "loss: 0.0314, lr: 0.0005, epoch: 3/9, step: 540/600\n",
      "loss: 0.4438, lr: 0.0005, epoch: 3/9, step: 541/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 3/9, step: 542/600\n",
      "loss: 0.3389, lr: 0.0005, epoch: 3/9, step: 543/600\n",
      "loss: 0.6123, lr: 0.0005, epoch: 3/9, step: 544/600\n",
      "loss: 0.2905, lr: 0.0005, epoch: 3/9, step: 545/600\n",
      "loss: 0.0341, lr: 0.0005, epoch: 3/9, step: 546/600\n",
      "loss: 0.3853, lr: 0.0005, epoch: 3/9, step: 547/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 3/9, step: 548/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 3/9, step: 549/600\n",
      "loss: 0.752, lr: 0.0005, epoch: 3/9, step: 550/600\n",
      "loss: 0.0494, lr: 0.0005, epoch: 3/9, step: 551/600\n",
      "loss: 0.458, lr: 0.0005, epoch: 3/9, step: 552/600\n",
      "loss: 0.0399, lr: 0.0005, epoch: 3/9, step: 553/600\n",
      "loss: 0.0107, lr: 0.0005, epoch: 3/9, step: 554/600\n",
      "loss: 0.6821, lr: 0.0005, epoch: 3/9, step: 555/600\n",
      "loss: 0.2498, lr: 0.0005, epoch: 3/9, step: 556/600\n",
      "loss: 0.0112, lr: 0.0005, epoch: 3/9, step: 557/600\n",
      "loss: 0.0469, lr: 0.0005, epoch: 3/9, step: 558/600\n",
      "loss: 0.0232, lr: 0.0005, epoch: 3/9, step: 559/600\n",
      "loss: 0.1624, lr: 0.0005, epoch: 3/9, step: 560/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 3/9, step: 561/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 3/9, step: 562/600\n",
      "loss: 0.3787, lr: 0.0005, epoch: 3/9, step: 563/600\n",
      "loss: 0.7422, lr: 0.0005, epoch: 3/9, step: 564/600\n",
      "loss: 0.2488, lr: 0.0005, epoch: 3/9, step: 565/600\n",
      "loss: 0.0271, lr: 0.0005, epoch: 3/9, step: 566/600\n",
      "loss: 0.416, lr: 0.0005, epoch: 3/9, step: 567/600\n",
      "loss: 0.6465, lr: 0.0005, epoch: 3/9, step: 568/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 3/9, step: 569/600\n",
      "loss: 0.0091, lr: 0.0005, epoch: 3/9, step: 570/600\n",
      "loss: 0.0445, lr: 0.0005, epoch: 3/9, step: 571/600\n",
      "loss: 0.0403, lr: 0.0005, epoch: 3/9, step: 572/600\n",
      "loss: 0.1841, lr: 0.0005, epoch: 3/9, step: 573/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 3/9, step: 574/600\n",
      "loss: 0.2583, lr: 0.0005, epoch: 3/9, step: 575/600\n",
      "loss: 0.0123, lr: 0.0005, epoch: 3/9, step: 576/600\n",
      "loss: 0.4524, lr: 0.0005, epoch: 3/9, step: 577/600\n",
      "loss: 0.5146, lr: 0.0005, epoch: 3/9, step: 578/600\n",
      "loss: 0.0283, lr: 0.0005, epoch: 3/9, step: 579/600\n",
      "loss: 0.2361, lr: 0.0005, epoch: 3/9, step: 580/600\n",
      "loss: 0.3831, lr: 0.0005, epoch: 3/9, step: 581/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 3/9, step: 582/600\n",
      "loss: 0.2336, lr: 0.0005, epoch: 3/9, step: 583/600\n",
      "loss: 0.6587, lr: 0.0005, epoch: 3/9, step: 584/600\n",
      "loss: 0.1984, lr: 0.0005, epoch: 3/9, step: 585/600\n",
      "loss: 0.3103, lr: 0.0005, epoch: 3/9, step: 586/600\n",
      "loss: 0.1589, lr: 0.0005, epoch: 3/9, step: 587/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 3/9, step: 588/600\n",
      "loss: 0.8242, lr: 0.0005, epoch: 3/9, step: 589/600\n",
      "loss: 0.1475, lr: 0.0005, epoch: 3/9, step: 590/600\n",
      "loss: 0.0209, lr: 0.0005, epoch: 3/9, step: 591/600\n",
      "loss: 0.4297, lr: 0.0005, epoch: 3/9, step: 592/600\n",
      "loss: 0.2581, lr: 0.0005, epoch: 3/9, step: 593/600\n",
      "loss: 0.52, lr: 0.0005, epoch: 3/9, step: 594/600\n",
      "loss: 0.0589, lr: 0.0005, epoch: 3/9, step: 595/600\n",
      "loss: 0.1688, lr: 0.0005, epoch: 3/9, step: 596/600\n",
      "loss: 0.4971, lr: 0.0005, epoch: 3/9, step: 597/600\n",
      "loss: 0.0237, lr: 0.0005, epoch: 3/9, step: 598/600\n",
      "loss: 0.6836, lr: 0.0005, epoch: 3/9, step: 599/600\n",
      "loss: 0.0234, lr: 0.0005, epoch: 3/9, step: 600/600\n",
      "loss: 0.448, lr: 0.0005, epoch: 4/9, step: 1/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 4/9, step: 2/600\n",
      "loss: 0.0246, lr: 0.0005, epoch: 4/9, step: 3/600\n",
      "loss: 0.1527, lr: 0.0005, epoch: 4/9, step: 4/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 4/9, step: 5/600\n",
      "loss: 0.2279, lr: 0.0005, epoch: 4/9, step: 6/600\n",
      "loss: 0.2328, lr: 0.0005, epoch: 4/9, step: 7/600\n",
      "loss: 0.1371, lr: 0.0005, epoch: 4/9, step: 8/600\n",
      "loss: 0.2573, lr: 0.0005, epoch: 4/9, step: 9/600\n",
      "loss: 0.1327, lr: 0.0005, epoch: 4/9, step: 10/600\n",
      "loss: 0.5176, lr: 0.0005, epoch: 4/9, step: 11/600\n",
      "loss: 0.0439, lr: 0.0005, epoch: 4/9, step: 12/600\n",
      "loss: 0.0248, lr: 0.0005, epoch: 4/9, step: 13/600\n",
      "loss: 0.1198, lr: 0.0005, epoch: 4/9, step: 14/600\n",
      "loss: 0.0464, lr: 0.0005, epoch: 4/9, step: 15/600\n",
      "loss: 0.2893, lr: 0.0005, epoch: 4/9, step: 16/600\n",
      "loss: 0.1169, lr: 0.0005, epoch: 4/9, step: 17/600\n",
      "loss: 0.2944, lr: 0.0005, epoch: 4/9, step: 18/600\n",
      "loss: 0.1234, lr: 0.0005, epoch: 4/9, step: 19/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 4/9, step: 20/600\n",
      "loss: 0.5161, lr: 0.0005, epoch: 4/9, step: 21/600\n",
      "loss: 0.1879, lr: 0.0005, epoch: 4/9, step: 22/600\n",
      "loss: 0.0984, lr: 0.0005, epoch: 4/9, step: 23/600\n",
      "loss: 0.0216, lr: 0.0005, epoch: 4/9, step: 24/600\n",
      "loss: 0.3455, lr: 0.0005, epoch: 4/9, step: 25/600\n",
      "loss: 0.0368, lr: 0.0005, epoch: 4/9, step: 26/600\n",
      "loss: 0.0398, lr: 0.0005, epoch: 4/9, step: 27/600\n",
      "loss: 0.0347, lr: 0.0005, epoch: 4/9, step: 28/600\n",
      "loss: 0.3274, lr: 0.0005, epoch: 4/9, step: 29/600\n",
      "loss: 0.3877, lr: 0.0005, epoch: 4/9, step: 30/600\n",
      "loss: 0.1895, lr: 0.0005, epoch: 4/9, step: 31/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 4/9, step: 32/600\n",
      "loss: 0.1698, lr: 0.0005, epoch: 4/9, step: 33/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 4/9, step: 34/600\n",
      "loss: 0.1371, lr: 0.0005, epoch: 4/9, step: 35/600\n",
      "loss: 0.3853, lr: 0.0005, epoch: 4/9, step: 36/600\n",
      "loss: 0.1893, lr: 0.0005, epoch: 4/9, step: 37/600\n",
      "loss: 0.6821, lr: 0.0005, epoch: 4/9, step: 38/600\n",
      "loss: 0.1077, lr: 0.0005, epoch: 4/9, step: 39/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 4/9, step: 40/600\n",
      "loss: 0.1033, lr: 0.0005, epoch: 4/9, step: 41/600\n",
      "loss: 0.1735, lr: 0.0005, epoch: 4/9, step: 42/600\n",
      "loss: 0.1234, lr: 0.0005, epoch: 4/9, step: 43/600\n",
      "loss: 0.1738, lr: 0.0005, epoch: 4/9, step: 44/600\n",
      "loss: 0.0969, lr: 0.0005, epoch: 4/9, step: 45/600\n",
      "loss: 0.1162, lr: 0.0005, epoch: 4/9, step: 46/600\n",
      "loss: 0.0756, lr: 0.0005, epoch: 4/9, step: 47/600\n",
      "loss: 0.7119, lr: 0.0005, epoch: 4/9, step: 48/600\n",
      "loss: 0.1326, lr: 0.0005, epoch: 4/9, step: 49/600\n",
      "loss: 0.0334, lr: 0.0005, epoch: 4/9, step: 50/600\n",
      "loss: 0.1888, lr: 0.0005, epoch: 4/9, step: 51/600\n",
      "loss: 0.3667, lr: 0.0005, epoch: 4/9, step: 52/600\n",
      "loss: 0.5542, lr: 0.0005, epoch: 4/9, step: 53/600\n",
      "loss: 0.0368, lr: 0.0005, epoch: 4/9, step: 54/600\n",
      "loss: 0.0526, lr: 0.0005, epoch: 4/9, step: 55/600\n",
      "loss: 0.1147, lr: 0.0005, epoch: 4/9, step: 56/600\n",
      "loss: 0.0389, lr: 0.0005, epoch: 4/9, step: 57/600\n",
      "loss: 0.1771, lr: 0.0005, epoch: 4/9, step: 58/600\n",
      "loss: 0.0692, lr: 0.0005, epoch: 4/9, step: 59/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 4/9, step: 60/600\n",
      "loss: 0.0319, lr: 0.0005, epoch: 4/9, step: 61/600\n",
      "loss: 0.4385, lr: 0.0005, epoch: 4/9, step: 62/600\n",
      "loss: 0.3662, lr: 0.0005, epoch: 4/9, step: 63/600\n",
      "loss: 0.2289, lr: 0.0005, epoch: 4/9, step: 64/600\n",
      "loss: 0.2483, lr: 0.0005, epoch: 4/9, step: 65/600\n",
      "loss: 0.2095, lr: 0.0005, epoch: 4/9, step: 66/600\n",
      "loss: 0.0843, lr: 0.0005, epoch: 4/9, step: 67/600\n",
      "loss: 0.0854, lr: 0.0005, epoch: 4/9, step: 68/600\n",
      "loss: 0.0103, lr: 0.0005, epoch: 4/9, step: 69/600\n",
      "loss: 0.0745, lr: 0.0005, epoch: 4/9, step: 70/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 4/9, step: 71/600\n",
      "loss: 0.4104, lr: 0.0005, epoch: 4/9, step: 72/600\n",
      "loss: 0.2939, lr: 0.0005, epoch: 4/9, step: 73/600\n",
      "loss: 0.0188, lr: 0.0005, epoch: 4/9, step: 74/600\n",
      "loss: 0.3091, lr: 0.0005, epoch: 4/9, step: 75/600\n",
      "loss: 0.3186, lr: 0.0005, epoch: 4/9, step: 76/600\n",
      "loss: 0.2996, lr: 0.0005, epoch: 4/9, step: 77/600\n",
      "loss: 0.4983, lr: 0.0005, epoch: 4/9, step: 78/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 4/9, step: 79/600\n",
      "loss: 0.1261, lr: 0.0005, epoch: 4/9, step: 80/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 4/9, step: 81/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 4/9, step: 82/600\n",
      "loss: 0.1609, lr: 0.0005, epoch: 4/9, step: 83/600\n",
      "loss: 0.4348, lr: 0.0005, epoch: 4/9, step: 84/600\n",
      "loss: 0.1121, lr: 0.0005, epoch: 4/9, step: 85/600\n",
      "loss: 0.5742, lr: 0.0005, epoch: 4/9, step: 86/600\n",
      "loss: 0.0455, lr: 0.0005, epoch: 4/9, step: 87/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 4/9, step: 88/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 4/9, step: 89/600\n",
      "loss: 0.025, lr: 0.0005, epoch: 4/9, step: 90/600\n",
      "loss: 0.0737, lr: 0.0005, epoch: 4/9, step: 91/600\n",
      "loss: 0.0842, lr: 0.0005, epoch: 4/9, step: 92/600\n",
      "loss: 0.4714, lr: 0.0005, epoch: 4/9, step: 93/600\n",
      "loss: 0.0101, lr: 0.0005, epoch: 4/9, step: 94/600\n",
      "loss: 0.0077, lr: 0.0005, epoch: 4/9, step: 95/600\n",
      "loss: 0.0826, lr: 0.0005, epoch: 4/9, step: 96/600\n",
      "loss: 0.095, lr: 0.0005, epoch: 4/9, step: 97/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 4/9, step: 98/600\n",
      "loss: 0.7134, lr: 0.0005, epoch: 4/9, step: 99/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 4/9, step: 100/600\n",
      "loss: 0.0466, lr: 0.0005, epoch: 4/9, step: 101/600\n",
      "loss: 0.5562, lr: 0.0005, epoch: 4/9, step: 102/600\n",
      "loss: 0.0274, lr: 0.0005, epoch: 4/9, step: 103/600\n",
      "loss: 0.0947, lr: 0.0005, epoch: 4/9, step: 104/600\n",
      "loss: 0.3289, lr: 0.0005, epoch: 4/9, step: 105/600\n",
      "loss: 0.1122, lr: 0.0005, epoch: 4/9, step: 106/600\n",
      "loss: 0.0315, lr: 0.0005, epoch: 4/9, step: 107/600\n",
      "loss: 0.3818, lr: 0.0005, epoch: 4/9, step: 108/600\n",
      "loss: 0.322, lr: 0.0005, epoch: 4/9, step: 109/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 4/9, step: 110/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 4/9, step: 111/600\n",
      "loss: 0.0252, lr: 0.0005, epoch: 4/9, step: 112/600\n",
      "loss: 0.0434, lr: 0.0005, epoch: 4/9, step: 113/600\n",
      "loss: 0.0871, lr: 0.0005, epoch: 4/9, step: 114/600\n",
      "loss: 0.3433, lr: 0.0005, epoch: 4/9, step: 115/600\n",
      "loss: 0.3643, lr: 0.0005, epoch: 4/9, step: 116/600\n",
      "loss: 0.033, lr: 0.0005, epoch: 4/9, step: 117/600\n",
      "loss: 0.1042, lr: 0.0005, epoch: 4/9, step: 118/600\n",
      "loss: 0.8516, lr: 0.0005, epoch: 4/9, step: 119/600\n",
      "loss: 0.2571, lr: 0.0005, epoch: 4/9, step: 120/600\n",
      "loss: 0.2886, lr: 0.0005, epoch: 4/9, step: 121/600\n",
      "loss: 0.5107, lr: 0.0005, epoch: 4/9, step: 122/600\n",
      "loss: 0.5371, lr: 0.0005, epoch: 4/9, step: 123/600\n",
      "loss: 0.0188, lr: 0.0005, epoch: 4/9, step: 124/600\n",
      "loss: 0.0743, lr: 0.0005, epoch: 4/9, step: 125/600\n",
      "loss: 0.4736, lr: 0.0005, epoch: 4/9, step: 126/600\n",
      "loss: 0.1565, lr: 0.0005, epoch: 4/9, step: 127/600\n",
      "loss: 0.3459, lr: 0.0005, epoch: 4/9, step: 128/600\n",
      "loss: 0.2134, lr: 0.0005, epoch: 4/9, step: 129/600\n",
      "loss: 0.3662, lr: 0.0005, epoch: 4/9, step: 130/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 4/9, step: 131/600\n",
      "loss: 0.5684, lr: 0.0005, epoch: 4/9, step: 132/600\n",
      "loss: 0.011, lr: 0.0005, epoch: 4/9, step: 133/600\n",
      "loss: 0.196, lr: 0.0005, epoch: 4/9, step: 134/600\n",
      "loss: 0.312, lr: 0.0005, epoch: 4/9, step: 135/600\n",
      "loss: 0.5425, lr: 0.0005, epoch: 4/9, step: 136/600\n",
      "loss: 0.3557, lr: 0.0005, epoch: 4/9, step: 137/600\n",
      "loss: 0.0527, lr: 0.0005, epoch: 4/9, step: 138/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 4/9, step: 139/600\n",
      "loss: 0.0704, lr: 0.0005, epoch: 4/9, step: 140/600\n",
      "loss: 0.2465, lr: 0.0005, epoch: 4/9, step: 141/600\n",
      "loss: 0.1549, lr: 0.0005, epoch: 4/9, step: 142/600\n",
      "loss: 0.3347, lr: 0.0005, epoch: 4/9, step: 143/600\n",
      "loss: 0.0335, lr: 0.0005, epoch: 4/9, step: 144/600\n",
      "loss: 0.4795, lr: 0.0005, epoch: 4/9, step: 145/600\n",
      "loss: 0.1019, lr: 0.0005, epoch: 4/9, step: 146/600\n",
      "loss: 0.0192, lr: 0.0005, epoch: 4/9, step: 147/600\n",
      "loss: 0.0588, lr: 0.0005, epoch: 4/9, step: 148/600\n",
      "loss: 0.0284, lr: 0.0005, epoch: 4/9, step: 149/600\n",
      "loss: 0.1007, lr: 0.0005, epoch: 4/9, step: 150/600\n",
      "loss: 0.3186, lr: 0.0005, epoch: 4/9, step: 151/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 4/9, step: 152/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 4/9, step: 153/600\n",
      "loss: 0.6426, lr: 0.0005, epoch: 4/9, step: 154/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 4/9, step: 155/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 4/9, step: 156/600\n",
      "loss: 0.0768, lr: 0.0005, epoch: 4/9, step: 157/600\n",
      "loss: 0.0253, lr: 0.0005, epoch: 4/9, step: 158/600\n",
      "loss: 0.3928, lr: 0.0005, epoch: 4/9, step: 159/600\n",
      "loss: 0.3352, lr: 0.0005, epoch: 4/9, step: 160/600\n",
      "loss: 0.0982, lr: 0.0005, epoch: 4/9, step: 161/600\n",
      "loss: 0.0844, lr: 0.0005, epoch: 4/9, step: 162/600\n",
      "loss: 0.4021, lr: 0.0005, epoch: 4/9, step: 163/600\n",
      "loss: 0.6084, lr: 0.0005, epoch: 4/9, step: 164/600\n",
      "loss: 0.1405, lr: 0.0005, epoch: 4/9, step: 165/600\n",
      "loss: 0.0707, lr: 0.0005, epoch: 4/9, step: 166/600\n",
      "loss: 0.021, lr: 0.0005, epoch: 4/9, step: 167/600\n",
      "loss: 0.3071, lr: 0.0005, epoch: 4/9, step: 168/600\n",
      "loss: 0.0544, lr: 0.0005, epoch: 4/9, step: 169/600\n",
      "loss: 0.2722, lr: 0.0005, epoch: 4/9, step: 170/600\n",
      "loss: 0.1494, lr: 0.0005, epoch: 4/9, step: 171/600\n",
      "loss: 0.1718, lr: 0.0005, epoch: 4/9, step: 172/600\n",
      "loss: 0.3115, lr: 0.0005, epoch: 4/9, step: 173/600\n",
      "loss: 0.8784, lr: 0.0005, epoch: 4/9, step: 174/600\n",
      "loss: 0.1137, lr: 0.0005, epoch: 4/9, step: 175/600\n",
      "loss: 0.0609, lr: 0.0005, epoch: 4/9, step: 176/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 4/9, step: 177/600\n",
      "loss: 0.3225, lr: 0.0005, epoch: 4/9, step: 178/600\n",
      "loss: 0.078, lr: 0.0005, epoch: 4/9, step: 179/600\n",
      "loss: 0.1946, lr: 0.0005, epoch: 4/9, step: 180/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 4/9, step: 181/600\n",
      "loss: 0.1426, lr: 0.0005, epoch: 4/9, step: 182/600\n",
      "loss: 0.2081, lr: 0.0005, epoch: 4/9, step: 183/600\n",
      "loss: 0.1205, lr: 0.0005, epoch: 4/9, step: 184/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 4/9, step: 185/600\n",
      "loss: 0.7065, lr: 0.0005, epoch: 4/9, step: 186/600\n",
      "loss: 0.4526, lr: 0.0005, epoch: 4/9, step: 187/600\n",
      "loss: 0.1689, lr: 0.0005, epoch: 4/9, step: 188/600\n",
      "loss: 0.0444, lr: 0.0005, epoch: 4/9, step: 189/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 4/9, step: 190/600\n",
      "loss: 0.4246, lr: 0.0005, epoch: 4/9, step: 191/600\n",
      "loss: 0.059, lr: 0.0005, epoch: 4/9, step: 192/600\n",
      "loss: 0.0051, lr: 0.0005, epoch: 4/9, step: 193/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 4/9, step: 194/600\n",
      "loss: 0.3323, lr: 0.0005, epoch: 4/9, step: 195/600\n",
      "loss: 0.1669, lr: 0.0005, epoch: 4/9, step: 196/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 4/9, step: 197/600\n",
      "loss: 0.0145, lr: 0.0005, epoch: 4/9, step: 198/600\n",
      "loss: 0.0079, lr: 0.0005, epoch: 4/9, step: 199/600\n",
      "loss: 0.5962, lr: 0.0005, epoch: 4/9, step: 200/600\n",
      "loss: 0.0091, lr: 0.0005, epoch: 4/9, step: 201/600\n",
      "loss: 0.0305, lr: 0.0005, epoch: 4/9, step: 202/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 4/9, step: 203/600\n",
      "loss: 0.0886, lr: 0.0005, epoch: 4/9, step: 204/600\n",
      "loss: 0.0894, lr: 0.0005, epoch: 4/9, step: 205/600\n",
      "loss: 0.1371, lr: 0.0005, epoch: 4/9, step: 206/600\n",
      "loss: 0.4614, lr: 0.0005, epoch: 4/9, step: 207/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 4/9, step: 208/600\n",
      "loss: 0.0293, lr: 0.0005, epoch: 4/9, step: 209/600\n",
      "loss: 0.7622, lr: 0.0005, epoch: 4/9, step: 210/600\n",
      "loss: 0.4224, lr: 0.0005, epoch: 4/9, step: 211/600\n",
      "loss: 0.0086, lr: 0.0005, epoch: 4/9, step: 212/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 4/9, step: 213/600\n",
      "loss: 0.0481, lr: 0.0005, epoch: 4/9, step: 214/600\n",
      "loss: 0.1349, lr: 0.0005, epoch: 4/9, step: 215/600\n",
      "loss: 0.6909, lr: 0.0005, epoch: 4/9, step: 216/600\n",
      "loss: 0.1886, lr: 0.0005, epoch: 4/9, step: 217/600\n",
      "loss: 0.0762, lr: 0.0005, epoch: 4/9, step: 218/600\n",
      "loss: 0.6528, lr: 0.0005, epoch: 4/9, step: 219/600\n",
      "loss: 0.2142, lr: 0.0005, epoch: 4/9, step: 220/600\n",
      "loss: 0.0318, lr: 0.0005, epoch: 4/9, step: 221/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 4/9, step: 222/600\n",
      "loss: 0.2488, lr: 0.0005, epoch: 4/9, step: 223/600\n",
      "loss: 0.2554, lr: 0.0005, epoch: 4/9, step: 224/600\n",
      "loss: 0.0375, lr: 0.0005, epoch: 4/9, step: 225/600\n",
      "loss: 0.0498, lr: 0.0005, epoch: 4/9, step: 226/600\n",
      "loss: 0.085, lr: 0.0005, epoch: 4/9, step: 227/600\n",
      "loss: 0.6533, lr: 0.0005, epoch: 4/9, step: 228/600\n",
      "loss: 0.5083, lr: 0.0005, epoch: 4/9, step: 229/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 4/9, step: 230/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 4/9, step: 231/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 4/9, step: 232/600\n",
      "loss: 0.2024, lr: 0.0005, epoch: 4/9, step: 233/600\n",
      "loss: 0.6162, lr: 0.0005, epoch: 4/9, step: 234/600\n",
      "loss: 0.5439, lr: 0.0005, epoch: 4/9, step: 235/600\n",
      "loss: 0.5845, lr: 0.0005, epoch: 4/9, step: 236/600\n",
      "loss: 0.067, lr: 0.0005, epoch: 4/9, step: 237/600\n",
      "loss: 0.1818, lr: 0.0005, epoch: 4/9, step: 238/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 4/9, step: 239/600\n",
      "loss: 0.1813, lr: 0.0005, epoch: 4/9, step: 240/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 4/9, step: 241/600\n",
      "loss: 0.0088, lr: 0.0005, epoch: 4/9, step: 242/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 4/9, step: 243/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 4/9, step: 244/600\n",
      "loss: 0.1788, lr: 0.0005, epoch: 4/9, step: 245/600\n",
      "loss: 0.1028, lr: 0.0005, epoch: 4/9, step: 246/600\n",
      "loss: 0.167, lr: 0.0005, epoch: 4/9, step: 247/600\n",
      "loss: 0.1257, lr: 0.0005, epoch: 4/9, step: 248/600\n",
      "loss: 0.1768, lr: 0.0005, epoch: 4/9, step: 249/600\n",
      "loss: 0.0113, lr: 0.0005, epoch: 4/9, step: 250/600\n",
      "loss: 0.6665, lr: 0.0005, epoch: 4/9, step: 251/600\n",
      "loss: 0.4114, lr: 0.0005, epoch: 4/9, step: 252/600\n",
      "loss: 0.0194, lr: 0.0005, epoch: 4/9, step: 253/600\n",
      "loss: 0.083, lr: 0.0005, epoch: 4/9, step: 254/600\n",
      "loss: 0.0328, lr: 0.0005, epoch: 4/9, step: 255/600\n",
      "loss: 0.0264, lr: 0.0005, epoch: 4/9, step: 256/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 4/9, step: 257/600\n",
      "loss: 0.3867, lr: 0.0005, epoch: 4/9, step: 258/600\n",
      "loss: 0.175, lr: 0.0005, epoch: 4/9, step: 259/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 4/9, step: 260/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 4/9, step: 261/600\n",
      "loss: 0.0186, lr: 0.0005, epoch: 4/9, step: 262/600\n",
      "loss: 0.1467, lr: 0.0005, epoch: 4/9, step: 263/600\n",
      "loss: 0.6533, lr: 0.0005, epoch: 4/9, step: 264/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 4/9, step: 265/600\n",
      "loss: 0.5786, lr: 0.0005, epoch: 4/9, step: 266/600\n",
      "loss: 0.397, lr: 0.0005, epoch: 4/9, step: 267/600\n",
      "loss: 0.0834, lr: 0.0005, epoch: 4/9, step: 268/600\n",
      "loss: 0.2451, lr: 0.0005, epoch: 4/9, step: 269/600\n",
      "loss: 0.0536, lr: 0.0005, epoch: 4/9, step: 270/600\n",
      "loss: 0.1241, lr: 0.0005, epoch: 4/9, step: 271/600\n",
      "loss: 0.2712, lr: 0.0005, epoch: 4/9, step: 272/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 4/9, step: 273/600\n",
      "loss: 0.1375, lr: 0.0005, epoch: 4/9, step: 274/600\n",
      "loss: 0.019, lr: 0.0005, epoch: 4/9, step: 275/600\n",
      "loss: 0.2368, lr: 0.0005, epoch: 4/9, step: 276/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 4/9, step: 277/600\n",
      "loss: 0.5195, lr: 0.0005, epoch: 4/9, step: 278/600\n",
      "loss: 0.0203, lr: 0.0005, epoch: 4/9, step: 279/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 4/9, step: 280/600\n",
      "loss: 0.0309, lr: 0.0005, epoch: 4/9, step: 281/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 4/9, step: 282/600\n",
      "loss: 0.0172, lr: 0.0005, epoch: 4/9, step: 283/600\n",
      "loss: 0.0377, lr: 0.0005, epoch: 4/9, step: 284/600\n",
      "loss: 0.7505, lr: 0.0005, epoch: 4/9, step: 285/600\n",
      "loss: 0.2474, lr: 0.0005, epoch: 4/9, step: 286/600\n",
      "loss: 0.1091, lr: 0.0005, epoch: 4/9, step: 287/600\n",
      "loss: 0.0756, lr: 0.0005, epoch: 4/9, step: 288/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 4/9, step: 289/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 4/9, step: 290/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 4/9, step: 291/600\n",
      "loss: 0.0077, lr: 0.0005, epoch: 4/9, step: 292/600\n",
      "loss: 0.2925, lr: 0.0005, epoch: 4/9, step: 293/600\n",
      "loss: 0.014, lr: 0.0005, epoch: 4/9, step: 294/600\n",
      "loss: 0.2482, lr: 0.0005, epoch: 4/9, step: 295/600\n",
      "loss: 0.7339, lr: 0.0005, epoch: 4/9, step: 296/600\n",
      "loss: 0.293, lr: 0.0005, epoch: 4/9, step: 297/600\n",
      "loss: 0.1149, lr: 0.0005, epoch: 4/9, step: 298/600\n",
      "loss: 0.0345, lr: 0.0005, epoch: 4/9, step: 299/600\n",
      "loss: 0.05, lr: 0.0005, epoch: 4/9, step: 300/600\n",
      "loss: 0.4907, lr: 0.0005, epoch: 4/9, step: 301/600\n",
      "loss: 0.1947, lr: 0.0005, epoch: 4/9, step: 302/600\n",
      "loss: 0.044, lr: 0.0005, epoch: 4/9, step: 303/600\n",
      "loss: 0.1454, lr: 0.0005, epoch: 4/9, step: 304/600\n",
      "loss: 0.0504, lr: 0.0005, epoch: 4/9, step: 305/600\n",
      "loss: 0.096, lr: 0.0005, epoch: 4/9, step: 306/600\n",
      "loss: 0.2883, lr: 0.0005, epoch: 4/9, step: 307/600\n",
      "loss: 0.4697, lr: 0.0005, epoch: 4/9, step: 308/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 4/9, step: 309/600\n",
      "loss: 0.4131, lr: 0.0005, epoch: 4/9, step: 310/600\n",
      "loss: 0.4343, lr: 0.0005, epoch: 4/9, step: 311/600\n",
      "loss: 0.2703, lr: 0.0005, epoch: 4/9, step: 312/600\n",
      "loss: 0.1232, lr: 0.0005, epoch: 4/9, step: 313/600\n",
      "loss: 0.3145, lr: 0.0005, epoch: 4/9, step: 314/600\n",
      "loss: 0.0094, lr: 0.0005, epoch: 4/9, step: 315/600\n",
      "loss: 0.2255, lr: 0.0005, epoch: 4/9, step: 316/600\n",
      "loss: 0.4563, lr: 0.0005, epoch: 4/9, step: 317/600\n",
      "loss: 0.3484, lr: 0.0005, epoch: 4/9, step: 318/600\n",
      "loss: 0.4031, lr: 0.0005, epoch: 4/9, step: 319/600\n",
      "loss: 0.5171, lr: 0.0005, epoch: 4/9, step: 320/600\n",
      "loss: 0.0384, lr: 0.0005, epoch: 4/9, step: 321/600\n",
      "loss: 0.0211, lr: 0.0005, epoch: 4/9, step: 322/600\n",
      "loss: 0.3474, lr: 0.0005, epoch: 4/9, step: 323/600\n",
      "loss: 0.7661, lr: 0.0005, epoch: 4/9, step: 324/600\n",
      "loss: 0.3342, lr: 0.0005, epoch: 4/9, step: 325/600\n",
      "loss: 0.0452, lr: 0.0005, epoch: 4/9, step: 326/600\n",
      "loss: 0.0184, lr: 0.0005, epoch: 4/9, step: 327/600\n",
      "loss: 0.0225, lr: 0.0005, epoch: 4/9, step: 328/600\n",
      "loss: 0.0427, lr: 0.0005, epoch: 4/9, step: 329/600\n",
      "loss: 0.4702, lr: 0.0005, epoch: 4/9, step: 330/600\n",
      "loss: 0.215, lr: 0.0005, epoch: 4/9, step: 331/600\n",
      "loss: 0.707, lr: 0.0005, epoch: 4/9, step: 332/600\n",
      "loss: 0.0361, lr: 0.0005, epoch: 4/9, step: 333/600\n",
      "loss: 0.0784, lr: 0.0005, epoch: 4/9, step: 334/600\n",
      "loss: 0.0144, lr: 0.0005, epoch: 4/9, step: 335/600\n",
      "loss: 0.2471, lr: 0.0005, epoch: 4/9, step: 336/600\n",
      "loss: 0.3401, lr: 0.0005, epoch: 4/9, step: 337/600\n",
      "loss: 0.1215, lr: 0.0005, epoch: 4/9, step: 338/600\n",
      "loss: 0.5244, lr: 0.0005, epoch: 4/9, step: 339/600\n",
      "loss: 0.2156, lr: 0.0005, epoch: 4/9, step: 340/600\n",
      "loss: 0.3269, lr: 0.0005, epoch: 4/9, step: 341/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 4/9, step: 342/600\n",
      "loss: 0.3442, lr: 0.0005, epoch: 4/9, step: 343/600\n",
      "loss: 0.3096, lr: 0.0005, epoch: 4/9, step: 344/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 4/9, step: 345/600\n",
      "loss: 0.0374, lr: 0.0005, epoch: 4/9, step: 346/600\n",
      "loss: 0.3564, lr: 0.0005, epoch: 4/9, step: 347/600\n",
      "loss: 0.1199, lr: 0.0005, epoch: 4/9, step: 348/600\n",
      "loss: 0.5298, lr: 0.0005, epoch: 4/9, step: 349/600\n",
      "loss: 0.3552, lr: 0.0005, epoch: 4/9, step: 350/600\n",
      "loss: 0.0556, lr: 0.0005, epoch: 4/9, step: 351/600\n",
      "loss: 0.058, lr: 0.0005, epoch: 4/9, step: 352/600\n",
      "loss: 0.3345, lr: 0.0005, epoch: 4/9, step: 353/600\n",
      "loss: 0.0088, lr: 0.0005, epoch: 4/9, step: 354/600\n",
      "loss: 0.1672, lr: 0.0005, epoch: 4/9, step: 355/600\n",
      "loss: 0.1075, lr: 0.0005, epoch: 4/9, step: 356/600\n",
      "loss: 0.353, lr: 0.0005, epoch: 4/9, step: 357/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 4/9, step: 358/600\n",
      "loss: 0.1383, lr: 0.0005, epoch: 4/9, step: 359/600\n",
      "loss: 0.0978, lr: 0.0005, epoch: 4/9, step: 360/600\n",
      "loss: 0.0795, lr: 0.0005, epoch: 4/9, step: 361/600\n",
      "loss: 0.0989, lr: 0.0005, epoch: 4/9, step: 362/600\n",
      "loss: 0.2052, lr: 0.0005, epoch: 4/9, step: 363/600\n",
      "loss: 0.2496, lr: 0.0005, epoch: 4/9, step: 364/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 4/9, step: 365/600\n",
      "loss: 0.0416, lr: 0.0005, epoch: 4/9, step: 366/600\n",
      "loss: 0.3533, lr: 0.0005, epoch: 4/9, step: 367/600\n",
      "loss: 0.0396, lr: 0.0005, epoch: 4/9, step: 368/600\n",
      "loss: 0.2737, lr: 0.0005, epoch: 4/9, step: 369/600\n",
      "loss: 0.0681, lr: 0.0005, epoch: 4/9, step: 370/600\n",
      "loss: 0.031, lr: 0.0005, epoch: 4/9, step: 371/600\n",
      "loss: 0.0298, lr: 0.0005, epoch: 4/9, step: 372/600\n",
      "loss: 0.0069, lr: 0.0005, epoch: 4/9, step: 373/600\n",
      "loss: 0.123, lr: 0.0005, epoch: 4/9, step: 374/600\n",
      "loss: 0.2004, lr: 0.0005, epoch: 4/9, step: 375/600\n",
      "loss: 0.0067, lr: 0.0005, epoch: 4/9, step: 376/600\n",
      "loss: 0.4976, lr: 0.0005, epoch: 4/9, step: 377/600\n",
      "loss: 0.0388, lr: 0.0005, epoch: 4/9, step: 378/600\n",
      "loss: 0.1079, lr: 0.0005, epoch: 4/9, step: 379/600\n",
      "loss: 0.1293, lr: 0.0005, epoch: 4/9, step: 380/600\n",
      "loss: 0.2075, lr: 0.0005, epoch: 4/9, step: 381/600\n",
      "loss: 0.0817, lr: 0.0005, epoch: 4/9, step: 382/600\n",
      "loss: 0.0445, lr: 0.0005, epoch: 4/9, step: 383/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 4/9, step: 384/600\n",
      "loss: 0.0379, lr: 0.0005, epoch: 4/9, step: 385/600\n",
      "loss: 0.5454, lr: 0.0005, epoch: 4/9, step: 386/600\n",
      "loss: 0.0885, lr: 0.0005, epoch: 4/9, step: 387/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 4/9, step: 388/600\n",
      "loss: 0.0847, lr: 0.0005, epoch: 4/9, step: 389/600\n",
      "loss: 0.0295, lr: 0.0005, epoch: 4/9, step: 390/600\n",
      "loss: 0.015, lr: 0.0005, epoch: 4/9, step: 391/600\n",
      "loss: 0.3713, lr: 0.0005, epoch: 4/9, step: 392/600\n",
      "loss: 0.0199, lr: 0.0005, epoch: 4/9, step: 393/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 4/9, step: 394/600\n",
      "loss: 0.0214, lr: 0.0005, epoch: 4/9, step: 395/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 4/9, step: 396/600\n",
      "loss: 0.1161, lr: 0.0005, epoch: 4/9, step: 397/600\n",
      "loss: 0.0575, lr: 0.0005, epoch: 4/9, step: 398/600\n",
      "loss: 0.3245, lr: 0.0005, epoch: 4/9, step: 399/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 4/9, step: 400/600\n",
      "loss: 0.2096, lr: 0.0005, epoch: 4/9, step: 401/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 4/9, step: 402/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 4/9, step: 403/600\n",
      "loss: 0.4062, lr: 0.0005, epoch: 4/9, step: 404/600\n",
      "loss: 0.0407, lr: 0.0005, epoch: 4/9, step: 405/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 4/9, step: 406/600\n",
      "loss: 0.0743, lr: 0.0005, epoch: 4/9, step: 407/600\n",
      "loss: 0.3579, lr: 0.0005, epoch: 4/9, step: 408/600\n",
      "loss: 0.0121, lr: 0.0005, epoch: 4/9, step: 409/600\n",
      "loss: 0.0166, lr: 0.0005, epoch: 4/9, step: 410/600\n",
      "loss: 0.1079, lr: 0.0005, epoch: 4/9, step: 411/600\n",
      "loss: 0.135, lr: 0.0005, epoch: 4/9, step: 412/600\n",
      "loss: 0.2617, lr: 0.0005, epoch: 4/9, step: 413/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 4/9, step: 414/600\n",
      "loss: 0.0263, lr: 0.0005, epoch: 4/9, step: 415/600\n",
      "loss: 0.2208, lr: 0.0005, epoch: 4/9, step: 416/600\n",
      "loss: 0.2433, lr: 0.0005, epoch: 4/9, step: 417/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 4/9, step: 418/600\n",
      "loss: 0.2898, lr: 0.0005, epoch: 4/9, step: 419/600\n",
      "loss: 0.05, lr: 0.0005, epoch: 4/9, step: 420/600\n",
      "loss: 0.029, lr: 0.0005, epoch: 4/9, step: 421/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 4/9, step: 422/600\n",
      "loss: 0.457, lr: 0.0005, epoch: 4/9, step: 423/600\n",
      "loss: 0.5776, lr: 0.0005, epoch: 4/9, step: 424/600\n",
      "loss: 0.1053, lr: 0.0005, epoch: 4/9, step: 425/600\n",
      "loss: 0.0922, lr: 0.0005, epoch: 4/9, step: 426/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 4/9, step: 427/600\n",
      "loss: 0.5581, lr: 0.0005, epoch: 4/9, step: 428/600\n",
      "loss: 0.5879, lr: 0.0005, epoch: 4/9, step: 429/600\n",
      "loss: 0.3428, lr: 0.0005, epoch: 4/9, step: 430/600\n",
      "loss: 0.3513, lr: 0.0005, epoch: 4/9, step: 431/600\n",
      "loss: 0.1724, lr: 0.0005, epoch: 4/9, step: 432/600\n",
      "loss: 0.0133, lr: 0.0005, epoch: 4/9, step: 433/600\n",
      "loss: 0.1335, lr: 0.0005, epoch: 4/9, step: 434/600\n",
      "loss: 0.2615, lr: 0.0005, epoch: 4/9, step: 435/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 4/9, step: 436/600\n",
      "loss: 0.0581, lr: 0.0005, epoch: 4/9, step: 437/600\n",
      "loss: 0.0544, lr: 0.0005, epoch: 4/9, step: 438/600\n",
      "loss: 0.491, lr: 0.0005, epoch: 4/9, step: 439/600\n",
      "loss: 0.0196, lr: 0.0005, epoch: 4/9, step: 440/600\n",
      "loss: 0.1456, lr: 0.0005, epoch: 4/9, step: 441/600\n",
      "loss: 0.2861, lr: 0.0005, epoch: 4/9, step: 442/600\n",
      "loss: 0.3513, lr: 0.0005, epoch: 4/9, step: 443/600\n",
      "loss: 0.7993, lr: 0.0005, epoch: 4/9, step: 444/600\n",
      "loss: 0.0366, lr: 0.0005, epoch: 4/9, step: 445/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 4/9, step: 446/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 4/9, step: 447/600\n",
      "loss: 0.0147, lr: 0.0005, epoch: 4/9, step: 448/600\n",
      "loss: 0.0112, lr: 0.0005, epoch: 4/9, step: 449/600\n",
      "loss: 0.0093, lr: 0.0005, epoch: 4/9, step: 450/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 4/9, step: 451/600\n",
      "loss: 0.0977, lr: 0.0005, epoch: 4/9, step: 452/600\n",
      "loss: 0.1199, lr: 0.0005, epoch: 4/9, step: 453/600\n",
      "loss: 0.2705, lr: 0.0005, epoch: 4/9, step: 454/600\n",
      "loss: 0.0435, lr: 0.0005, epoch: 4/9, step: 455/600\n",
      "loss: 0.0932, lr: 0.0005, epoch: 4/9, step: 456/600\n",
      "loss: 0.1941, lr: 0.0005, epoch: 4/9, step: 457/600\n",
      "loss: 0.197, lr: 0.0005, epoch: 4/9, step: 458/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 4/9, step: 459/600\n",
      "loss: 0.0799, lr: 0.0005, epoch: 4/9, step: 460/600\n",
      "loss: 0.0405, lr: 0.0005, epoch: 4/9, step: 461/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 4/9, step: 462/600\n",
      "loss: 0.0129, lr: 0.0005, epoch: 4/9, step: 463/600\n",
      "loss: 0.0269, lr: 0.0005, epoch: 4/9, step: 464/600\n",
      "loss: 0.4246, lr: 0.0005, epoch: 4/9, step: 465/600\n",
      "loss: 0.0108, lr: 0.0005, epoch: 4/9, step: 466/600\n",
      "loss: 0.2742, lr: 0.0005, epoch: 4/9, step: 467/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 4/9, step: 468/600\n",
      "loss: 0.1401, lr: 0.0005, epoch: 4/9, step: 469/600\n",
      "loss: 0.2983, lr: 0.0005, epoch: 4/9, step: 470/600\n",
      "loss: 0.0564, lr: 0.0005, epoch: 4/9, step: 471/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 4/9, step: 472/600\n",
      "loss: 0.1107, lr: 0.0005, epoch: 4/9, step: 473/600\n",
      "loss: 0.408, lr: 0.0005, epoch: 4/9, step: 474/600\n",
      "loss: 0.3967, lr: 0.0005, epoch: 4/9, step: 475/600\n",
      "loss: 0.0024, lr: 0.0005, epoch: 4/9, step: 476/600\n",
      "loss: 0.0217, lr: 0.0005, epoch: 4/9, step: 477/600\n",
      "loss: 0.119, lr: 0.0005, epoch: 4/9, step: 478/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 4/9, step: 479/600\n",
      "loss: 0.4114, lr: 0.0005, epoch: 4/9, step: 480/600\n",
      "loss: 0.0149, lr: 0.0005, epoch: 4/9, step: 481/600\n",
      "loss: 0.183, lr: 0.0005, epoch: 4/9, step: 482/600\n",
      "loss: 0.0172, lr: 0.0005, epoch: 4/9, step: 483/600\n",
      "loss: 0.0074, lr: 0.0005, epoch: 4/9, step: 484/600\n",
      "loss: 0.0418, lr: 0.0005, epoch: 4/9, step: 485/600\n",
      "loss: 0.024, lr: 0.0005, epoch: 4/9, step: 486/600\n",
      "loss: 0.0168, lr: 0.0005, epoch: 4/9, step: 487/600\n",
      "loss: 0.0262, lr: 0.0005, epoch: 4/9, step: 488/600\n",
      "loss: 0.3235, lr: 0.0005, epoch: 4/9, step: 489/600\n",
      "loss: 0.0239, lr: 0.0005, epoch: 4/9, step: 490/600\n",
      "loss: 0.0767, lr: 0.0005, epoch: 4/9, step: 491/600\n",
      "loss: 0.0318, lr: 0.0005, epoch: 4/9, step: 492/600\n",
      "loss: 0.0894, lr: 0.0005, epoch: 4/9, step: 493/600\n",
      "loss: 0.0777, lr: 0.0005, epoch: 4/9, step: 494/600\n",
      "loss: 0.408, lr: 0.0005, epoch: 4/9, step: 495/600\n",
      "loss: 0.022, lr: 0.0005, epoch: 4/9, step: 496/600\n",
      "loss: 0.3645, lr: 0.0005, epoch: 4/9, step: 497/600\n",
      "loss: 0.1182, lr: 0.0005, epoch: 4/9, step: 498/600\n",
      "loss: 0.2203, lr: 0.0005, epoch: 4/9, step: 499/600\n",
      "loss: 0.4429, lr: 0.0005, epoch: 4/9, step: 500/600\n",
      "loss: 0.062, lr: 0.0005, epoch: 4/9, step: 501/600\n",
      "loss: 0.2494, lr: 0.0005, epoch: 4/9, step: 502/600\n",
      "loss: 0.2303, lr: 0.0005, epoch: 4/9, step: 503/600\n",
      "loss: 0.0127, lr: 0.0005, epoch: 4/9, step: 504/600\n",
      "loss: 0.063, lr: 0.0005, epoch: 4/9, step: 505/600\n",
      "loss: 0.2693, lr: 0.0005, epoch: 4/9, step: 506/600\n",
      "loss: 0.2205, lr: 0.0005, epoch: 4/9, step: 507/600\n",
      "loss: 0.0936, lr: 0.0005, epoch: 4/9, step: 508/600\n",
      "loss: 0.1614, lr: 0.0005, epoch: 4/9, step: 509/600\n",
      "loss: 0.8027, lr: 0.0005, epoch: 4/9, step: 510/600\n",
      "loss: 0.0479, lr: 0.0005, epoch: 4/9, step: 511/600\n",
      "loss: 0.1232, lr: 0.0005, epoch: 4/9, step: 512/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 4/9, step: 513/600\n",
      "loss: 0.0249, lr: 0.0005, epoch: 4/9, step: 514/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 4/9, step: 515/600\n",
      "loss: 0.3442, lr: 0.0005, epoch: 4/9, step: 516/600\n",
      "loss: 0.4551, lr: 0.0005, epoch: 4/9, step: 517/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 4/9, step: 518/600\n",
      "loss: 0.015, lr: 0.0005, epoch: 4/9, step: 519/600\n",
      "loss: 0.2327, lr: 0.0005, epoch: 4/9, step: 520/600\n",
      "loss: 0.1829, lr: 0.0005, epoch: 4/9, step: 521/600\n",
      "loss: 0.026, lr: 0.0005, epoch: 4/9, step: 522/600\n",
      "loss: 0.2832, lr: 0.0005, epoch: 4/9, step: 523/600\n",
      "loss: 0.2334, lr: 0.0005, epoch: 4/9, step: 524/600\n",
      "loss: 0.0278, lr: 0.0005, epoch: 4/9, step: 525/600\n",
      "loss: 0.4592, lr: 0.0005, epoch: 4/9, step: 526/600\n",
      "loss: 0.4619, lr: 0.0005, epoch: 4/9, step: 527/600\n",
      "loss: 0.1735, lr: 0.0005, epoch: 4/9, step: 528/600\n",
      "loss: 0.4849, lr: 0.0005, epoch: 4/9, step: 529/600\n",
      "loss: 0.4373, lr: 0.0005, epoch: 4/9, step: 530/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 4/9, step: 531/600\n",
      "loss: 0.3987, lr: 0.0005, epoch: 4/9, step: 532/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 4/9, step: 533/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 4/9, step: 534/600\n",
      "loss: 0.0177, lr: 0.0005, epoch: 4/9, step: 535/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 4/9, step: 536/600\n",
      "loss: 0.2228, lr: 0.0005, epoch: 4/9, step: 537/600\n",
      "loss: 0.4058, lr: 0.0005, epoch: 4/9, step: 538/600\n",
      "loss: 0.2081, lr: 0.0005, epoch: 4/9, step: 539/600\n",
      "loss: 0.0638, lr: 0.0005, epoch: 4/9, step: 540/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 4/9, step: 541/600\n",
      "loss: 0.2057, lr: 0.0005, epoch: 4/9, step: 542/600\n",
      "loss: 0.4351, lr: 0.0005, epoch: 4/9, step: 543/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 4/9, step: 544/600\n",
      "loss: 0.5127, lr: 0.0005, epoch: 4/9, step: 545/600\n",
      "loss: 0.0132, lr: 0.0005, epoch: 4/9, step: 546/600\n",
      "loss: 0.2559, lr: 0.0005, epoch: 4/9, step: 547/600\n",
      "loss: 0.4421, lr: 0.0005, epoch: 4/9, step: 548/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 4/9, step: 549/600\n",
      "loss: 0.0292, lr: 0.0005, epoch: 4/9, step: 550/600\n",
      "loss: 0.4834, lr: 0.0005, epoch: 4/9, step: 551/600\n",
      "loss: 0.1466, lr: 0.0005, epoch: 4/9, step: 552/600\n",
      "loss: 0.3433, lr: 0.0005, epoch: 4/9, step: 553/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 4/9, step: 554/600\n",
      "loss: 0.014, lr: 0.0005, epoch: 4/9, step: 555/600\n",
      "loss: 0.3655, lr: 0.0005, epoch: 4/9, step: 556/600\n",
      "loss: 0.3625, lr: 0.0005, epoch: 4/9, step: 557/600\n",
      "loss: 0.0818, lr: 0.0005, epoch: 4/9, step: 558/600\n",
      "loss: 0.4602, lr: 0.0005, epoch: 4/9, step: 559/600\n",
      "loss: 0.0933, lr: 0.0005, epoch: 4/9, step: 560/600\n",
      "loss: 0.0273, lr: 0.0005, epoch: 4/9, step: 561/600\n",
      "loss: 0.0752, lr: 0.0005, epoch: 4/9, step: 562/600\n",
      "loss: 0.4895, lr: 0.0005, epoch: 4/9, step: 563/600\n",
      "loss: 0.2974, lr: 0.0005, epoch: 4/9, step: 564/600\n",
      "loss: 0.0188, lr: 0.0005, epoch: 4/9, step: 565/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 4/9, step: 566/600\n",
      "loss: 0.026, lr: 0.0005, epoch: 4/9, step: 567/600\n",
      "loss: 0.0645, lr: 0.0005, epoch: 4/9, step: 568/600\n",
      "loss: 0.4397, lr: 0.0005, epoch: 4/9, step: 569/600\n",
      "loss: 0.1483, lr: 0.0005, epoch: 4/9, step: 570/600\n",
      "loss: 0.2026, lr: 0.0005, epoch: 4/9, step: 571/600\n",
      "loss: 0.0142, lr: 0.0005, epoch: 4/9, step: 572/600\n",
      "loss: 0.0285, lr: 0.0005, epoch: 4/9, step: 573/600\n",
      "loss: 0.0313, lr: 0.0005, epoch: 4/9, step: 574/600\n",
      "loss: 0.0095, lr: 0.0005, epoch: 4/9, step: 575/600\n",
      "loss: 0.1414, lr: 0.0005, epoch: 4/9, step: 576/600\n",
      "loss: 0.0131, lr: 0.0005, epoch: 4/9, step: 577/600\n",
      "loss: 0.4731, lr: 0.0005, epoch: 4/9, step: 578/600\n",
      "loss: 0.5347, lr: 0.0005, epoch: 4/9, step: 579/600\n",
      "loss: 0.0077, lr: 0.0005, epoch: 4/9, step: 580/600\n",
      "loss: 0.0247, lr: 0.0005, epoch: 4/9, step: 581/600\n",
      "loss: 0.2354, lr: 0.0005, epoch: 4/9, step: 582/600\n",
      "loss: 0.3044, lr: 0.0005, epoch: 4/9, step: 583/600\n",
      "loss: 0.0714, lr: 0.0005, epoch: 4/9, step: 584/600\n",
      "loss: 0.0779, lr: 0.0005, epoch: 4/9, step: 585/600\n",
      "loss: 0.0453, lr: 0.0005, epoch: 4/9, step: 586/600\n",
      "loss: 0.0472, lr: 0.0005, epoch: 4/9, step: 587/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 4/9, step: 588/600\n",
      "loss: 0.1886, lr: 0.0005, epoch: 4/9, step: 589/600\n",
      "loss: 0.0154, lr: 0.0005, epoch: 4/9, step: 590/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 4/9, step: 591/600\n",
      "loss: 0.1611, lr: 0.0005, epoch: 4/9, step: 592/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 4/9, step: 593/600\n",
      "loss: 0.3328, lr: 0.0005, epoch: 4/9, step: 594/600\n",
      "loss: 0.7944, lr: 0.0005, epoch: 4/9, step: 595/600\n",
      "loss: 0.3394, lr: 0.0005, epoch: 4/9, step: 596/600\n",
      "loss: 0.0377, lr: 0.0005, epoch: 4/9, step: 597/600\n",
      "loss: 0.2793, lr: 0.0005, epoch: 4/9, step: 598/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 4/9, step: 599/600\n",
      "loss: 0.0751, lr: 0.0005, epoch: 4/9, step: 600/600\n",
      "loss: 0.012, lr: 0.0005, epoch: 5/9, step: 1/600\n",
      "loss: 0.0388, lr: 0.0005, epoch: 5/9, step: 2/600\n",
      "loss: 0.045, lr: 0.0005, epoch: 5/9, step: 3/600\n",
      "loss: 0.5166, lr: 0.0005, epoch: 5/9, step: 4/600\n",
      "loss: 0.0329, lr: 0.0005, epoch: 5/9, step: 5/600\n",
      "loss: 0.3479, lr: 0.0005, epoch: 5/9, step: 6/600\n",
      "loss: 0.3027, lr: 0.0005, epoch: 5/9, step: 7/600\n",
      "loss: 0.1266, lr: 0.0005, epoch: 5/9, step: 8/600\n",
      "loss: 0.019, lr: 0.0005, epoch: 5/9, step: 9/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 5/9, step: 10/600\n",
      "loss: 0.0276, lr: 0.0005, epoch: 5/9, step: 11/600\n",
      "loss: 0.0363, lr: 0.0005, epoch: 5/9, step: 12/600\n",
      "loss: 0.1843, lr: 0.0005, epoch: 5/9, step: 13/600\n",
      "loss: 0.54, lr: 0.0005, epoch: 5/9, step: 14/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 5/9, step: 15/600\n",
      "loss: 0.1222, lr: 0.0005, epoch: 5/9, step: 16/600\n",
      "loss: 0.1349, lr: 0.0005, epoch: 5/9, step: 17/600\n",
      "loss: 0.814, lr: 0.0005, epoch: 5/9, step: 18/600\n",
      "loss: 0.0624, lr: 0.0005, epoch: 5/9, step: 19/600\n",
      "loss: 0.1097, lr: 0.0005, epoch: 5/9, step: 20/600\n",
      "loss: 0.3645, lr: 0.0005, epoch: 5/9, step: 21/600\n",
      "loss: 0.0809, lr: 0.0005, epoch: 5/9, step: 22/600\n",
      "loss: 0.2421, lr: 0.0005, epoch: 5/9, step: 23/600\n",
      "loss: 0.2161, lr: 0.0005, epoch: 5/9, step: 24/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 5/9, step: 25/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 5/9, step: 26/600\n",
      "loss: 0.395, lr: 0.0005, epoch: 5/9, step: 27/600\n",
      "loss: 0.0913, lr: 0.0005, epoch: 5/9, step: 28/600\n",
      "loss: 0.4231, lr: 0.0005, epoch: 5/9, step: 29/600\n",
      "loss: 0.0215, lr: 0.0005, epoch: 5/9, step: 30/600\n",
      "loss: 0.1381, lr: 0.0005, epoch: 5/9, step: 31/600\n",
      "loss: 0.4939, lr: 0.0005, epoch: 5/9, step: 32/600\n",
      "loss: 0.0508, lr: 0.0005, epoch: 5/9, step: 33/600\n",
      "loss: 0.8472, lr: 0.0005, epoch: 5/9, step: 34/600\n",
      "loss: 0.0942, lr: 0.0005, epoch: 5/9, step: 35/600\n",
      "loss: 0.0534, lr: 0.0005, epoch: 5/9, step: 36/600\n",
      "loss: 0.0295, lr: 0.0005, epoch: 5/9, step: 37/600\n",
      "loss: 0.3545, lr: 0.0005, epoch: 5/9, step: 38/600\n",
      "loss: 0.4526, lr: 0.0005, epoch: 5/9, step: 39/600\n",
      "loss: 0.2354, lr: 0.0005, epoch: 5/9, step: 40/600\n",
      "loss: 0.6138, lr: 0.0005, epoch: 5/9, step: 41/600\n",
      "loss: 0.0847, lr: 0.0005, epoch: 5/9, step: 42/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 5/9, step: 43/600\n",
      "loss: 0.3508, lr: 0.0005, epoch: 5/9, step: 44/600\n",
      "loss: 0.039, lr: 0.0005, epoch: 5/9, step: 45/600\n",
      "loss: 0.3027, lr: 0.0005, epoch: 5/9, step: 46/600\n",
      "loss: 0.5845, lr: 0.0005, epoch: 5/9, step: 47/600\n",
      "loss: 0.0069, lr: 0.0005, epoch: 5/9, step: 48/600\n",
      "loss: 0.0195, lr: 0.0005, epoch: 5/9, step: 49/600\n",
      "loss: 0.2306, lr: 0.0005, epoch: 5/9, step: 50/600\n",
      "loss: 0.3049, lr: 0.0005, epoch: 5/9, step: 51/600\n",
      "loss: 0.0956, lr: 0.0005, epoch: 5/9, step: 52/600\n",
      "loss: 0.0182, lr: 0.0005, epoch: 5/9, step: 53/600\n",
      "loss: 0.519, lr: 0.0005, epoch: 5/9, step: 54/600\n",
      "loss: 0.1263, lr: 0.0005, epoch: 5/9, step: 55/600\n",
      "loss: 0.3899, lr: 0.0005, epoch: 5/9, step: 56/600\n",
      "loss: 0.6602, lr: 0.0005, epoch: 5/9, step: 57/600\n",
      "loss: 0.0134, lr: 0.0005, epoch: 5/9, step: 58/600\n",
      "loss: 0.1102, lr: 0.0005, epoch: 5/9, step: 59/600\n",
      "loss: 0.0179, lr: 0.0005, epoch: 5/9, step: 60/600\n",
      "loss: 0.1005, lr: 0.0005, epoch: 5/9, step: 61/600\n",
      "loss: 0.0297, lr: 0.0005, epoch: 5/9, step: 62/600\n",
      "loss: 0.6094, lr: 0.0005, epoch: 5/9, step: 63/600\n",
      "loss: 0.0961, lr: 0.0005, epoch: 5/9, step: 64/600\n",
      "loss: 0.0147, lr: 0.0005, epoch: 5/9, step: 65/600\n",
      "loss: 0.3013, lr: 0.0005, epoch: 5/9, step: 66/600\n",
      "loss: 0.1613, lr: 0.0005, epoch: 5/9, step: 67/600\n",
      "loss: 0.0323, lr: 0.0005, epoch: 5/9, step: 68/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 5/9, step: 69/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 5/9, step: 70/600\n",
      "loss: 0.0322, lr: 0.0005, epoch: 5/9, step: 71/600\n",
      "loss: 0.0527, lr: 0.0005, epoch: 5/9, step: 72/600\n",
      "loss: 0.0302, lr: 0.0005, epoch: 5/9, step: 73/600\n",
      "loss: 0.3486, lr: 0.0005, epoch: 5/9, step: 74/600\n",
      "loss: 0.29, lr: 0.0005, epoch: 5/9, step: 75/600\n",
      "loss: 0.3796, lr: 0.0005, epoch: 5/9, step: 76/600\n",
      "loss: 0.0997, lr: 0.0005, epoch: 5/9, step: 77/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 5/9, step: 78/600\n",
      "loss: 0.603, lr: 0.0005, epoch: 5/9, step: 79/600\n",
      "loss: 0.167, lr: 0.0005, epoch: 5/9, step: 80/600\n",
      "loss: 0.1351, lr: 0.0005, epoch: 5/9, step: 81/600\n",
      "loss: 0.0769, lr: 0.0005, epoch: 5/9, step: 82/600\n",
      "loss: 0.0174, lr: 0.0005, epoch: 5/9, step: 83/600\n",
      "loss: 0.3525, lr: 0.0005, epoch: 5/9, step: 84/600\n",
      "loss: 0.1737, lr: 0.0005, epoch: 5/9, step: 85/600\n",
      "loss: 0.0317, lr: 0.0005, epoch: 5/9, step: 86/600\n",
      "loss: 0.0753, lr: 0.0005, epoch: 5/9, step: 87/600\n",
      "loss: 0.3181, lr: 0.0005, epoch: 5/9, step: 88/600\n",
      "loss: 0.4297, lr: 0.0005, epoch: 5/9, step: 89/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 5/9, step: 90/600\n",
      "loss: 0.0174, lr: 0.0005, epoch: 5/9, step: 91/600\n",
      "loss: 0.2593, lr: 0.0005, epoch: 5/9, step: 92/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 5/9, step: 93/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 5/9, step: 94/600\n",
      "loss: 0.3228, lr: 0.0005, epoch: 5/9, step: 95/600\n",
      "loss: 0.5024, lr: 0.0005, epoch: 5/9, step: 96/600\n",
      "loss: 0.2491, lr: 0.0005, epoch: 5/9, step: 97/600\n",
      "loss: 0.1229, lr: 0.0005, epoch: 5/9, step: 98/600\n",
      "loss: 0.6299, lr: 0.0005, epoch: 5/9, step: 99/600\n",
      "loss: 0.0342, lr: 0.0005, epoch: 5/9, step: 100/600\n",
      "loss: 0.2029, lr: 0.0005, epoch: 5/9, step: 101/600\n",
      "loss: 0.4714, lr: 0.0005, epoch: 5/9, step: 102/600\n",
      "loss: 0.4045, lr: 0.0005, epoch: 5/9, step: 103/600\n",
      "loss: 0.5488, lr: 0.0005, epoch: 5/9, step: 104/600\n",
      "loss: 0.054, lr: 0.0005, epoch: 5/9, step: 105/600\n",
      "loss: 0.2433, lr: 0.0005, epoch: 5/9, step: 106/600\n",
      "loss: 0.4292, lr: 0.0005, epoch: 5/9, step: 107/600\n",
      "loss: 0.0865, lr: 0.0005, epoch: 5/9, step: 108/600\n",
      "loss: 0.2212, lr: 0.0005, epoch: 5/9, step: 109/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 5/9, step: 110/600\n",
      "loss: 0.3296, lr: 0.0005, epoch: 5/9, step: 111/600\n",
      "loss: 0.1815, lr: 0.0005, epoch: 5/9, step: 112/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 5/9, step: 113/600\n",
      "loss: 0.2666, lr: 0.0005, epoch: 5/9, step: 114/600\n",
      "loss: 0.6826, lr: 0.0005, epoch: 5/9, step: 115/600\n",
      "loss: 0.2795, lr: 0.0005, epoch: 5/9, step: 116/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 5/9, step: 117/600\n",
      "loss: 0.1439, lr: 0.0005, epoch: 5/9, step: 118/600\n",
      "loss: 0.0296, lr: 0.0005, epoch: 5/9, step: 119/600\n",
      "loss: 0.2118, lr: 0.0005, epoch: 5/9, step: 120/600\n",
      "loss: 0.0309, lr: 0.0005, epoch: 5/9, step: 121/600\n",
      "loss: 0.543, lr: 0.0005, epoch: 5/9, step: 122/600\n",
      "loss: 0.0687, lr: 0.0005, epoch: 5/9, step: 123/600\n",
      "loss: 0.2267, lr: 0.0005, epoch: 5/9, step: 124/600\n",
      "loss: 0.061, lr: 0.0005, epoch: 5/9, step: 125/600\n",
      "loss: 0.2693, lr: 0.0005, epoch: 5/9, step: 126/600\n",
      "loss: 0.519, lr: 0.0005, epoch: 5/9, step: 127/600\n",
      "loss: 0.1219, lr: 0.0005, epoch: 5/9, step: 128/600\n",
      "loss: 0.2791, lr: 0.0005, epoch: 5/9, step: 129/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 5/9, step: 130/600\n",
      "loss: 0.177, lr: 0.0005, epoch: 5/9, step: 131/600\n",
      "loss: 0.1509, lr: 0.0005, epoch: 5/9, step: 132/600\n",
      "loss: 0.5635, lr: 0.0005, epoch: 5/9, step: 133/600\n",
      "loss: 0.0255, lr: 0.0005, epoch: 5/9, step: 134/600\n",
      "loss: 0.5454, lr: 0.0005, epoch: 5/9, step: 135/600\n",
      "loss: 0.0141, lr: 0.0005, epoch: 5/9, step: 136/600\n",
      "loss: 0.7793, lr: 0.0005, epoch: 5/9, step: 137/600\n",
      "loss: 0.0145, lr: 0.0005, epoch: 5/9, step: 138/600\n",
      "loss: 0.0395, lr: 0.0005, epoch: 5/9, step: 139/600\n",
      "loss: 0.1818, lr: 0.0005, epoch: 5/9, step: 140/600\n",
      "loss: 0.0306, lr: 0.0005, epoch: 5/9, step: 141/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 5/9, step: 142/600\n",
      "loss: 0.0364, lr: 0.0005, epoch: 5/9, step: 143/600\n",
      "loss: 0.0154, lr: 0.0005, epoch: 5/9, step: 144/600\n",
      "loss: 0.4871, lr: 0.0005, epoch: 5/9, step: 145/600\n",
      "loss: 0.2125, lr: 0.0005, epoch: 5/9, step: 146/600\n",
      "loss: 0.0214, lr: 0.0005, epoch: 5/9, step: 147/600\n",
      "loss: 0.0148, lr: 0.0005, epoch: 5/9, step: 148/600\n",
      "loss: 0.469, lr: 0.0005, epoch: 5/9, step: 149/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 5/9, step: 150/600\n",
      "loss: 0.0483, lr: 0.0005, epoch: 5/9, step: 151/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 5/9, step: 152/600\n",
      "loss: 0.4299, lr: 0.0005, epoch: 5/9, step: 153/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 5/9, step: 154/600\n",
      "loss: 0.0387, lr: 0.0005, epoch: 5/9, step: 155/600\n",
      "loss: 0.1122, lr: 0.0005, epoch: 5/9, step: 156/600\n",
      "loss: 0.0162, lr: 0.0005, epoch: 5/9, step: 157/600\n",
      "loss: 0.5278, lr: 0.0005, epoch: 5/9, step: 158/600\n",
      "loss: 0.2571, lr: 0.0005, epoch: 5/9, step: 159/600\n",
      "loss: 0.0457, lr: 0.0005, epoch: 5/9, step: 160/600\n",
      "loss: 0.4434, lr: 0.0005, epoch: 5/9, step: 161/600\n",
      "loss: 0.1119, lr: 0.0005, epoch: 5/9, step: 162/600\n",
      "loss: 0.896, lr: 0.0005, epoch: 5/9, step: 163/600\n",
      "loss: 0.1494, lr: 0.0005, epoch: 5/9, step: 164/600\n",
      "loss: 0.4409, lr: 0.0005, epoch: 5/9, step: 165/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 5/9, step: 166/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 5/9, step: 167/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 5/9, step: 168/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 5/9, step: 169/600\n",
      "loss: 0.2908, lr: 0.0005, epoch: 5/9, step: 170/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 5/9, step: 171/600\n",
      "loss: 0.0333, lr: 0.0005, epoch: 5/9, step: 172/600\n",
      "loss: 0.0126, lr: 0.0005, epoch: 5/9, step: 173/600\n",
      "loss: 0.0436, lr: 0.0005, epoch: 5/9, step: 174/600\n",
      "loss: 0.0149, lr: 0.0005, epoch: 5/9, step: 175/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 5/9, step: 176/600\n",
      "loss: 0.3237, lr: 0.0005, epoch: 5/9, step: 177/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 5/9, step: 178/600\n",
      "loss: 0.0113, lr: 0.0005, epoch: 5/9, step: 179/600\n",
      "loss: 0.1462, lr: 0.0005, epoch: 5/9, step: 180/600\n",
      "loss: 0.1177, lr: 0.0005, epoch: 5/9, step: 181/600\n",
      "loss: 0.3022, lr: 0.0005, epoch: 5/9, step: 182/600\n",
      "loss: 0.5015, lr: 0.0005, epoch: 5/9, step: 183/600\n",
      "loss: 0.48, lr: 0.0005, epoch: 5/9, step: 184/600\n",
      "loss: 0.0276, lr: 0.0005, epoch: 5/9, step: 185/600\n",
      "loss: 0.3169, lr: 0.0005, epoch: 5/9, step: 186/600\n",
      "loss: 0.2131, lr: 0.0005, epoch: 5/9, step: 187/600\n",
      "loss: 0.0137, lr: 0.0005, epoch: 5/9, step: 188/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 5/9, step: 189/600\n",
      "loss: 0.5986, lr: 0.0005, epoch: 5/9, step: 190/600\n",
      "loss: 0.0743, lr: 0.0005, epoch: 5/9, step: 191/600\n",
      "loss: 0.4631, lr: 0.0005, epoch: 5/9, step: 192/600\n",
      "loss: 0.1302, lr: 0.0005, epoch: 5/9, step: 193/600\n",
      "loss: 0.5527, lr: 0.0005, epoch: 5/9, step: 194/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 5/9, step: 195/600\n",
      "loss: 0.3333, lr: 0.0005, epoch: 5/9, step: 196/600\n",
      "loss: 0.0173, lr: 0.0005, epoch: 5/9, step: 197/600\n",
      "loss: 0.016, lr: 0.0005, epoch: 5/9, step: 198/600\n",
      "loss: 0.0242, lr: 0.0005, epoch: 5/9, step: 199/600\n",
      "loss: 0.0365, lr: 0.0005, epoch: 5/9, step: 200/600\n",
      "loss: 0.0714, lr: 0.0005, epoch: 5/9, step: 201/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 5/9, step: 202/600\n",
      "loss: 0.0365, lr: 0.0005, epoch: 5/9, step: 203/600\n",
      "loss: 0.2915, lr: 0.0005, epoch: 5/9, step: 204/600\n",
      "loss: 0.0584, lr: 0.0005, epoch: 5/9, step: 205/600\n",
      "loss: 0.1169, lr: 0.0005, epoch: 5/9, step: 206/600\n",
      "loss: 0.3337, lr: 0.0005, epoch: 5/9, step: 207/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 5/9, step: 208/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 5/9, step: 209/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 5/9, step: 210/600\n",
      "loss: 0.4397, lr: 0.0005, epoch: 5/9, step: 211/600\n",
      "loss: 0.5298, lr: 0.0005, epoch: 5/9, step: 212/600\n",
      "loss: 0.2656, lr: 0.0005, epoch: 5/9, step: 213/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 5/9, step: 214/600\n",
      "loss: 0.2329, lr: 0.0005, epoch: 5/9, step: 215/600\n",
      "loss: 0.0396, lr: 0.0005, epoch: 5/9, step: 216/600\n",
      "loss: 0.1503, lr: 0.0005, epoch: 5/9, step: 217/600\n",
      "loss: 0.0215, lr: 0.0005, epoch: 5/9, step: 218/600\n",
      "loss: 0.0554, lr: 0.0005, epoch: 5/9, step: 219/600\n",
      "loss: 0.0364, lr: 0.0005, epoch: 5/9, step: 220/600\n",
      "loss: 0.02, lr: 0.0005, epoch: 5/9, step: 221/600\n",
      "loss: 0.6099, lr: 0.0005, epoch: 5/9, step: 222/600\n",
      "loss: 0.0667, lr: 0.0005, epoch: 5/9, step: 223/600\n",
      "loss: 0.0961, lr: 0.0005, epoch: 5/9, step: 224/600\n",
      "loss: 0.4995, lr: 0.0005, epoch: 5/9, step: 225/600\n",
      "loss: 0.0173, lr: 0.0005, epoch: 5/9, step: 226/600\n",
      "loss: 0.2131, lr: 0.0005, epoch: 5/9, step: 227/600\n",
      "loss: 0.0257, lr: 0.0005, epoch: 5/9, step: 228/600\n",
      "loss: 0.4604, lr: 0.0005, epoch: 5/9, step: 229/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 5/9, step: 230/600\n",
      "loss: 0.4109, lr: 0.0005, epoch: 5/9, step: 231/600\n",
      "loss: 0.3284, lr: 0.0005, epoch: 5/9, step: 232/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 5/9, step: 233/600\n",
      "loss: 0.5918, lr: 0.0005, epoch: 5/9, step: 234/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 5/9, step: 235/600\n",
      "loss: 0.2031, lr: 0.0005, epoch: 5/9, step: 236/600\n",
      "loss: 0.0222, lr: 0.0005, epoch: 5/9, step: 237/600\n",
      "loss: 0.3855, lr: 0.0005, epoch: 5/9, step: 238/600\n",
      "loss: 0.1255, lr: 0.0005, epoch: 5/9, step: 239/600\n",
      "loss: 0.0186, lr: 0.0005, epoch: 5/9, step: 240/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 5/9, step: 241/600\n",
      "loss: 0.3752, lr: 0.0005, epoch: 5/9, step: 242/600\n",
      "loss: 0.1938, lr: 0.0005, epoch: 5/9, step: 243/600\n",
      "loss: 0.3137, lr: 0.0005, epoch: 5/9, step: 244/600\n",
      "loss: 0.007, lr: 0.0005, epoch: 5/9, step: 245/600\n",
      "loss: 0.4153, lr: 0.0005, epoch: 5/9, step: 246/600\n",
      "loss: 0.0734, lr: 0.0005, epoch: 5/9, step: 247/600\n",
      "loss: 0.5508, lr: 0.0005, epoch: 5/9, step: 248/600\n",
      "loss: 0.3762, lr: 0.0005, epoch: 5/9, step: 249/600\n",
      "loss: 0.1119, lr: 0.0005, epoch: 5/9, step: 250/600\n",
      "loss: 0.0408, lr: 0.0005, epoch: 5/9, step: 251/600\n",
      "loss: 0.2224, lr: 0.0005, epoch: 5/9, step: 252/600\n",
      "loss: 0.2812, lr: 0.0005, epoch: 5/9, step: 253/600\n",
      "loss: 0.3579, lr: 0.0005, epoch: 5/9, step: 254/600\n",
      "loss: 0.3286, lr: 0.0005, epoch: 5/9, step: 255/600\n",
      "loss: 0.0407, lr: 0.0005, epoch: 5/9, step: 256/600\n",
      "loss: 0.0655, lr: 0.0005, epoch: 5/9, step: 257/600\n",
      "loss: 0.437, lr: 0.0005, epoch: 5/9, step: 258/600\n",
      "loss: 0.5625, lr: 0.0005, epoch: 5/9, step: 259/600\n",
      "loss: 0.1104, lr: 0.0005, epoch: 5/9, step: 260/600\n",
      "loss: 0.2986, lr: 0.0005, epoch: 5/9, step: 261/600\n",
      "loss: 0.407, lr: 0.0005, epoch: 5/9, step: 262/600\n",
      "loss: 0.1403, lr: 0.0005, epoch: 5/9, step: 263/600\n",
      "loss: 0.0948, lr: 0.0005, epoch: 5/9, step: 264/600\n",
      "loss: 0.5942, lr: 0.0005, epoch: 5/9, step: 265/600\n",
      "loss: 0.0203, lr: 0.0005, epoch: 5/9, step: 266/600\n",
      "loss: 0.0612, lr: 0.0005, epoch: 5/9, step: 267/600\n",
      "loss: 0.0804, lr: 0.0005, epoch: 5/9, step: 268/600\n",
      "loss: 0.2438, lr: 0.0005, epoch: 5/9, step: 269/600\n",
      "loss: 0.1414, lr: 0.0005, epoch: 5/9, step: 270/600\n",
      "loss: 0.0887, lr: 0.0005, epoch: 5/9, step: 271/600\n",
      "loss: 0.1876, lr: 0.0005, epoch: 5/9, step: 272/600\n",
      "loss: 0.4324, lr: 0.0005, epoch: 5/9, step: 273/600\n",
      "loss: 0.3936, lr: 0.0005, epoch: 5/9, step: 274/600\n",
      "loss: 0.0804, lr: 0.0005, epoch: 5/9, step: 275/600\n",
      "loss: 0.063, lr: 0.0005, epoch: 5/9, step: 276/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 5/9, step: 277/600\n",
      "loss: 0.501, lr: 0.0005, epoch: 5/9, step: 278/600\n",
      "loss: 0.6509, lr: 0.0005, epoch: 5/9, step: 279/600\n",
      "loss: 0.0158, lr: 0.0005, epoch: 5/9, step: 280/600\n",
      "loss: 0.0396, lr: 0.0005, epoch: 5/9, step: 281/600\n",
      "loss: 0.2893, lr: 0.0005, epoch: 5/9, step: 282/600\n",
      "loss: 0.2163, lr: 0.0005, epoch: 5/9, step: 283/600\n",
      "loss: 0.225, lr: 0.0005, epoch: 5/9, step: 284/600\n",
      "loss: 0.1318, lr: 0.0005, epoch: 5/9, step: 285/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 5/9, step: 286/600\n",
      "loss: 0.0411, lr: 0.0005, epoch: 5/9, step: 287/600\n",
      "loss: 0.3569, lr: 0.0005, epoch: 5/9, step: 288/600\n",
      "loss: 0.3379, lr: 0.0005, epoch: 5/9, step: 289/600\n",
      "loss: 0.0308, lr: 0.0005, epoch: 5/9, step: 290/600\n",
      "loss: 0.1152, lr: 0.0005, epoch: 5/9, step: 291/600\n",
      "loss: 0.034, lr: 0.0005, epoch: 5/9, step: 292/600\n",
      "loss: 0.0888, lr: 0.0005, epoch: 5/9, step: 293/600\n",
      "loss: 0.3374, lr: 0.0005, epoch: 5/9, step: 294/600\n",
      "loss: 0.0397, lr: 0.0005, epoch: 5/9, step: 295/600\n",
      "loss: 0.0375, lr: 0.0005, epoch: 5/9, step: 296/600\n",
      "loss: 0.3066, lr: 0.0005, epoch: 5/9, step: 297/600\n",
      "loss: 0.2764, lr: 0.0005, epoch: 5/9, step: 298/600\n",
      "loss: 0.0535, lr: 0.0005, epoch: 5/9, step: 299/600\n",
      "loss: 0.1268, lr: 0.0005, epoch: 5/9, step: 300/600\n",
      "loss: 0.0425, lr: 0.0005, epoch: 5/9, step: 301/600\n",
      "loss: 0.6904, lr: 0.0005, epoch: 5/9, step: 302/600\n",
      "loss: 0.4116, lr: 0.0005, epoch: 5/9, step: 303/600\n",
      "loss: 0.1224, lr: 0.0005, epoch: 5/9, step: 304/600\n",
      "loss: 0.0158, lr: 0.0005, epoch: 5/9, step: 305/600\n",
      "loss: 0.0952, lr: 0.0005, epoch: 5/9, step: 306/600\n",
      "loss: 0.077, lr: 0.0005, epoch: 5/9, step: 307/600\n",
      "loss: 0.3767, lr: 0.0005, epoch: 5/9, step: 308/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 5/9, step: 309/600\n",
      "loss: 0.0364, lr: 0.0005, epoch: 5/9, step: 310/600\n",
      "loss: 0.0262, lr: 0.0005, epoch: 5/9, step: 311/600\n",
      "loss: 0.0655, lr: 0.0005, epoch: 5/9, step: 312/600\n",
      "loss: 0.3206, lr: 0.0005, epoch: 5/9, step: 313/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 5/9, step: 314/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 5/9, step: 315/600\n",
      "loss: 0.01, lr: 0.0005, epoch: 5/9, step: 316/600\n",
      "loss: 0.1399, lr: 0.0005, epoch: 5/9, step: 317/600\n",
      "loss: 0.0946, lr: 0.0005, epoch: 5/9, step: 318/600\n",
      "loss: 0.0953, lr: 0.0005, epoch: 5/9, step: 319/600\n",
      "loss: 0.1771, lr: 0.0005, epoch: 5/9, step: 320/600\n",
      "loss: 0.9917, lr: 0.0005, epoch: 5/9, step: 321/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 5/9, step: 322/600\n",
      "loss: 0.7969, lr: 0.0005, epoch: 5/9, step: 323/600\n",
      "loss: 0.1191, lr: 0.0005, epoch: 5/9, step: 324/600\n",
      "loss: 0.5156, lr: 0.0005, epoch: 5/9, step: 325/600\n",
      "loss: 0.1497, lr: 0.0005, epoch: 5/9, step: 326/600\n",
      "loss: 0.0245, lr: 0.0005, epoch: 5/9, step: 327/600\n",
      "loss: 0.8345, lr: 0.0005, epoch: 5/9, step: 328/600\n",
      "loss: 0.4553, lr: 0.0005, epoch: 5/9, step: 329/600\n",
      "loss: 0.8721, lr: 0.0005, epoch: 5/9, step: 330/600\n",
      "loss: 0.0925, lr: 0.0005, epoch: 5/9, step: 331/600\n",
      "loss: 0.2234, lr: 0.0005, epoch: 5/9, step: 332/600\n",
      "loss: 0.0647, lr: 0.0005, epoch: 5/9, step: 333/600\n",
      "loss: 0.1293, lr: 0.0005, epoch: 5/9, step: 334/600\n",
      "loss: 0.2693, lr: 0.0005, epoch: 5/9, step: 335/600\n",
      "loss: 0.6191, lr: 0.0005, epoch: 5/9, step: 336/600\n",
      "loss: 0.0668, lr: 0.0005, epoch: 5/9, step: 337/600\n",
      "loss: 0.332, lr: 0.0005, epoch: 5/9, step: 338/600\n",
      "loss: 0.037, lr: 0.0005, epoch: 5/9, step: 339/600\n",
      "loss: 0.2085, lr: 0.0005, epoch: 5/9, step: 340/600\n",
      "loss: 0.0237, lr: 0.0005, epoch: 5/9, step: 341/600\n",
      "loss: 0.3127, lr: 0.0005, epoch: 5/9, step: 342/600\n",
      "loss: 0.1335, lr: 0.0005, epoch: 5/9, step: 343/600\n",
      "loss: 0.3423, lr: 0.0005, epoch: 5/9, step: 344/600\n",
      "loss: 0.647, lr: 0.0005, epoch: 5/9, step: 345/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 5/9, step: 346/600\n",
      "loss: 0.3079, lr: 0.0005, epoch: 5/9, step: 347/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 5/9, step: 348/600\n",
      "loss: 0.0851, lr: 0.0005, epoch: 5/9, step: 349/600\n",
      "loss: 0.0628, lr: 0.0005, epoch: 5/9, step: 350/600\n",
      "loss: 0.0145, lr: 0.0005, epoch: 5/9, step: 351/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 5/9, step: 352/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 5/9, step: 353/600\n",
      "loss: 0.0255, lr: 0.0005, epoch: 5/9, step: 354/600\n",
      "loss: 0.3955, lr: 0.0005, epoch: 5/9, step: 355/600\n",
      "loss: 0.1608, lr: 0.0005, epoch: 5/9, step: 356/600\n",
      "loss: 0.0837, lr: 0.0005, epoch: 5/9, step: 357/600\n",
      "loss: 0.092, lr: 0.0005, epoch: 5/9, step: 358/600\n",
      "loss: 0.0583, lr: 0.0005, epoch: 5/9, step: 359/600\n",
      "loss: 0.4795, lr: 0.0005, epoch: 5/9, step: 360/600\n",
      "loss: 0.4875, lr: 0.0005, epoch: 5/9, step: 361/600\n",
      "loss: 0.0183, lr: 0.0005, epoch: 5/9, step: 362/600\n",
      "loss: 0.0235, lr: 0.0005, epoch: 5/9, step: 363/600\n",
      "loss: 0.0383, lr: 0.0005, epoch: 5/9, step: 364/600\n",
      "loss: 0.0441, lr: 0.0005, epoch: 5/9, step: 365/600\n",
      "loss: 0.0315, lr: 0.0005, epoch: 5/9, step: 366/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 5/9, step: 367/600\n",
      "loss: 0.3909, lr: 0.0005, epoch: 5/9, step: 368/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 5/9, step: 369/600\n",
      "loss: 0.0434, lr: 0.0005, epoch: 5/9, step: 370/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 5/9, step: 371/600\n",
      "loss: 0.0254, lr: 0.0005, epoch: 5/9, step: 372/600\n",
      "loss: 0.0336, lr: 0.0005, epoch: 5/9, step: 373/600\n",
      "loss: 0.4502, lr: 0.0005, epoch: 5/9, step: 374/600\n",
      "loss: 0.0449, lr: 0.0005, epoch: 5/9, step: 375/600\n",
      "loss: 0.0196, lr: 0.0005, epoch: 5/9, step: 376/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 5/9, step: 377/600\n",
      "loss: 0.0387, lr: 0.0005, epoch: 5/9, step: 378/600\n",
      "loss: 0.0332, lr: 0.0005, epoch: 5/9, step: 379/600\n",
      "loss: 0.0128, lr: 0.0005, epoch: 5/9, step: 380/600\n",
      "loss: 0.3284, lr: 0.0005, epoch: 5/9, step: 381/600\n",
      "loss: 0.0341, lr: 0.0005, epoch: 5/9, step: 382/600\n",
      "loss: 0.2076, lr: 0.0005, epoch: 5/9, step: 383/600\n",
      "loss: 0.101, lr: 0.0005, epoch: 5/9, step: 384/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 5/9, step: 385/600\n",
      "loss: 0.0762, lr: 0.0005, epoch: 5/9, step: 386/600\n",
      "loss: 0.5903, lr: 0.0005, epoch: 5/9, step: 387/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 5/9, step: 388/600\n",
      "loss: 0.0308, lr: 0.0005, epoch: 5/9, step: 389/600\n",
      "loss: 0.0021, lr: 0.0005, epoch: 5/9, step: 390/600\n",
      "loss: 0.0291, lr: 0.0005, epoch: 5/9, step: 391/600\n",
      "loss: 0.1125, lr: 0.0005, epoch: 5/9, step: 392/600\n",
      "loss: 0.0447, lr: 0.0005, epoch: 5/9, step: 393/600\n",
      "loss: 0.2095, lr: 0.0005, epoch: 5/9, step: 394/600\n",
      "loss: 0.0726, lr: 0.0005, epoch: 5/9, step: 395/600\n",
      "loss: 0.7559, lr: 0.0005, epoch: 5/9, step: 396/600\n",
      "loss: 0.395, lr: 0.0005, epoch: 5/9, step: 397/600\n",
      "loss: 0.2661, lr: 0.0005, epoch: 5/9, step: 398/600\n",
      "loss: 0.0326, lr: 0.0005, epoch: 5/9, step: 399/600\n",
      "loss: 0.0122, lr: 0.0005, epoch: 5/9, step: 400/600\n",
      "loss: 0.2783, lr: 0.0005, epoch: 5/9, step: 401/600\n",
      "loss: 0.039, lr: 0.0005, epoch: 5/9, step: 402/600\n",
      "loss: 0.478, lr: 0.0005, epoch: 5/9, step: 403/600\n",
      "loss: 0.2445, lr: 0.0005, epoch: 5/9, step: 404/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 5/9, step: 405/600\n",
      "loss: 0.0111, lr: 0.0005, epoch: 5/9, step: 406/600\n",
      "loss: 0.0191, lr: 0.0005, epoch: 5/9, step: 407/600\n",
      "loss: 0.2289, lr: 0.0005, epoch: 5/9, step: 408/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 5/9, step: 409/600\n",
      "loss: 0.0745, lr: 0.0005, epoch: 5/9, step: 410/600\n",
      "loss: 0.3491, lr: 0.0005, epoch: 5/9, step: 411/600\n",
      "loss: 0.184, lr: 0.0005, epoch: 5/9, step: 412/600\n",
      "loss: 0.4512, lr: 0.0005, epoch: 5/9, step: 413/600\n",
      "loss: 0.5269, lr: 0.0005, epoch: 5/9, step: 414/600\n",
      "loss: 0.3633, lr: 0.0005, epoch: 5/9, step: 415/600\n",
      "loss: 0.0116, lr: 0.0005, epoch: 5/9, step: 416/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 5/9, step: 417/600\n",
      "loss: 0.3413, lr: 0.0005, epoch: 5/9, step: 418/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 5/9, step: 419/600\n",
      "loss: 0.0283, lr: 0.0005, epoch: 5/9, step: 420/600\n",
      "loss: 0.0221, lr: 0.0005, epoch: 5/9, step: 421/600\n",
      "loss: 0.7256, lr: 0.0005, epoch: 5/9, step: 422/600\n",
      "loss: 0.4102, lr: 0.0005, epoch: 5/9, step: 423/600\n",
      "loss: 0.064, lr: 0.0005, epoch: 5/9, step: 424/600\n",
      "loss: 0.0366, lr: 0.0005, epoch: 5/9, step: 425/600\n",
      "loss: 0.0316, lr: 0.0005, epoch: 5/9, step: 426/600\n",
      "loss: 0.1326, lr: 0.0005, epoch: 5/9, step: 427/600\n",
      "loss: 0.0329, lr: 0.0005, epoch: 5/9, step: 428/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 5/9, step: 429/600\n",
      "loss: 0.3157, lr: 0.0005, epoch: 5/9, step: 430/600\n",
      "loss: 0.1885, lr: 0.0005, epoch: 5/9, step: 431/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 5/9, step: 432/600\n",
      "loss: 0.0673, lr: 0.0005, epoch: 5/9, step: 433/600\n",
      "loss: 0.0347, lr: 0.0005, epoch: 5/9, step: 434/600\n",
      "loss: 0.1937, lr: 0.0005, epoch: 5/9, step: 435/600\n",
      "loss: 0.1281, lr: 0.0005, epoch: 5/9, step: 436/600\n",
      "loss: 0.0445, lr: 0.0005, epoch: 5/9, step: 437/600\n",
      "loss: 0.0936, lr: 0.0005, epoch: 5/9, step: 438/600\n",
      "loss: 0.3049, lr: 0.0005, epoch: 5/9, step: 439/600\n",
      "loss: 0.4446, lr: 0.0005, epoch: 5/9, step: 440/600\n",
      "loss: 0.0073, lr: 0.0005, epoch: 5/9, step: 441/600\n",
      "loss: 0.0341, lr: 0.0005, epoch: 5/9, step: 442/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 5/9, step: 443/600\n",
      "loss: 0.4741, lr: 0.0005, epoch: 5/9, step: 444/600\n",
      "loss: 0.1094, lr: 0.0005, epoch: 5/9, step: 445/600\n",
      "loss: 0.1108, lr: 0.0005, epoch: 5/9, step: 446/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 5/9, step: 447/600\n",
      "loss: 0.1613, lr: 0.0005, epoch: 5/9, step: 448/600\n",
      "loss: 0.5815, lr: 0.0005, epoch: 5/9, step: 449/600\n",
      "loss: 0.1981, lr: 0.0005, epoch: 5/9, step: 450/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 5/9, step: 451/600\n",
      "loss: 0.0144, lr: 0.0005, epoch: 5/9, step: 452/600\n",
      "loss: 0.5059, lr: 0.0005, epoch: 5/9, step: 453/600\n",
      "loss: 0.0281, lr: 0.0005, epoch: 5/9, step: 454/600\n",
      "loss: 0.2549, lr: 0.0005, epoch: 5/9, step: 455/600\n",
      "loss: 0.1727, lr: 0.0005, epoch: 5/9, step: 456/600\n",
      "loss: 0.427, lr: 0.0005, epoch: 5/9, step: 457/600\n",
      "loss: 0.0551, lr: 0.0005, epoch: 5/9, step: 458/600\n",
      "loss: 0.1947, lr: 0.0005, epoch: 5/9, step: 459/600\n",
      "loss: 0.5513, lr: 0.0005, epoch: 5/9, step: 460/600\n",
      "loss: 0.1858, lr: 0.0005, epoch: 5/9, step: 461/600\n",
      "loss: 0.0101, lr: 0.0005, epoch: 5/9, step: 462/600\n",
      "loss: 0.0174, lr: 0.0005, epoch: 5/9, step: 463/600\n",
      "loss: 0.2871, lr: 0.0005, epoch: 5/9, step: 464/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 5/9, step: 465/600\n",
      "loss: 0.0105, lr: 0.0005, epoch: 5/9, step: 466/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 5/9, step: 467/600\n",
      "loss: 0.3232, lr: 0.0005, epoch: 5/9, step: 468/600\n",
      "loss: 0.0609, lr: 0.0005, epoch: 5/9, step: 469/600\n",
      "loss: 0.6504, lr: 0.0005, epoch: 5/9, step: 470/600\n",
      "loss: 0.0088, lr: 0.0005, epoch: 5/9, step: 471/600\n",
      "loss: 0.1821, lr: 0.0005, epoch: 5/9, step: 472/600\n",
      "loss: 0.2776, lr: 0.0005, epoch: 5/9, step: 473/600\n",
      "loss: 0.1613, lr: 0.0005, epoch: 5/9, step: 474/600\n",
      "loss: 0.3003, lr: 0.0005, epoch: 5/9, step: 475/600\n",
      "loss: 0.1516, lr: 0.0005, epoch: 5/9, step: 476/600\n",
      "loss: 0.6382, lr: 0.0005, epoch: 5/9, step: 477/600\n",
      "loss: 0.0764, lr: 0.0005, epoch: 5/9, step: 478/600\n",
      "loss: 0.0397, lr: 0.0005, epoch: 5/9, step: 479/600\n",
      "loss: 0.0905, lr: 0.0005, epoch: 5/9, step: 480/600\n",
      "loss: 0.0203, lr: 0.0005, epoch: 5/9, step: 481/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 5/9, step: 482/600\n",
      "loss: 0.0456, lr: 0.0005, epoch: 5/9, step: 483/600\n",
      "loss: 0.0257, lr: 0.0005, epoch: 5/9, step: 484/600\n",
      "loss: 0.3467, lr: 0.0005, epoch: 5/9, step: 485/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 5/9, step: 486/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 5/9, step: 487/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 5/9, step: 488/600\n",
      "loss: 0.0663, lr: 0.0005, epoch: 5/9, step: 489/600\n",
      "loss: 0.0233, lr: 0.0005, epoch: 5/9, step: 490/600\n",
      "loss: 0.0992, lr: 0.0005, epoch: 5/9, step: 491/600\n",
      "loss: 0.5596, lr: 0.0005, epoch: 5/9, step: 492/600\n",
      "loss: 0.1895, lr: 0.0005, epoch: 5/9, step: 493/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 5/9, step: 494/600\n",
      "loss: 0.5239, lr: 0.0005, epoch: 5/9, step: 495/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 5/9, step: 496/600\n",
      "loss: 0.0105, lr: 0.0005, epoch: 5/9, step: 497/600\n",
      "loss: 0.0428, lr: 0.0005, epoch: 5/9, step: 498/600\n",
      "loss: 0.5776, lr: 0.0005, epoch: 5/9, step: 499/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 5/9, step: 500/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 5/9, step: 501/600\n",
      "loss: 0.0252, lr: 0.0005, epoch: 5/9, step: 502/600\n",
      "loss: 0.4829, lr: 0.0005, epoch: 5/9, step: 503/600\n",
      "loss: 0.3796, lr: 0.0005, epoch: 5/9, step: 504/600\n",
      "loss: 0.0093, lr: 0.0005, epoch: 5/9, step: 505/600\n",
      "loss: 0.0273, lr: 0.0005, epoch: 5/9, step: 506/600\n",
      "loss: 0.1453, lr: 0.0005, epoch: 5/9, step: 507/600\n",
      "loss: 0.7788, lr: 0.0005, epoch: 5/9, step: 508/600\n",
      "loss: 0.2252, lr: 0.0005, epoch: 5/9, step: 509/600\n",
      "loss: 0.152, lr: 0.0005, epoch: 5/9, step: 510/600\n",
      "loss: 0.0203, lr: 0.0005, epoch: 5/9, step: 511/600\n",
      "loss: 0.1909, lr: 0.0005, epoch: 5/9, step: 512/600\n",
      "loss: 0.067, lr: 0.0005, epoch: 5/9, step: 513/600\n",
      "loss: 0.1342, lr: 0.0005, epoch: 5/9, step: 514/600\n",
      "loss: 0.0179, lr: 0.0005, epoch: 5/9, step: 515/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 5/9, step: 516/600\n",
      "loss: 0.0236, lr: 0.0005, epoch: 5/9, step: 517/600\n",
      "loss: 0.7061, lr: 0.0005, epoch: 5/9, step: 518/600\n",
      "loss: 0.0181, lr: 0.0005, epoch: 5/9, step: 519/600\n",
      "loss: 0.0232, lr: 0.0005, epoch: 5/9, step: 520/600\n",
      "loss: 0.4172, lr: 0.0005, epoch: 5/9, step: 521/600\n",
      "loss: 0.1783, lr: 0.0005, epoch: 5/9, step: 522/600\n",
      "loss: 0.2412, lr: 0.0005, epoch: 5/9, step: 523/600\n",
      "loss: 0.0763, lr: 0.0005, epoch: 5/9, step: 524/600\n",
      "loss: 0.1309, lr: 0.0005, epoch: 5/9, step: 525/600\n",
      "loss: 0.562, lr: 0.0005, epoch: 5/9, step: 526/600\n",
      "loss: 0.0553, lr: 0.0005, epoch: 5/9, step: 527/600\n",
      "loss: 0.6636, lr: 0.0005, epoch: 5/9, step: 528/600\n",
      "loss: 0.2644, lr: 0.0005, epoch: 5/9, step: 529/600\n",
      "loss: 0.4958, lr: 0.0005, epoch: 5/9, step: 530/600\n",
      "loss: 0.108, lr: 0.0005, epoch: 5/9, step: 531/600\n",
      "loss: 0.6182, lr: 0.0005, epoch: 5/9, step: 532/600\n",
      "loss: 0.0103, lr: 0.0005, epoch: 5/9, step: 533/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 5/9, step: 534/600\n",
      "loss: 0.353, lr: 0.0005, epoch: 5/9, step: 535/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 5/9, step: 536/600\n",
      "loss: 0.5034, lr: 0.0005, epoch: 5/9, step: 537/600\n",
      "loss: 0.0705, lr: 0.0005, epoch: 5/9, step: 538/600\n",
      "loss: 0.1433, lr: 0.0005, epoch: 5/9, step: 539/600\n",
      "loss: 0.0021, lr: 0.0005, epoch: 5/9, step: 540/600\n",
      "loss: 0.2764, lr: 0.0005, epoch: 5/9, step: 541/600\n",
      "loss: 0.1121, lr: 0.0005, epoch: 5/9, step: 542/600\n",
      "loss: 0.0241, lr: 0.0005, epoch: 5/9, step: 543/600\n",
      "loss: 0.7012, lr: 0.0005, epoch: 5/9, step: 544/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 5/9, step: 545/600\n",
      "loss: 0.1609, lr: 0.0005, epoch: 5/9, step: 546/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 5/9, step: 547/600\n",
      "loss: 0.1876, lr: 0.0005, epoch: 5/9, step: 548/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 5/9, step: 549/600\n",
      "loss: 0.3125, lr: 0.0005, epoch: 5/9, step: 550/600\n",
      "loss: 0.2883, lr: 0.0005, epoch: 5/9, step: 551/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 5/9, step: 552/600\n",
      "loss: 0.046, lr: 0.0005, epoch: 5/9, step: 553/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 5/9, step: 554/600\n",
      "loss: 0.0967, lr: 0.0005, epoch: 5/9, step: 555/600\n",
      "loss: 0.0471, lr: 0.0005, epoch: 5/9, step: 556/600\n",
      "loss: 0.6069, lr: 0.0005, epoch: 5/9, step: 557/600\n",
      "loss: 0.6226, lr: 0.0005, epoch: 5/9, step: 558/600\n",
      "loss: 0.2057, lr: 0.0005, epoch: 5/9, step: 559/600\n",
      "loss: 0.4646, lr: 0.0005, epoch: 5/9, step: 560/600\n",
      "loss: 0.3462, lr: 0.0005, epoch: 5/9, step: 561/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 5/9, step: 562/600\n",
      "loss: 0.2291, lr: 0.0005, epoch: 5/9, step: 563/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 5/9, step: 564/600\n",
      "loss: 0.3008, lr: 0.0005, epoch: 5/9, step: 565/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 5/9, step: 566/600\n",
      "loss: 0.6479, lr: 0.0005, epoch: 5/9, step: 567/600\n",
      "loss: 0.0789, lr: 0.0005, epoch: 5/9, step: 568/600\n",
      "loss: 0.0552, lr: 0.0005, epoch: 5/9, step: 569/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 5/9, step: 570/600\n",
      "loss: 0.1193, lr: 0.0005, epoch: 5/9, step: 571/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 5/9, step: 572/600\n",
      "loss: 0.1869, lr: 0.0005, epoch: 5/9, step: 573/600\n",
      "loss: 0.2974, lr: 0.0005, epoch: 5/9, step: 574/600\n",
      "loss: 0.0297, lr: 0.0005, epoch: 5/9, step: 575/600\n",
      "loss: 0.0127, lr: 0.0005, epoch: 5/9, step: 576/600\n",
      "loss: 0.6309, lr: 0.0005, epoch: 5/9, step: 577/600\n",
      "loss: 0.4124, lr: 0.0005, epoch: 5/9, step: 578/600\n",
      "loss: 0.1133, lr: 0.0005, epoch: 5/9, step: 579/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 5/9, step: 580/600\n",
      "loss: 0.2074, lr: 0.0005, epoch: 5/9, step: 581/600\n",
      "loss: 0.0163, lr: 0.0005, epoch: 5/9, step: 582/600\n",
      "loss: 0.4412, lr: 0.0005, epoch: 5/9, step: 583/600\n",
      "loss: 0.3164, lr: 0.0005, epoch: 5/9, step: 584/600\n",
      "loss: 0.0455, lr: 0.0005, epoch: 5/9, step: 585/600\n",
      "loss: 0.2271, lr: 0.0005, epoch: 5/9, step: 586/600\n",
      "loss: 0.6909, lr: 0.0005, epoch: 5/9, step: 587/600\n",
      "loss: 0.5625, lr: 0.0005, epoch: 5/9, step: 588/600\n",
      "loss: 0.344, lr: 0.0005, epoch: 5/9, step: 589/600\n",
      "loss: 0.1392, lr: 0.0005, epoch: 5/9, step: 590/600\n",
      "loss: 0.4612, lr: 0.0005, epoch: 5/9, step: 591/600\n",
      "loss: 0.0591, lr: 0.0005, epoch: 5/9, step: 592/600\n",
      "loss: 0.427, lr: 0.0005, epoch: 5/9, step: 593/600\n",
      "loss: 0.0201, lr: 0.0005, epoch: 5/9, step: 594/600\n",
      "loss: 0.147, lr: 0.0005, epoch: 5/9, step: 595/600\n",
      "loss: 0.0176, lr: 0.0005, epoch: 5/9, step: 596/600\n",
      "loss: 0.0743, lr: 0.0005, epoch: 5/9, step: 597/600\n",
      "loss: 0.1005, lr: 0.0005, epoch: 5/9, step: 598/600\n",
      "loss: 0.3877, lr: 0.0005, epoch: 5/9, step: 599/600\n",
      "loss: 0.2607, lr: 0.0005, epoch: 5/9, step: 600/600\n",
      "loss: 0.0229, lr: 0.0005, epoch: 6/9, step: 1/600\n",
      "loss: 0.097, lr: 0.0005, epoch: 6/9, step: 2/600\n",
      "loss: 0.2021, lr: 0.0005, epoch: 6/9, step: 3/600\n",
      "loss: 0.2615, lr: 0.0005, epoch: 6/9, step: 4/600\n",
      "loss: 0.0637, lr: 0.0005, epoch: 6/9, step: 5/600\n",
      "loss: 0.0603, lr: 0.0005, epoch: 6/9, step: 6/600\n",
      "loss: 0.2661, lr: 0.0005, epoch: 6/9, step: 7/600\n",
      "loss: 0.0704, lr: 0.0005, epoch: 6/9, step: 8/600\n",
      "loss: 0.1312, lr: 0.0005, epoch: 6/9, step: 9/600\n",
      "loss: 0.1141, lr: 0.0005, epoch: 6/9, step: 10/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 6/9, step: 11/600\n",
      "loss: 0.2114, lr: 0.0005, epoch: 6/9, step: 12/600\n",
      "loss: 0.0416, lr: 0.0005, epoch: 6/9, step: 13/600\n",
      "loss: 0.2969, lr: 0.0005, epoch: 6/9, step: 14/600\n",
      "loss: 0.6396, lr: 0.0005, epoch: 6/9, step: 15/600\n",
      "loss: 0.0475, lr: 0.0005, epoch: 6/9, step: 16/600\n",
      "loss: 0.0277, lr: 0.0005, epoch: 6/9, step: 17/600\n",
      "loss: 0.0462, lr: 0.0005, epoch: 6/9, step: 18/600\n",
      "loss: 0.1438, lr: 0.0005, epoch: 6/9, step: 19/600\n",
      "loss: 0.4824, lr: 0.0005, epoch: 6/9, step: 20/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 6/9, step: 21/600\n",
      "loss: 0.1407, lr: 0.0005, epoch: 6/9, step: 22/600\n",
      "loss: 0.122, lr: 0.0005, epoch: 6/9, step: 23/600\n",
      "loss: 0.3293, lr: 0.0005, epoch: 6/9, step: 24/600\n",
      "loss: 0.0986, lr: 0.0005, epoch: 6/9, step: 25/600\n",
      "loss: 0.063, lr: 0.0005, epoch: 6/9, step: 26/600\n",
      "loss: 0.0265, lr: 0.0005, epoch: 6/9, step: 27/600\n",
      "loss: 0.1096, lr: 0.0005, epoch: 6/9, step: 28/600\n",
      "loss: 0.0105, lr: 0.0005, epoch: 6/9, step: 29/600\n",
      "loss: 0.2184, lr: 0.0005, epoch: 6/9, step: 30/600\n",
      "loss: 0.1785, lr: 0.0005, epoch: 6/9, step: 31/600\n",
      "loss: 0.0349, lr: 0.0005, epoch: 6/9, step: 32/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 6/9, step: 33/600\n",
      "loss: 0.1115, lr: 0.0005, epoch: 6/9, step: 34/600\n",
      "loss: 0.1367, lr: 0.0005, epoch: 6/9, step: 35/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 6/9, step: 36/600\n",
      "loss: 0.0656, lr: 0.0005, epoch: 6/9, step: 37/600\n",
      "loss: 0.0512, lr: 0.0005, epoch: 6/9, step: 38/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 6/9, step: 39/600\n",
      "loss: 0.2172, lr: 0.0005, epoch: 6/9, step: 40/600\n",
      "loss: 0.1696, lr: 0.0005, epoch: 6/9, step: 41/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 6/9, step: 42/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 6/9, step: 43/600\n",
      "loss: 0.2085, lr: 0.0005, epoch: 6/9, step: 44/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 6/9, step: 45/600\n",
      "loss: 0.4607, lr: 0.0005, epoch: 6/9, step: 46/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 6/9, step: 47/600\n",
      "loss: 0.2686, lr: 0.0005, epoch: 6/9, step: 48/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 6/9, step: 49/600\n",
      "loss: 0.2686, lr: 0.0005, epoch: 6/9, step: 50/600\n",
      "loss: 0.0742, lr: 0.0005, epoch: 6/9, step: 51/600\n",
      "loss: 0.0668, lr: 0.0005, epoch: 6/9, step: 52/600\n",
      "loss: 0.0814, lr: 0.0005, epoch: 6/9, step: 53/600\n",
      "loss: 0.1464, lr: 0.0005, epoch: 6/9, step: 54/600\n",
      "loss: 0.5532, lr: 0.0005, epoch: 6/9, step: 55/600\n",
      "loss: 0.0657, lr: 0.0005, epoch: 6/9, step: 56/600\n",
      "loss: 0.0974, lr: 0.0005, epoch: 6/9, step: 57/600\n",
      "loss: 0.102, lr: 0.0005, epoch: 6/9, step: 58/600\n",
      "loss: 0.1281, lr: 0.0005, epoch: 6/9, step: 59/600\n",
      "loss: 0.0547, lr: 0.0005, epoch: 6/9, step: 60/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 6/9, step: 61/600\n",
      "loss: 0.2148, lr: 0.0005, epoch: 6/9, step: 62/600\n",
      "loss: 0.1978, lr: 0.0005, epoch: 6/9, step: 63/600\n",
      "loss: 0.1938, lr: 0.0005, epoch: 6/9, step: 64/600\n",
      "loss: 0.0196, lr: 0.0005, epoch: 6/9, step: 65/600\n",
      "loss: 0.1731, lr: 0.0005, epoch: 6/9, step: 66/600\n",
      "loss: 0.2737, lr: 0.0005, epoch: 6/9, step: 67/600\n",
      "loss: 0.1418, lr: 0.0005, epoch: 6/9, step: 68/600\n",
      "loss: 0.8804, lr: 0.0005, epoch: 6/9, step: 69/600\n",
      "loss: 0.249, lr: 0.0005, epoch: 6/9, step: 70/600\n",
      "loss: 0.3311, lr: 0.0005, epoch: 6/9, step: 71/600\n",
      "loss: 0.0143, lr: 0.0005, epoch: 6/9, step: 72/600\n",
      "loss: 0.1385, lr: 0.0005, epoch: 6/9, step: 73/600\n",
      "loss: 0.1578, lr: 0.0005, epoch: 6/9, step: 74/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 75/600\n",
      "loss: 0.0269, lr: 0.0005, epoch: 6/9, step: 76/600\n",
      "loss: 0.0782, lr: 0.0005, epoch: 6/9, step: 77/600\n",
      "loss: 0.0209, lr: 0.0005, epoch: 6/9, step: 78/600\n",
      "loss: 0.132, lr: 0.0005, epoch: 6/9, step: 79/600\n",
      "loss: 0.4089, lr: 0.0005, epoch: 6/9, step: 80/600\n",
      "loss: 0.2563, lr: 0.0005, epoch: 6/9, step: 81/600\n",
      "loss: 0.0461, lr: 0.0005, epoch: 6/9, step: 82/600\n",
      "loss: 0.0579, lr: 0.0005, epoch: 6/9, step: 83/600\n",
      "loss: 0.5557, lr: 0.0005, epoch: 6/9, step: 84/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 6/9, step: 85/600\n",
      "loss: 0.098, lr: 0.0005, epoch: 6/9, step: 86/600\n",
      "loss: 0.7046, lr: 0.0005, epoch: 6/9, step: 87/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 6/9, step: 88/600\n",
      "loss: 0.01, lr: 0.0005, epoch: 6/9, step: 89/600\n",
      "loss: 0.2468, lr: 0.0005, epoch: 6/9, step: 90/600\n",
      "loss: 0.1354, lr: 0.0005, epoch: 6/9, step: 91/600\n",
      "loss: 0.3606, lr: 0.0005, epoch: 6/9, step: 92/600\n",
      "loss: 0.4578, lr: 0.0005, epoch: 6/9, step: 93/600\n",
      "loss: 0.0842, lr: 0.0005, epoch: 6/9, step: 94/600\n",
      "loss: 0.1572, lr: 0.0005, epoch: 6/9, step: 95/600\n",
      "loss: 0.0603, lr: 0.0005, epoch: 6/9, step: 96/600\n",
      "loss: 0.1831, lr: 0.0005, epoch: 6/9, step: 97/600\n",
      "loss: 0.3047, lr: 0.0005, epoch: 6/9, step: 98/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 6/9, step: 99/600\n",
      "loss: 0.056, lr: 0.0005, epoch: 6/9, step: 100/600\n",
      "loss: 0.1804, lr: 0.0005, epoch: 6/9, step: 101/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 6/9, step: 102/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 6/9, step: 103/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 6/9, step: 104/600\n",
      "loss: 0.4124, lr: 0.0005, epoch: 6/9, step: 105/600\n",
      "loss: 0.2764, lr: 0.0005, epoch: 6/9, step: 106/600\n",
      "loss: 0.3323, lr: 0.0005, epoch: 6/9, step: 107/600\n",
      "loss: 0.4209, lr: 0.0005, epoch: 6/9, step: 108/600\n",
      "loss: 0.0468, lr: 0.0005, epoch: 6/9, step: 109/600\n",
      "loss: 0.418, lr: 0.0005, epoch: 6/9, step: 110/600\n",
      "loss: 0.0331, lr: 0.0005, epoch: 6/9, step: 111/600\n",
      "loss: 0.1332, lr: 0.0005, epoch: 6/9, step: 112/600\n",
      "loss: 0.1641, lr: 0.0005, epoch: 6/9, step: 113/600\n",
      "loss: 0.5542, lr: 0.0005, epoch: 6/9, step: 114/600\n",
      "loss: 0.7231, lr: 0.0005, epoch: 6/9, step: 115/600\n",
      "loss: 0.6035, lr: 0.0005, epoch: 6/9, step: 116/600\n",
      "loss: 0.4697, lr: 0.0005, epoch: 6/9, step: 117/600\n",
      "loss: 0.0187, lr: 0.0005, epoch: 6/9, step: 118/600\n",
      "loss: 0.0392, lr: 0.0005, epoch: 6/9, step: 119/600\n",
      "loss: 0.3916, lr: 0.0005, epoch: 6/9, step: 120/600\n",
      "loss: 0.1722, lr: 0.0005, epoch: 6/9, step: 121/600\n",
      "loss: 0.1305, lr: 0.0005, epoch: 6/9, step: 122/600\n",
      "loss: 0.1453, lr: 0.0005, epoch: 6/9, step: 123/600\n",
      "loss: 0.6572, lr: 0.0005, epoch: 6/9, step: 124/600\n",
      "loss: 0.0886, lr: 0.0005, epoch: 6/9, step: 125/600\n",
      "loss: 0.1938, lr: 0.0005, epoch: 6/9, step: 126/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 6/9, step: 127/600\n",
      "loss: 0.0731, lr: 0.0005, epoch: 6/9, step: 128/600\n",
      "loss: 0.024, lr: 0.0005, epoch: 6/9, step: 129/600\n",
      "loss: 0.2056, lr: 0.0005, epoch: 6/9, step: 130/600\n",
      "loss: 0.1309, lr: 0.0005, epoch: 6/9, step: 131/600\n",
      "loss: 0.0346, lr: 0.0005, epoch: 6/9, step: 132/600\n",
      "loss: 0.5176, lr: 0.0005, epoch: 6/9, step: 133/600\n",
      "loss: 0.625, lr: 0.0005, epoch: 6/9, step: 134/600\n",
      "loss: 0.0191, lr: 0.0005, epoch: 6/9, step: 135/600\n",
      "loss: 0.1083, lr: 0.0005, epoch: 6/9, step: 136/600\n",
      "loss: 0.1038, lr: 0.0005, epoch: 6/9, step: 137/600\n",
      "loss: 0.2888, lr: 0.0005, epoch: 6/9, step: 138/600\n",
      "loss: 0.055, lr: 0.0005, epoch: 6/9, step: 139/600\n",
      "loss: 0.1123, lr: 0.0005, epoch: 6/9, step: 140/600\n",
      "loss: 0.0993, lr: 0.0005, epoch: 6/9, step: 141/600\n",
      "loss: 0.5635, lr: 0.0005, epoch: 6/9, step: 142/600\n",
      "loss: 0.0299, lr: 0.0005, epoch: 6/9, step: 143/600\n",
      "loss: 0.3755, lr: 0.0005, epoch: 6/9, step: 144/600\n",
      "loss: 0.2218, lr: 0.0005, epoch: 6/9, step: 145/600\n",
      "loss: 0.3022, lr: 0.0005, epoch: 6/9, step: 146/600\n",
      "loss: 0.0387, lr: 0.0005, epoch: 6/9, step: 147/600\n",
      "loss: 0.3521, lr: 0.0005, epoch: 6/9, step: 148/600\n",
      "loss: 0.2163, lr: 0.0005, epoch: 6/9, step: 149/600\n",
      "loss: 0.0315, lr: 0.0005, epoch: 6/9, step: 150/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 6/9, step: 151/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 6/9, step: 152/600\n",
      "loss: 0.3105, lr: 0.0005, epoch: 6/9, step: 153/600\n",
      "loss: 0.1624, lr: 0.0005, epoch: 6/9, step: 154/600\n",
      "loss: 0.3032, lr: 0.0005, epoch: 6/9, step: 155/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 6/9, step: 156/600\n",
      "loss: 0.2045, lr: 0.0005, epoch: 6/9, step: 157/600\n",
      "loss: 0.3015, lr: 0.0005, epoch: 6/9, step: 158/600\n",
      "loss: 0.4272, lr: 0.0005, epoch: 6/9, step: 159/600\n",
      "loss: 0.1913, lr: 0.0005, epoch: 6/9, step: 160/600\n",
      "loss: 0.1575, lr: 0.0005, epoch: 6/9, step: 161/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 6/9, step: 162/600\n",
      "loss: 0.0366, lr: 0.0005, epoch: 6/9, step: 163/600\n",
      "loss: 0.3035, lr: 0.0005, epoch: 6/9, step: 164/600\n",
      "loss: 0.1205, lr: 0.0005, epoch: 6/9, step: 165/600\n",
      "loss: 0.053, lr: 0.0005, epoch: 6/9, step: 166/600\n",
      "loss: 0.2922, lr: 0.0005, epoch: 6/9, step: 167/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 6/9, step: 168/600\n",
      "loss: 0.3357, lr: 0.0005, epoch: 6/9, step: 169/600\n",
      "loss: 0.4258, lr: 0.0005, epoch: 6/9, step: 170/600\n",
      "loss: 0.4316, lr: 0.0005, epoch: 6/9, step: 171/600\n",
      "loss: 0.1296, lr: 0.0005, epoch: 6/9, step: 172/600\n",
      "loss: 0.1254, lr: 0.0005, epoch: 6/9, step: 173/600\n",
      "loss: 0.1086, lr: 0.0005, epoch: 6/9, step: 174/600\n",
      "loss: 0.4614, lr: 0.0005, epoch: 6/9, step: 175/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 6/9, step: 176/600\n",
      "loss: 0.2847, lr: 0.0005, epoch: 6/9, step: 177/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 6/9, step: 178/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 6/9, step: 179/600\n",
      "loss: 0.4985, lr: 0.0005, epoch: 6/9, step: 180/600\n",
      "loss: 0.0276, lr: 0.0005, epoch: 6/9, step: 181/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 6/9, step: 182/600\n",
      "loss: 0.668, lr: 0.0005, epoch: 6/9, step: 183/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 6/9, step: 184/600\n",
      "loss: 0.0371, lr: 0.0005, epoch: 6/9, step: 185/600\n",
      "loss: 0.0294, lr: 0.0005, epoch: 6/9, step: 186/600\n",
      "loss: 0.099, lr: 0.0005, epoch: 6/9, step: 187/600\n",
      "loss: 0.0116, lr: 0.0005, epoch: 6/9, step: 188/600\n",
      "loss: 0.0803, lr: 0.0005, epoch: 6/9, step: 189/600\n",
      "loss: 0.1107, lr: 0.0005, epoch: 6/9, step: 190/600\n",
      "loss: 0.0316, lr: 0.0005, epoch: 6/9, step: 191/600\n",
      "loss: 0.0834, lr: 0.0005, epoch: 6/9, step: 192/600\n",
      "loss: 0.2532, lr: 0.0005, epoch: 6/9, step: 193/600\n",
      "loss: 0.4355, lr: 0.0005, epoch: 6/9, step: 194/600\n",
      "loss: 0.0659, lr: 0.0005, epoch: 6/9, step: 195/600\n",
      "loss: 0.0241, lr: 0.0005, epoch: 6/9, step: 196/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 6/9, step: 197/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 198/600\n",
      "loss: 0.0647, lr: 0.0005, epoch: 6/9, step: 199/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 6/9, step: 200/600\n",
      "loss: 0.1428, lr: 0.0005, epoch: 6/9, step: 201/600\n",
      "loss: 0.0301, lr: 0.0005, epoch: 6/9, step: 202/600\n",
      "loss: 0.3079, lr: 0.0005, epoch: 6/9, step: 203/600\n",
      "loss: 0.0488, lr: 0.0005, epoch: 6/9, step: 204/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 6/9, step: 205/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 6/9, step: 206/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 6/9, step: 207/600\n",
      "loss: 0.0165, lr: 0.0005, epoch: 6/9, step: 208/600\n",
      "loss: 0.1652, lr: 0.0005, epoch: 6/9, step: 209/600\n",
      "loss: 0.0407, lr: 0.0005, epoch: 6/9, step: 210/600\n",
      "loss: 0.0861, lr: 0.0005, epoch: 6/9, step: 211/600\n",
      "loss: 0.0073, lr: 0.0005, epoch: 6/9, step: 212/600\n",
      "loss: 0.1886, lr: 0.0005, epoch: 6/9, step: 213/600\n",
      "loss: 0.4541, lr: 0.0005, epoch: 6/9, step: 214/600\n",
      "loss: 0.386, lr: 0.0005, epoch: 6/9, step: 215/600\n",
      "loss: 0.1121, lr: 0.0005, epoch: 6/9, step: 216/600\n",
      "loss: 0.156, lr: 0.0005, epoch: 6/9, step: 217/600\n",
      "loss: 0.832, lr: 0.0005, epoch: 6/9, step: 218/600\n",
      "loss: 0.1006, lr: 0.0005, epoch: 6/9, step: 219/600\n",
      "loss: 0.3955, lr: 0.0005, epoch: 6/9, step: 220/600\n",
      "loss: 0.0208, lr: 0.0005, epoch: 6/9, step: 221/600\n",
      "loss: 0.0305, lr: 0.0005, epoch: 6/9, step: 222/600\n",
      "loss: 0.0513, lr: 0.0005, epoch: 6/9, step: 223/600\n",
      "loss: 0.1913, lr: 0.0005, epoch: 6/9, step: 224/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 225/600\n",
      "loss: 0.3513, lr: 0.0005, epoch: 6/9, step: 226/600\n",
      "loss: 0.0427, lr: 0.0005, epoch: 6/9, step: 227/600\n",
      "loss: 0.561, lr: 0.0005, epoch: 6/9, step: 228/600\n",
      "loss: 0.035, lr: 0.0005, epoch: 6/9, step: 229/600\n",
      "loss: 0.4397, lr: 0.0005, epoch: 6/9, step: 230/600\n",
      "loss: 0.2593, lr: 0.0005, epoch: 6/9, step: 231/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 6/9, step: 232/600\n",
      "loss: 0.0263, lr: 0.0005, epoch: 6/9, step: 233/600\n",
      "loss: 0.283, lr: 0.0005, epoch: 6/9, step: 234/600\n",
      "loss: 0.0897, lr: 0.0005, epoch: 6/9, step: 235/600\n",
      "loss: 0.2798, lr: 0.0005, epoch: 6/9, step: 236/600\n",
      "loss: 0.6333, lr: 0.0005, epoch: 6/9, step: 237/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 6/9, step: 238/600\n",
      "loss: 0.2092, lr: 0.0005, epoch: 6/9, step: 239/600\n",
      "loss: 0.311, lr: 0.0005, epoch: 6/9, step: 240/600\n",
      "loss: 0.8081, lr: 0.0005, epoch: 6/9, step: 241/600\n",
      "loss: 0.3059, lr: 0.0005, epoch: 6/9, step: 242/600\n",
      "loss: 0.731, lr: 0.0005, epoch: 6/9, step: 243/600\n",
      "loss: 0.3306, lr: 0.0005, epoch: 6/9, step: 244/600\n",
      "loss: 0.0748, lr: 0.0005, epoch: 6/9, step: 245/600\n",
      "loss: 0.3247, lr: 0.0005, epoch: 6/9, step: 246/600\n",
      "loss: 0.1172, lr: 0.0005, epoch: 6/9, step: 247/600\n",
      "loss: 0.0116, lr: 0.0005, epoch: 6/9, step: 248/600\n",
      "loss: 0.0286, lr: 0.0005, epoch: 6/9, step: 249/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 6/9, step: 250/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 6/9, step: 251/600\n",
      "loss: 0.0227, lr: 0.0005, epoch: 6/9, step: 252/600\n",
      "loss: 0.0147, lr: 0.0005, epoch: 6/9, step: 253/600\n",
      "loss: 0.0464, lr: 0.0005, epoch: 6/9, step: 254/600\n",
      "loss: 0.0777, lr: 0.0005, epoch: 6/9, step: 255/600\n",
      "loss: 0.0132, lr: 0.0005, epoch: 6/9, step: 256/600\n",
      "loss: 0.4243, lr: 0.0005, epoch: 6/9, step: 257/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 6/9, step: 258/600\n",
      "loss: 0.0371, lr: 0.0005, epoch: 6/9, step: 259/600\n",
      "loss: 0.1718, lr: 0.0005, epoch: 6/9, step: 260/600\n",
      "loss: 0.1367, lr: 0.0005, epoch: 6/9, step: 261/600\n",
      "loss: 0.0279, lr: 0.0005, epoch: 6/9, step: 262/600\n",
      "loss: 0.204, lr: 0.0005, epoch: 6/9, step: 263/600\n",
      "loss: 0.0224, lr: 0.0005, epoch: 6/9, step: 264/600\n",
      "loss: 0.0776, lr: 0.0005, epoch: 6/9, step: 265/600\n",
      "loss: 0.3201, lr: 0.0005, epoch: 6/9, step: 266/600\n",
      "loss: 0.1334, lr: 0.0005, epoch: 6/9, step: 267/600\n",
      "loss: 0.4321, lr: 0.0005, epoch: 6/9, step: 268/600\n",
      "loss: 0.0314, lr: 0.0005, epoch: 6/9, step: 269/600\n",
      "loss: 0.011, lr: 0.0005, epoch: 6/9, step: 270/600\n",
      "loss: 0.0396, lr: 0.0005, epoch: 6/9, step: 271/600\n",
      "loss: 0.3291, lr: 0.0005, epoch: 6/9, step: 272/600\n",
      "loss: 0.0987, lr: 0.0005, epoch: 6/9, step: 273/600\n",
      "loss: 0.3625, lr: 0.0005, epoch: 6/9, step: 274/600\n",
      "loss: 0.1965, lr: 0.0005, epoch: 6/9, step: 275/600\n",
      "loss: 0.7769, lr: 0.0005, epoch: 6/9, step: 276/600\n",
      "loss: 0.408, lr: 0.0005, epoch: 6/9, step: 277/600\n",
      "loss: 0.8569, lr: 0.0005, epoch: 6/9, step: 278/600\n",
      "loss: 0.0413, lr: 0.0005, epoch: 6/9, step: 279/600\n",
      "loss: 0.6162, lr: 0.0005, epoch: 6/9, step: 280/600\n",
      "loss: 0.2476, lr: 0.0005, epoch: 6/9, step: 281/600\n",
      "loss: 0.0319, lr: 0.0005, epoch: 6/9, step: 282/600\n",
      "loss: 0.2644, lr: 0.0005, epoch: 6/9, step: 283/600\n",
      "loss: 0.6289, lr: 0.0005, epoch: 6/9, step: 284/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 6/9, step: 285/600\n",
      "loss: 0.0763, lr: 0.0005, epoch: 6/9, step: 286/600\n",
      "loss: 0.2175, lr: 0.0005, epoch: 6/9, step: 287/600\n",
      "loss: 0.034, lr: 0.0005, epoch: 6/9, step: 288/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 6/9, step: 289/600\n",
      "loss: 0.1045, lr: 0.0005, epoch: 6/9, step: 290/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 6/9, step: 291/600\n",
      "loss: 0.0107, lr: 0.0005, epoch: 6/9, step: 292/600\n",
      "loss: 0.2295, lr: 0.0005, epoch: 6/9, step: 293/600\n",
      "loss: 0.1857, lr: 0.0005, epoch: 6/9, step: 294/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 6/9, step: 295/600\n",
      "loss: 0.2246, lr: 0.0005, epoch: 6/9, step: 296/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 6/9, step: 297/600\n",
      "loss: 0.0472, lr: 0.0005, epoch: 6/9, step: 298/600\n",
      "loss: 0.1609, lr: 0.0005, epoch: 6/9, step: 299/600\n",
      "loss: 0.0073, lr: 0.0005, epoch: 6/9, step: 300/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 6/9, step: 301/600\n",
      "loss: 0.0876, lr: 0.0005, epoch: 6/9, step: 302/600\n",
      "loss: 0.026, lr: 0.0005, epoch: 6/9, step: 303/600\n",
      "loss: 0.5552, lr: 0.0005, epoch: 6/9, step: 304/600\n",
      "loss: 0.0404, lr: 0.0005, epoch: 6/9, step: 305/600\n",
      "loss: 0.0464, lr: 0.0005, epoch: 6/9, step: 306/600\n",
      "loss: 0.2181, lr: 0.0005, epoch: 6/9, step: 307/600\n",
      "loss: 0.01, lr: 0.0005, epoch: 6/9, step: 308/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 6/9, step: 309/600\n",
      "loss: 0.0753, lr: 0.0005, epoch: 6/9, step: 310/600\n",
      "loss: 0.3862, lr: 0.0005, epoch: 6/9, step: 311/600\n",
      "loss: 0.1881, lr: 0.0005, epoch: 6/9, step: 312/600\n",
      "loss: 0.3574, lr: 0.0005, epoch: 6/9, step: 313/600\n",
      "loss: 0.0973, lr: 0.0005, epoch: 6/9, step: 314/600\n",
      "loss: 0.1089, lr: 0.0005, epoch: 6/9, step: 315/600\n",
      "loss: 0.0136, lr: 0.0005, epoch: 6/9, step: 316/600\n",
      "loss: 0.405, lr: 0.0005, epoch: 6/9, step: 317/600\n",
      "loss: 0.5537, lr: 0.0005, epoch: 6/9, step: 318/600\n",
      "loss: 0.0081, lr: 0.0005, epoch: 6/9, step: 319/600\n",
      "loss: 0.0457, lr: 0.0005, epoch: 6/9, step: 320/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 6/9, step: 321/600\n",
      "loss: 0.2373, lr: 0.0005, epoch: 6/9, step: 322/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 323/600\n",
      "loss: 0.0467, lr: 0.0005, epoch: 6/9, step: 324/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 6/9, step: 325/600\n",
      "loss: 0.3245, lr: 0.0005, epoch: 6/9, step: 326/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 6/9, step: 327/600\n",
      "loss: 0.1486, lr: 0.0005, epoch: 6/9, step: 328/600\n",
      "loss: 0.3889, lr: 0.0005, epoch: 6/9, step: 329/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 6/9, step: 330/600\n",
      "loss: 0.0669, lr: 0.0005, epoch: 6/9, step: 331/600\n",
      "loss: 0.0495, lr: 0.0005, epoch: 6/9, step: 332/600\n",
      "loss: 0.3967, lr: 0.0005, epoch: 6/9, step: 333/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 334/600\n",
      "loss: 0.241, lr: 0.0005, epoch: 6/9, step: 335/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 6/9, step: 336/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 6/9, step: 337/600\n",
      "loss: 0.2115, lr: 0.0005, epoch: 6/9, step: 338/600\n",
      "loss: 0.0687, lr: 0.0005, epoch: 6/9, step: 339/600\n",
      "loss: 0.1189, lr: 0.0005, epoch: 6/9, step: 340/600\n",
      "loss: 0.7773, lr: 0.0005, epoch: 6/9, step: 341/600\n",
      "loss: 0.0024, lr: 0.0005, epoch: 6/9, step: 342/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 6/9, step: 343/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 6/9, step: 344/600\n",
      "loss: 0.2208, lr: 0.0005, epoch: 6/9, step: 345/600\n",
      "loss: 0.0571, lr: 0.0005, epoch: 6/9, step: 346/600\n",
      "loss: 0.0716, lr: 0.0005, epoch: 6/9, step: 347/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 6/9, step: 348/600\n",
      "loss: 0.0826, lr: 0.0005, epoch: 6/9, step: 349/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 6/9, step: 350/600\n",
      "loss: 0.0156, lr: 0.0005, epoch: 6/9, step: 351/600\n",
      "loss: 0.2363, lr: 0.0005, epoch: 6/9, step: 352/600\n",
      "loss: 0.6519, lr: 0.0005, epoch: 6/9, step: 353/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 6/9, step: 354/600\n",
      "loss: 0.0967, lr: 0.0005, epoch: 6/9, step: 355/600\n",
      "loss: 0.8828, lr: 0.0005, epoch: 6/9, step: 356/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 6/9, step: 357/600\n",
      "loss: 0.3855, lr: 0.0005, epoch: 6/9, step: 358/600\n",
      "loss: 0.08, lr: 0.0005, epoch: 6/9, step: 359/600\n",
      "loss: 0.0339, lr: 0.0005, epoch: 6/9, step: 360/600\n",
      "loss: 0.2401, lr: 0.0005, epoch: 6/9, step: 361/600\n",
      "loss: 0.832, lr: 0.0005, epoch: 6/9, step: 362/600\n",
      "loss: 0.1741, lr: 0.0005, epoch: 6/9, step: 363/600\n",
      "loss: 0.3613, lr: 0.0005, epoch: 6/9, step: 364/600\n",
      "loss: 0.2476, lr: 0.0005, epoch: 6/9, step: 365/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 366/600\n",
      "loss: 0.0094, lr: 0.0005, epoch: 6/9, step: 367/600\n",
      "loss: 0.5366, lr: 0.0005, epoch: 6/9, step: 368/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 369/600\n",
      "loss: 0.0537, lr: 0.0005, epoch: 6/9, step: 370/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 6/9, step: 371/600\n",
      "loss: 0.0159, lr: 0.0005, epoch: 6/9, step: 372/600\n",
      "loss: 0.0509, lr: 0.0005, epoch: 6/9, step: 373/600\n",
      "loss: 0.1368, lr: 0.0005, epoch: 6/9, step: 374/600\n",
      "loss: 0.0437, lr: 0.0005, epoch: 6/9, step: 375/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 6/9, step: 376/600\n",
      "loss: 0.1305, lr: 0.0005, epoch: 6/9, step: 377/600\n",
      "loss: 0.2356, lr: 0.0005, epoch: 6/9, step: 378/600\n",
      "loss: 0.2158, lr: 0.0005, epoch: 6/9, step: 379/600\n",
      "loss: 0.3232, lr: 0.0005, epoch: 6/9, step: 380/600\n",
      "loss: 0.4529, lr: 0.0005, epoch: 6/9, step: 381/600\n",
      "loss: 0.3269, lr: 0.0005, epoch: 6/9, step: 382/600\n",
      "loss: 0.2297, lr: 0.0005, epoch: 6/9, step: 383/600\n",
      "loss: 0.1273, lr: 0.0005, epoch: 6/9, step: 384/600\n",
      "loss: 0.0632, lr: 0.0005, epoch: 6/9, step: 385/600\n",
      "loss: 0.0288, lr: 0.0005, epoch: 6/9, step: 386/600\n",
      "loss: 0.0424, lr: 0.0005, epoch: 6/9, step: 387/600\n",
      "loss: 0.7012, lr: 0.0005, epoch: 6/9, step: 388/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 6/9, step: 389/600\n",
      "loss: 0.2566, lr: 0.0005, epoch: 6/9, step: 390/600\n",
      "loss: 0.4475, lr: 0.0005, epoch: 6/9, step: 391/600\n",
      "loss: 0.5073, lr: 0.0005, epoch: 6/9, step: 392/600\n",
      "loss: 0.0306, lr: 0.0005, epoch: 6/9, step: 393/600\n",
      "loss: 0.021, lr: 0.0005, epoch: 6/9, step: 394/600\n",
      "loss: 0.0458, lr: 0.0005, epoch: 6/9, step: 395/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 6/9, step: 396/600\n",
      "loss: 0.3376, lr: 0.0005, epoch: 6/9, step: 397/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 6/9, step: 398/600\n",
      "loss: 0.0629, lr: 0.0005, epoch: 6/9, step: 399/600\n",
      "loss: 0.1611, lr: 0.0005, epoch: 6/9, step: 400/600\n",
      "loss: 0.0745, lr: 0.0005, epoch: 6/9, step: 401/600\n",
      "loss: 0.0021, lr: 0.0005, epoch: 6/9, step: 402/600\n",
      "loss: 0.0351, lr: 0.0005, epoch: 6/9, step: 403/600\n",
      "loss: 0.3816, lr: 0.0005, epoch: 6/9, step: 404/600\n",
      "loss: 0.1909, lr: 0.0005, epoch: 6/9, step: 405/600\n",
      "loss: 0.2362, lr: 0.0005, epoch: 6/9, step: 406/600\n",
      "loss: 0.0189, lr: 0.0005, epoch: 6/9, step: 407/600\n",
      "loss: 0.0213, lr: 0.0005, epoch: 6/9, step: 408/600\n",
      "loss: 0.1971, lr: 0.0005, epoch: 6/9, step: 409/600\n",
      "loss: 0.2805, lr: 0.0005, epoch: 6/9, step: 410/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 6/9, step: 411/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 6/9, step: 412/600\n",
      "loss: 0.2075, lr: 0.0005, epoch: 6/9, step: 413/600\n",
      "loss: 0.0573, lr: 0.0005, epoch: 6/9, step: 414/600\n",
      "loss: 0.0787, lr: 0.0005, epoch: 6/9, step: 415/600\n",
      "loss: 0.094, lr: 0.0005, epoch: 6/9, step: 416/600\n",
      "loss: 0.0388, lr: 0.0005, epoch: 6/9, step: 417/600\n",
      "loss: 0.0963, lr: 0.0005, epoch: 6/9, step: 418/600\n",
      "loss: 0.502, lr: 0.0005, epoch: 6/9, step: 419/600\n",
      "loss: 0.4019, lr: 0.0005, epoch: 6/9, step: 420/600\n",
      "loss: 0.0215, lr: 0.0005, epoch: 6/9, step: 421/600\n",
      "loss: 0.0375, lr: 0.0005, epoch: 6/9, step: 422/600\n",
      "loss: 0.1898, lr: 0.0005, epoch: 6/9, step: 423/600\n",
      "loss: 0.02, lr: 0.0005, epoch: 6/9, step: 424/600\n",
      "loss: 0.3948, lr: 0.0005, epoch: 6/9, step: 425/600\n",
      "loss: 0.1478, lr: 0.0005, epoch: 6/9, step: 426/600\n",
      "loss: 0.089, lr: 0.0005, epoch: 6/9, step: 427/600\n",
      "loss: 0.0332, lr: 0.0005, epoch: 6/9, step: 428/600\n",
      "loss: 0.0502, lr: 0.0005, epoch: 6/9, step: 429/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 6/9, step: 430/600\n",
      "loss: 0.4385, lr: 0.0005, epoch: 6/9, step: 431/600\n",
      "loss: 0.3665, lr: 0.0005, epoch: 6/9, step: 432/600\n",
      "loss: 0.0575, lr: 0.0005, epoch: 6/9, step: 433/600\n",
      "loss: 0.3352, lr: 0.0005, epoch: 6/9, step: 434/600\n",
      "loss: 0.0201, lr: 0.0005, epoch: 6/9, step: 435/600\n",
      "loss: 0.0071, lr: 0.0005, epoch: 6/9, step: 436/600\n",
      "loss: 0.2483, lr: 0.0005, epoch: 6/9, step: 437/600\n",
      "loss: 0.6689, lr: 0.0005, epoch: 6/9, step: 438/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 6/9, step: 439/600\n",
      "loss: 0.1031, lr: 0.0005, epoch: 6/9, step: 440/600\n",
      "loss: 0.2467, lr: 0.0005, epoch: 6/9, step: 441/600\n",
      "loss: 0.2275, lr: 0.0005, epoch: 6/9, step: 442/600\n",
      "loss: 0.2333, lr: 0.0005, epoch: 6/9, step: 443/600\n",
      "loss: 0.3008, lr: 0.0005, epoch: 6/9, step: 444/600\n",
      "loss: 0.3145, lr: 0.0005, epoch: 6/9, step: 445/600\n",
      "loss: 0.4968, lr: 0.0005, epoch: 6/9, step: 446/600\n",
      "loss: 0.0758, lr: 0.0005, epoch: 6/9, step: 447/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 6/9, step: 448/600\n",
      "loss: 0.3472, lr: 0.0005, epoch: 6/9, step: 449/600\n",
      "loss: 0.3206, lr: 0.0005, epoch: 6/9, step: 450/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 6/9, step: 451/600\n",
      "loss: 0.0069, lr: 0.0005, epoch: 6/9, step: 452/600\n",
      "loss: 0.3022, lr: 0.0005, epoch: 6/9, step: 453/600\n",
      "loss: 0.0481, lr: 0.0005, epoch: 6/9, step: 454/600\n",
      "loss: 0.3179, lr: 0.0005, epoch: 6/9, step: 455/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 6/9, step: 456/600\n",
      "loss: 0.6421, lr: 0.0005, epoch: 6/9, step: 457/600\n",
      "loss: 0.1392, lr: 0.0005, epoch: 6/9, step: 458/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 6/9, step: 459/600\n",
      "loss: 0.1236, lr: 0.0005, epoch: 6/9, step: 460/600\n",
      "loss: 0.0659, lr: 0.0005, epoch: 6/9, step: 461/600\n",
      "loss: 0.0279, lr: 0.0005, epoch: 6/9, step: 462/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 6/9, step: 463/600\n",
      "loss: 0.0227, lr: 0.0005, epoch: 6/9, step: 464/600\n",
      "loss: 0.1018, lr: 0.0005, epoch: 6/9, step: 465/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 6/9, step: 466/600\n",
      "loss: 0.0127, lr: 0.0005, epoch: 6/9, step: 467/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 6/9, step: 468/600\n",
      "loss: 0.0853, lr: 0.0005, epoch: 6/9, step: 469/600\n",
      "loss: 0.0995, lr: 0.0005, epoch: 6/9, step: 470/600\n",
      "loss: 0.3906, lr: 0.0005, epoch: 6/9, step: 471/600\n",
      "loss: 0.1423, lr: 0.0005, epoch: 6/9, step: 472/600\n",
      "loss: 0.311, lr: 0.0005, epoch: 6/9, step: 473/600\n",
      "loss: 0.4214, lr: 0.0005, epoch: 6/9, step: 474/600\n",
      "loss: 0.0649, lr: 0.0005, epoch: 6/9, step: 475/600\n",
      "loss: 0.2272, lr: 0.0005, epoch: 6/9, step: 476/600\n",
      "loss: 0.1868, lr: 0.0005, epoch: 6/9, step: 477/600\n",
      "loss: 0.2234, lr: 0.0005, epoch: 6/9, step: 478/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 6/9, step: 479/600\n",
      "loss: 0.542, lr: 0.0005, epoch: 6/9, step: 480/600\n",
      "loss: 0.0893, lr: 0.0005, epoch: 6/9, step: 481/600\n",
      "loss: 0.0425, lr: 0.0005, epoch: 6/9, step: 482/600\n",
      "loss: 0.0519, lr: 0.0005, epoch: 6/9, step: 483/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 6/9, step: 484/600\n",
      "loss: 0.2646, lr: 0.0005, epoch: 6/9, step: 485/600\n",
      "loss: 0.1005, lr: 0.0005, epoch: 6/9, step: 486/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 6/9, step: 487/600\n",
      "loss: 0.0858, lr: 0.0005, epoch: 6/9, step: 488/600\n",
      "loss: 0.0249, lr: 0.0005, epoch: 6/9, step: 489/600\n",
      "loss: 0.016, lr: 0.0005, epoch: 6/9, step: 490/600\n",
      "loss: 0.2673, lr: 0.0005, epoch: 6/9, step: 491/600\n",
      "loss: 0.0119, lr: 0.0005, epoch: 6/9, step: 492/600\n",
      "loss: 0.1123, lr: 0.0005, epoch: 6/9, step: 493/600\n",
      "loss: 0.9644, lr: 0.0005, epoch: 6/9, step: 494/600\n",
      "loss: 0.4089, lr: 0.0005, epoch: 6/9, step: 495/600\n",
      "loss: 0.1064, lr: 0.0005, epoch: 6/9, step: 496/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 6/9, step: 497/600\n",
      "loss: 0.322, lr: 0.0005, epoch: 6/9, step: 498/600\n",
      "loss: 0.1979, lr: 0.0005, epoch: 6/9, step: 499/600\n",
      "loss: 0.3086, lr: 0.0005, epoch: 6/9, step: 500/600\n",
      "loss: 0.0399, lr: 0.0005, epoch: 6/9, step: 501/600\n",
      "loss: 0.0236, lr: 0.0005, epoch: 6/9, step: 502/600\n",
      "loss: 0.0687, lr: 0.0005, epoch: 6/9, step: 503/600\n",
      "loss: 0.176, lr: 0.0005, epoch: 6/9, step: 504/600\n",
      "loss: 0.2258, lr: 0.0005, epoch: 6/9, step: 505/600\n",
      "loss: 0.5552, lr: 0.0005, epoch: 6/9, step: 506/600\n",
      "loss: 0.1781, lr: 0.0005, epoch: 6/9, step: 507/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 6/9, step: 508/600\n",
      "loss: 0.344, lr: 0.0005, epoch: 6/9, step: 509/600\n",
      "loss: 0.0278, lr: 0.0005, epoch: 6/9, step: 510/600\n",
      "loss: 0.2128, lr: 0.0005, epoch: 6/9, step: 511/600\n",
      "loss: 0.1376, lr: 0.0005, epoch: 6/9, step: 512/600\n",
      "loss: 0.1863, lr: 0.0005, epoch: 6/9, step: 513/600\n",
      "loss: 0.0938, lr: 0.0005, epoch: 6/9, step: 514/600\n",
      "loss: 0.0435, lr: 0.0005, epoch: 6/9, step: 515/600\n",
      "loss: 0.333, lr: 0.0005, epoch: 6/9, step: 516/600\n",
      "loss: 0.0362, lr: 0.0005, epoch: 6/9, step: 517/600\n",
      "loss: 0.069, lr: 0.0005, epoch: 6/9, step: 518/600\n",
      "loss: 0.406, lr: 0.0005, epoch: 6/9, step: 519/600\n",
      "loss: 0.1879, lr: 0.0005, epoch: 6/9, step: 520/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 6/9, step: 521/600\n",
      "loss: 0.16, lr: 0.0005, epoch: 6/9, step: 522/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 6/9, step: 523/600\n",
      "loss: 0.0125, lr: 0.0005, epoch: 6/9, step: 524/600\n",
      "loss: 0.0406, lr: 0.0005, epoch: 6/9, step: 525/600\n",
      "loss: 0.1401, lr: 0.0005, epoch: 6/9, step: 526/600\n",
      "loss: 0.0202, lr: 0.0005, epoch: 6/9, step: 527/600\n",
      "loss: 0.3162, lr: 0.0005, epoch: 6/9, step: 528/600\n",
      "loss: 0.8711, lr: 0.0005, epoch: 6/9, step: 529/600\n",
      "loss: 0.042, lr: 0.0005, epoch: 6/9, step: 530/600\n",
      "loss: 0.1847, lr: 0.0005, epoch: 6/9, step: 531/600\n",
      "loss: 0.0177, lr: 0.0005, epoch: 6/9, step: 532/600\n",
      "loss: 0.0547, lr: 0.0005, epoch: 6/9, step: 533/600\n",
      "loss: 0.2563, lr: 0.0005, epoch: 6/9, step: 534/600\n",
      "loss: 0.0626, lr: 0.0005, epoch: 6/9, step: 535/600\n",
      "loss: 0.3418, lr: 0.0005, epoch: 6/9, step: 536/600\n",
      "loss: 0.0828, lr: 0.0005, epoch: 6/9, step: 537/600\n",
      "loss: 0.4756, lr: 0.0005, epoch: 6/9, step: 538/600\n",
      "loss: 0.3188, lr: 0.0005, epoch: 6/9, step: 539/600\n",
      "loss: 0.3945, lr: 0.0005, epoch: 6/9, step: 540/600\n",
      "loss: 0.2537, lr: 0.0005, epoch: 6/9, step: 541/600\n",
      "loss: 0.059, lr: 0.0005, epoch: 6/9, step: 542/600\n",
      "loss: 0.0509, lr: 0.0005, epoch: 6/9, step: 543/600\n",
      "loss: 0.12, lr: 0.0005, epoch: 6/9, step: 544/600\n",
      "loss: 0.0717, lr: 0.0005, epoch: 6/9, step: 545/600\n",
      "loss: 0.4846, lr: 0.0005, epoch: 6/9, step: 546/600\n",
      "loss: 0.1775, lr: 0.0005, epoch: 6/9, step: 547/600\n",
      "loss: 0.0184, lr: 0.0005, epoch: 6/9, step: 548/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 6/9, step: 549/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 6/9, step: 550/600\n",
      "loss: 0.2593, lr: 0.0005, epoch: 6/9, step: 551/600\n",
      "loss: 0.0117, lr: 0.0005, epoch: 6/9, step: 552/600\n",
      "loss: 0.3601, lr: 0.0005, epoch: 6/9, step: 553/600\n",
      "loss: 0.5376, lr: 0.0005, epoch: 6/9, step: 554/600\n",
      "loss: 0.2389, lr: 0.0005, epoch: 6/9, step: 555/600\n",
      "loss: 0.3369, lr: 0.0005, epoch: 6/9, step: 556/600\n",
      "loss: 0.0162, lr: 0.0005, epoch: 6/9, step: 557/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 6/9, step: 558/600\n",
      "loss: 0.0586, lr: 0.0005, epoch: 6/9, step: 559/600\n",
      "loss: 0.2739, lr: 0.0005, epoch: 6/9, step: 560/600\n",
      "loss: 0.0559, lr: 0.0005, epoch: 6/9, step: 561/600\n",
      "loss: 0.3911, lr: 0.0005, epoch: 6/9, step: 562/600\n",
      "loss: 0.2083, lr: 0.0005, epoch: 6/9, step: 563/600\n",
      "loss: 0.2805, lr: 0.0005, epoch: 6/9, step: 564/600\n",
      "loss: 0.0103, lr: 0.0005, epoch: 6/9, step: 565/600\n",
      "loss: 0.0094, lr: 0.0005, epoch: 6/9, step: 566/600\n",
      "loss: 0.0554, lr: 0.0005, epoch: 6/9, step: 567/600\n",
      "loss: 0.353, lr: 0.0005, epoch: 6/9, step: 568/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 6/9, step: 569/600\n",
      "loss: 0.034, lr: 0.0005, epoch: 6/9, step: 570/600\n",
      "loss: 0.0055, lr: 0.0005, epoch: 6/9, step: 571/600\n",
      "loss: 0.1626, lr: 0.0005, epoch: 6/9, step: 572/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 6/9, step: 573/600\n",
      "loss: 0.0124, lr: 0.0005, epoch: 6/9, step: 574/600\n",
      "loss: 0.1067, lr: 0.0005, epoch: 6/9, step: 575/600\n",
      "loss: 0.1261, lr: 0.0005, epoch: 6/9, step: 576/600\n",
      "loss: 0.3306, lr: 0.0005, epoch: 6/9, step: 577/600\n",
      "loss: 0.0891, lr: 0.0005, epoch: 6/9, step: 578/600\n",
      "loss: 0.6064, lr: 0.0005, epoch: 6/9, step: 579/600\n",
      "loss: 0.4333, lr: 0.0005, epoch: 6/9, step: 580/600\n",
      "loss: 0.2649, lr: 0.0005, epoch: 6/9, step: 581/600\n",
      "loss: 0.0119, lr: 0.0005, epoch: 6/9, step: 582/600\n",
      "loss: 0.1033, lr: 0.0005, epoch: 6/9, step: 583/600\n",
      "loss: 0.4585, lr: 0.0005, epoch: 6/9, step: 584/600\n",
      "loss: 0.1874, lr: 0.0005, epoch: 6/9, step: 585/600\n",
      "loss: 0.0129, lr: 0.0005, epoch: 6/9, step: 586/600\n",
      "loss: 0.5176, lr: 0.0005, epoch: 6/9, step: 587/600\n",
      "loss: 0.281, lr: 0.0005, epoch: 6/9, step: 588/600\n",
      "loss: 0.5234, lr: 0.0005, epoch: 6/9, step: 589/600\n",
      "loss: 0.1115, lr: 0.0005, epoch: 6/9, step: 590/600\n",
      "loss: 0.3511, lr: 0.0005, epoch: 6/9, step: 591/600\n",
      "loss: 0.5815, lr: 0.0005, epoch: 6/9, step: 592/600\n",
      "loss: 0.5532, lr: 0.0005, epoch: 6/9, step: 593/600\n",
      "loss: 0.2085, lr: 0.0005, epoch: 6/9, step: 594/600\n",
      "loss: 0.0024, lr: 0.0005, epoch: 6/9, step: 595/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 6/9, step: 596/600\n",
      "loss: 0.0225, lr: 0.0005, epoch: 6/9, step: 597/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 6/9, step: 598/600\n",
      "loss: 0.3247, lr: 0.0005, epoch: 6/9, step: 599/600\n",
      "loss: 0.1292, lr: 0.0005, epoch: 6/9, step: 600/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 7/9, step: 1/600\n",
      "loss: 0.1085, lr: 0.0005, epoch: 7/9, step: 2/600\n",
      "loss: 0.6387, lr: 0.0005, epoch: 7/9, step: 3/600\n",
      "loss: 0.8291, lr: 0.0005, epoch: 7/9, step: 4/600\n",
      "loss: 0.4622, lr: 0.0005, epoch: 7/9, step: 5/600\n",
      "loss: 0.0711, lr: 0.0005, epoch: 7/9, step: 6/600\n",
      "loss: 0.0698, lr: 0.0005, epoch: 7/9, step: 7/600\n",
      "loss: 0.3889, lr: 0.0005, epoch: 7/9, step: 8/600\n",
      "loss: 0.2085, lr: 0.0005, epoch: 7/9, step: 9/600\n",
      "loss: 0.223, lr: 0.0005, epoch: 7/9, step: 10/600\n",
      "loss: 0.2205, lr: 0.0005, epoch: 7/9, step: 11/600\n",
      "loss: 0.165, lr: 0.0005, epoch: 7/9, step: 12/600\n",
      "loss: 0.1383, lr: 0.0005, epoch: 7/9, step: 13/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 7/9, step: 14/600\n",
      "loss: 0.0963, lr: 0.0005, epoch: 7/9, step: 15/600\n",
      "loss: 0.0657, lr: 0.0005, epoch: 7/9, step: 16/600\n",
      "loss: 0.1194, lr: 0.0005, epoch: 7/9, step: 17/600\n",
      "loss: 0.0464, lr: 0.0005, epoch: 7/9, step: 18/600\n",
      "loss: 0.1508, lr: 0.0005, epoch: 7/9, step: 19/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 7/9, step: 20/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 7/9, step: 21/600\n",
      "loss: 0.2573, lr: 0.0005, epoch: 7/9, step: 22/600\n",
      "loss: 0.2783, lr: 0.0005, epoch: 7/9, step: 23/600\n",
      "loss: 0.1132, lr: 0.0005, epoch: 7/9, step: 24/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 7/9, step: 25/600\n",
      "loss: 0.0718, lr: 0.0005, epoch: 7/9, step: 26/600\n",
      "loss: 0.107, lr: 0.0005, epoch: 7/9, step: 27/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 7/9, step: 28/600\n",
      "loss: 0.0283, lr: 0.0005, epoch: 7/9, step: 29/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 7/9, step: 30/600\n",
      "loss: 0.0622, lr: 0.0005, epoch: 7/9, step: 31/600\n",
      "loss: 0.1975, lr: 0.0005, epoch: 7/9, step: 32/600\n",
      "loss: 0.4714, lr: 0.0005, epoch: 7/9, step: 33/600\n",
      "loss: 0.1633, lr: 0.0005, epoch: 7/9, step: 34/600\n",
      "loss: 0.1753, lr: 0.0005, epoch: 7/9, step: 35/600\n",
      "loss: 0.0073, lr: 0.0005, epoch: 7/9, step: 36/600\n",
      "loss: 0.0754, lr: 0.0005, epoch: 7/9, step: 37/600\n",
      "loss: 0.4421, lr: 0.0005, epoch: 7/9, step: 38/600\n",
      "loss: 0.2046, lr: 0.0005, epoch: 7/9, step: 39/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 7/9, step: 40/600\n",
      "loss: 0.2937, lr: 0.0005, epoch: 7/9, step: 41/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 7/9, step: 42/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 7/9, step: 43/600\n",
      "loss: 0.353, lr: 0.0005, epoch: 7/9, step: 44/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 7/9, step: 45/600\n",
      "loss: 0.0192, lr: 0.0005, epoch: 7/9, step: 46/600\n",
      "loss: 0.0089, lr: 0.0005, epoch: 7/9, step: 47/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 7/9, step: 48/600\n",
      "loss: 0.6909, lr: 0.0005, epoch: 7/9, step: 49/600\n",
      "loss: 0.3049, lr: 0.0005, epoch: 7/9, step: 50/600\n",
      "loss: 0.4683, lr: 0.0005, epoch: 7/9, step: 51/600\n",
      "loss: 0.1149, lr: 0.0005, epoch: 7/9, step: 52/600\n",
      "loss: 0.3411, lr: 0.0005, epoch: 7/9, step: 53/600\n",
      "loss: 0.2659, lr: 0.0005, epoch: 7/9, step: 54/600\n",
      "loss: 0.0514, lr: 0.0005, epoch: 7/9, step: 55/600\n",
      "loss: 0.2788, lr: 0.0005, epoch: 7/9, step: 56/600\n",
      "loss: 0.3999, lr: 0.0005, epoch: 7/9, step: 57/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 7/9, step: 58/600\n",
      "loss: 0.3516, lr: 0.0005, epoch: 7/9, step: 59/600\n",
      "loss: 0.3889, lr: 0.0005, epoch: 7/9, step: 60/600\n",
      "loss: 0.0452, lr: 0.0005, epoch: 7/9, step: 61/600\n",
      "loss: 0.3477, lr: 0.0005, epoch: 7/9, step: 62/600\n",
      "loss: 0.5171, lr: 0.0005, epoch: 7/9, step: 63/600\n",
      "loss: 0.3896, lr: 0.0005, epoch: 7/9, step: 64/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 7/9, step: 65/600\n",
      "loss: 0.3135, lr: 0.0005, epoch: 7/9, step: 66/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 7/9, step: 67/600\n",
      "loss: 0.4578, lr: 0.0005, epoch: 7/9, step: 68/600\n",
      "loss: 0.3835, lr: 0.0005, epoch: 7/9, step: 69/600\n",
      "loss: 0.2703, lr: 0.0005, epoch: 7/9, step: 70/600\n",
      "loss: 0.5708, lr: 0.0005, epoch: 7/9, step: 71/600\n",
      "loss: 0.0133, lr: 0.0005, epoch: 7/9, step: 72/600\n",
      "loss: 0.036, lr: 0.0005, epoch: 7/9, step: 73/600\n",
      "loss: 0.0229, lr: 0.0005, epoch: 7/9, step: 74/600\n",
      "loss: 0.0196, lr: 0.0005, epoch: 7/9, step: 75/600\n",
      "loss: 0.334, lr: 0.0005, epoch: 7/9, step: 76/600\n",
      "loss: 0.0236, lr: 0.0005, epoch: 7/9, step: 77/600\n",
      "loss: 0.2325, lr: 0.0005, epoch: 7/9, step: 78/600\n",
      "loss: 0.0121, lr: 0.0005, epoch: 7/9, step: 79/600\n",
      "loss: 0.1565, lr: 0.0005, epoch: 7/9, step: 80/600\n",
      "loss: 0.0439, lr: 0.0005, epoch: 7/9, step: 81/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 7/9, step: 82/600\n",
      "loss: 0.4968, lr: 0.0005, epoch: 7/9, step: 83/600\n",
      "loss: 0.1584, lr: 0.0005, epoch: 7/9, step: 84/600\n",
      "loss: 0.3806, lr: 0.0005, epoch: 7/9, step: 85/600\n",
      "loss: 0.3193, lr: 0.0005, epoch: 7/9, step: 86/600\n",
      "loss: 0.6665, lr: 0.0005, epoch: 7/9, step: 87/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 7/9, step: 88/600\n",
      "loss: 0.6167, lr: 0.0005, epoch: 7/9, step: 89/600\n",
      "loss: 0.1832, lr: 0.0005, epoch: 7/9, step: 90/600\n",
      "loss: 0.0728, lr: 0.0005, epoch: 7/9, step: 91/600\n",
      "loss: 0.217, lr: 0.0005, epoch: 7/9, step: 92/600\n",
      "loss: 0.1534, lr: 0.0005, epoch: 7/9, step: 93/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 7/9, step: 94/600\n",
      "loss: 0.0975, lr: 0.0005, epoch: 7/9, step: 95/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 7/9, step: 96/600\n",
      "loss: 0.2164, lr: 0.0005, epoch: 7/9, step: 97/600\n",
      "loss: 0.3235, lr: 0.0005, epoch: 7/9, step: 98/600\n",
      "loss: 0.2136, lr: 0.0005, epoch: 7/9, step: 99/600\n",
      "loss: 0.8452, lr: 0.0005, epoch: 7/9, step: 100/600\n",
      "loss: 0.023, lr: 0.0005, epoch: 7/9, step: 101/600\n",
      "loss: 0.3967, lr: 0.0005, epoch: 7/9, step: 102/600\n",
      "loss: 0.0173, lr: 0.0005, epoch: 7/9, step: 103/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 7/9, step: 104/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 7/9, step: 105/600\n",
      "loss: 0.0366, lr: 0.0005, epoch: 7/9, step: 106/600\n",
      "loss: 0.0414, lr: 0.0005, epoch: 7/9, step: 107/600\n",
      "loss: 0.03, lr: 0.0005, epoch: 7/9, step: 108/600\n",
      "loss: 0.0851, lr: 0.0005, epoch: 7/9, step: 109/600\n",
      "loss: 0.0407, lr: 0.0005, epoch: 7/9, step: 110/600\n",
      "loss: 0.1339, lr: 0.0005, epoch: 7/9, step: 111/600\n",
      "loss: 0.0792, lr: 0.0005, epoch: 7/9, step: 112/600\n",
      "loss: 0.302, lr: 0.0005, epoch: 7/9, step: 113/600\n",
      "loss: 0.4404, lr: 0.0005, epoch: 7/9, step: 114/600\n",
      "loss: 0.0894, lr: 0.0005, epoch: 7/9, step: 115/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 7/9, step: 116/600\n",
      "loss: 0.3787, lr: 0.0005, epoch: 7/9, step: 117/600\n",
      "loss: 0.5039, lr: 0.0005, epoch: 7/9, step: 118/600\n",
      "loss: 0.2544, lr: 0.0005, epoch: 7/9, step: 119/600\n",
      "loss: 0.5854, lr: 0.0005, epoch: 7/9, step: 120/600\n",
      "loss: 0.1095, lr: 0.0005, epoch: 7/9, step: 121/600\n",
      "loss: 0.2627, lr: 0.0005, epoch: 7/9, step: 122/600\n",
      "loss: 0.1416, lr: 0.0005, epoch: 7/9, step: 123/600\n",
      "loss: 0.0587, lr: 0.0005, epoch: 7/9, step: 124/600\n",
      "loss: 0.1114, lr: 0.0005, epoch: 7/9, step: 125/600\n",
      "loss: 0.3799, lr: 0.0005, epoch: 7/9, step: 126/600\n",
      "loss: 0.0422, lr: 0.0005, epoch: 7/9, step: 127/600\n",
      "loss: 0.2549, lr: 0.0005, epoch: 7/9, step: 128/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 7/9, step: 129/600\n",
      "loss: 0.519, lr: 0.0005, epoch: 7/9, step: 130/600\n",
      "loss: 0.055, lr: 0.0005, epoch: 7/9, step: 131/600\n",
      "loss: 0.3289, lr: 0.0005, epoch: 7/9, step: 132/600\n",
      "loss: 0.3433, lr: 0.0005, epoch: 7/9, step: 133/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 7/9, step: 134/600\n",
      "loss: 0.126, lr: 0.0005, epoch: 7/9, step: 135/600\n",
      "loss: 0.0268, lr: 0.0005, epoch: 7/9, step: 136/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 7/9, step: 137/600\n",
      "loss: 0.0243, lr: 0.0005, epoch: 7/9, step: 138/600\n",
      "loss: 0.0168, lr: 0.0005, epoch: 7/9, step: 139/600\n",
      "loss: 0.3115, lr: 0.0005, epoch: 7/9, step: 140/600\n",
      "loss: 0.1809, lr: 0.0005, epoch: 7/9, step: 141/600\n",
      "loss: 0.141, lr: 0.0005, epoch: 7/9, step: 142/600\n",
      "loss: 0.0654, lr: 0.0005, epoch: 7/9, step: 143/600\n",
      "loss: 0.344, lr: 0.0005, epoch: 7/9, step: 144/600\n",
      "loss: 0.0854, lr: 0.0005, epoch: 7/9, step: 145/600\n",
      "loss: 0.0881, lr: 0.0005, epoch: 7/9, step: 146/600\n",
      "loss: 0.2223, lr: 0.0005, epoch: 7/9, step: 147/600\n",
      "loss: 0.0227, lr: 0.0005, epoch: 7/9, step: 148/600\n",
      "loss: 0.2152, lr: 0.0005, epoch: 7/9, step: 149/600\n",
      "loss: 0.0518, lr: 0.0005, epoch: 7/9, step: 150/600\n",
      "loss: 0.5107, lr: 0.0005, epoch: 7/9, step: 151/600\n",
      "loss: 0.01, lr: 0.0005, epoch: 7/9, step: 152/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 7/9, step: 153/600\n",
      "loss: 0.2517, lr: 0.0005, epoch: 7/9, step: 154/600\n",
      "loss: 0.2612, lr: 0.0005, epoch: 7/9, step: 155/600\n",
      "loss: 0.0649, lr: 0.0005, epoch: 7/9, step: 156/600\n",
      "loss: 0.4912, lr: 0.0005, epoch: 7/9, step: 157/600\n",
      "loss: 0.016, lr: 0.0005, epoch: 7/9, step: 158/600\n",
      "loss: 0.2035, lr: 0.0005, epoch: 7/9, step: 159/600\n",
      "loss: 0.084, lr: 0.0005, epoch: 7/9, step: 160/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 7/9, step: 161/600\n",
      "loss: 0.1738, lr: 0.0005, epoch: 7/9, step: 162/600\n",
      "loss: 0.2935, lr: 0.0005, epoch: 7/9, step: 163/600\n",
      "loss: 0.0234, lr: 0.0005, epoch: 7/9, step: 164/600\n",
      "loss: 0.0706, lr: 0.0005, epoch: 7/9, step: 165/600\n",
      "loss: 0.1772, lr: 0.0005, epoch: 7/9, step: 166/600\n",
      "loss: 0.8218, lr: 0.0005, epoch: 7/9, step: 167/600\n",
      "loss: 0.1242, lr: 0.0005, epoch: 7/9, step: 168/600\n",
      "loss: 0.105, lr: 0.0005, epoch: 7/9, step: 169/600\n",
      "loss: 0.199, lr: 0.0005, epoch: 7/9, step: 170/600\n",
      "loss: 0.1083, lr: 0.0005, epoch: 7/9, step: 171/600\n",
      "loss: 0.2866, lr: 0.0005, epoch: 7/9, step: 172/600\n",
      "loss: 0.0199, lr: 0.0005, epoch: 7/9, step: 173/600\n",
      "loss: 0.1844, lr: 0.0005, epoch: 7/9, step: 174/600\n",
      "loss: 0.6694, lr: 0.0005, epoch: 7/9, step: 175/600\n",
      "loss: 0.0144, lr: 0.0005, epoch: 7/9, step: 176/600\n",
      "loss: 0.1089, lr: 0.0005, epoch: 7/9, step: 177/600\n",
      "loss: 0.0134, lr: 0.0005, epoch: 7/9, step: 178/600\n",
      "loss: 0.1616, lr: 0.0005, epoch: 7/9, step: 179/600\n",
      "loss: 0.2891, lr: 0.0005, epoch: 7/9, step: 180/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 7/9, step: 181/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 7/9, step: 182/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 7/9, step: 183/600\n",
      "loss: 0.0611, lr: 0.0005, epoch: 7/9, step: 184/600\n",
      "loss: 0.1763, lr: 0.0005, epoch: 7/9, step: 185/600\n",
      "loss: 0.0245, lr: 0.0005, epoch: 7/9, step: 186/600\n",
      "loss: 0.1323, lr: 0.0005, epoch: 7/9, step: 187/600\n",
      "loss: 0.0702, lr: 0.0005, epoch: 7/9, step: 188/600\n",
      "loss: 0.1678, lr: 0.0005, epoch: 7/9, step: 189/600\n",
      "loss: 0.3557, lr: 0.0005, epoch: 7/9, step: 190/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 7/9, step: 191/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 7/9, step: 192/600\n",
      "loss: 0.1874, lr: 0.0005, epoch: 7/9, step: 193/600\n",
      "loss: 0.0131, lr: 0.0005, epoch: 7/9, step: 194/600\n",
      "loss: 0.0179, lr: 0.0005, epoch: 7/9, step: 195/600\n",
      "loss: 0.4856, lr: 0.0005, epoch: 7/9, step: 196/600\n",
      "loss: 0.0145, lr: 0.0005, epoch: 7/9, step: 197/600\n",
      "loss: 0.026, lr: 0.0005, epoch: 7/9, step: 198/600\n",
      "loss: 0.033, lr: 0.0005, epoch: 7/9, step: 199/600\n",
      "loss: 0.1689, lr: 0.0005, epoch: 7/9, step: 200/600\n",
      "loss: 0.0413, lr: 0.0005, epoch: 7/9, step: 201/600\n",
      "loss: 0.0303, lr: 0.0005, epoch: 7/9, step: 202/600\n",
      "loss: 0.0174, lr: 0.0005, epoch: 7/9, step: 203/600\n",
      "loss: 0.0706, lr: 0.0005, epoch: 7/9, step: 204/600\n",
      "loss: 0.2852, lr: 0.0005, epoch: 7/9, step: 205/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 7/9, step: 206/600\n",
      "loss: 0.3611, lr: 0.0005, epoch: 7/9, step: 207/600\n",
      "loss: 0.0054, lr: 0.0005, epoch: 7/9, step: 208/600\n",
      "loss: 0.1495, lr: 0.0005, epoch: 7/9, step: 209/600\n",
      "loss: 0.0635, lr: 0.0005, epoch: 7/9, step: 210/600\n",
      "loss: 0.1855, lr: 0.0005, epoch: 7/9, step: 211/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 7/9, step: 212/600\n",
      "loss: 0.0548, lr: 0.0005, epoch: 7/9, step: 213/600\n",
      "loss: 0.0159, lr: 0.0005, epoch: 7/9, step: 214/600\n",
      "loss: 0.0338, lr: 0.0005, epoch: 7/9, step: 215/600\n",
      "loss: 0.0165, lr: 0.0005, epoch: 7/9, step: 216/600\n",
      "loss: 0.3621, lr: 0.0005, epoch: 7/9, step: 217/600\n",
      "loss: 0.5547, lr: 0.0005, epoch: 7/9, step: 218/600\n",
      "loss: 0.156, lr: 0.0005, epoch: 7/9, step: 219/600\n",
      "loss: 0.0205, lr: 0.0005, epoch: 7/9, step: 220/600\n",
      "loss: 0.5278, lr: 0.0005, epoch: 7/9, step: 221/600\n",
      "loss: 0.2974, lr: 0.0005, epoch: 7/9, step: 222/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 7/9, step: 223/600\n",
      "loss: 0.4351, lr: 0.0005, epoch: 7/9, step: 224/600\n",
      "loss: 0.3511, lr: 0.0005, epoch: 7/9, step: 225/600\n",
      "loss: 0.0863, lr: 0.0005, epoch: 7/9, step: 226/600\n",
      "loss: 0.1093, lr: 0.0005, epoch: 7/9, step: 227/600\n",
      "loss: 0.0185, lr: 0.0005, epoch: 7/9, step: 228/600\n",
      "loss: 0.2279, lr: 0.0005, epoch: 7/9, step: 229/600\n",
      "loss: 0.0275, lr: 0.0005, epoch: 7/9, step: 230/600\n",
      "loss: 0.6201, lr: 0.0005, epoch: 7/9, step: 231/600\n",
      "loss: 0.201, lr: 0.0005, epoch: 7/9, step: 232/600\n",
      "loss: 0.0233, lr: 0.0005, epoch: 7/9, step: 233/600\n",
      "loss: 0.5254, lr: 0.0005, epoch: 7/9, step: 234/600\n",
      "loss: 0.1923, lr: 0.0005, epoch: 7/9, step: 235/600\n",
      "loss: 0.0149, lr: 0.0005, epoch: 7/9, step: 236/600\n",
      "loss: 0.2588, lr: 0.0005, epoch: 7/9, step: 237/600\n",
      "loss: 0.3555, lr: 0.0005, epoch: 7/9, step: 238/600\n",
      "loss: 0.0194, lr: 0.0005, epoch: 7/9, step: 239/600\n",
      "loss: 0.0966, lr: 0.0005, epoch: 7/9, step: 240/600\n",
      "loss: 0.135, lr: 0.0005, epoch: 7/9, step: 241/600\n",
      "loss: 0.0157, lr: 0.0005, epoch: 7/9, step: 242/600\n",
      "loss: 0.0635, lr: 0.0005, epoch: 7/9, step: 243/600\n",
      "loss: 0.5361, lr: 0.0005, epoch: 7/9, step: 244/600\n",
      "loss: 0.0908, lr: 0.0005, epoch: 7/9, step: 245/600\n",
      "loss: 0.4563, lr: 0.0005, epoch: 7/9, step: 246/600\n",
      "loss: 0.8013, lr: 0.0005, epoch: 7/9, step: 247/600\n",
      "loss: 0.3484, lr: 0.0005, epoch: 7/9, step: 248/600\n",
      "loss: 0.0229, lr: 0.0005, epoch: 7/9, step: 249/600\n",
      "loss: 0.1249, lr: 0.0005, epoch: 7/9, step: 250/600\n",
      "loss: 0.1252, lr: 0.0005, epoch: 7/9, step: 251/600\n",
      "loss: 0.1343, lr: 0.0005, epoch: 7/9, step: 252/600\n",
      "loss: 0.582, lr: 0.0005, epoch: 7/9, step: 253/600\n",
      "loss: 0.0319, lr: 0.0005, epoch: 7/9, step: 254/600\n",
      "loss: 0.1785, lr: 0.0005, epoch: 7/9, step: 255/600\n",
      "loss: 0.007, lr: 0.0005, epoch: 7/9, step: 256/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 7/9, step: 257/600\n",
      "loss: 0.2959, lr: 0.0005, epoch: 7/9, step: 258/600\n",
      "loss: 0.2073, lr: 0.0005, epoch: 7/9, step: 259/600\n",
      "loss: 0.3857, lr: 0.0005, epoch: 7/9, step: 260/600\n",
      "loss: 0.3801, lr: 0.0005, epoch: 7/9, step: 261/600\n",
      "loss: 0.1317, lr: 0.0005, epoch: 7/9, step: 262/600\n",
      "loss: 0.5918, lr: 0.0005, epoch: 7/9, step: 263/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 7/9, step: 264/600\n",
      "loss: 0.8706, lr: 0.0005, epoch: 7/9, step: 265/600\n",
      "loss: 0.2219, lr: 0.0005, epoch: 7/9, step: 266/600\n",
      "loss: 0.3679, lr: 0.0005, epoch: 7/9, step: 267/600\n",
      "loss: 0.1729, lr: 0.0005, epoch: 7/9, step: 268/600\n",
      "loss: 0.7559, lr: 0.0005, epoch: 7/9, step: 269/600\n",
      "loss: 0.4844, lr: 0.0005, epoch: 7/9, step: 270/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 7/9, step: 271/600\n",
      "loss: 0.384, lr: 0.0005, epoch: 7/9, step: 272/600\n",
      "loss: 0.0159, lr: 0.0005, epoch: 7/9, step: 273/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 7/9, step: 274/600\n",
      "loss: 0.0215, lr: 0.0005, epoch: 7/9, step: 275/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 7/9, step: 276/600\n",
      "loss: 0.9346, lr: 0.0005, epoch: 7/9, step: 277/600\n",
      "loss: 0.0037, lr: 0.0005, epoch: 7/9, step: 278/600\n",
      "loss: 0.1203, lr: 0.0005, epoch: 7/9, step: 279/600\n",
      "loss: 0.0245, lr: 0.0005, epoch: 7/9, step: 280/600\n",
      "loss: 0.0324, lr: 0.0005, epoch: 7/9, step: 281/600\n",
      "loss: 0.0481, lr: 0.0005, epoch: 7/9, step: 282/600\n",
      "loss: 0.0472, lr: 0.0005, epoch: 7/9, step: 283/600\n",
      "loss: 0.1473, lr: 0.0005, epoch: 7/9, step: 284/600\n",
      "loss: 0.1172, lr: 0.0005, epoch: 7/9, step: 285/600\n",
      "loss: 0.1118, lr: 0.0005, epoch: 7/9, step: 286/600\n",
      "loss: 0.0581, lr: 0.0005, epoch: 7/9, step: 287/600\n",
      "loss: 0.4436, lr: 0.0005, epoch: 7/9, step: 288/600\n",
      "loss: 0.0316, lr: 0.0005, epoch: 7/9, step: 289/600\n",
      "loss: 0.1327, lr: 0.0005, epoch: 7/9, step: 290/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 7/9, step: 291/600\n",
      "loss: 0.5962, lr: 0.0005, epoch: 7/9, step: 292/600\n",
      "loss: 0.0547, lr: 0.0005, epoch: 7/9, step: 293/600\n",
      "loss: 0.1053, lr: 0.0005, epoch: 7/9, step: 294/600\n",
      "loss: 0.0354, lr: 0.0005, epoch: 7/9, step: 295/600\n",
      "loss: 0.3069, lr: 0.0005, epoch: 7/9, step: 296/600\n",
      "loss: 0.2119, lr: 0.0005, epoch: 7/9, step: 297/600\n",
      "loss: 0.3921, lr: 0.0005, epoch: 7/9, step: 298/600\n",
      "loss: 0.3923, lr: 0.0005, epoch: 7/9, step: 299/600\n",
      "loss: 0.5757, lr: 0.0005, epoch: 7/9, step: 300/600\n",
      "loss: 0.1792, lr: 0.0005, epoch: 7/9, step: 301/600\n",
      "loss: 0.2167, lr: 0.0005, epoch: 7/9, step: 302/600\n",
      "loss: 0.7622, lr: 0.0005, epoch: 7/9, step: 303/600\n",
      "loss: 0.0251, lr: 0.0005, epoch: 7/9, step: 304/600\n",
      "loss: 0.1334, lr: 0.0005, epoch: 7/9, step: 305/600\n",
      "loss: 0.3647, lr: 0.0005, epoch: 7/9, step: 306/600\n",
      "loss: 0.3696, lr: 0.0005, epoch: 7/9, step: 307/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 7/9, step: 308/600\n",
      "loss: 0.3708, lr: 0.0005, epoch: 7/9, step: 309/600\n",
      "loss: 0.5659, lr: 0.0005, epoch: 7/9, step: 310/600\n",
      "loss: 0.7627, lr: 0.0005, epoch: 7/9, step: 311/600\n",
      "loss: 0.0878, lr: 0.0005, epoch: 7/9, step: 312/600\n",
      "loss: 0.0137, lr: 0.0005, epoch: 7/9, step: 313/600\n",
      "loss: 0.1499, lr: 0.0005, epoch: 7/9, step: 314/600\n",
      "loss: 0.5581, lr: 0.0005, epoch: 7/9, step: 315/600\n",
      "loss: 0.1098, lr: 0.0005, epoch: 7/9, step: 316/600\n",
      "loss: 0.0791, lr: 0.0005, epoch: 7/9, step: 317/600\n",
      "loss: 0.1737, lr: 0.0005, epoch: 7/9, step: 318/600\n",
      "loss: 0.0073, lr: 0.0005, epoch: 7/9, step: 319/600\n",
      "loss: 0.134, lr: 0.0005, epoch: 7/9, step: 320/600\n",
      "loss: 0.5498, lr: 0.0005, epoch: 7/9, step: 321/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 7/9, step: 322/600\n",
      "loss: 0.1223, lr: 0.0005, epoch: 7/9, step: 323/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 7/9, step: 324/600\n",
      "loss: 0.0818, lr: 0.0005, epoch: 7/9, step: 325/600\n",
      "loss: 0.4705, lr: 0.0005, epoch: 7/9, step: 326/600\n",
      "loss: 0.0055, lr: 0.0005, epoch: 7/9, step: 327/600\n",
      "loss: 0.0549, lr: 0.0005, epoch: 7/9, step: 328/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 7/9, step: 329/600\n",
      "loss: 0.2107, lr: 0.0005, epoch: 7/9, step: 330/600\n",
      "loss: 0.1796, lr: 0.0005, epoch: 7/9, step: 331/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 7/9, step: 332/600\n",
      "loss: 0.2124, lr: 0.0005, epoch: 7/9, step: 333/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 7/9, step: 334/600\n",
      "loss: 0.1163, lr: 0.0005, epoch: 7/9, step: 335/600\n",
      "loss: 0.1113, lr: 0.0005, epoch: 7/9, step: 336/600\n",
      "loss: 0.0875, lr: 0.0005, epoch: 7/9, step: 337/600\n",
      "loss: 0.0079, lr: 0.0005, epoch: 7/9, step: 338/600\n",
      "loss: 0.0122, lr: 0.0005, epoch: 7/9, step: 339/600\n",
      "loss: 0.0195, lr: 0.0005, epoch: 7/9, step: 340/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 7/9, step: 341/600\n",
      "loss: 0.085, lr: 0.0005, epoch: 7/9, step: 342/600\n",
      "loss: 0.03, lr: 0.0005, epoch: 7/9, step: 343/600\n",
      "loss: 0.1836, lr: 0.0005, epoch: 7/9, step: 344/600\n",
      "loss: 0.0373, lr: 0.0005, epoch: 7/9, step: 345/600\n",
      "loss: 0.009, lr: 0.0005, epoch: 7/9, step: 346/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 7/9, step: 347/600\n",
      "loss: 0.251, lr: 0.0005, epoch: 7/9, step: 348/600\n",
      "loss: 0.1431, lr: 0.0005, epoch: 7/9, step: 349/600\n",
      "loss: 0.2037, lr: 0.0005, epoch: 7/9, step: 350/600\n",
      "loss: 0.0753, lr: 0.0005, epoch: 7/9, step: 351/600\n",
      "loss: 0.5146, lr: 0.0005, epoch: 7/9, step: 352/600\n",
      "loss: 0.0377, lr: 0.0005, epoch: 7/9, step: 353/600\n",
      "loss: 0.021, lr: 0.0005, epoch: 7/9, step: 354/600\n",
      "loss: 0.0271, lr: 0.0005, epoch: 7/9, step: 355/600\n",
      "loss: 0.5, lr: 0.0005, epoch: 7/9, step: 356/600\n",
      "loss: 0.7432, lr: 0.0005, epoch: 7/9, step: 357/600\n",
      "loss: 0.2834, lr: 0.0005, epoch: 7/9, step: 358/600\n",
      "loss: 0.0779, lr: 0.0005, epoch: 7/9, step: 359/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 7/9, step: 360/600\n",
      "loss: 0.0116, lr: 0.0005, epoch: 7/9, step: 361/600\n",
      "loss: 0.3679, lr: 0.0005, epoch: 7/9, step: 362/600\n",
      "loss: 0.2673, lr: 0.0005, epoch: 7/9, step: 363/600\n",
      "loss: 0.3171, lr: 0.0005, epoch: 7/9, step: 364/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 7/9, step: 365/600\n",
      "loss: 0.5884, lr: 0.0005, epoch: 7/9, step: 366/600\n",
      "loss: 0.364, lr: 0.0005, epoch: 7/9, step: 367/600\n",
      "loss: 0.4775, lr: 0.0005, epoch: 7/9, step: 368/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 7/9, step: 369/600\n",
      "loss: 0.081, lr: 0.0005, epoch: 7/9, step: 370/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 7/9, step: 371/600\n",
      "loss: 0.0197, lr: 0.0005, epoch: 7/9, step: 372/600\n",
      "loss: 0.7959, lr: 0.0005, epoch: 7/9, step: 373/600\n",
      "loss: 0.053, lr: 0.0005, epoch: 7/9, step: 374/600\n",
      "loss: 0.0088, lr: 0.0005, epoch: 7/9, step: 375/600\n",
      "loss: 0.0234, lr: 0.0005, epoch: 7/9, step: 376/600\n",
      "loss: 0.1768, lr: 0.0005, epoch: 7/9, step: 377/600\n",
      "loss: 0.0125, lr: 0.0005, epoch: 7/9, step: 378/600\n",
      "loss: 0.6484, lr: 0.0005, epoch: 7/9, step: 379/600\n",
      "loss: 0.9609, lr: 0.0005, epoch: 7/9, step: 380/600\n",
      "loss: 0.5801, lr: 0.0005, epoch: 7/9, step: 381/600\n",
      "loss: 0.1301, lr: 0.0005, epoch: 7/9, step: 382/600\n",
      "loss: 0.058, lr: 0.0005, epoch: 7/9, step: 383/600\n",
      "loss: 0.5107, lr: 0.0005, epoch: 7/9, step: 384/600\n",
      "loss: 0.0426, lr: 0.0005, epoch: 7/9, step: 385/600\n",
      "loss: 0.6533, lr: 0.0005, epoch: 7/9, step: 386/600\n",
      "loss: 0.0168, lr: 0.0005, epoch: 7/9, step: 387/600\n",
      "loss: 0.0148, lr: 0.0005, epoch: 7/9, step: 388/600\n",
      "loss: 0.0641, lr: 0.0005, epoch: 7/9, step: 389/600\n",
      "loss: 0.4128, lr: 0.0005, epoch: 7/9, step: 390/600\n",
      "loss: 0.5698, lr: 0.0005, epoch: 7/9, step: 391/600\n",
      "loss: 0.6841, lr: 0.0005, epoch: 7/9, step: 392/600\n",
      "loss: 0.0168, lr: 0.0005, epoch: 7/9, step: 393/600\n",
      "loss: 0.0188, lr: 0.0005, epoch: 7/9, step: 394/600\n",
      "loss: 0.4111, lr: 0.0005, epoch: 7/9, step: 395/600\n",
      "loss: 0.0565, lr: 0.0005, epoch: 7/9, step: 396/600\n",
      "loss: 0.0207, lr: 0.0005, epoch: 7/9, step: 397/600\n",
      "loss: 0.3845, lr: 0.0005, epoch: 7/9, step: 398/600\n",
      "loss: 0.0268, lr: 0.0005, epoch: 7/9, step: 399/600\n",
      "loss: 0.1366, lr: 0.0005, epoch: 7/9, step: 400/600\n",
      "loss: 0.9258, lr: 0.0005, epoch: 7/9, step: 401/600\n",
      "loss: 0.5176, lr: 0.0005, epoch: 7/9, step: 402/600\n",
      "loss: 0.0342, lr: 0.0005, epoch: 7/9, step: 403/600\n",
      "loss: 0.0024, lr: 0.0005, epoch: 7/9, step: 404/600\n",
      "loss: 0.2159, lr: 0.0005, epoch: 7/9, step: 405/600\n",
      "loss: 0.2852, lr: 0.0005, epoch: 7/9, step: 406/600\n",
      "loss: 0.3054, lr: 0.0005, epoch: 7/9, step: 407/600\n",
      "loss: 0.6025, lr: 0.0005, epoch: 7/9, step: 408/600\n",
      "loss: 0.0111, lr: 0.0005, epoch: 7/9, step: 409/600\n",
      "loss: 0.1859, lr: 0.0005, epoch: 7/9, step: 410/600\n",
      "loss: 0.5381, lr: 0.0005, epoch: 7/9, step: 411/600\n",
      "loss: 0.0024, lr: 0.0005, epoch: 7/9, step: 412/600\n",
      "loss: 0.5127, lr: 0.0005, epoch: 7/9, step: 413/600\n",
      "loss: 0.4619, lr: 0.0005, epoch: 7/9, step: 414/600\n",
      "loss: 0.0264, lr: 0.0005, epoch: 7/9, step: 415/600\n",
      "loss: 0.6069, lr: 0.0005, epoch: 7/9, step: 416/600\n",
      "loss: 0.3254, lr: 0.0005, epoch: 7/9, step: 417/600\n",
      "loss: 0.7061, lr: 0.0005, epoch: 7/9, step: 418/600\n",
      "loss: 0.161, lr: 0.0005, epoch: 7/9, step: 419/600\n",
      "loss: 0.6704, lr: 0.0005, epoch: 7/9, step: 420/600\n",
      "loss: 0.1144, lr: 0.0005, epoch: 7/9, step: 421/600\n",
      "loss: 0.2959, lr: 0.0005, epoch: 7/9, step: 422/600\n",
      "loss: 0.2637, lr: 0.0005, epoch: 7/9, step: 423/600\n",
      "loss: 0.3867, lr: 0.0005, epoch: 7/9, step: 424/600\n",
      "loss: 0.0756, lr: 0.0005, epoch: 7/9, step: 425/600\n",
      "loss: 0.2227, lr: 0.0005, epoch: 7/9, step: 426/600\n",
      "loss: 0.6938, lr: 0.0005, epoch: 7/9, step: 427/600\n",
      "loss: 0.1853, lr: 0.0005, epoch: 7/9, step: 428/600\n",
      "loss: 0.0958, lr: 0.0005, epoch: 7/9, step: 429/600\n",
      "loss: 0.0994, lr: 0.0005, epoch: 7/9, step: 430/600\n",
      "loss: 0.4697, lr: 0.0005, epoch: 7/9, step: 431/600\n",
      "loss: 0.0119, lr: 0.0005, epoch: 7/9, step: 432/600\n",
      "loss: 0.0533, lr: 0.0005, epoch: 7/9, step: 433/600\n",
      "loss: 0.1464, lr: 0.0005, epoch: 7/9, step: 434/600\n",
      "loss: 0.5874, lr: 0.0005, epoch: 7/9, step: 435/600\n",
      "loss: 0.6729, lr: 0.0005, epoch: 7/9, step: 436/600\n",
      "loss: 0.0696, lr: 0.0005, epoch: 7/9, step: 437/600\n",
      "loss: 0.2844, lr: 0.0005, epoch: 7/9, step: 438/600\n",
      "loss: 0.0522, lr: 0.0005, epoch: 7/9, step: 439/600\n",
      "loss: 0.7178, lr: 0.0005, epoch: 7/9, step: 440/600\n",
      "loss: 0.1064, lr: 0.0005, epoch: 7/9, step: 441/600\n",
      "loss: 0.0111, lr: 0.0005, epoch: 7/9, step: 442/600\n",
      "loss: 0.111, lr: 0.0005, epoch: 7/9, step: 443/600\n",
      "loss: 0.0101, lr: 0.0005, epoch: 7/9, step: 444/600\n",
      "loss: 0.3601, lr: 0.0005, epoch: 7/9, step: 445/600\n",
      "loss: 0.4851, lr: 0.0005, epoch: 7/9, step: 446/600\n",
      "loss: 0.4072, lr: 0.0005, epoch: 7/9, step: 447/600\n",
      "loss: 0.3782, lr: 0.0005, epoch: 7/9, step: 448/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 7/9, step: 449/600\n",
      "loss: 0.1925, lr: 0.0005, epoch: 7/9, step: 450/600\n",
      "loss: 0.0191, lr: 0.0005, epoch: 7/9, step: 451/600\n",
      "loss: 0.1681, lr: 0.0005, epoch: 7/9, step: 452/600\n",
      "loss: 0.0515, lr: 0.0005, epoch: 7/9, step: 453/600\n",
      "loss: 0.09, lr: 0.0005, epoch: 7/9, step: 454/600\n",
      "loss: 0.0379, lr: 0.0005, epoch: 7/9, step: 455/600\n",
      "loss: 0.3445, lr: 0.0005, epoch: 7/9, step: 456/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 7/9, step: 457/600\n",
      "loss: 0.0551, lr: 0.0005, epoch: 7/9, step: 458/600\n",
      "loss: 0.0352, lr: 0.0005, epoch: 7/9, step: 459/600\n",
      "loss: 0.0291, lr: 0.0005, epoch: 7/9, step: 460/600\n",
      "loss: 0.2844, lr: 0.0005, epoch: 7/9, step: 461/600\n",
      "loss: 0.4668, lr: 0.0005, epoch: 7/9, step: 462/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 7/9, step: 463/600\n",
      "loss: 0.3904, lr: 0.0005, epoch: 7/9, step: 464/600\n",
      "loss: 0.3184, lr: 0.0005, epoch: 7/9, step: 465/600\n",
      "loss: 0.0205, lr: 0.0005, epoch: 7/9, step: 466/600\n",
      "loss: 0.0098, lr: 0.0005, epoch: 7/9, step: 467/600\n",
      "loss: 0.0091, lr: 0.0005, epoch: 7/9, step: 468/600\n",
      "loss: 0.355, lr: 0.0005, epoch: 7/9, step: 469/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 7/9, step: 470/600\n",
      "loss: 0.1108, lr: 0.0005, epoch: 7/9, step: 471/600\n",
      "loss: 0.2312, lr: 0.0005, epoch: 7/9, step: 472/600\n",
      "loss: 0.0294, lr: 0.0005, epoch: 7/9, step: 473/600\n",
      "loss: 0.6958, lr: 0.0005, epoch: 7/9, step: 474/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 7/9, step: 475/600\n",
      "loss: 0.2976, lr: 0.0005, epoch: 7/9, step: 476/600\n",
      "loss: 0.3323, lr: 0.0005, epoch: 7/9, step: 477/600\n",
      "loss: 0.5117, lr: 0.0005, epoch: 7/9, step: 478/600\n",
      "loss: 0.5439, lr: 0.0005, epoch: 7/9, step: 479/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 7/9, step: 480/600\n",
      "loss: 0.1298, lr: 0.0005, epoch: 7/9, step: 481/600\n",
      "loss: 0.1582, lr: 0.0005, epoch: 7/9, step: 482/600\n",
      "loss: 0.1986, lr: 0.0005, epoch: 7/9, step: 483/600\n",
      "loss: 0.002, lr: 0.0005, epoch: 7/9, step: 484/600\n",
      "loss: 0.0299, lr: 0.0005, epoch: 7/9, step: 485/600\n",
      "loss: 0.0255, lr: 0.0005, epoch: 7/9, step: 486/600\n",
      "loss: 0.0201, lr: 0.0005, epoch: 7/9, step: 487/600\n",
      "loss: 0.0477, lr: 0.0005, epoch: 7/9, step: 488/600\n",
      "loss: 0.0451, lr: 0.0005, epoch: 7/9, step: 489/600\n",
      "loss: 0.0247, lr: 0.0005, epoch: 7/9, step: 490/600\n",
      "loss: 0.0118, lr: 0.0005, epoch: 7/9, step: 491/600\n",
      "loss: 0.1848, lr: 0.0005, epoch: 7/9, step: 492/600\n",
      "loss: 0.5654, lr: 0.0005, epoch: 7/9, step: 493/600\n",
      "loss: 0.8071, lr: 0.0005, epoch: 7/9, step: 494/600\n",
      "loss: 0.2034, lr: 0.0005, epoch: 7/9, step: 495/600\n",
      "loss: 0.0298, lr: 0.0005, epoch: 7/9, step: 496/600\n",
      "loss: 0.199, lr: 0.0005, epoch: 7/9, step: 497/600\n",
      "loss: 0.4968, lr: 0.0005, epoch: 7/9, step: 498/600\n",
      "loss: 0.5342, lr: 0.0005, epoch: 7/9, step: 499/600\n",
      "loss: 0.5532, lr: 0.0005, epoch: 7/9, step: 500/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 7/9, step: 501/600\n",
      "loss: 0.5322, lr: 0.0005, epoch: 7/9, step: 502/600\n",
      "loss: 0.2103, lr: 0.0005, epoch: 7/9, step: 503/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 7/9, step: 504/600\n",
      "loss: 0.4019, lr: 0.0005, epoch: 7/9, step: 505/600\n",
      "loss: 0.0289, lr: 0.0005, epoch: 7/9, step: 506/600\n",
      "loss: 0.0136, lr: 0.0005, epoch: 7/9, step: 507/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 7/9, step: 508/600\n",
      "loss: 0.0296, lr: 0.0005, epoch: 7/9, step: 509/600\n",
      "loss: 0.0509, lr: 0.0005, epoch: 7/9, step: 510/600\n",
      "loss: 0.1425, lr: 0.0005, epoch: 7/9, step: 511/600\n",
      "loss: 0.0414, lr: 0.0005, epoch: 7/9, step: 512/600\n",
      "loss: 0.3367, lr: 0.0005, epoch: 7/9, step: 513/600\n",
      "loss: 0.064, lr: 0.0005, epoch: 7/9, step: 514/600\n",
      "loss: 0.2625, lr: 0.0005, epoch: 7/9, step: 515/600\n",
      "loss: 0.0713, lr: 0.0005, epoch: 7/9, step: 516/600\n",
      "loss: 0.1118, lr: 0.0005, epoch: 7/9, step: 517/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 7/9, step: 518/600\n",
      "loss: 0.5737, lr: 0.0005, epoch: 7/9, step: 519/600\n",
      "loss: 0.3076, lr: 0.0005, epoch: 7/9, step: 520/600\n",
      "loss: 0.499, lr: 0.0005, epoch: 7/9, step: 521/600\n",
      "loss: 0.3469, lr: 0.0005, epoch: 7/9, step: 522/600\n",
      "loss: 0.4368, lr: 0.0005, epoch: 7/9, step: 523/600\n",
      "loss: 0.1843, lr: 0.0005, epoch: 7/9, step: 524/600\n",
      "loss: 0.042, lr: 0.0005, epoch: 7/9, step: 525/600\n",
      "loss: 0.05, lr: 0.0005, epoch: 7/9, step: 526/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 7/9, step: 527/600\n",
      "loss: 0.201, lr: 0.0005, epoch: 7/9, step: 528/600\n",
      "loss: 0.0186, lr: 0.0005, epoch: 7/9, step: 529/600\n",
      "loss: 0.3528, lr: 0.0005, epoch: 7/9, step: 530/600\n",
      "loss: 0.0083, lr: 0.0005, epoch: 7/9, step: 531/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 7/9, step: 532/600\n",
      "loss: 0.7925, lr: 0.0005, epoch: 7/9, step: 533/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 7/9, step: 534/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 7/9, step: 535/600\n",
      "loss: 0.5249, lr: 0.0005, epoch: 7/9, step: 536/600\n",
      "loss: 0.0157, lr: 0.0005, epoch: 7/9, step: 537/600\n",
      "loss: 0.0596, lr: 0.0005, epoch: 7/9, step: 538/600\n",
      "loss: 0.3982, lr: 0.0005, epoch: 7/9, step: 539/600\n",
      "loss: 0.1044, lr: 0.0005, epoch: 7/9, step: 540/600\n",
      "loss: 0.397, lr: 0.0005, epoch: 7/9, step: 541/600\n",
      "loss: 0.2739, lr: 0.0005, epoch: 7/9, step: 542/600\n",
      "loss: 0.5718, lr: 0.0005, epoch: 7/9, step: 543/600\n",
      "loss: 0.3452, lr: 0.0005, epoch: 7/9, step: 544/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 7/9, step: 545/600\n",
      "loss: 0.4641, lr: 0.0005, epoch: 7/9, step: 546/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 7/9, step: 547/600\n",
      "loss: 0.086, lr: 0.0005, epoch: 7/9, step: 548/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 7/9, step: 549/600\n",
      "loss: 0.2673, lr: 0.0005, epoch: 7/9, step: 550/600\n",
      "loss: 0.428, lr: 0.0005, epoch: 7/9, step: 551/600\n",
      "loss: 0.2512, lr: 0.0005, epoch: 7/9, step: 552/600\n",
      "loss: 0.1901, lr: 0.0005, epoch: 7/9, step: 553/600\n",
      "loss: 0.321, lr: 0.0005, epoch: 7/9, step: 554/600\n",
      "loss: 0.2854, lr: 0.0005, epoch: 7/9, step: 555/600\n",
      "loss: 0.0428, lr: 0.0005, epoch: 7/9, step: 556/600\n",
      "loss: 0.09, lr: 0.0005, epoch: 7/9, step: 557/600\n",
      "loss: 0.2051, lr: 0.0005, epoch: 7/9, step: 558/600\n",
      "loss: 0.9272, lr: 0.0005, epoch: 7/9, step: 559/600\n",
      "loss: 0.1578, lr: 0.0005, epoch: 7/9, step: 560/600\n",
      "loss: 0.0197, lr: 0.0005, epoch: 7/9, step: 561/600\n",
      "loss: 0.2043, lr: 0.0005, epoch: 7/9, step: 562/600\n",
      "loss: 0.1553, lr: 0.0005, epoch: 7/9, step: 563/600\n",
      "loss: 0.013, lr: 0.0005, epoch: 7/9, step: 564/600\n",
      "loss: 0.2233, lr: 0.0005, epoch: 7/9, step: 565/600\n",
      "loss: 0.2476, lr: 0.0005, epoch: 7/9, step: 566/600\n",
      "loss: 0.0389, lr: 0.0005, epoch: 7/9, step: 567/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 7/9, step: 568/600\n",
      "loss: 0.438, lr: 0.0005, epoch: 7/9, step: 569/600\n",
      "loss: 0.6665, lr: 0.0005, epoch: 7/9, step: 570/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 7/9, step: 571/600\n",
      "loss: 0.0795, lr: 0.0005, epoch: 7/9, step: 572/600\n",
      "loss: 0.1456, lr: 0.0005, epoch: 7/9, step: 573/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 7/9, step: 574/600\n",
      "loss: 0.2556, lr: 0.0005, epoch: 7/9, step: 575/600\n",
      "loss: 0.0369, lr: 0.0005, epoch: 7/9, step: 576/600\n",
      "loss: 0.3184, lr: 0.0005, epoch: 7/9, step: 577/600\n",
      "loss: 0.0079, lr: 0.0005, epoch: 7/9, step: 578/600\n",
      "loss: 0.0215, lr: 0.0005, epoch: 7/9, step: 579/600\n",
      "loss: 0.0248, lr: 0.0005, epoch: 7/9, step: 580/600\n",
      "loss: 0.0945, lr: 0.0005, epoch: 7/9, step: 581/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 7/9, step: 582/600\n",
      "loss: 0.076, lr: 0.0005, epoch: 7/9, step: 583/600\n",
      "loss: 0.0824, lr: 0.0005, epoch: 7/9, step: 584/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 7/9, step: 585/600\n",
      "loss: 0.2404, lr: 0.0005, epoch: 7/9, step: 586/600\n",
      "loss: 0.2325, lr: 0.0005, epoch: 7/9, step: 587/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 7/9, step: 588/600\n",
      "loss: 0.2561, lr: 0.0005, epoch: 7/9, step: 589/600\n",
      "loss: 0.3235, lr: 0.0005, epoch: 7/9, step: 590/600\n",
      "loss: 0.2349, lr: 0.0005, epoch: 7/9, step: 591/600\n",
      "loss: 0.1764, lr: 0.0005, epoch: 7/9, step: 592/600\n",
      "loss: 0.2463, lr: 0.0005, epoch: 7/9, step: 593/600\n",
      "loss: 0.3286, lr: 0.0005, epoch: 7/9, step: 594/600\n",
      "loss: 0.2349, lr: 0.0005, epoch: 7/9, step: 595/600\n",
      "loss: 0.0411, lr: 0.0005, epoch: 7/9, step: 596/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 7/9, step: 597/600\n",
      "loss: 0.3997, lr: 0.0005, epoch: 7/9, step: 598/600\n",
      "loss: 0.236, lr: 0.0005, epoch: 7/9, step: 599/600\n",
      "loss: 0.0434, lr: 0.0005, epoch: 7/9, step: 600/600\n",
      "loss: 0.0159, lr: 0.0005, epoch: 8/9, step: 1/600\n",
      "loss: 0.3008, lr: 0.0005, epoch: 8/9, step: 2/600\n",
      "loss: 0.4768, lr: 0.0005, epoch: 8/9, step: 3/600\n",
      "loss: 0.0133, lr: 0.0005, epoch: 8/9, step: 4/600\n",
      "loss: 0.0259, lr: 0.0005, epoch: 8/9, step: 5/600\n",
      "loss: 0.0189, lr: 0.0005, epoch: 8/9, step: 6/600\n",
      "loss: 0.4219, lr: 0.0005, epoch: 8/9, step: 7/600\n",
      "loss: 0.1025, lr: 0.0005, epoch: 8/9, step: 8/600\n",
      "loss: 0.2622, lr: 0.0005, epoch: 8/9, step: 9/600\n",
      "loss: 0.5615, lr: 0.0005, epoch: 8/9, step: 10/600\n",
      "loss: 0.521, lr: 0.0005, epoch: 8/9, step: 11/600\n",
      "loss: 0.1654, lr: 0.0005, epoch: 8/9, step: 12/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 8/9, step: 13/600\n",
      "loss: 0.1321, lr: 0.0005, epoch: 8/9, step: 14/600\n",
      "loss: 0.0132, lr: 0.0005, epoch: 8/9, step: 15/600\n",
      "loss: 0.0754, lr: 0.0005, epoch: 8/9, step: 16/600\n",
      "loss: 0.163, lr: 0.0005, epoch: 8/9, step: 17/600\n",
      "loss: 0.3025, lr: 0.0005, epoch: 8/9, step: 18/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 8/9, step: 19/600\n",
      "loss: 0.0206, lr: 0.0005, epoch: 8/9, step: 20/600\n",
      "loss: 0.0143, lr: 0.0005, epoch: 8/9, step: 21/600\n",
      "loss: 0.1243, lr: 0.0005, epoch: 8/9, step: 22/600\n",
      "loss: 0.3235, lr: 0.0005, epoch: 8/9, step: 23/600\n",
      "loss: 0.0406, lr: 0.0005, epoch: 8/9, step: 24/600\n",
      "loss: 0.0566, lr: 0.0005, epoch: 8/9, step: 25/600\n",
      "loss: 0.2491, lr: 0.0005, epoch: 8/9, step: 26/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 8/9, step: 27/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 8/9, step: 28/600\n",
      "loss: 0.0107, lr: 0.0005, epoch: 8/9, step: 29/600\n",
      "loss: 0.1595, lr: 0.0005, epoch: 8/9, step: 30/600\n",
      "loss: 0.4353, lr: 0.0005, epoch: 8/9, step: 31/600\n",
      "loss: 0.4661, lr: 0.0005, epoch: 8/9, step: 32/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 8/9, step: 33/600\n",
      "loss: 0.0131, lr: 0.0005, epoch: 8/9, step: 34/600\n",
      "loss: 0.2357, lr: 0.0005, epoch: 8/9, step: 35/600\n",
      "loss: 0.1881, lr: 0.0005, epoch: 8/9, step: 36/600\n",
      "loss: 0.4016, lr: 0.0005, epoch: 8/9, step: 37/600\n",
      "loss: 0.5322, lr: 0.0005, epoch: 8/9, step: 38/600\n",
      "loss: 0.0198, lr: 0.0005, epoch: 8/9, step: 39/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 8/9, step: 40/600\n",
      "loss: 0.5708, lr: 0.0005, epoch: 8/9, step: 41/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 8/9, step: 42/600\n",
      "loss: 0.0635, lr: 0.0005, epoch: 8/9, step: 43/600\n",
      "loss: 0.1266, lr: 0.0005, epoch: 8/9, step: 44/600\n",
      "loss: 0.3125, lr: 0.0005, epoch: 8/9, step: 45/600\n",
      "loss: 0.3538, lr: 0.0005, epoch: 8/9, step: 46/600\n",
      "loss: 0.3958, lr: 0.0005, epoch: 8/9, step: 47/600\n",
      "loss: 0.0316, lr: 0.0005, epoch: 8/9, step: 48/600\n",
      "loss: 0.2028, lr: 0.0005, epoch: 8/9, step: 49/600\n",
      "loss: 0.0884, lr: 0.0005, epoch: 8/9, step: 50/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 8/9, step: 51/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 8/9, step: 52/600\n",
      "loss: 0.5342, lr: 0.0005, epoch: 8/9, step: 53/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 8/9, step: 54/600\n",
      "loss: 0.0448, lr: 0.0005, epoch: 8/9, step: 55/600\n",
      "loss: 0.0177, lr: 0.0005, epoch: 8/9, step: 56/600\n",
      "loss: 0.5674, lr: 0.0005, epoch: 8/9, step: 57/600\n",
      "loss: 0.0442, lr: 0.0005, epoch: 8/9, step: 58/600\n",
      "loss: 0.2323, lr: 0.0005, epoch: 8/9, step: 59/600\n",
      "loss: 0.0695, lr: 0.0005, epoch: 8/9, step: 60/600\n",
      "loss: 0.1417, lr: 0.0005, epoch: 8/9, step: 61/600\n",
      "loss: 0.0276, lr: 0.0005, epoch: 8/9, step: 62/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 8/9, step: 63/600\n",
      "loss: 0.2861, lr: 0.0005, epoch: 8/9, step: 64/600\n",
      "loss: 0.3262, lr: 0.0005, epoch: 8/9, step: 65/600\n",
      "loss: 0.1321, lr: 0.0005, epoch: 8/9, step: 66/600\n",
      "loss: 0.0875, lr: 0.0005, epoch: 8/9, step: 67/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 8/9, step: 68/600\n",
      "loss: 0.2566, lr: 0.0005, epoch: 8/9, step: 69/600\n",
      "loss: 0.6426, lr: 0.0005, epoch: 8/9, step: 70/600\n",
      "loss: 0.4185, lr: 0.0005, epoch: 8/9, step: 71/600\n",
      "loss: 0.0177, lr: 0.0005, epoch: 8/9, step: 72/600\n",
      "loss: 0.5547, lr: 0.0005, epoch: 8/9, step: 73/600\n",
      "loss: 0.2095, lr: 0.0005, epoch: 8/9, step: 74/600\n",
      "loss: 0.3125, lr: 0.0005, epoch: 8/9, step: 75/600\n",
      "loss: 0.2876, lr: 0.0005, epoch: 8/9, step: 76/600\n",
      "loss: 0.229, lr: 0.0005, epoch: 8/9, step: 77/600\n",
      "loss: 0.0308, lr: 0.0005, epoch: 8/9, step: 78/600\n",
      "loss: 0.228, lr: 0.0005, epoch: 8/9, step: 79/600\n",
      "loss: 0.0136, lr: 0.0005, epoch: 8/9, step: 80/600\n",
      "loss: 0.0419, lr: 0.0005, epoch: 8/9, step: 81/600\n",
      "loss: 0.2737, lr: 0.0005, epoch: 8/9, step: 82/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 8/9, step: 83/600\n",
      "loss: 0.0662, lr: 0.0005, epoch: 8/9, step: 84/600\n",
      "loss: 0.2106, lr: 0.0005, epoch: 8/9, step: 85/600\n",
      "loss: 0.0156, lr: 0.0005, epoch: 8/9, step: 86/600\n",
      "loss: 0.1094, lr: 0.0005, epoch: 8/9, step: 87/600\n",
      "loss: 0.1823, lr: 0.0005, epoch: 8/9, step: 88/600\n",
      "loss: 0.4258, lr: 0.0005, epoch: 8/9, step: 89/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 8/9, step: 90/600\n",
      "loss: 0.0179, lr: 0.0005, epoch: 8/9, step: 91/600\n",
      "loss: 0.5264, lr: 0.0005, epoch: 8/9, step: 92/600\n",
      "loss: 0.0239, lr: 0.0005, epoch: 8/9, step: 93/600\n",
      "loss: 0.1359, lr: 0.0005, epoch: 8/9, step: 94/600\n",
      "loss: 0.0379, lr: 0.0005, epoch: 8/9, step: 95/600\n",
      "loss: 0.5396, lr: 0.0005, epoch: 8/9, step: 96/600\n",
      "loss: 0.0157, lr: 0.0005, epoch: 8/9, step: 97/600\n",
      "loss: 0.4163, lr: 0.0005, epoch: 8/9, step: 98/600\n",
      "loss: 0.1636, lr: 0.0005, epoch: 8/9, step: 99/600\n",
      "loss: 0.2568, lr: 0.0005, epoch: 8/9, step: 100/600\n",
      "loss: 0.5186, lr: 0.0005, epoch: 8/9, step: 101/600\n",
      "loss: 0.0069, lr: 0.0005, epoch: 8/9, step: 102/600\n",
      "loss: 0.0055, lr: 0.0005, epoch: 8/9, step: 103/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 8/9, step: 104/600\n",
      "loss: 0.1774, lr: 0.0005, epoch: 8/9, step: 105/600\n",
      "loss: 0.168, lr: 0.0005, epoch: 8/9, step: 106/600\n",
      "loss: 0.0162, lr: 0.0005, epoch: 8/9, step: 107/600\n",
      "loss: 0.1605, lr: 0.0005, epoch: 8/9, step: 108/600\n",
      "loss: 0.0534, lr: 0.0005, epoch: 8/9, step: 109/600\n",
      "loss: 0.0285, lr: 0.0005, epoch: 8/9, step: 110/600\n",
      "loss: 0.2201, lr: 0.0005, epoch: 8/9, step: 111/600\n",
      "loss: 0.0548, lr: 0.0005, epoch: 8/9, step: 112/600\n",
      "loss: 0.0569, lr: 0.0005, epoch: 8/9, step: 113/600\n",
      "loss: 0.1147, lr: 0.0005, epoch: 8/9, step: 114/600\n",
      "loss: 0.2832, lr: 0.0005, epoch: 8/9, step: 115/600\n",
      "loss: 0.004, lr: 0.0005, epoch: 8/9, step: 116/600\n",
      "loss: 0.3374, lr: 0.0005, epoch: 8/9, step: 117/600\n",
      "loss: 0.2451, lr: 0.0005, epoch: 8/9, step: 118/600\n",
      "loss: 0.0438, lr: 0.0005, epoch: 8/9, step: 119/600\n",
      "loss: 0.408, lr: 0.0005, epoch: 8/9, step: 120/600\n",
      "loss: 0.5542, lr: 0.0005, epoch: 8/9, step: 121/600\n",
      "loss: 0.1296, lr: 0.0005, epoch: 8/9, step: 122/600\n",
      "loss: 0.1364, lr: 0.0005, epoch: 8/9, step: 123/600\n",
      "loss: 0.2467, lr: 0.0005, epoch: 8/9, step: 124/600\n",
      "loss: 0.1979, lr: 0.0005, epoch: 8/9, step: 125/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 8/9, step: 126/600\n",
      "loss: 0.1838, lr: 0.0005, epoch: 8/9, step: 127/600\n",
      "loss: 0.2401, lr: 0.0005, epoch: 8/9, step: 128/600\n",
      "loss: 0.1486, lr: 0.0005, epoch: 8/9, step: 129/600\n",
      "loss: 0.3677, lr: 0.0005, epoch: 8/9, step: 130/600\n",
      "loss: 0.2271, lr: 0.0005, epoch: 8/9, step: 131/600\n",
      "loss: 0.0339, lr: 0.0005, epoch: 8/9, step: 132/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 8/9, step: 133/600\n",
      "loss: 0.4724, lr: 0.0005, epoch: 8/9, step: 134/600\n",
      "loss: 0.0301, lr: 0.0005, epoch: 8/9, step: 135/600\n",
      "loss: 0.5474, lr: 0.0005, epoch: 8/9, step: 136/600\n",
      "loss: 0.3228, lr: 0.0005, epoch: 8/9, step: 137/600\n",
      "loss: 0.1208, lr: 0.0005, epoch: 8/9, step: 138/600\n",
      "loss: 0.0461, lr: 0.0005, epoch: 8/9, step: 139/600\n",
      "loss: 0.4697, lr: 0.0005, epoch: 8/9, step: 140/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 8/9, step: 141/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 8/9, step: 142/600\n",
      "loss: 0.0082, lr: 0.0005, epoch: 8/9, step: 143/600\n",
      "loss: 0.0484, lr: 0.0005, epoch: 8/9, step: 144/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 8/9, step: 145/600\n",
      "loss: 0.8589, lr: 0.0005, epoch: 8/9, step: 146/600\n",
      "loss: 0.3684, lr: 0.0005, epoch: 8/9, step: 147/600\n",
      "loss: 0.01, lr: 0.0005, epoch: 8/9, step: 148/600\n",
      "loss: 0.0509, lr: 0.0005, epoch: 8/9, step: 149/600\n",
      "loss: 0.0266, lr: 0.0005, epoch: 8/9, step: 150/600\n",
      "loss: 0.0503, lr: 0.0005, epoch: 8/9, step: 151/600\n",
      "loss: 0.2407, lr: 0.0005, epoch: 8/9, step: 152/600\n",
      "loss: 0.0742, lr: 0.0005, epoch: 8/9, step: 153/600\n",
      "loss: 0.4495, lr: 0.0005, epoch: 8/9, step: 154/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 8/9, step: 155/600\n",
      "loss: 0.2053, lr: 0.0005, epoch: 8/9, step: 156/600\n",
      "loss: 0.0164, lr: 0.0005, epoch: 8/9, step: 157/600\n",
      "loss: 0.1284, lr: 0.0005, epoch: 8/9, step: 158/600\n",
      "loss: 0.1559, lr: 0.0005, epoch: 8/9, step: 159/600\n",
      "loss: 0.1037, lr: 0.0005, epoch: 8/9, step: 160/600\n",
      "loss: 0.0489, lr: 0.0005, epoch: 8/9, step: 161/600\n",
      "loss: 0.7129, lr: 0.0005, epoch: 8/9, step: 162/600\n",
      "loss: 0.1785, lr: 0.0005, epoch: 8/9, step: 163/600\n",
      "loss: 0.0497, lr: 0.0005, epoch: 8/9, step: 164/600\n",
      "loss: 0.2859, lr: 0.0005, epoch: 8/9, step: 165/600\n",
      "loss: 0.5361, lr: 0.0005, epoch: 8/9, step: 166/600\n",
      "loss: 0.0055, lr: 0.0005, epoch: 8/9, step: 167/600\n",
      "loss: 0.4221, lr: 0.0005, epoch: 8/9, step: 168/600\n",
      "loss: 0.049, lr: 0.0005, epoch: 8/9, step: 169/600\n",
      "loss: 0.1284, lr: 0.0005, epoch: 8/9, step: 170/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 8/9, step: 171/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 8/9, step: 172/600\n",
      "loss: 0.0122, lr: 0.0005, epoch: 8/9, step: 173/600\n",
      "loss: 0.0511, lr: 0.0005, epoch: 8/9, step: 174/600\n",
      "loss: 0.2566, lr: 0.0005, epoch: 8/9, step: 175/600\n",
      "loss: 0.2744, lr: 0.0005, epoch: 8/9, step: 176/600\n",
      "loss: 0.3872, lr: 0.0005, epoch: 8/9, step: 177/600\n",
      "loss: 0.0086, lr: 0.0005, epoch: 8/9, step: 178/600\n",
      "loss: 0.5835, lr: 0.0005, epoch: 8/9, step: 179/600\n",
      "loss: 0.6357, lr: 0.0005, epoch: 8/9, step: 180/600\n",
      "loss: 0.0139, lr: 0.0005, epoch: 8/9, step: 181/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 8/9, step: 182/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 8/9, step: 183/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 8/9, step: 184/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 8/9, step: 185/600\n",
      "loss: 0.0332, lr: 0.0005, epoch: 8/9, step: 186/600\n",
      "loss: 0.0774, lr: 0.0005, epoch: 8/9, step: 187/600\n",
      "loss: 0.0539, lr: 0.0005, epoch: 8/9, step: 188/600\n",
      "loss: 0.8604, lr: 0.0005, epoch: 8/9, step: 189/600\n",
      "loss: 0.5923, lr: 0.0005, epoch: 8/9, step: 190/600\n",
      "loss: 0.0404, lr: 0.0005, epoch: 8/9, step: 191/600\n",
      "loss: 0.2155, lr: 0.0005, epoch: 8/9, step: 192/600\n",
      "loss: 0.2805, lr: 0.0005, epoch: 8/9, step: 193/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 8/9, step: 194/600\n",
      "loss: 0.1102, lr: 0.0005, epoch: 8/9, step: 195/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 8/9, step: 196/600\n",
      "loss: 0.0398, lr: 0.0005, epoch: 8/9, step: 197/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 8/9, step: 198/600\n",
      "loss: 0.123, lr: 0.0005, epoch: 8/9, step: 199/600\n",
      "loss: 0.1637, lr: 0.0005, epoch: 8/9, step: 200/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 8/9, step: 201/600\n",
      "loss: 0.5366, lr: 0.0005, epoch: 8/9, step: 202/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 8/9, step: 203/600\n",
      "loss: 0.1144, lr: 0.0005, epoch: 8/9, step: 204/600\n",
      "loss: 0.5142, lr: 0.0005, epoch: 8/9, step: 205/600\n",
      "loss: 0.5137, lr: 0.0005, epoch: 8/9, step: 206/600\n",
      "loss: 0.0325, lr: 0.0005, epoch: 8/9, step: 207/600\n",
      "loss: 0.0562, lr: 0.0005, epoch: 8/9, step: 208/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 8/9, step: 209/600\n",
      "loss: 0.1559, lr: 0.0005, epoch: 8/9, step: 210/600\n",
      "loss: 0.0846, lr: 0.0005, epoch: 8/9, step: 211/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 8/9, step: 212/600\n",
      "loss: 0.5522, lr: 0.0005, epoch: 8/9, step: 213/600\n",
      "loss: 0.0091, lr: 0.0005, epoch: 8/9, step: 214/600\n",
      "loss: 0.0145, lr: 0.0005, epoch: 8/9, step: 215/600\n",
      "loss: 0.0345, lr: 0.0005, epoch: 8/9, step: 216/600\n",
      "loss: 0.3074, lr: 0.0005, epoch: 8/9, step: 217/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 8/9, step: 218/600\n",
      "loss: 0.0693, lr: 0.0005, epoch: 8/9, step: 219/600\n",
      "loss: 0.366, lr: 0.0005, epoch: 8/9, step: 220/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 8/9, step: 221/600\n",
      "loss: 0.0085, lr: 0.0005, epoch: 8/9, step: 222/600\n",
      "loss: 0.0125, lr: 0.0005, epoch: 8/9, step: 223/600\n",
      "loss: 0.116, lr: 0.0005, epoch: 8/9, step: 224/600\n",
      "loss: 0.5859, lr: 0.0005, epoch: 8/9, step: 225/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 8/9, step: 226/600\n",
      "loss: 0.2839, lr: 0.0005, epoch: 8/9, step: 227/600\n",
      "loss: 0.2766, lr: 0.0005, epoch: 8/9, step: 228/600\n",
      "loss: 0.3494, lr: 0.0005, epoch: 8/9, step: 229/600\n",
      "loss: 0.3008, lr: 0.0005, epoch: 8/9, step: 230/600\n",
      "loss: 0.0724, lr: 0.0005, epoch: 8/9, step: 231/600\n",
      "loss: 0.1704, lr: 0.0005, epoch: 8/9, step: 232/600\n",
      "loss: 0.1159, lr: 0.0005, epoch: 8/9, step: 233/600\n",
      "loss: 0.3386, lr: 0.0005, epoch: 8/9, step: 234/600\n",
      "loss: 0.1399, lr: 0.0005, epoch: 8/9, step: 235/600\n",
      "loss: 0.2561, lr: 0.0005, epoch: 8/9, step: 236/600\n",
      "loss: 0.2374, lr: 0.0005, epoch: 8/9, step: 237/600\n",
      "loss: 0.2244, lr: 0.0005, epoch: 8/9, step: 238/600\n",
      "loss: 0.2241, lr: 0.0005, epoch: 8/9, step: 239/600\n",
      "loss: 0.0273, lr: 0.0005, epoch: 8/9, step: 240/600\n",
      "loss: 0.4719, lr: 0.0005, epoch: 8/9, step: 241/600\n",
      "loss: 0.0096, lr: 0.0005, epoch: 8/9, step: 242/600\n",
      "loss: 0.2438, lr: 0.0005, epoch: 8/9, step: 243/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 8/9, step: 244/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 8/9, step: 245/600\n",
      "loss: 0.3594, lr: 0.0005, epoch: 8/9, step: 246/600\n",
      "loss: 0.4436, lr: 0.0005, epoch: 8/9, step: 247/600\n",
      "loss: 0.0878, lr: 0.0005, epoch: 8/9, step: 248/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 8/9, step: 249/600\n",
      "loss: 0.2444, lr: 0.0005, epoch: 8/9, step: 250/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 8/9, step: 251/600\n",
      "loss: 0.1092, lr: 0.0005, epoch: 8/9, step: 252/600\n",
      "loss: 0.1444, lr: 0.0005, epoch: 8/9, step: 253/600\n",
      "loss: 0.0157, lr: 0.0005, epoch: 8/9, step: 254/600\n",
      "loss: 0.0516, lr: 0.0005, epoch: 8/9, step: 255/600\n",
      "loss: 0.0192, lr: 0.0005, epoch: 8/9, step: 256/600\n",
      "loss: 0.0382, lr: 0.0005, epoch: 8/9, step: 257/600\n",
      "loss: 0.0764, lr: 0.0005, epoch: 8/9, step: 258/600\n",
      "loss: 0.203, lr: 0.0005, epoch: 8/9, step: 259/600\n",
      "loss: 0.0377, lr: 0.0005, epoch: 8/9, step: 260/600\n",
      "loss: 0.1399, lr: 0.0005, epoch: 8/9, step: 261/600\n",
      "loss: 0.1342, lr: 0.0005, epoch: 8/9, step: 262/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 8/9, step: 263/600\n",
      "loss: 0.519, lr: 0.0005, epoch: 8/9, step: 264/600\n",
      "loss: 0.009, lr: 0.0005, epoch: 8/9, step: 265/600\n",
      "loss: 0.3811, lr: 0.0005, epoch: 8/9, step: 266/600\n",
      "loss: 0.1552, lr: 0.0005, epoch: 8/9, step: 267/600\n",
      "loss: 0.1897, lr: 0.0005, epoch: 8/9, step: 268/600\n",
      "loss: 0.153, lr: 0.0005, epoch: 8/9, step: 269/600\n",
      "loss: 0.0268, lr: 0.0005, epoch: 8/9, step: 270/600\n",
      "loss: 0.3232, lr: 0.0005, epoch: 8/9, step: 271/600\n",
      "loss: 0.7285, lr: 0.0005, epoch: 8/9, step: 272/600\n",
      "loss: 0.1083, lr: 0.0005, epoch: 8/9, step: 273/600\n",
      "loss: 0.4099, lr: 0.0005, epoch: 8/9, step: 274/600\n",
      "loss: 0.3376, lr: 0.0005, epoch: 8/9, step: 275/600\n",
      "loss: 0.1161, lr: 0.0005, epoch: 8/9, step: 276/600\n",
      "loss: 0.2351, lr: 0.0005, epoch: 8/9, step: 277/600\n",
      "loss: 0.6284, lr: 0.0005, epoch: 8/9, step: 278/600\n",
      "loss: 0.1454, lr: 0.0005, epoch: 8/9, step: 279/600\n",
      "loss: 0.0714, lr: 0.0005, epoch: 8/9, step: 280/600\n",
      "loss: 0.0246, lr: 0.0005, epoch: 8/9, step: 281/600\n",
      "loss: 0.2362, lr: 0.0005, epoch: 8/9, step: 282/600\n",
      "loss: 0.0665, lr: 0.0005, epoch: 8/9, step: 283/600\n",
      "loss: 0.0979, lr: 0.0005, epoch: 8/9, step: 284/600\n",
      "loss: 0.0467, lr: 0.0005, epoch: 8/9, step: 285/600\n",
      "loss: 0.1089, lr: 0.0005, epoch: 8/9, step: 286/600\n",
      "loss: 0.0462, lr: 0.0005, epoch: 8/9, step: 287/600\n",
      "loss: 0.8008, lr: 0.0005, epoch: 8/9, step: 288/600\n",
      "loss: 0.0172, lr: 0.0005, epoch: 8/9, step: 289/600\n",
      "loss: 0.03, lr: 0.0005, epoch: 8/9, step: 290/600\n",
      "loss: 0.1168, lr: 0.0005, epoch: 8/9, step: 291/600\n",
      "loss: 0.0543, lr: 0.0005, epoch: 8/9, step: 292/600\n",
      "loss: 0.0853, lr: 0.0005, epoch: 8/9, step: 293/600\n",
      "loss: 0.6548, lr: 0.0005, epoch: 8/9, step: 294/600\n",
      "loss: 0.4185, lr: 0.0005, epoch: 8/9, step: 295/600\n",
      "loss: 0.0686, lr: 0.0005, epoch: 8/9, step: 296/600\n",
      "loss: 0.0044, lr: 0.0005, epoch: 8/9, step: 297/600\n",
      "loss: 0.5078, lr: 0.0005, epoch: 8/9, step: 298/600\n",
      "loss: 0.0421, lr: 0.0005, epoch: 8/9, step: 299/600\n",
      "loss: 0.2341, lr: 0.0005, epoch: 8/9, step: 300/600\n",
      "loss: 0.0303, lr: 0.0005, epoch: 8/9, step: 301/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 8/9, step: 302/600\n",
      "loss: 0.0611, lr: 0.0005, epoch: 8/9, step: 303/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 8/9, step: 304/600\n",
      "loss: 0.0143, lr: 0.0005, epoch: 8/9, step: 305/600\n",
      "loss: 0.1801, lr: 0.0005, epoch: 8/9, step: 306/600\n",
      "loss: 0.8066, lr: 0.0005, epoch: 8/9, step: 307/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 8/9, step: 308/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 8/9, step: 309/600\n",
      "loss: 0.0733, lr: 0.0005, epoch: 8/9, step: 310/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 8/9, step: 311/600\n",
      "loss: 0.0887, lr: 0.0005, epoch: 8/9, step: 312/600\n",
      "loss: 0.024, lr: 0.0005, epoch: 8/9, step: 313/600\n",
      "loss: 0.0034, lr: 0.0005, epoch: 8/9, step: 314/600\n",
      "loss: 0.446, lr: 0.0005, epoch: 8/9, step: 315/600\n",
      "loss: 0.0648, lr: 0.0005, epoch: 8/9, step: 316/600\n",
      "loss: 0.563, lr: 0.0005, epoch: 8/9, step: 317/600\n",
      "loss: 0.0563, lr: 0.0005, epoch: 8/9, step: 318/600\n",
      "loss: 0.0701, lr: 0.0005, epoch: 8/9, step: 319/600\n",
      "loss: 0.1327, lr: 0.0005, epoch: 8/9, step: 320/600\n",
      "loss: 0.1526, lr: 0.0005, epoch: 8/9, step: 321/600\n",
      "loss: 0.4036, lr: 0.0005, epoch: 8/9, step: 322/600\n",
      "loss: 0.1892, lr: 0.0005, epoch: 8/9, step: 323/600\n",
      "loss: 0.5649, lr: 0.0005, epoch: 8/9, step: 324/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 8/9, step: 325/600\n",
      "loss: 0.4673, lr: 0.0005, epoch: 8/9, step: 326/600\n",
      "loss: 0.0148, lr: 0.0005, epoch: 8/9, step: 327/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 8/9, step: 328/600\n",
      "loss: 0.0111, lr: 0.0005, epoch: 8/9, step: 329/600\n",
      "loss: 0.3311, lr: 0.0005, epoch: 8/9, step: 330/600\n",
      "loss: 0.6035, lr: 0.0005, epoch: 8/9, step: 331/600\n",
      "loss: 0.0733, lr: 0.0005, epoch: 8/9, step: 332/600\n",
      "loss: 0.0333, lr: 0.0005, epoch: 8/9, step: 333/600\n",
      "loss: 0.0021, lr: 0.0005, epoch: 8/9, step: 334/600\n",
      "loss: 0.0249, lr: 0.0005, epoch: 8/9, step: 335/600\n",
      "loss: 0.238, lr: 0.0005, epoch: 8/9, step: 336/600\n",
      "loss: 0.6045, lr: 0.0005, epoch: 8/9, step: 337/600\n",
      "loss: 0.5225, lr: 0.0005, epoch: 8/9, step: 338/600\n",
      "loss: 0.2627, lr: 0.0005, epoch: 8/9, step: 339/600\n",
      "loss: 0.4822, lr: 0.0005, epoch: 8/9, step: 340/600\n",
      "loss: 0.0726, lr: 0.0005, epoch: 8/9, step: 341/600\n",
      "loss: 0.0501, lr: 0.0005, epoch: 8/9, step: 342/600\n",
      "loss: 0.2032, lr: 0.0005, epoch: 8/9, step: 343/600\n",
      "loss: 0.2947, lr: 0.0005, epoch: 8/9, step: 344/600\n",
      "loss: 0.3059, lr: 0.0005, epoch: 8/9, step: 345/600\n",
      "loss: 0.3391, lr: 0.0005, epoch: 8/9, step: 346/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 8/9, step: 347/600\n",
      "loss: 0.376, lr: 0.0005, epoch: 8/9, step: 348/600\n",
      "loss: 0.0568, lr: 0.0005, epoch: 8/9, step: 349/600\n",
      "loss: 0.2314, lr: 0.0005, epoch: 8/9, step: 350/600\n",
      "loss: 0.4841, lr: 0.0005, epoch: 8/9, step: 351/600\n",
      "loss: 0.0231, lr: 0.0005, epoch: 8/9, step: 352/600\n",
      "loss: 0.0344, lr: 0.0005, epoch: 8/9, step: 353/600\n",
      "loss: 0.042, lr: 0.0005, epoch: 8/9, step: 354/600\n",
      "loss: 0.1597, lr: 0.0005, epoch: 8/9, step: 355/600\n",
      "loss: 0.1121, lr: 0.0005, epoch: 8/9, step: 356/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 8/9, step: 357/600\n",
      "loss: 0.0252, lr: 0.0005, epoch: 8/9, step: 358/600\n",
      "loss: 0.0266, lr: 0.0005, epoch: 8/9, step: 359/600\n",
      "loss: 0.2079, lr: 0.0005, epoch: 8/9, step: 360/600\n",
      "loss: 0.4734, lr: 0.0005, epoch: 8/9, step: 361/600\n",
      "loss: 0.5518, lr: 0.0005, epoch: 8/9, step: 362/600\n",
      "loss: 0.3672, lr: 0.0005, epoch: 8/9, step: 363/600\n",
      "loss: 0.14, lr: 0.0005, epoch: 8/9, step: 364/600\n",
      "loss: 0.4629, lr: 0.0005, epoch: 8/9, step: 365/600\n",
      "loss: 0.0146, lr: 0.0005, epoch: 8/9, step: 366/600\n",
      "loss: 0.0956, lr: 0.0005, epoch: 8/9, step: 367/600\n",
      "loss: 0.0116, lr: 0.0005, epoch: 8/9, step: 368/600\n",
      "loss: 0.2634, lr: 0.0005, epoch: 8/9, step: 369/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 8/9, step: 370/600\n",
      "loss: 0.024, lr: 0.0005, epoch: 8/9, step: 371/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 8/9, step: 372/600\n",
      "loss: 0.4207, lr: 0.0005, epoch: 8/9, step: 373/600\n",
      "loss: 0.0808, lr: 0.0005, epoch: 8/9, step: 374/600\n",
      "loss: 0.1796, lr: 0.0005, epoch: 8/9, step: 375/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 8/9, step: 376/600\n",
      "loss: 0.2191, lr: 0.0005, epoch: 8/9, step: 377/600\n",
      "loss: 0.2817, lr: 0.0005, epoch: 8/9, step: 378/600\n",
      "loss: 0.0291, lr: 0.0005, epoch: 8/9, step: 379/600\n",
      "loss: 0.1943, lr: 0.0005, epoch: 8/9, step: 380/600\n",
      "loss: 0.0139, lr: 0.0005, epoch: 8/9, step: 381/600\n",
      "loss: 0.3708, lr: 0.0005, epoch: 8/9, step: 382/600\n",
      "loss: 0.1877, lr: 0.0005, epoch: 8/9, step: 383/600\n",
      "loss: 0.0639, lr: 0.0005, epoch: 8/9, step: 384/600\n",
      "loss: 0.1672, lr: 0.0005, epoch: 8/9, step: 385/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 8/9, step: 386/600\n",
      "loss: 0.1456, lr: 0.0005, epoch: 8/9, step: 387/600\n",
      "loss: 0.0209, lr: 0.0005, epoch: 8/9, step: 388/600\n",
      "loss: 0.6313, lr: 0.0005, epoch: 8/9, step: 389/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 8/9, step: 390/600\n",
      "loss: 0.0844, lr: 0.0005, epoch: 8/9, step: 391/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 8/9, step: 392/600\n",
      "loss: 0.0187, lr: 0.0005, epoch: 8/9, step: 393/600\n",
      "loss: 0.4971, lr: 0.0005, epoch: 8/9, step: 394/600\n",
      "loss: 0.0221, lr: 0.0005, epoch: 8/9, step: 395/600\n",
      "loss: 0.059, lr: 0.0005, epoch: 8/9, step: 396/600\n",
      "loss: 0.334, lr: 0.0005, epoch: 8/9, step: 397/600\n",
      "loss: 0.0089, lr: 0.0005, epoch: 8/9, step: 398/600\n",
      "loss: 0.0148, lr: 0.0005, epoch: 8/9, step: 399/600\n",
      "loss: 0.0791, lr: 0.0005, epoch: 8/9, step: 400/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 8/9, step: 401/600\n",
      "loss: 0.2783, lr: 0.0005, epoch: 8/9, step: 402/600\n",
      "loss: 0.3577, lr: 0.0005, epoch: 8/9, step: 403/600\n",
      "loss: 0.29, lr: 0.0005, epoch: 8/9, step: 404/600\n",
      "loss: 0.2737, lr: 0.0005, epoch: 8/9, step: 405/600\n",
      "loss: 0.0199, lr: 0.0005, epoch: 8/9, step: 406/600\n",
      "loss: 0.1144, lr: 0.0005, epoch: 8/9, step: 407/600\n",
      "loss: 0.8979, lr: 0.0005, epoch: 8/9, step: 408/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 8/9, step: 409/600\n",
      "loss: 0.4697, lr: 0.0005, epoch: 8/9, step: 410/600\n",
      "loss: 0.047, lr: 0.0005, epoch: 8/9, step: 411/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 8/9, step: 412/600\n",
      "loss: 0.3599, lr: 0.0005, epoch: 8/9, step: 413/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 8/9, step: 414/600\n",
      "loss: 0.1356, lr: 0.0005, epoch: 8/9, step: 415/600\n",
      "loss: 0.0134, lr: 0.0005, epoch: 8/9, step: 416/600\n",
      "loss: 0.1643, lr: 0.0005, epoch: 8/9, step: 417/600\n",
      "loss: 0.0638, lr: 0.0005, epoch: 8/9, step: 418/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 8/9, step: 419/600\n",
      "loss: 0.0317, lr: 0.0005, epoch: 8/9, step: 420/600\n",
      "loss: 0.1803, lr: 0.0005, epoch: 8/9, step: 421/600\n",
      "loss: 0.1039, lr: 0.0005, epoch: 8/9, step: 422/600\n",
      "loss: 0.0686, lr: 0.0005, epoch: 8/9, step: 423/600\n",
      "loss: 0.0336, lr: 0.0005, epoch: 8/9, step: 424/600\n",
      "loss: 0.0515, lr: 0.0005, epoch: 8/9, step: 425/600\n",
      "loss: 0.0118, lr: 0.0005, epoch: 8/9, step: 426/600\n",
      "loss: 0.0723, lr: 0.0005, epoch: 8/9, step: 427/600\n",
      "loss: 0.0135, lr: 0.0005, epoch: 8/9, step: 428/600\n",
      "loss: 0.0274, lr: 0.0005, epoch: 8/9, step: 429/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 8/9, step: 430/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 8/9, step: 431/600\n",
      "loss: 0.5083, lr: 0.0005, epoch: 8/9, step: 432/600\n",
      "loss: 0.1059, lr: 0.0005, epoch: 8/9, step: 433/600\n",
      "loss: 0.3088, lr: 0.0005, epoch: 8/9, step: 434/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 8/9, step: 435/600\n",
      "loss: 0.0153, lr: 0.0005, epoch: 8/9, step: 436/600\n",
      "loss: 0.0153, lr: 0.0005, epoch: 8/9, step: 437/600\n",
      "loss: 0.1351, lr: 0.0005, epoch: 8/9, step: 438/600\n",
      "loss: 0.7124, lr: 0.0005, epoch: 8/9, step: 439/600\n",
      "loss: 0.0582, lr: 0.0005, epoch: 8/9, step: 440/600\n",
      "loss: 0.377, lr: 0.0005, epoch: 8/9, step: 441/600\n",
      "loss: 0.1149, lr: 0.0005, epoch: 8/9, step: 442/600\n",
      "loss: 0.0095, lr: 0.0005, epoch: 8/9, step: 443/600\n",
      "loss: 0.6562, lr: 0.0005, epoch: 8/9, step: 444/600\n",
      "loss: 0.0418, lr: 0.0005, epoch: 8/9, step: 445/600\n",
      "loss: 0.0077, lr: 0.0005, epoch: 8/9, step: 446/600\n",
      "loss: 0.0073, lr: 0.0005, epoch: 8/9, step: 447/600\n",
      "loss: 0.3225, lr: 0.0005, epoch: 8/9, step: 448/600\n",
      "loss: 0.0999, lr: 0.0005, epoch: 8/9, step: 449/600\n",
      "loss: 0.3894, lr: 0.0005, epoch: 8/9, step: 450/600\n",
      "loss: 0.2111, lr: 0.0005, epoch: 8/9, step: 451/600\n",
      "loss: 0.0075, lr: 0.0005, epoch: 8/9, step: 452/600\n",
      "loss: 0.0182, lr: 0.0005, epoch: 8/9, step: 453/600\n",
      "loss: 0.0958, lr: 0.0005, epoch: 8/9, step: 454/600\n",
      "loss: 0.0944, lr: 0.0005, epoch: 8/9, step: 455/600\n",
      "loss: 0.0107, lr: 0.0005, epoch: 8/9, step: 456/600\n",
      "loss: 0.0896, lr: 0.0005, epoch: 8/9, step: 457/600\n",
      "loss: 0.0046, lr: 0.0005, epoch: 8/9, step: 458/600\n",
      "loss: 0.0112, lr: 0.0005, epoch: 8/9, step: 459/600\n",
      "loss: 0.2148, lr: 0.0005, epoch: 8/9, step: 460/600\n",
      "loss: 0.0049, lr: 0.0005, epoch: 8/9, step: 461/600\n",
      "loss: 0.1943, lr: 0.0005, epoch: 8/9, step: 462/600\n",
      "loss: 0.012, lr: 0.0005, epoch: 8/9, step: 463/600\n",
      "loss: 0.1635, lr: 0.0005, epoch: 8/9, step: 464/600\n",
      "loss: 0.0489, lr: 0.0005, epoch: 8/9, step: 465/600\n",
      "loss: 0.0455, lr: 0.0005, epoch: 8/9, step: 466/600\n",
      "loss: 0.0378, lr: 0.0005, epoch: 8/9, step: 467/600\n",
      "loss: 0.4644, lr: 0.0005, epoch: 8/9, step: 468/600\n",
      "loss: 0.0184, lr: 0.0005, epoch: 8/9, step: 469/600\n",
      "loss: 0.541, lr: 0.0005, epoch: 8/9, step: 470/600\n",
      "loss: 0.0758, lr: 0.0005, epoch: 8/9, step: 471/600\n",
      "loss: 0.2671, lr: 0.0005, epoch: 8/9, step: 472/600\n",
      "loss: 0.0626, lr: 0.0005, epoch: 8/9, step: 473/600\n",
      "loss: 0.3306, lr: 0.0005, epoch: 8/9, step: 474/600\n",
      "loss: 0.0163, lr: 0.0005, epoch: 8/9, step: 475/600\n",
      "loss: 0.0077, lr: 0.0005, epoch: 8/9, step: 476/600\n",
      "loss: 0.4177, lr: 0.0005, epoch: 8/9, step: 477/600\n",
      "loss: 0.1162, lr: 0.0005, epoch: 8/9, step: 478/600\n",
      "loss: 0.0423, lr: 0.0005, epoch: 8/9, step: 479/600\n",
      "loss: 0.1049, lr: 0.0005, epoch: 8/9, step: 480/600\n",
      "loss: 0.6152, lr: 0.0005, epoch: 8/9, step: 481/600\n",
      "loss: 0.0687, lr: 0.0005, epoch: 8/9, step: 482/600\n",
      "loss: 0.092, lr: 0.0005, epoch: 8/9, step: 483/600\n",
      "loss: 0.0322, lr: 0.0005, epoch: 8/9, step: 484/600\n",
      "loss: 0.15, lr: 0.0005, epoch: 8/9, step: 485/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 8/9, step: 486/600\n",
      "loss: 0.3481, lr: 0.0005, epoch: 8/9, step: 487/600\n",
      "loss: 0.0988, lr: 0.0005, epoch: 8/9, step: 488/600\n",
      "loss: 0.0211, lr: 0.0005, epoch: 8/9, step: 489/600\n",
      "loss: 0.0155, lr: 0.0005, epoch: 8/9, step: 490/600\n",
      "loss: 0.5059, lr: 0.0005, epoch: 8/9, step: 491/600\n",
      "loss: 0.0538, lr: 0.0005, epoch: 8/9, step: 492/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 8/9, step: 493/600\n",
      "loss: 0.0063, lr: 0.0005, epoch: 8/9, step: 494/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 8/9, step: 495/600\n",
      "loss: 0.1826, lr: 0.0005, epoch: 8/9, step: 496/600\n",
      "loss: 0.7515, lr: 0.0005, epoch: 8/9, step: 497/600\n",
      "loss: 0.3748, lr: 0.0005, epoch: 8/9, step: 498/600\n",
      "loss: 0.0284, lr: 0.0005, epoch: 8/9, step: 499/600\n",
      "loss: 0.0629, lr: 0.0005, epoch: 8/9, step: 500/600\n",
      "loss: 0.0072, lr: 0.0005, epoch: 8/9, step: 501/600\n",
      "loss: 0.3381, lr: 0.0005, epoch: 8/9, step: 502/600\n",
      "loss: 0.0141, lr: 0.0005, epoch: 8/9, step: 503/600\n",
      "loss: 0.0056, lr: 0.0005, epoch: 8/9, step: 504/600\n",
      "loss: 0.2203, lr: 0.0005, epoch: 8/9, step: 505/600\n",
      "loss: 0.009, lr: 0.0005, epoch: 8/9, step: 506/600\n",
      "loss: 0.009, lr: 0.0005, epoch: 8/9, step: 507/600\n",
      "loss: 0.0444, lr: 0.0005, epoch: 8/9, step: 508/600\n",
      "loss: 0.2634, lr: 0.0005, epoch: 8/9, step: 509/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 8/9, step: 510/600\n",
      "loss: 0.2778, lr: 0.0005, epoch: 8/9, step: 511/600\n",
      "loss: 0.6382, lr: 0.0005, epoch: 8/9, step: 512/600\n",
      "loss: 0.0257, lr: 0.0005, epoch: 8/9, step: 513/600\n",
      "loss: 0.4741, lr: 0.0005, epoch: 8/9, step: 514/600\n",
      "loss: 0.364, lr: 0.0005, epoch: 8/9, step: 515/600\n",
      "loss: 0.3274, lr: 0.0005, epoch: 8/9, step: 516/600\n",
      "loss: 0.1498, lr: 0.0005, epoch: 8/9, step: 517/600\n",
      "loss: 0.0567, lr: 0.0005, epoch: 8/9, step: 518/600\n",
      "loss: 0.122, lr: 0.0005, epoch: 8/9, step: 519/600\n",
      "loss: 0.163, lr: 0.0005, epoch: 8/9, step: 520/600\n",
      "loss: 0.049, lr: 0.0005, epoch: 8/9, step: 521/600\n",
      "loss: 0.0129, lr: 0.0005, epoch: 8/9, step: 522/600\n",
      "loss: 0.0369, lr: 0.0005, epoch: 8/9, step: 523/600\n",
      "loss: 0.1846, lr: 0.0005, epoch: 8/9, step: 524/600\n",
      "loss: 0.2539, lr: 0.0005, epoch: 8/9, step: 525/600\n",
      "loss: 0.6084, lr: 0.0005, epoch: 8/9, step: 526/600\n",
      "loss: 0.2554, lr: 0.0005, epoch: 8/9, step: 527/600\n",
      "loss: 0.0815, lr: 0.0005, epoch: 8/9, step: 528/600\n",
      "loss: 0.1652, lr: 0.0005, epoch: 8/9, step: 529/600\n",
      "loss: 0.1747, lr: 0.0005, epoch: 8/9, step: 530/600\n",
      "loss: 0.1072, lr: 0.0005, epoch: 8/9, step: 531/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 8/9, step: 532/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 8/9, step: 533/600\n",
      "loss: 0.4021, lr: 0.0005, epoch: 8/9, step: 534/600\n",
      "loss: 0.6079, lr: 0.0005, epoch: 8/9, step: 535/600\n",
      "loss: 0.0266, lr: 0.0005, epoch: 8/9, step: 536/600\n",
      "loss: 0.2654, lr: 0.0005, epoch: 8/9, step: 537/600\n",
      "loss: 0.0553, lr: 0.0005, epoch: 8/9, step: 538/600\n",
      "loss: 0.6211, lr: 0.0005, epoch: 8/9, step: 539/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 8/9, step: 540/600\n",
      "loss: 0.3408, lr: 0.0005, epoch: 8/9, step: 541/600\n",
      "loss: 0.0086, lr: 0.0005, epoch: 8/9, step: 542/600\n",
      "loss: 0.3433, lr: 0.0005, epoch: 8/9, step: 543/600\n",
      "loss: 0.2612, lr: 0.0005, epoch: 8/9, step: 544/600\n",
      "loss: 0.0359, lr: 0.0005, epoch: 8/9, step: 545/600\n",
      "loss: 0.7334, lr: 0.0005, epoch: 8/9, step: 546/600\n",
      "loss: 0.0887, lr: 0.0005, epoch: 8/9, step: 547/600\n",
      "loss: 0.4314, lr: 0.0005, epoch: 8/9, step: 548/600\n",
      "loss: 0.1006, lr: 0.0005, epoch: 8/9, step: 549/600\n",
      "loss: 0.4495, lr: 0.0005, epoch: 8/9, step: 550/600\n",
      "loss: 0.0088, lr: 0.0005, epoch: 8/9, step: 551/600\n",
      "loss: 0.325, lr: 0.0005, epoch: 8/9, step: 552/600\n",
      "loss: 0.1293, lr: 0.0005, epoch: 8/9, step: 553/600\n",
      "loss: 0.0278, lr: 0.0005, epoch: 8/9, step: 554/600\n",
      "loss: 0.0189, lr: 0.0005, epoch: 8/9, step: 555/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 8/9, step: 556/600\n",
      "loss: 0.0318, lr: 0.0005, epoch: 8/9, step: 557/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 8/9, step: 558/600\n",
      "loss: 0.5107, lr: 0.0005, epoch: 8/9, step: 559/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 8/9, step: 560/600\n",
      "loss: 0.0087, lr: 0.0005, epoch: 8/9, step: 561/600\n",
      "loss: 0.5132, lr: 0.0005, epoch: 8/9, step: 562/600\n",
      "loss: 0.0262, lr: 0.0005, epoch: 8/9, step: 563/600\n",
      "loss: 0.5439, lr: 0.0005, epoch: 8/9, step: 564/600\n",
      "loss: 0.4878, lr: 0.0005, epoch: 8/9, step: 565/600\n",
      "loss: 0.542, lr: 0.0005, epoch: 8/9, step: 566/600\n",
      "loss: 0.2052, lr: 0.0005, epoch: 8/9, step: 567/600\n",
      "loss: 0.3547, lr: 0.0005, epoch: 8/9, step: 568/600\n",
      "loss: 0.181, lr: 0.0005, epoch: 8/9, step: 569/600\n",
      "loss: 0.6367, lr: 0.0005, epoch: 8/9, step: 570/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 8/9, step: 571/600\n",
      "loss: 0.1384, lr: 0.0005, epoch: 8/9, step: 572/600\n",
      "loss: 0.1443, lr: 0.0005, epoch: 8/9, step: 573/600\n",
      "loss: 0.0318, lr: 0.0005, epoch: 8/9, step: 574/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 8/9, step: 575/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 8/9, step: 576/600\n",
      "loss: 0.0258, lr: 0.0005, epoch: 8/9, step: 577/600\n",
      "loss: 0.0906, lr: 0.0005, epoch: 8/9, step: 578/600\n",
      "loss: 0.075, lr: 0.0005, epoch: 8/9, step: 579/600\n",
      "loss: 0.0053, lr: 0.0005, epoch: 8/9, step: 580/600\n",
      "loss: 0.1896, lr: 0.0005, epoch: 8/9, step: 581/600\n",
      "loss: 0.1053, lr: 0.0005, epoch: 8/9, step: 582/600\n",
      "loss: 0.0465, lr: 0.0005, epoch: 8/9, step: 583/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 8/9, step: 584/600\n",
      "loss: 0.2198, lr: 0.0005, epoch: 8/9, step: 585/600\n",
      "loss: 0.562, lr: 0.0005, epoch: 8/9, step: 586/600\n",
      "loss: 0.4607, lr: 0.0005, epoch: 8/9, step: 587/600\n",
      "loss: 0.0125, lr: 0.0005, epoch: 8/9, step: 588/600\n",
      "loss: 0.3745, lr: 0.0005, epoch: 8/9, step: 589/600\n",
      "loss: 0.3008, lr: 0.0005, epoch: 8/9, step: 590/600\n",
      "loss: 0.2285, lr: 0.0005, epoch: 8/9, step: 591/600\n",
      "loss: 0.1971, lr: 0.0005, epoch: 8/9, step: 592/600\n",
      "loss: 0.0067, lr: 0.0005, epoch: 8/9, step: 593/600\n",
      "loss: 0.6387, lr: 0.0005, epoch: 8/9, step: 594/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 8/9, step: 595/600\n",
      "loss: 0.0193, lr: 0.0005, epoch: 8/9, step: 596/600\n",
      "loss: 0.1915, lr: 0.0005, epoch: 8/9, step: 597/600\n",
      "loss: 0.0409, lr: 0.0005, epoch: 8/9, step: 598/600\n",
      "loss: 0.0962, lr: 0.0005, epoch: 8/9, step: 599/600\n",
      "loss: 0.3389, lr: 0.0005, epoch: 8/9, step: 600/600\n",
      "loss: 0.0203, lr: 0.0005, epoch: 9/9, step: 1/600\n",
      "loss: 0.0269, lr: 0.0005, epoch: 9/9, step: 2/600\n",
      "loss: 0.035, lr: 0.0005, epoch: 9/9, step: 3/600\n",
      "loss: 0.01, lr: 0.0005, epoch: 9/9, step: 4/600\n",
      "loss: 0.4253, lr: 0.0005, epoch: 9/9, step: 5/600\n",
      "loss: 0.1572, lr: 0.0005, epoch: 9/9, step: 6/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 9/9, step: 7/600\n",
      "loss: 0.0212, lr: 0.0005, epoch: 9/9, step: 8/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 9/9, step: 9/600\n",
      "loss: 0.0447, lr: 0.0005, epoch: 9/9, step: 10/600\n",
      "loss: 0.0742, lr: 0.0005, epoch: 9/9, step: 11/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 9/9, step: 12/600\n",
      "loss: 0.0649, lr: 0.0005, epoch: 9/9, step: 13/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 9/9, step: 14/600\n",
      "loss: 0.036, lr: 0.0005, epoch: 9/9, step: 15/600\n",
      "loss: 0.057, lr: 0.0005, epoch: 9/9, step: 16/600\n",
      "loss: 0.6997, lr: 0.0005, epoch: 9/9, step: 17/600\n",
      "loss: 0.0709, lr: 0.0005, epoch: 9/9, step: 18/600\n",
      "loss: 0.0974, lr: 0.0005, epoch: 9/9, step: 19/600\n",
      "loss: 0.3359, lr: 0.0005, epoch: 9/9, step: 20/600\n",
      "loss: 0.3452, lr: 0.0005, epoch: 9/9, step: 21/600\n",
      "loss: 0.0189, lr: 0.0005, epoch: 9/9, step: 22/600\n",
      "loss: 0.0086, lr: 0.0005, epoch: 9/9, step: 23/600\n",
      "loss: 0.6411, lr: 0.0005, epoch: 9/9, step: 24/600\n",
      "loss: 0.1691, lr: 0.0005, epoch: 9/9, step: 25/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 9/9, step: 26/600\n",
      "loss: 0.4656, lr: 0.0005, epoch: 9/9, step: 27/600\n",
      "loss: 0.0408, lr: 0.0005, epoch: 9/9, step: 28/600\n",
      "loss: 0.5898, lr: 0.0005, epoch: 9/9, step: 29/600\n",
      "loss: 0.1697, lr: 0.0005, epoch: 9/9, step: 30/600\n",
      "loss: 0.8486, lr: 0.0005, epoch: 9/9, step: 31/600\n",
      "loss: 0.0649, lr: 0.0005, epoch: 9/9, step: 32/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 9/9, step: 33/600\n",
      "loss: 0.018, lr: 0.0005, epoch: 9/9, step: 34/600\n",
      "loss: 0.0202, lr: 0.0005, epoch: 9/9, step: 35/600\n",
      "loss: 0.626, lr: 0.0005, epoch: 9/9, step: 36/600\n",
      "loss: 0.4844, lr: 0.0005, epoch: 9/9, step: 37/600\n",
      "loss: 0.3972, lr: 0.0005, epoch: 9/9, step: 38/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 9/9, step: 39/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 9/9, step: 40/600\n",
      "loss: 0.012, lr: 0.0005, epoch: 9/9, step: 41/600\n",
      "loss: 0.3481, lr: 0.0005, epoch: 9/9, step: 42/600\n",
      "loss: 0.467, lr: 0.0005, epoch: 9/9, step: 43/600\n",
      "loss: 0.4014, lr: 0.0005, epoch: 9/9, step: 44/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 9/9, step: 45/600\n",
      "loss: 0.3235, lr: 0.0005, epoch: 9/9, step: 46/600\n",
      "loss: 0.4985, lr: 0.0005, epoch: 9/9, step: 47/600\n",
      "loss: 0.075, lr: 0.0005, epoch: 9/9, step: 48/600\n",
      "loss: 0.0623, lr: 0.0005, epoch: 9/9, step: 49/600\n",
      "loss: 0.0123, lr: 0.0005, epoch: 9/9, step: 50/600\n",
      "loss: 0.5664, lr: 0.0005, epoch: 9/9, step: 51/600\n",
      "loss: 0.4207, lr: 0.0005, epoch: 9/9, step: 52/600\n",
      "loss: 0.5469, lr: 0.0005, epoch: 9/9, step: 53/600\n",
      "loss: 0.2328, lr: 0.0005, epoch: 9/9, step: 54/600\n",
      "loss: 0.1951, lr: 0.0005, epoch: 9/9, step: 55/600\n",
      "loss: 0.0038, lr: 0.0005, epoch: 9/9, step: 56/600\n",
      "loss: 0.2581, lr: 0.0005, epoch: 9/9, step: 57/600\n",
      "loss: 0.3706, lr: 0.0005, epoch: 9/9, step: 58/600\n",
      "loss: 0.3049, lr: 0.0005, epoch: 9/9, step: 59/600\n",
      "loss: 0.0128, lr: 0.0005, epoch: 9/9, step: 60/600\n",
      "loss: 0.3806, lr: 0.0005, epoch: 9/9, step: 61/600\n",
      "loss: 0.2015, lr: 0.0005, epoch: 9/9, step: 62/600\n",
      "loss: 0.0216, lr: 0.0005, epoch: 9/9, step: 63/600\n",
      "loss: 0.5098, lr: 0.0005, epoch: 9/9, step: 64/600\n",
      "loss: 0.3223, lr: 0.0005, epoch: 9/9, step: 65/600\n",
      "loss: 0.283, lr: 0.0005, epoch: 9/9, step: 66/600\n",
      "loss: 0.439, lr: 0.0005, epoch: 9/9, step: 67/600\n",
      "loss: 0.0032, lr: 0.0005, epoch: 9/9, step: 68/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 9/9, step: 69/600\n",
      "loss: 0.603, lr: 0.0005, epoch: 9/9, step: 70/600\n",
      "loss: 0.0076, lr: 0.0005, epoch: 9/9, step: 71/600\n",
      "loss: 0.2201, lr: 0.0005, epoch: 9/9, step: 72/600\n",
      "loss: 0.1357, lr: 0.0005, epoch: 9/9, step: 73/600\n",
      "loss: 0.0717, lr: 0.0005, epoch: 9/9, step: 74/600\n",
      "loss: 0.0115, lr: 0.0005, epoch: 9/9, step: 75/600\n",
      "loss: 0.1022, lr: 0.0005, epoch: 9/9, step: 76/600\n",
      "loss: 0.0394, lr: 0.0005, epoch: 9/9, step: 77/600\n",
      "loss: 0.2522, lr: 0.0005, epoch: 9/9, step: 78/600\n",
      "loss: 0.0352, lr: 0.0005, epoch: 9/9, step: 79/600\n",
      "loss: 0.2949, lr: 0.0005, epoch: 9/9, step: 80/600\n",
      "loss: 0.208, lr: 0.0005, epoch: 9/9, step: 81/600\n",
      "loss: 0.2515, lr: 0.0005, epoch: 9/9, step: 82/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 9/9, step: 83/600\n",
      "loss: 0.0224, lr: 0.0005, epoch: 9/9, step: 84/600\n",
      "loss: 0.0638, lr: 0.0005, epoch: 9/9, step: 85/600\n",
      "loss: 0.5474, lr: 0.0005, epoch: 9/9, step: 86/600\n",
      "loss: 0.0423, lr: 0.0005, epoch: 9/9, step: 87/600\n",
      "loss: 0.5596, lr: 0.0005, epoch: 9/9, step: 88/600\n",
      "loss: 0.5024, lr: 0.0005, epoch: 9/9, step: 89/600\n",
      "loss: 0.5547, lr: 0.0005, epoch: 9/9, step: 90/600\n",
      "loss: 0.5796, lr: 0.0005, epoch: 9/9, step: 91/600\n",
      "loss: 0.0379, lr: 0.0005, epoch: 9/9, step: 92/600\n",
      "loss: 0.1211, lr: 0.0005, epoch: 9/9, step: 93/600\n",
      "loss: 0.3596, lr: 0.0005, epoch: 9/9, step: 94/600\n",
      "loss: 0.0093, lr: 0.0005, epoch: 9/9, step: 95/600\n",
      "loss: 0.3535, lr: 0.0005, epoch: 9/9, step: 96/600\n",
      "loss: 0.0447, lr: 0.0005, epoch: 9/9, step: 97/600\n",
      "loss: 0.0711, lr: 0.0005, epoch: 9/9, step: 98/600\n",
      "loss: 0.6675, lr: 0.0005, epoch: 9/9, step: 99/600\n",
      "loss: 0.0868, lr: 0.0005, epoch: 9/9, step: 100/600\n",
      "loss: 0.0205, lr: 0.0005, epoch: 9/9, step: 101/600\n",
      "loss: 0.0711, lr: 0.0005, epoch: 9/9, step: 102/600\n",
      "loss: 0.1639, lr: 0.0005, epoch: 9/9, step: 103/600\n",
      "loss: 0.0476, lr: 0.0005, epoch: 9/9, step: 104/600\n",
      "loss: 0.469, lr: 0.0005, epoch: 9/9, step: 105/600\n",
      "loss: 0.3027, lr: 0.0005, epoch: 9/9, step: 106/600\n",
      "loss: 0.0152, lr: 0.0005, epoch: 9/9, step: 107/600\n",
      "loss: 0.8525, lr: 0.0005, epoch: 9/9, step: 108/600\n",
      "loss: 0.8701, lr: 0.0005, epoch: 9/9, step: 109/600\n",
      "loss: 0.79, lr: 0.0005, epoch: 9/9, step: 110/600\n",
      "loss: 0.1238, lr: 0.0005, epoch: 9/9, step: 111/600\n",
      "loss: 0.0141, lr: 0.0005, epoch: 9/9, step: 112/600\n",
      "loss: 0.2771, lr: 0.0005, epoch: 9/9, step: 113/600\n",
      "loss: 0.0024, lr: 0.0005, epoch: 9/9, step: 114/600\n",
      "loss: 0.0344, lr: 0.0005, epoch: 9/9, step: 115/600\n",
      "loss: 0.1081, lr: 0.0005, epoch: 9/9, step: 116/600\n",
      "loss: 0.5532, lr: 0.0005, epoch: 9/9, step: 117/600\n",
      "loss: 0.1174, lr: 0.0005, epoch: 9/9, step: 118/600\n",
      "loss: 0.062, lr: 0.0005, epoch: 9/9, step: 119/600\n",
      "loss: 0.5083, lr: 0.0005, epoch: 9/9, step: 120/600\n",
      "loss: 0.5249, lr: 0.0005, epoch: 9/9, step: 121/600\n",
      "loss: 0.2296, lr: 0.0005, epoch: 9/9, step: 122/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 9/9, step: 123/600\n",
      "loss: 0.1586, lr: 0.0005, epoch: 9/9, step: 124/600\n",
      "loss: 0.1364, lr: 0.0005, epoch: 9/9, step: 125/600\n",
      "loss: 0.1091, lr: 0.0005, epoch: 9/9, step: 126/600\n",
      "loss: 0.2734, lr: 0.0005, epoch: 9/9, step: 127/600\n",
      "loss: 0.3645, lr: 0.0005, epoch: 9/9, step: 128/600\n",
      "loss: 0.025, lr: 0.0005, epoch: 9/9, step: 129/600\n",
      "loss: 0.4219, lr: 0.0005, epoch: 9/9, step: 130/600\n",
      "loss: 0.2281, lr: 0.0005, epoch: 9/9, step: 131/600\n",
      "loss: 0.6465, lr: 0.0005, epoch: 9/9, step: 132/600\n",
      "loss: 0.4529, lr: 0.0005, epoch: 9/9, step: 133/600\n",
      "loss: 0.0258, lr: 0.0005, epoch: 9/9, step: 134/600\n",
      "loss: 0.4119, lr: 0.0005, epoch: 9/9, step: 135/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 9/9, step: 136/600\n",
      "loss: 0.014, lr: 0.0005, epoch: 9/9, step: 137/600\n",
      "loss: 0.2998, lr: 0.0005, epoch: 9/9, step: 138/600\n",
      "loss: 0.1108, lr: 0.0005, epoch: 9/9, step: 139/600\n",
      "loss: 0.0224, lr: 0.0005, epoch: 9/9, step: 140/600\n",
      "loss: 0.012, lr: 0.0005, epoch: 9/9, step: 141/600\n",
      "loss: 0.3357, lr: 0.0005, epoch: 9/9, step: 142/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 9/9, step: 143/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 9/9, step: 144/600\n",
      "loss: 0.0205, lr: 0.0005, epoch: 9/9, step: 145/600\n",
      "loss: 0.0448, lr: 0.0005, epoch: 9/9, step: 146/600\n",
      "loss: 0.2856, lr: 0.0005, epoch: 9/9, step: 147/600\n",
      "loss: 0.2871, lr: 0.0005, epoch: 9/9, step: 148/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 9/9, step: 149/600\n",
      "loss: 0.1096, lr: 0.0005, epoch: 9/9, step: 150/600\n",
      "loss: 0.2646, lr: 0.0005, epoch: 9/9, step: 151/600\n",
      "loss: 0.003, lr: 0.0005, epoch: 9/9, step: 152/600\n",
      "loss: 0.0225, lr: 0.0005, epoch: 9/9, step: 153/600\n",
      "loss: 0.0526, lr: 0.0005, epoch: 9/9, step: 154/600\n",
      "loss: 0.0102, lr: 0.0005, epoch: 9/9, step: 155/600\n",
      "loss: 0.015, lr: 0.0005, epoch: 9/9, step: 156/600\n",
      "loss: 0.5874, lr: 0.0005, epoch: 9/9, step: 157/600\n",
      "loss: 0.0953, lr: 0.0005, epoch: 9/9, step: 158/600\n",
      "loss: 0.0149, lr: 0.0005, epoch: 9/9, step: 159/600\n",
      "loss: 0.0145, lr: 0.0005, epoch: 9/9, step: 160/600\n",
      "loss: 0.3818, lr: 0.0005, epoch: 9/9, step: 161/600\n",
      "loss: 0.429, lr: 0.0005, epoch: 9/9, step: 162/600\n",
      "loss: 0.0139, lr: 0.0005, epoch: 9/9, step: 163/600\n",
      "loss: 0.5308, lr: 0.0005, epoch: 9/9, step: 164/600\n",
      "loss: 0.0179, lr: 0.0005, epoch: 9/9, step: 165/600\n",
      "loss: 0.009, lr: 0.0005, epoch: 9/9, step: 166/600\n",
      "loss: 0.03, lr: 0.0005, epoch: 9/9, step: 167/600\n",
      "loss: 0.0394, lr: 0.0005, epoch: 9/9, step: 168/600\n",
      "loss: 0.5908, lr: 0.0005, epoch: 9/9, step: 169/600\n",
      "loss: 0.271, lr: 0.0005, epoch: 9/9, step: 170/600\n",
      "loss: 0.2048, lr: 0.0005, epoch: 9/9, step: 171/600\n",
      "loss: 0.2837, lr: 0.0005, epoch: 9/9, step: 172/600\n",
      "loss: 0.0475, lr: 0.0005, epoch: 9/9, step: 173/600\n",
      "loss: 0.0369, lr: 0.0005, epoch: 9/9, step: 174/600\n",
      "loss: 0.054, lr: 0.0005, epoch: 9/9, step: 175/600\n",
      "loss: 0.1503, lr: 0.0005, epoch: 9/9, step: 176/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 9/9, step: 177/600\n",
      "loss: 0.2651, lr: 0.0005, epoch: 9/9, step: 178/600\n",
      "loss: 0.1923, lr: 0.0005, epoch: 9/9, step: 179/600\n",
      "loss: 0.0535, lr: 0.0005, epoch: 9/9, step: 180/600\n",
      "loss: 0.0584, lr: 0.0005, epoch: 9/9, step: 181/600\n",
      "loss: 0.0379, lr: 0.0005, epoch: 9/9, step: 182/600\n",
      "loss: 0.4954, lr: 0.0005, epoch: 9/9, step: 183/600\n",
      "loss: 0.0219, lr: 0.0005, epoch: 9/9, step: 184/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 9/9, step: 185/600\n",
      "loss: 0.0453, lr: 0.0005, epoch: 9/9, step: 186/600\n",
      "loss: 0.342, lr: 0.0005, epoch: 9/9, step: 187/600\n",
      "loss: 0.0184, lr: 0.0005, epoch: 9/9, step: 188/600\n",
      "loss: 0.0914, lr: 0.0005, epoch: 9/9, step: 189/600\n",
      "loss: 0.7861, lr: 0.0005, epoch: 9/9, step: 190/600\n",
      "loss: 0.2069, lr: 0.0005, epoch: 9/9, step: 191/600\n",
      "loss: 0.0433, lr: 0.0005, epoch: 9/9, step: 192/600\n",
      "loss: 0.5996, lr: 0.0005, epoch: 9/9, step: 193/600\n",
      "loss: 0.23, lr: 0.0005, epoch: 9/9, step: 194/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 9/9, step: 195/600\n",
      "loss: 0.0026, lr: 0.0005, epoch: 9/9, step: 196/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 9/9, step: 197/600\n",
      "loss: 0.0271, lr: 0.0005, epoch: 9/9, step: 198/600\n",
      "loss: 0.2202, lr: 0.0005, epoch: 9/9, step: 199/600\n",
      "loss: 0.006, lr: 0.0005, epoch: 9/9, step: 200/600\n",
      "loss: 0.0525, lr: 0.0005, epoch: 9/9, step: 201/600\n",
      "loss: 0.0317, lr: 0.0005, epoch: 9/9, step: 202/600\n",
      "loss: 0.2615, lr: 0.0005, epoch: 9/9, step: 203/600\n",
      "loss: 0.1045, lr: 0.0005, epoch: 9/9, step: 204/600\n",
      "loss: 0.2844, lr: 0.0005, epoch: 9/9, step: 205/600\n",
      "loss: 0.1259, lr: 0.0005, epoch: 9/9, step: 206/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 9/9, step: 207/600\n",
      "loss: 0.0264, lr: 0.0005, epoch: 9/9, step: 208/600\n",
      "loss: 0.0022, lr: 0.0005, epoch: 9/9, step: 209/600\n",
      "loss: 0.0244, lr: 0.0005, epoch: 9/9, step: 210/600\n",
      "loss: 0.0539, lr: 0.0005, epoch: 9/9, step: 211/600\n",
      "loss: 0.6055, lr: 0.0005, epoch: 9/9, step: 212/600\n",
      "loss: 0.2445, lr: 0.0005, epoch: 9/9, step: 213/600\n",
      "loss: 0.0425, lr: 0.0005, epoch: 9/9, step: 214/600\n",
      "loss: 0.038, lr: 0.0005, epoch: 9/9, step: 215/600\n",
      "loss: 0.3523, lr: 0.0005, epoch: 9/9, step: 216/600\n",
      "loss: 0.0162, lr: 0.0005, epoch: 9/9, step: 217/600\n",
      "loss: 0.0523, lr: 0.0005, epoch: 9/9, step: 218/600\n",
      "loss: 0.2275, lr: 0.0005, epoch: 9/9, step: 219/600\n",
      "loss: 0.0089, lr: 0.0005, epoch: 9/9, step: 220/600\n",
      "loss: 0.1588, lr: 0.0005, epoch: 9/9, step: 221/600\n",
      "loss: 0.5586, lr: 0.0005, epoch: 9/9, step: 222/600\n",
      "loss: 0.3079, lr: 0.0005, epoch: 9/9, step: 223/600\n",
      "loss: 0.3667, lr: 0.0005, epoch: 9/9, step: 224/600\n",
      "loss: 0.5586, lr: 0.0005, epoch: 9/9, step: 225/600\n",
      "loss: 0.0387, lr: 0.0005, epoch: 9/9, step: 226/600\n",
      "loss: 0.0401, lr: 0.0005, epoch: 9/9, step: 227/600\n",
      "loss: 0.7915, lr: 0.0005, epoch: 9/9, step: 228/600\n",
      "loss: 0.4377, lr: 0.0005, epoch: 9/9, step: 229/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 9/9, step: 230/600\n",
      "loss: 0.5435, lr: 0.0005, epoch: 9/9, step: 231/600\n",
      "loss: 0.1451, lr: 0.0005, epoch: 9/9, step: 232/600\n",
      "loss: 0.0163, lr: 0.0005, epoch: 9/9, step: 233/600\n",
      "loss: 0.3301, lr: 0.0005, epoch: 9/9, step: 234/600\n",
      "loss: 0.5708, lr: 0.0005, epoch: 9/9, step: 235/600\n",
      "loss: 0.1378, lr: 0.0005, epoch: 9/9, step: 236/600\n",
      "loss: 0.6597, lr: 0.0005, epoch: 9/9, step: 237/600\n",
      "loss: 0.0438, lr: 0.0005, epoch: 9/9, step: 238/600\n",
      "loss: 0.1109, lr: 0.0005, epoch: 9/9, step: 239/600\n",
      "loss: 0.1045, lr: 0.0005, epoch: 9/9, step: 240/600\n",
      "loss: 0.0048, lr: 0.0005, epoch: 9/9, step: 241/600\n",
      "loss: 0.0181, lr: 0.0005, epoch: 9/9, step: 242/600\n",
      "loss: 0.103, lr: 0.0005, epoch: 9/9, step: 243/600\n",
      "loss: 0.46, lr: 0.0005, epoch: 9/9, step: 244/600\n",
      "loss: 0.0214, lr: 0.0005, epoch: 9/9, step: 245/600\n",
      "loss: 0.178, lr: 0.0005, epoch: 9/9, step: 246/600\n",
      "loss: 0.2218, lr: 0.0005, epoch: 9/9, step: 247/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 9/9, step: 248/600\n",
      "loss: 0.856, lr: 0.0005, epoch: 9/9, step: 249/600\n",
      "loss: 0.2649, lr: 0.0005, epoch: 9/9, step: 250/600\n",
      "loss: 0.1, lr: 0.0005, epoch: 9/9, step: 251/600\n",
      "loss: 0.2766, lr: 0.0005, epoch: 9/9, step: 252/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 9/9, step: 253/600\n",
      "loss: 0.5273, lr: 0.0005, epoch: 9/9, step: 254/600\n",
      "loss: 0.1177, lr: 0.0005, epoch: 9/9, step: 255/600\n",
      "loss: 0.1096, lr: 0.0005, epoch: 9/9, step: 256/600\n",
      "loss: 0.0646, lr: 0.0005, epoch: 9/9, step: 257/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 9/9, step: 258/600\n",
      "loss: 0.0614, lr: 0.0005, epoch: 9/9, step: 259/600\n",
      "loss: 0.0965, lr: 0.0005, epoch: 9/9, step: 260/600\n",
      "loss: 0.6362, lr: 0.0005, epoch: 9/9, step: 261/600\n",
      "loss: 0.1143, lr: 0.0005, epoch: 9/9, step: 262/600\n",
      "loss: 0.7651, lr: 0.0005, epoch: 9/9, step: 263/600\n",
      "loss: 0.6562, lr: 0.0005, epoch: 9/9, step: 264/600\n",
      "loss: 0.1068, lr: 0.0005, epoch: 9/9, step: 265/600\n",
      "loss: 0.6396, lr: 0.0005, epoch: 9/9, step: 266/600\n",
      "loss: 0.7207, lr: 0.0005, epoch: 9/9, step: 267/600\n",
      "loss: 0.0801, lr: 0.0005, epoch: 9/9, step: 268/600\n",
      "loss: 0.0256, lr: 0.0005, epoch: 9/9, step: 269/600\n",
      "loss: 0.6025, lr: 0.0005, epoch: 9/9, step: 270/600\n",
      "loss: 0.0078, lr: 0.0005, epoch: 9/9, step: 271/600\n",
      "loss: 0.1591, lr: 0.0005, epoch: 9/9, step: 272/600\n",
      "loss: 0.2181, lr: 0.0005, epoch: 9/9, step: 273/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 9/9, step: 274/600\n",
      "loss: 0.5254, lr: 0.0005, epoch: 9/9, step: 275/600\n",
      "loss: 0.0097, lr: 0.0005, epoch: 9/9, step: 276/600\n",
      "loss: 0.3284, lr: 0.0005, epoch: 9/9, step: 277/600\n",
      "loss: 0.0605, lr: 0.0005, epoch: 9/9, step: 278/600\n",
      "loss: 0.1377, lr: 0.0005, epoch: 9/9, step: 279/600\n",
      "loss: 0.1476, lr: 0.0005, epoch: 9/9, step: 280/600\n",
      "loss: 0.1447, lr: 0.0005, epoch: 9/9, step: 281/600\n",
      "loss: 0.4124, lr: 0.0005, epoch: 9/9, step: 282/600\n",
      "loss: 0.0512, lr: 0.0005, epoch: 9/9, step: 283/600\n",
      "loss: 0.0605, lr: 0.0005, epoch: 9/9, step: 284/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 9/9, step: 285/600\n",
      "loss: 0.0663, lr: 0.0005, epoch: 9/9, step: 286/600\n",
      "loss: 0.1499, lr: 0.0005, epoch: 9/9, step: 287/600\n",
      "loss: 0.0186, lr: 0.0005, epoch: 9/9, step: 288/600\n",
      "loss: 0.0094, lr: 0.0005, epoch: 9/9, step: 289/600\n",
      "loss: 0.1783, lr: 0.0005, epoch: 9/9, step: 290/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 9/9, step: 291/600\n",
      "loss: 0.4478, lr: 0.0005, epoch: 9/9, step: 292/600\n",
      "loss: 0.0275, lr: 0.0005, epoch: 9/9, step: 293/600\n",
      "loss: 0.0308, lr: 0.0005, epoch: 9/9, step: 294/600\n",
      "loss: 0.1626, lr: 0.0005, epoch: 9/9, step: 295/600\n",
      "loss: 0.182, lr: 0.0005, epoch: 9/9, step: 296/600\n",
      "loss: 0.4321, lr: 0.0005, epoch: 9/9, step: 297/600\n",
      "loss: 0.4763, lr: 0.0005, epoch: 9/9, step: 298/600\n",
      "loss: 0.2844, lr: 0.0005, epoch: 9/9, step: 299/600\n",
      "loss: 0.248, lr: 0.0005, epoch: 9/9, step: 300/600\n",
      "loss: 0.0039, lr: 0.0005, epoch: 9/9, step: 301/600\n",
      "loss: 0.1204, lr: 0.0005, epoch: 9/9, step: 302/600\n",
      "loss: 0.014, lr: 0.0005, epoch: 9/9, step: 303/600\n",
      "loss: 0.1725, lr: 0.0005, epoch: 9/9, step: 304/600\n",
      "loss: 0.0801, lr: 0.0005, epoch: 9/9, step: 305/600\n",
      "loss: 0.0842, lr: 0.0005, epoch: 9/9, step: 306/600\n",
      "loss: 0.1577, lr: 0.0005, epoch: 9/9, step: 307/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 9/9, step: 308/600\n",
      "loss: 0.0051, lr: 0.0005, epoch: 9/9, step: 309/600\n",
      "loss: 0.0068, lr: 0.0005, epoch: 9/9, step: 310/600\n",
      "loss: 0.1669, lr: 0.0005, epoch: 9/9, step: 311/600\n",
      "loss: 0.2455, lr: 0.0005, epoch: 9/9, step: 312/600\n",
      "loss: 0.2001, lr: 0.0005, epoch: 9/9, step: 313/600\n",
      "loss: 0.029, lr: 0.0005, epoch: 9/9, step: 314/600\n",
      "loss: 0.4277, lr: 0.0005, epoch: 9/9, step: 315/600\n",
      "loss: 0.0304, lr: 0.0005, epoch: 9/9, step: 316/600\n",
      "loss: 0.2952, lr: 0.0005, epoch: 9/9, step: 317/600\n",
      "loss: 0.0486, lr: 0.0005, epoch: 9/9, step: 318/600\n",
      "loss: 0.1514, lr: 0.0005, epoch: 9/9, step: 319/600\n",
      "loss: 0.0185, lr: 0.0005, epoch: 9/9, step: 320/600\n",
      "loss: 0.0233, lr: 0.0005, epoch: 9/9, step: 321/600\n",
      "loss: 0.3875, lr: 0.0005, epoch: 9/9, step: 322/600\n",
      "loss: 0.2157, lr: 0.0005, epoch: 9/9, step: 323/600\n",
      "loss: 0.3286, lr: 0.0005, epoch: 9/9, step: 324/600\n",
      "loss: 0.0149, lr: 0.0005, epoch: 9/9, step: 325/600\n",
      "loss: 0.5708, lr: 0.0005, epoch: 9/9, step: 326/600\n",
      "loss: 0.0208, lr: 0.0005, epoch: 9/9, step: 327/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 9/9, step: 328/600\n",
      "loss: 0.0176, lr: 0.0005, epoch: 9/9, step: 329/600\n",
      "loss: 0.0459, lr: 0.0005, epoch: 9/9, step: 330/600\n",
      "loss: 0.0042, lr: 0.0005, epoch: 9/9, step: 331/600\n",
      "loss: 0.0677, lr: 0.0005, epoch: 9/9, step: 332/600\n",
      "loss: 0.0152, lr: 0.0005, epoch: 9/9, step: 333/600\n",
      "loss: 0.2598, lr: 0.0005, epoch: 9/9, step: 334/600\n",
      "loss: 0.025, lr: 0.0005, epoch: 9/9, step: 335/600\n",
      "loss: 0.1892, lr: 0.0005, epoch: 9/9, step: 336/600\n",
      "loss: 0.0083, lr: 0.0005, epoch: 9/9, step: 337/600\n",
      "loss: 0.2109, lr: 0.0005, epoch: 9/9, step: 338/600\n",
      "loss: 0.1476, lr: 0.0005, epoch: 9/9, step: 339/600\n",
      "loss: 0.4546, lr: 0.0005, epoch: 9/9, step: 340/600\n",
      "loss: 0.0684, lr: 0.0005, epoch: 9/9, step: 341/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 9/9, step: 342/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 9/9, step: 343/600\n",
      "loss: 0.2627, lr: 0.0005, epoch: 9/9, step: 344/600\n",
      "loss: 0.426, lr: 0.0005, epoch: 9/9, step: 345/600\n",
      "loss: 0.2355, lr: 0.0005, epoch: 9/9, step: 346/600\n",
      "loss: 0.2441, lr: 0.0005, epoch: 9/9, step: 347/600\n",
      "loss: 0.0659, lr: 0.0005, epoch: 9/9, step: 348/600\n",
      "loss: 0.007, lr: 0.0005, epoch: 9/9, step: 349/600\n",
      "loss: 0.1589, lr: 0.0005, epoch: 9/9, step: 350/600\n",
      "loss: 0.0134, lr: 0.0005, epoch: 9/9, step: 351/600\n",
      "loss: 0.4741, lr: 0.0005, epoch: 9/9, step: 352/600\n",
      "loss: 0.0112, lr: 0.0005, epoch: 9/9, step: 353/600\n",
      "loss: 0.1434, lr: 0.0005, epoch: 9/9, step: 354/600\n",
      "loss: 0.1329, lr: 0.0005, epoch: 9/9, step: 355/600\n",
      "loss: 0.0127, lr: 0.0005, epoch: 9/9, step: 356/600\n",
      "loss: 0.0228, lr: 0.0005, epoch: 9/9, step: 357/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 9/9, step: 358/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 9/9, step: 359/600\n",
      "loss: 0.0964, lr: 0.0005, epoch: 9/9, step: 360/600\n",
      "loss: 0.5669, lr: 0.0005, epoch: 9/9, step: 361/600\n",
      "loss: 0.0092, lr: 0.0005, epoch: 9/9, step: 362/600\n",
      "loss: 0.6904, lr: 0.0005, epoch: 9/9, step: 363/600\n",
      "loss: 0.0111, lr: 0.0005, epoch: 9/9, step: 364/600\n",
      "loss: 0.0197, lr: 0.0005, epoch: 9/9, step: 365/600\n",
      "loss: 0.1395, lr: 0.0005, epoch: 9/9, step: 366/600\n",
      "loss: 0.0047, lr: 0.0005, epoch: 9/9, step: 367/600\n",
      "loss: 0.0025, lr: 0.0005, epoch: 9/9, step: 368/600\n",
      "loss: 0.2568, lr: 0.0005, epoch: 9/9, step: 369/600\n",
      "loss: 0.2032, lr: 0.0005, epoch: 9/9, step: 370/600\n",
      "loss: 0.6587, lr: 0.0005, epoch: 9/9, step: 371/600\n",
      "loss: 0.7534, lr: 0.0005, epoch: 9/9, step: 372/600\n",
      "loss: 0.0067, lr: 0.0005, epoch: 9/9, step: 373/600\n",
      "loss: 0.1899, lr: 0.0005, epoch: 9/9, step: 374/600\n",
      "loss: 0.3582, lr: 0.0005, epoch: 9/9, step: 375/600\n",
      "loss: 0.3748, lr: 0.0005, epoch: 9/9, step: 376/600\n",
      "loss: 0.5278, lr: 0.0005, epoch: 9/9, step: 377/600\n",
      "loss: 0.188, lr: 0.0005, epoch: 9/9, step: 378/600\n",
      "loss: 0.032, lr: 0.0005, epoch: 9/9, step: 379/600\n",
      "loss: 0.3452, lr: 0.0005, epoch: 9/9, step: 380/600\n",
      "loss: 0.0086, lr: 0.0005, epoch: 9/9, step: 381/600\n",
      "loss: 0.0181, lr: 0.0005, epoch: 9/9, step: 382/600\n",
      "loss: 0.5127, lr: 0.0005, epoch: 9/9, step: 383/600\n",
      "loss: 0.1558, lr: 0.0005, epoch: 9/9, step: 384/600\n",
      "loss: 0.0177, lr: 0.0005, epoch: 9/9, step: 385/600\n",
      "loss: 0.0817, lr: 0.0005, epoch: 9/9, step: 386/600\n",
      "loss: 0.0127, lr: 0.0005, epoch: 9/9, step: 387/600\n",
      "loss: 0.1726, lr: 0.0005, epoch: 9/9, step: 388/600\n",
      "loss: 0.2313, lr: 0.0005, epoch: 9/9, step: 389/600\n",
      "loss: 0.083, lr: 0.0005, epoch: 9/9, step: 390/600\n",
      "loss: 0.1731, lr: 0.0005, epoch: 9/9, step: 391/600\n",
      "loss: 0.1514, lr: 0.0005, epoch: 9/9, step: 392/600\n",
      "loss: 0.0523, lr: 0.0005, epoch: 9/9, step: 393/600\n",
      "loss: 0.1683, lr: 0.0005, epoch: 9/9, step: 394/600\n",
      "loss: 0.2783, lr: 0.0005, epoch: 9/9, step: 395/600\n",
      "loss: 0.2168, lr: 0.0005, epoch: 9/9, step: 396/600\n",
      "loss: 0.4287, lr: 0.0005, epoch: 9/9, step: 397/600\n",
      "loss: 0.1154, lr: 0.0005, epoch: 9/9, step: 398/600\n",
      "loss: 0.1643, lr: 0.0005, epoch: 9/9, step: 399/600\n",
      "loss: 0.2218, lr: 0.0005, epoch: 9/9, step: 400/600\n",
      "loss: 0.0915, lr: 0.0005, epoch: 9/9, step: 401/600\n",
      "loss: 0.0057, lr: 0.0005, epoch: 9/9, step: 402/600\n",
      "loss: 0.4341, lr: 0.0005, epoch: 9/9, step: 403/600\n",
      "loss: 0.2269, lr: 0.0005, epoch: 9/9, step: 404/600\n",
      "loss: 0.0099, lr: 0.0005, epoch: 9/9, step: 405/600\n",
      "loss: 0.6357, lr: 0.0005, epoch: 9/9, step: 406/600\n",
      "loss: 0.0423, lr: 0.0005, epoch: 9/9, step: 407/600\n",
      "loss: 0.5, lr: 0.0005, epoch: 9/9, step: 408/600\n",
      "loss: 0.0211, lr: 0.0005, epoch: 9/9, step: 409/600\n",
      "loss: 0.1582, lr: 0.0005, epoch: 9/9, step: 410/600\n",
      "loss: 0.1658, lr: 0.0005, epoch: 9/9, step: 411/600\n",
      "loss: 0.3047, lr: 0.0005, epoch: 9/9, step: 412/600\n",
      "loss: 0.2578, lr: 0.0005, epoch: 9/9, step: 413/600\n",
      "loss: 0.6685, lr: 0.0005, epoch: 9/9, step: 414/600\n",
      "loss: 0.0266, lr: 0.0005, epoch: 9/9, step: 415/600\n",
      "loss: 0.2856, lr: 0.0005, epoch: 9/9, step: 416/600\n",
      "loss: 0.1411, lr: 0.0005, epoch: 9/9, step: 417/600\n",
      "loss: 0.0859, lr: 0.0005, epoch: 9/9, step: 418/600\n",
      "loss: 0.2477, lr: 0.0005, epoch: 9/9, step: 419/600\n",
      "loss: 0.0154, lr: 0.0005, epoch: 9/9, step: 420/600\n",
      "loss: 0.2217, lr: 0.0005, epoch: 9/9, step: 421/600\n",
      "loss: 0.0095, lr: 0.0005, epoch: 9/9, step: 422/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 9/9, step: 423/600\n",
      "loss: 0.0735, lr: 0.0005, epoch: 9/9, step: 424/600\n",
      "loss: 0.0273, lr: 0.0005, epoch: 9/9, step: 425/600\n",
      "loss: 0.3503, lr: 0.0005, epoch: 9/9, step: 426/600\n",
      "loss: 0.0065, lr: 0.0005, epoch: 9/9, step: 427/600\n",
      "loss: 0.0029, lr: 0.0005, epoch: 9/9, step: 428/600\n",
      "loss: 0.6323, lr: 0.0005, epoch: 9/9, step: 429/600\n",
      "loss: 0.0649, lr: 0.0005, epoch: 9/9, step: 430/600\n",
      "loss: 0.1025, lr: 0.0005, epoch: 9/9, step: 431/600\n",
      "loss: 0.3962, lr: 0.0005, epoch: 9/9, step: 432/600\n",
      "loss: 0.665, lr: 0.0005, epoch: 9/9, step: 433/600\n",
      "loss: 0.0104, lr: 0.0005, epoch: 9/9, step: 434/600\n",
      "loss: 0.0066, lr: 0.0005, epoch: 9/9, step: 435/600\n",
      "loss: 0.036, lr: 0.0005, epoch: 9/9, step: 436/600\n",
      "loss: 0.0985, lr: 0.0005, epoch: 9/9, step: 437/600\n",
      "loss: 0.3242, lr: 0.0005, epoch: 9/9, step: 438/600\n",
      "loss: 0.2551, lr: 0.0005, epoch: 9/9, step: 439/600\n",
      "loss: 0.0109, lr: 0.0005, epoch: 9/9, step: 440/600\n",
      "loss: 0.0365, lr: 0.0005, epoch: 9/9, step: 441/600\n",
      "loss: 0.4658, lr: 0.0005, epoch: 9/9, step: 442/600\n",
      "loss: 0.0208, lr: 0.0005, epoch: 9/9, step: 443/600\n",
      "loss: 0.0058, lr: 0.0005, epoch: 9/9, step: 444/600\n",
      "loss: 0.1874, lr: 0.0005, epoch: 9/9, step: 445/600\n",
      "loss: 0.4072, lr: 0.0005, epoch: 9/9, step: 446/600\n",
      "loss: 0.1432, lr: 0.0005, epoch: 9/9, step: 447/600\n",
      "loss: 0.063, lr: 0.0005, epoch: 9/9, step: 448/600\n",
      "loss: 0.2267, lr: 0.0005, epoch: 9/9, step: 449/600\n",
      "loss: 0.0878, lr: 0.0005, epoch: 9/9, step: 450/600\n",
      "loss: 0.0172, lr: 0.0005, epoch: 9/9, step: 451/600\n",
      "loss: 0.1526, lr: 0.0005, epoch: 9/9, step: 452/600\n",
      "loss: 0.2001, lr: 0.0005, epoch: 9/9, step: 453/600\n",
      "loss: 0.0437, lr: 0.0005, epoch: 9/9, step: 454/600\n",
      "loss: 0.1057, lr: 0.0005, epoch: 9/9, step: 455/600\n",
      "loss: 0.0456, lr: 0.0005, epoch: 9/9, step: 456/600\n",
      "loss: 0.0356, lr: 0.0005, epoch: 9/9, step: 457/600\n",
      "loss: 0.212, lr: 0.0005, epoch: 9/9, step: 458/600\n",
      "loss: 0.0592, lr: 0.0005, epoch: 9/9, step: 459/600\n",
      "loss: 0.0224, lr: 0.0005, epoch: 9/9, step: 460/600\n",
      "loss: 0.1213, lr: 0.0005, epoch: 9/9, step: 461/600\n",
      "loss: 0.3394, lr: 0.0005, epoch: 9/9, step: 462/600\n",
      "loss: 0.1748, lr: 0.0005, epoch: 9/9, step: 463/600\n",
      "loss: 0.1842, lr: 0.0005, epoch: 9/9, step: 464/600\n",
      "loss: 0.0114, lr: 0.0005, epoch: 9/9, step: 465/600\n",
      "loss: 0.1223, lr: 0.0005, epoch: 9/9, step: 466/600\n",
      "loss: 0.0028, lr: 0.0005, epoch: 9/9, step: 467/600\n",
      "loss: 0.2893, lr: 0.0005, epoch: 9/9, step: 468/600\n",
      "loss: 0.011, lr: 0.0005, epoch: 9/9, step: 469/600\n",
      "loss: 0.0746, lr: 0.0005, epoch: 9/9, step: 470/600\n",
      "loss: 0.1102, lr: 0.0005, epoch: 9/9, step: 471/600\n",
      "loss: 0.4961, lr: 0.0005, epoch: 9/9, step: 472/600\n",
      "loss: 0.2019, lr: 0.0005, epoch: 9/9, step: 473/600\n",
      "loss: 0.1755, lr: 0.0005, epoch: 9/9, step: 474/600\n",
      "loss: 0.0473, lr: 0.0005, epoch: 9/9, step: 475/600\n",
      "loss: 0.8838, lr: 0.0005, epoch: 9/9, step: 476/600\n",
      "loss: 0.3596, lr: 0.0005, epoch: 9/9, step: 477/600\n",
      "loss: 0.0027, lr: 0.0005, epoch: 9/9, step: 478/600\n",
      "loss: 0.1978, lr: 0.0005, epoch: 9/9, step: 479/600\n",
      "loss: 0.0036, lr: 0.0005, epoch: 9/9, step: 480/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 9/9, step: 481/600\n",
      "loss: 0.0504, lr: 0.0005, epoch: 9/9, step: 482/600\n",
      "loss: 0.0782, lr: 0.0005, epoch: 9/9, step: 483/600\n",
      "loss: 0.005, lr: 0.0005, epoch: 9/9, step: 484/600\n",
      "loss: 0.0031, lr: 0.0005, epoch: 9/9, step: 485/600\n",
      "loss: 0.0059, lr: 0.0005, epoch: 9/9, step: 486/600\n",
      "loss: 0.1426, lr: 0.0005, epoch: 9/9, step: 487/600\n",
      "loss: 0.0033, lr: 0.0005, epoch: 9/9, step: 488/600\n",
      "loss: 0.4109, lr: 0.0005, epoch: 9/9, step: 489/600\n",
      "loss: 0.4194, lr: 0.0005, epoch: 9/9, step: 490/600\n",
      "loss: 0.7153, lr: 0.0005, epoch: 9/9, step: 491/600\n",
      "loss: 0.0062, lr: 0.0005, epoch: 9/9, step: 492/600\n",
      "loss: 0.0084, lr: 0.0005, epoch: 9/9, step: 493/600\n",
      "loss: 0.0524, lr: 0.0005, epoch: 9/9, step: 494/600\n",
      "loss: 0.0153, lr: 0.0005, epoch: 9/9, step: 495/600\n",
      "loss: 0.0291, lr: 0.0005, epoch: 9/9, step: 496/600\n",
      "loss: 0.0325, lr: 0.0005, epoch: 9/9, step: 497/600\n",
      "loss: 0.3071, lr: 0.0005, epoch: 9/9, step: 498/600\n",
      "loss: 0.0131, lr: 0.0005, epoch: 9/9, step: 499/600\n",
      "loss: 0.1388, lr: 0.0005, epoch: 9/9, step: 500/600\n",
      "loss: 0.1733, lr: 0.0005, epoch: 9/9, step: 501/600\n",
      "loss: 0.9395, lr: 0.0005, epoch: 9/9, step: 502/600\n",
      "loss: 0.8545, lr: 0.0005, epoch: 9/9, step: 503/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 9/9, step: 504/600\n",
      "loss: 0.0212, lr: 0.0005, epoch: 9/9, step: 505/600\n",
      "loss: 0.282, lr: 0.0005, epoch: 9/9, step: 506/600\n",
      "loss: 0.3599, lr: 0.0005, epoch: 9/9, step: 507/600\n",
      "loss: 0.3701, lr: 0.0005, epoch: 9/9, step: 508/600\n",
      "loss: 0.2263, lr: 0.0005, epoch: 9/9, step: 509/600\n",
      "loss: 0.0211, lr: 0.0005, epoch: 9/9, step: 510/600\n",
      "loss: 0.0043, lr: 0.0005, epoch: 9/9, step: 511/600\n",
      "loss: 0.0785, lr: 0.0005, epoch: 9/9, step: 512/600\n",
      "loss: 0.0378, lr: 0.0005, epoch: 9/9, step: 513/600\n",
      "loss: 0.3586, lr: 0.0005, epoch: 9/9, step: 514/600\n",
      "loss: 0.0023, lr: 0.0005, epoch: 9/9, step: 515/600\n",
      "loss: 0.3269, lr: 0.0005, epoch: 9/9, step: 516/600\n",
      "loss: 0.0281, lr: 0.0005, epoch: 9/9, step: 517/600\n",
      "loss: 0.0151, lr: 0.0005, epoch: 9/9, step: 518/600\n",
      "loss: 0.0143, lr: 0.0005, epoch: 9/9, step: 519/600\n",
      "loss: 0.2815, lr: 0.0005, epoch: 9/9, step: 520/600\n",
      "loss: 0.0217, lr: 0.0005, epoch: 9/9, step: 521/600\n",
      "loss: 0.4905, lr: 0.0005, epoch: 9/9, step: 522/600\n",
      "loss: 0.1768, lr: 0.0005, epoch: 9/9, step: 523/600\n",
      "loss: 0.0143, lr: 0.0005, epoch: 9/9, step: 524/600\n",
      "loss: 0.0892, lr: 0.0005, epoch: 9/9, step: 525/600\n",
      "loss: 0.063, lr: 0.0005, epoch: 9/9, step: 526/600\n",
      "loss: 0.0124, lr: 0.0005, epoch: 9/9, step: 527/600\n",
      "loss: 0.2883, lr: 0.0005, epoch: 9/9, step: 528/600\n",
      "loss: 0.0686, lr: 0.0005, epoch: 9/9, step: 529/600\n",
      "loss: 0.1824, lr: 0.0005, epoch: 9/9, step: 530/600\n",
      "loss: 0.0108, lr: 0.0005, epoch: 9/9, step: 531/600\n",
      "loss: 0.0035, lr: 0.0005, epoch: 9/9, step: 532/600\n",
      "loss: 0.2454, lr: 0.0005, epoch: 9/9, step: 533/600\n",
      "loss: 0.0045, lr: 0.0005, epoch: 9/9, step: 534/600\n",
      "loss: 0.0442, lr: 0.0005, epoch: 9/9, step: 535/600\n",
      "loss: 0.3, lr: 0.0005, epoch: 9/9, step: 536/600\n",
      "loss: 0.1949, lr: 0.0005, epoch: 9/9, step: 537/600\n",
      "loss: 0.1715, lr: 0.0005, epoch: 9/9, step: 538/600\n",
      "loss: 0.0417, lr: 0.0005, epoch: 9/9, step: 539/600\n",
      "loss: 0.5576, lr: 0.0005, epoch: 9/9, step: 540/600\n",
      "loss: 0.0609, lr: 0.0005, epoch: 9/9, step: 541/600\n",
      "loss: 0.0061, lr: 0.0005, epoch: 9/9, step: 542/600\n",
      "loss: 0.312, lr: 0.0005, epoch: 9/9, step: 543/600\n",
      "loss: 0.3638, lr: 0.0005, epoch: 9/9, step: 544/600\n",
      "loss: 0.5142, lr: 0.0005, epoch: 9/9, step: 545/600\n",
      "loss: 0.3313, lr: 0.0005, epoch: 9/9, step: 546/600\n",
      "loss: 0.4082, lr: 0.0005, epoch: 9/9, step: 547/600\n",
      "loss: 0.23, lr: 0.0005, epoch: 9/9, step: 548/600\n",
      "loss: 0.4836, lr: 0.0005, epoch: 9/9, step: 549/600\n",
      "loss: 0.0439, lr: 0.0005, epoch: 9/9, step: 550/600\n",
      "loss: 0.016, lr: 0.0005, epoch: 9/9, step: 551/600\n",
      "loss: 0.0993, lr: 0.0005, epoch: 9/9, step: 552/600\n",
      "loss: 0.0106, lr: 0.0005, epoch: 9/9, step: 553/600\n",
      "loss: 0.437, lr: 0.0005, epoch: 9/9, step: 554/600\n",
      "loss: 0.4473, lr: 0.0005, epoch: 9/9, step: 555/600\n",
      "loss: 0.915, lr: 0.0005, epoch: 9/9, step: 556/600\n",
      "loss: 0.0041, lr: 0.0005, epoch: 9/9, step: 557/600\n",
      "loss: 0.0185, lr: 0.0005, epoch: 9/9, step: 558/600\n",
      "loss: 0.4695, lr: 0.0005, epoch: 9/9, step: 559/600\n",
      "loss: 0.182, lr: 0.0005, epoch: 9/9, step: 560/600\n",
      "loss: 0.0447, lr: 0.0005, epoch: 9/9, step: 561/600\n",
      "loss: 0.0175, lr: 0.0005, epoch: 9/9, step: 562/600\n",
      "loss: 0.1782, lr: 0.0005, epoch: 9/9, step: 563/600\n",
      "loss: 0.3406, lr: 0.0005, epoch: 9/9, step: 564/600\n",
      "loss: 0.0391, lr: 0.0005, epoch: 9/9, step: 565/600\n",
      "loss: 0.0152, lr: 0.0005, epoch: 9/9, step: 566/600\n",
      "loss: 0.0052, lr: 0.0005, epoch: 9/9, step: 567/600\n",
      "loss: 0.0955, lr: 0.0005, epoch: 9/9, step: 568/600\n",
      "loss: 0.4478, lr: 0.0005, epoch: 9/9, step: 569/600\n",
      "loss: 0.1829, lr: 0.0005, epoch: 9/9, step: 570/600\n",
      "loss: 0.0132, lr: 0.0005, epoch: 9/9, step: 571/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 9/9, step: 572/600\n",
      "loss: 0.0234, lr: 0.0005, epoch: 9/9, step: 573/600\n",
      "loss: 0.4214, lr: 0.0005, epoch: 9/9, step: 574/600\n",
      "loss: 0.212, lr: 0.0005, epoch: 9/9, step: 575/600\n",
      "loss: 0.0228, lr: 0.0005, epoch: 9/9, step: 576/600\n",
      "loss: 0.008, lr: 0.0005, epoch: 9/9, step: 577/600\n",
      "loss: 0.7769, lr: 0.0005, epoch: 9/9, step: 578/600\n",
      "loss: 0.0064, lr: 0.0005, epoch: 9/9, step: 579/600\n",
      "loss: 0.0787, lr: 0.0005, epoch: 9/9, step: 580/600\n",
      "loss: 0.1223, lr: 0.0005, epoch: 9/9, step: 581/600\n",
      "loss: 0.076, lr: 0.0005, epoch: 9/9, step: 582/600\n",
      "loss: 0.0267, lr: 0.0005, epoch: 9/9, step: 583/600\n",
      "loss: 0.2021, lr: 0.0005, epoch: 9/9, step: 584/600\n",
      "loss: 0.2173, lr: 0.0005, epoch: 9/9, step: 585/600\n",
      "loss: 0.0802, lr: 0.0005, epoch: 9/9, step: 586/600\n",
      "loss: 0.0148, lr: 0.0005, epoch: 9/9, step: 587/600\n",
      "loss: 0.1881, lr: 0.0005, epoch: 9/9, step: 588/600\n",
      "loss: 0.1371, lr: 0.0005, epoch: 9/9, step: 589/600\n",
      "loss: 0.0257, lr: 0.0005, epoch: 9/9, step: 590/600\n",
      "loss: 0.0734, lr: 0.0005, epoch: 9/9, step: 591/600\n",
      "loss: 0.1721, lr: 0.0005, epoch: 9/9, step: 592/600\n",
      "loss: 0.1771, lr: 0.0005, epoch: 9/9, step: 593/600\n",
      "loss: 0.0132, lr: 0.0005, epoch: 9/9, step: 594/600\n",
      "loss: 0.0421, lr: 0.0005, epoch: 9/9, step: 595/600\n",
      "loss: 0.0122, lr: 0.0005, epoch: 9/9, step: 596/600\n",
      "loss: 0.0101, lr: 0.0005, epoch: 9/9, step: 597/600\n",
      "loss: 0.135, lr: 0.0005, epoch: 9/9, step: 598/600\n",
      "loss: 0.2771, lr: 0.0005, epoch: 9/9, step: 599/600\n",
      "loss: 0.0685, lr: 0.0005, epoch: 9/9, step: 600/600\n",
      "***** Training Completed *****\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(text_encoder.get_input_embeddings().parameters(), lr=5e-4, eps=1e-7)\n",
    "\n",
    "# Training\n",
    "data_folder = f'../data/{property_name}'\n",
    "train_model(property_name, data_folder, optimizer, max_train_steps=2400)  # Ideal: 1000-2400 steps\n",
    "\n",
    "# Save final model\n",
    "save_model(f'saved_models/textual_inversion/{property_name}', f'{property_name}_final.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cc8010bf3f78e9c10d4febe712c77abe75f8df416c09ebdb6a9b39023fa5c08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
