{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler\n",
    "from itertools import chain\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, logging\n",
    "\n",
    "# Setup\n",
    "diffusion_model_id = 'runwayml/stable-diffusion-v1-5'\n",
    "text_encoder_model_id = 'openai/clip-vit-large-patch14'\n",
    "device = 'cuda'\n",
    "seed = 1024\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Textual inversion settings\n",
    "property_name = 'elden_ring'  # Name of property to learn\n",
    "property_type = 'style'  # Type of property to learn (object, style)\n",
    "placeholder_token = '<elden-ring>'  # Token that represents new property\n",
    "initializer_token = 'medieval'  # Initial embedding for new property\n",
    "\n",
    "# Hugging Face access token\n",
    "token = ''\n",
    "with open('hugging_face_token.txt', 'r') as secret:\n",
    "    token = secret.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model components\n",
    "\n",
    "# Text Encoder + Tokenizer\n",
    "tokenizer = CLIPTokenizer.from_pretrained(text_encoder_model_id)\n",
    "text_encoder = CLIPTextModel.from_pretrained(text_encoder_model_id, torch_dtype=torch.float16)\n",
    "text_encoder.to(device)\n",
    "\n",
    "# Variational Autoencoder\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    diffusion_model_id, subfolder='vae', torch_dtype=torch.float16,\n",
    "    revision='fp16', use_auth_token=token)\n",
    "vae.to(device)\n",
    "\n",
    "# U-Net Model\n",
    "u_net = UNet2DConditionModel.from_pretrained(\n",
    "    diffusion_model_id, subfolder='unet', torch_dtype=torch.float16,\n",
    "    revision='fp16', use_auth_token=token)\n",
    "u_net.to(device)\n",
    "\n",
    "# Noise Scheduler\n",
    "noise_scheduler = DDPMScheduler.from_config(diffusion_model_id, subfolder='scheduler', use_auth_token=token)\n",
    "\n",
    "# Freeze parameters for a model\n",
    "def freeze_params(params):\n",
    "    for param in params:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Freeze all pre-trained models except for token embeddings in the text encoder\n",
    "freeze_params(vae.parameters())\n",
    "freeze_params(u_net.parameters())\n",
    "encoder_params_to_freeze = itertools.chain(\n",
    "        text_encoder.text_model.encoder.parameters(),\n",
    "        text_encoder.text_model.final_layer_norm.parameters(),\n",
    "        text_encoder.text_model.embeddings.position_embedding.parameters(),\n",
    ")\n",
    "freeze_params(encoder_params_to_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer and text encoder\n",
    "\n",
    "# Add the placeholder token in tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(placeholder_token)\n",
    "\n",
    "# Convert the initializer token and placeholder token to ids\n",
    "token_ids = tokenizer.encode(initializer_token, add_special_tokens=False)\n",
    "initializer_token_id = token_ids[0]\n",
    "placeholder_token_id = tokenizer.convert_tokens_to_ids(placeholder_token)\n",
    "\n",
    "# Resize the token embeddings as we are adding new special tokens to the tokenizer\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Initialize the newly added placeholder token with the embeddings of the initializer token\n",
    "token_embeds = text_encoder.get_input_embeddings().weight.data\n",
    "token_embeds[placeholder_token_id] = token_embeds[initializer_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates\n",
    "\n",
    "# Object\n",
    "object_templates = [\n",
    "    'a photo of a {}',\n",
    "    'a rendering of a {}',\n",
    "    'a cropped photo of the {}',\n",
    "    'the photo of a {}',\n",
    "    'a photo of a clean {}',\n",
    "    'a photo of a dirty {}',\n",
    "    'a dark photo of the {}',\n",
    "    'a photo of my {}',\n",
    "    'a photo of the cool {}',\n",
    "    'a close-up photo of a {}',\n",
    "    'a bright photo of the {}',\n",
    "    'a cropped photo of a {}',\n",
    "    'a photo of the {}',\n",
    "    'a good photo of the {}',\n",
    "    'a photo of one {}',\n",
    "    'a close-up photo of the {}',\n",
    "    'a rendition of the {}',\n",
    "    'a photo of the clean {}',\n",
    "    'a rendition of a {}',\n",
    "    'a photo of a nice {}',\n",
    "    'a good photo of a {}',\n",
    "    'a photo of the nice {}',\n",
    "    'a photo of the small {}',\n",
    "    'a photo of the weird {}',\n",
    "    'a photo of the large {}',\n",
    "    'a photo of a cool {}',\n",
    "    'a photo of a small {}',\n",
    "]\n",
    "\n",
    "# Style\n",
    "style_templates = [\n",
    "    'a painting in the style of {}',\n",
    "    'a rendering in the style of {}',\n",
    "    'a cropped painting in the style of {}',\n",
    "    'the painting in the style of {}',\n",
    "    'a clean painting in the style of {}',\n",
    "    'a dirty painting in the style of {}',\n",
    "    'a dark painting in the style of {}',\n",
    "    'a picture in the style of {}',\n",
    "    'a cool painting in the style of {}',\n",
    "    'a close-up painting in the style of {}',\n",
    "    'a bright painting in the style of {}',\n",
    "    'a cropped painting in the style of {}',\n",
    "    'a good painting in the style of {}',\n",
    "    'a close-up painting in the style of {}',\n",
    "    'a rendition in the style of {}',\n",
    "    'a nice painting in the style of {}',\n",
    "    'a small painting in the style of {}',\n",
    "    'a weird painting in the style of {}',\n",
    "    'a large painting in the style of {}',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class TextualInversionDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root,\n",
    "        learnable_property,\n",
    "        placeholder_token,\n",
    "        repeats=10,  # 100\n",
    "        flip_p=0.5,\n",
    "    ):\n",
    "        self.data_root = data_root\n",
    "        self.learnable_property = learnable_property\n",
    "        self.placeholder_token = placeholder_token\n",
    "        self.flip_p = flip_p\n",
    "        self.flip_transform = RandomHorizontalFlip(p=self.flip_p)\n",
    "\n",
    "        # Data settings\n",
    "        self.image_paths = [os.path.join(self.data_root, file_path) for file_path in os.listdir(self.data_root)]\n",
    "        self.num_images = len(self.image_paths)\n",
    "        self._length = self.num_images * repeats\n",
    "        self.templates = object_templates if property_type == 'object' else style_templates\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Get and prepare image\n",
    "        image = Image.open(self.image_paths[i % self.num_images])\n",
    "        image = self.flip_transform(image)\n",
    "        image = np.array(image).astype(np.uint8)\n",
    "        image = (image / 127.5 - 1.0).astype(np.float16)\n",
    "\n",
    "        # Get text prompt\n",
    "        text = random.choice(self.templates).format(self.placeholder_token)\n",
    "\n",
    "        # Create example\n",
    "        example = {}\n",
    "        example['input_prompt'] = text\n",
    "        example['pixel_values'] = torch.from_numpy(image).permute(2, 0, 1).to(device)\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "# Encode input prompt\n",
    "def encode_prompt(prompt):\n",
    "    text_inputs = tokenizer(\n",
    "        prompt, padding='max_length', max_length=tokenizer.model_max_length,\n",
    "        truncation=True, return_tensors='pt')\n",
    "    text_embeddings = text_encoder(text_inputs.input_ids.to(device))[0]\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to a pytorch file\n",
    "def save_model(path_dir, filename):\n",
    "    if not os.path.isdir(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    learned_embeddings = text_encoder.get_input_embeddings().weight[placeholder_token_id]\n",
    "    torch.save({placeholder_token: learned_embeddings.detach().cpu()}, os.path.join(path_dir, filename))\n",
    "\n",
    "# Model training\n",
    "def train_model(property, data_root, optimizer, num_train_epochs=50, batch_size=1):\n",
    "    # Initialize dataset\n",
    "    train_dataset = TextualInversionDataset(data_root, property_type, placeholder_token)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    max_train_steps = num_train_epochs * len(train_dataloader)\n",
    "    lr_scheduler = LambdaLR(optimizer, lambda _: 1)\n",
    "\n",
    "    # Training loop\n",
    "    print('***** Running Training *****')\n",
    "    print(f'  Num. Examples = {len(train_dataset)}')\n",
    "    print(f'  Num. Epochs = {num_train_epochs}')\n",
    "    loss_queue = deque(maxlen=20)\n",
    "    for epoch in range(num_train_epochs):\n",
    "        # Save current model\n",
    "        if not (epoch % 10):\n",
    "            save_model(f'saved_models/textual_inversion/{property}', f'{property}_{epoch // 10}.pt')\n",
    "\n",
    "        # Train for another epoch\n",
    "        text_encoder.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Convert images to latent space\n",
    "            latents = vae.encode(batch['pixel_values']).latent_dist.sample()\n",
    "            latents *= 0.18215\n",
    "\n",
    "            # Sample noise that we'll add to the latents\n",
    "            noise = torch.randn(latents.shape, dtype=torch.float16).to(latents.device)\n",
    "            bsz = latents.shape[0]\n",
    "\n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device\n",
    "            ).long()\n",
    "\n",
    "            # Add noise to the latents according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "            # Get the text embedding for conditioning\n",
    "            encoder_hidden_states = encode_prompt(batch['input_prompt'])\n",
    "\n",
    "            # Predict the noise residual\n",
    "            noise_pred = u_net(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "\n",
    "            # Backwards pass\n",
    "            loss = F.mse_loss(noise_pred, noise, reduction='none').mean([1, 2, 3]).mean()\n",
    "            loss.backward()\n",
    "\n",
    "            # Zero out the gradients for all token embeddings except the placeholder token\n",
    "            grads = text_encoder.get_input_embeddings().weight.grad\n",
    "            index_grads_to_zero = torch.arange(len(tokenizer)) != placeholder_token_id\n",
    "            grads.data[index_grads_to_zero, :] = grads.data[index_grads_to_zero, :].fill_(0)\n",
    "\n",
    "            # Optimizer pass\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Print logs\n",
    "            current_loss = round(loss.detach().item(), 4)\n",
    "            loss_queue.append(current_loss)\n",
    "            recent_loss = round(sum(loss_queue) / len(loss_queue), 4)\n",
    "            print(f'loss: {current_loss}, last_20: {recent_loss}, lr: {lr_scheduler.get_last_lr()[0]}, '\n",
    "                  f'epoch: {epoch + 1}/{num_train_epochs}, step: {step + 1}/{len(train_dataloader)}')\n",
    "    print('***** Training Completed *****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running Training *****\n",
      "  Num. Examples = 80\n",
      "  Num. Epochs = 25\n",
      "loss: 0.3906, last_20: 0.3906, lr: 0.0001, epoch: 1/25, step: 1/80\n",
      "loss: 0.008, last_20: 0.1993, lr: 0.0001, epoch: 1/25, step: 2/80\n",
      "loss: 0.0396, last_20: 0.1461, lr: 0.0001, epoch: 1/25, step: 3/80\n",
      "loss: 0.0399, last_20: 0.1195, lr: 0.0001, epoch: 1/25, step: 4/80\n",
      "loss: 0.0319, last_20: 0.102, lr: 0.0001, epoch: 1/25, step: 5/80\n",
      "loss: 0.3074, last_20: 0.1362, lr: 0.0001, epoch: 1/25, step: 6/80\n",
      "loss: 0.0645, last_20: 0.126, lr: 0.0001, epoch: 1/25, step: 7/80\n",
      "loss: 0.2542, last_20: 0.142, lr: 0.0001, epoch: 1/25, step: 8/80\n",
      "loss: 0.0121, last_20: 0.1276, lr: 0.0001, epoch: 1/25, step: 9/80\n",
      "loss: 0.044, last_20: 0.1192, lr: 0.0001, epoch: 1/25, step: 10/80\n",
      "loss: 0.1405, last_20: 0.1212, lr: 0.0001, epoch: 1/25, step: 11/80\n",
      "loss: 0.0638, last_20: 0.1164, lr: 0.0001, epoch: 1/25, step: 12/80\n",
      "loss: 0.0366, last_20: 0.1102, lr: 0.0001, epoch: 1/25, step: 13/80\n",
      "loss: 0.4734, last_20: 0.1362, lr: 0.0001, epoch: 1/25, step: 14/80\n",
      "loss: 0.0288, last_20: 0.129, lr: 0.0001, epoch: 1/25, step: 15/80\n",
      "loss: 0.3145, last_20: 0.1406, lr: 0.0001, epoch: 1/25, step: 16/80\n",
      "loss: 0.105, last_20: 0.1385, lr: 0.0001, epoch: 1/25, step: 17/80\n",
      "loss: 0.0314, last_20: 0.1326, lr: 0.0001, epoch: 1/25, step: 18/80\n",
      "loss: 0.0061, last_20: 0.1259, lr: 0.0001, epoch: 1/25, step: 19/80\n",
      "loss: 0.2764, last_20: 0.1334, lr: 0.0001, epoch: 1/25, step: 20/80\n",
      "loss: 0.0087, last_20: 0.1143, lr: 0.0001, epoch: 1/25, step: 21/80\n",
      "loss: 0.3584, last_20: 0.1319, lr: 0.0001, epoch: 1/25, step: 22/80\n",
      "loss: 0.3765, last_20: 0.1487, lr: 0.0001, epoch: 1/25, step: 23/80\n",
      "loss: 0.07, last_20: 0.1502, lr: 0.0001, epoch: 1/25, step: 24/80\n",
      "loss: 0.4473, last_20: 0.171, lr: 0.0001, epoch: 1/25, step: 25/80\n",
      "loss: 0.2932, last_20: 0.1703, lr: 0.0001, epoch: 1/25, step: 26/80\n",
      "loss: 0.2905, last_20: 0.1816, lr: 0.0001, epoch: 1/25, step: 27/80\n",
      "loss: 0.1713, last_20: 0.1774, lr: 0.0001, epoch: 1/25, step: 28/80\n",
      "loss: 0.5054, last_20: 0.2021, lr: 0.0001, epoch: 1/25, step: 29/80\n",
      "loss: 0.0568, last_20: 0.2027, lr: 0.0001, epoch: 1/25, step: 30/80\n",
      "loss: 0.5962, last_20: 0.2255, lr: 0.0001, epoch: 1/25, step: 31/80\n",
      "loss: 0.157, last_20: 0.2302, lr: 0.0001, epoch: 1/25, step: 32/80\n",
      "loss: 0.0393, last_20: 0.2303, lr: 0.0001, epoch: 1/25, step: 33/80\n",
      "loss: 0.0688, last_20: 0.2101, lr: 0.0001, epoch: 1/25, step: 34/80\n",
      "loss: 0.0187, last_20: 0.2096, lr: 0.0001, epoch: 1/25, step: 35/80\n",
      "loss: 0.1821, last_20: 0.203, lr: 0.0001, epoch: 1/25, step: 36/80\n",
      "loss: 0.427, last_20: 0.2191, lr: 0.0001, epoch: 1/25, step: 37/80\n",
      "loss: 0.2172, last_20: 0.2283, lr: 0.0001, epoch: 1/25, step: 38/80\n",
      "loss: 0.0091, last_20: 0.2285, lr: 0.0001, epoch: 1/25, step: 39/80\n",
      "loss: 0.0324, last_20: 0.2163, lr: 0.0001, epoch: 1/25, step: 40/80\n",
      "loss: 0.1675, last_20: 0.2242, lr: 0.0001, epoch: 1/25, step: 41/80\n",
      "loss: 0.2103, last_20: 0.2168, lr: 0.0001, epoch: 1/25, step: 42/80\n",
      "loss: 0.3127, last_20: 0.2136, lr: 0.0001, epoch: 1/25, step: 43/80\n",
      "loss: 0.0166, last_20: 0.211, lr: 0.0001, epoch: 1/25, step: 44/80\n",
      "loss: 0.0094, last_20: 0.1891, lr: 0.0001, epoch: 1/25, step: 45/80\n",
      "loss: 0.0094, last_20: 0.1749, lr: 0.0001, epoch: 1/25, step: 46/80\n",
      "loss: 0.1176, last_20: 0.1662, lr: 0.0001, epoch: 1/25, step: 47/80\n",
      "loss: 0.0497, last_20: 0.1602, lr: 0.0001, epoch: 1/25, step: 48/80\n",
      "loss: 0.1381, last_20: 0.1418, lr: 0.0001, epoch: 1/25, step: 49/80\n",
      "loss: 0.0583, last_20: 0.1419, lr: 0.0001, epoch: 1/25, step: 50/80\n",
      "loss: 0.6743, last_20: 0.1458, lr: 0.0001, epoch: 1/25, step: 51/80\n",
      "loss: 0.3413, last_20: 0.155, lr: 0.0001, epoch: 1/25, step: 52/80\n",
      "loss: 0.0054, last_20: 0.1533, lr: 0.0001, epoch: 1/25, step: 53/80\n",
      "loss: 0.005, last_20: 0.1501, lr: 0.0001, epoch: 1/25, step: 54/80\n",
      "loss: 0.0646, last_20: 0.1524, lr: 0.0001, epoch: 1/25, step: 55/80\n",
      "loss: 0.0044, last_20: 0.1435, lr: 0.0001, epoch: 1/25, step: 56/80\n",
      "loss: 0.0147, last_20: 0.1229, lr: 0.0001, epoch: 1/25, step: 57/80\n",
      "loss: 0.0142, last_20: 0.1127, lr: 0.0001, epoch: 1/25, step: 58/80\n",
      "loss: 0.0029, last_20: 0.1124, lr: 0.0001, epoch: 1/25, step: 59/80\n",
      "loss: 0.0166, last_20: 0.1116, lr: 0.0001, epoch: 1/25, step: 60/80\n",
      "loss: 0.0352, last_20: 0.105, lr: 0.0001, epoch: 1/25, step: 61/80\n",
      "loss: 0.3435, last_20: 0.1117, lr: 0.0001, epoch: 1/25, step: 62/80\n",
      "loss: 0.6426, last_20: 0.1282, lr: 0.0001, epoch: 1/25, step: 63/80\n",
      "loss: 0.031, last_20: 0.1289, lr: 0.0001, epoch: 1/25, step: 64/80\n",
      "loss: 0.178, last_20: 0.1373, lr: 0.0001, epoch: 1/25, step: 65/80\n",
      "loss: 0.2228, last_20: 0.148, lr: 0.0001, epoch: 1/25, step: 66/80\n",
      "loss: 0.1792, last_20: 0.1511, lr: 0.0001, epoch: 1/25, step: 67/80\n",
      "loss: 0.3662, last_20: 0.1669, lr: 0.0001, epoch: 1/25, step: 68/80\n",
      "loss: 0.1189, last_20: 0.166, lr: 0.0001, epoch: 1/25, step: 69/80\n",
      "loss: 0.4958, last_20: 0.1878, lr: 0.0001, epoch: 1/25, step: 70/80\n",
      "loss: 0.0134, last_20: 0.1548, lr: 0.0001, epoch: 1/25, step: 71/80\n",
      "loss: 0.3962, last_20: 0.1575, lr: 0.0001, epoch: 1/25, step: 72/80\n",
      "loss: 0.604, last_20: 0.1875, lr: 0.0001, epoch: 1/25, step: 73/80\n",
      "loss: 0.2561, last_20: 0.2, lr: 0.0001, epoch: 1/25, step: 74/80\n",
      "loss: 0.0051, last_20: 0.197, lr: 0.0001, epoch: 1/25, step: 75/80\n",
      "loss: 0.3608, last_20: 0.2149, lr: 0.0001, epoch: 1/25, step: 76/80\n",
      "loss: 0.02, last_20: 0.2151, lr: 0.0001, epoch: 1/25, step: 77/80\n",
      "loss: 0.2335, last_20: 0.2261, lr: 0.0001, epoch: 1/25, step: 78/80\n",
      "loss: 0.0029, last_20: 0.2261, lr: 0.0001, epoch: 1/25, step: 79/80\n",
      "loss: 0.3562, last_20: 0.2431, lr: 0.0001, epoch: 1/25, step: 80/80\n",
      "loss: 0.1975, last_20: 0.2512, lr: 0.0001, epoch: 2/25, step: 1/80\n",
      "loss: 0.0919, last_20: 0.2386, lr: 0.0001, epoch: 2/25, step: 2/80\n",
      "loss: 0.1181, last_20: 0.2124, lr: 0.0001, epoch: 2/25, step: 3/80\n",
      "loss: 0.0054, last_20: 0.2111, lr: 0.0001, epoch: 2/25, step: 4/80\n",
      "loss: 0.1818, last_20: 0.2113, lr: 0.0001, epoch: 2/25, step: 5/80\n",
      "loss: 0.0678, last_20: 0.2035, lr: 0.0001, epoch: 2/25, step: 6/80\n",
      "loss: 0.0285, last_20: 0.196, lr: 0.0001, epoch: 2/25, step: 7/80\n",
      "loss: 0.0223, last_20: 0.1788, lr: 0.0001, epoch: 2/25, step: 8/80\n",
      "loss: 0.1038, last_20: 0.1781, lr: 0.0001, epoch: 2/25, step: 9/80\n",
      "loss: 0.7783, last_20: 0.1922, lr: 0.0001, epoch: 2/25, step: 10/80\n",
      "loss: 0.0089, last_20: 0.192, lr: 0.0001, epoch: 2/25, step: 11/80\n",
      "loss: 0.3975, last_20: 0.192, lr: 0.0001, epoch: 2/25, step: 12/80\n",
      "loss: 0.0299, last_20: 0.1633, lr: 0.0001, epoch: 2/25, step: 13/80\n",
      "loss: 0.0442, last_20: 0.1527, lr: 0.0001, epoch: 2/25, step: 14/80\n",
      "loss: 0.2311, last_20: 0.164, lr: 0.0001, epoch: 2/25, step: 15/80\n",
      "loss: 0.1678, last_20: 0.1544, lr: 0.0001, epoch: 2/25, step: 16/80\n",
      "loss: 0.2532, last_20: 0.166, lr: 0.0001, epoch: 2/25, step: 17/80\n",
      "loss: 0.0028, last_20: 0.1545, lr: 0.0001, epoch: 2/25, step: 18/80\n",
      "loss: 0.119, last_20: 0.1603, lr: 0.0001, epoch: 2/25, step: 19/80\n",
      "loss: 0.1674, last_20: 0.1509, lr: 0.0001, epoch: 2/25, step: 20/80\n",
      "loss: 0.0607, last_20: 0.144, lr: 0.0001, epoch: 2/25, step: 21/80\n",
      "loss: 0.0093, last_20: 0.1399, lr: 0.0001, epoch: 2/25, step: 22/80\n",
      "loss: 0.2052, last_20: 0.1442, lr: 0.0001, epoch: 2/25, step: 23/80\n",
      "loss: 0.023, last_20: 0.1451, lr: 0.0001, epoch: 2/25, step: 24/80\n",
      "loss: 0.0612, last_20: 0.1391, lr: 0.0001, epoch: 2/25, step: 25/80\n",
      "loss: 0.0344, last_20: 0.1374, lr: 0.0001, epoch: 2/25, step: 26/80\n",
      "loss: 0.0327, last_20: 0.1376, lr: 0.0001, epoch: 2/25, step: 27/80\n",
      "loss: 0.0626, last_20: 0.1397, lr: 0.0001, epoch: 2/25, step: 28/80\n",
      "loss: 0.0041, last_20: 0.1347, lr: 0.0001, epoch: 2/25, step: 29/80\n",
      "loss: 0.0024, last_20: 0.0959, lr: 0.0001, epoch: 2/25, step: 30/80\n",
      "loss: 0.4465, last_20: 0.1177, lr: 0.0001, epoch: 2/25, step: 31/80\n",
      "loss: 0.4634, last_20: 0.121, lr: 0.0001, epoch: 2/25, step: 32/80\n",
      "loss: 0.0229, last_20: 0.1207, lr: 0.0001, epoch: 2/25, step: 33/80\n",
      "loss: 0.005, last_20: 0.1187, lr: 0.0001, epoch: 2/25, step: 34/80\n",
      "loss: 0.396, last_20: 0.127, lr: 0.0001, epoch: 2/25, step: 35/80\n",
      "loss: 0.0076, last_20: 0.119, lr: 0.0001, epoch: 2/25, step: 36/80\n",
      "loss: 0.1604, last_20: 0.1143, lr: 0.0001, epoch: 2/25, step: 37/80\n",
      "loss: 0.0395, last_20: 0.1162, lr: 0.0001, epoch: 2/25, step: 38/80\n",
      "loss: 0.0493, last_20: 0.1127, lr: 0.0001, epoch: 2/25, step: 39/80\n",
      "loss: 0.0425, last_20: 0.1064, lr: 0.0001, epoch: 2/25, step: 40/80\n",
      "loss: 0.3599, last_20: 0.1214, lr: 0.0001, epoch: 2/25, step: 41/80\n",
      "loss: 0.0161, last_20: 0.1217, lr: 0.0001, epoch: 2/25, step: 42/80\n",
      "loss: 0.0118, last_20: 0.1121, lr: 0.0001, epoch: 2/25, step: 43/80\n",
      "loss: 0.0159, last_20: 0.1117, lr: 0.0001, epoch: 2/25, step: 44/80\n",
      "loss: 0.0707, last_20: 0.1122, lr: 0.0001, epoch: 2/25, step: 45/80\n",
      "loss: 0.0058, last_20: 0.1108, lr: 0.0001, epoch: 2/25, step: 46/80\n",
      "loss: 0.5527, last_20: 0.1368, lr: 0.0001, epoch: 2/25, step: 47/80\n",
      "loss: 0.0042, last_20: 0.1338, lr: 0.0001, epoch: 2/25, step: 48/80\n",
      "loss: 0.3694, last_20: 0.1521, lr: 0.0001, epoch: 2/25, step: 49/80\n",
      "loss: 0.2681, last_20: 0.1654, lr: 0.0001, epoch: 2/25, step: 50/80\n",
      "loss: 0.3276, last_20: 0.1594, lr: 0.0001, epoch: 2/25, step: 51/80\n",
      "loss: 0.009, last_20: 0.1367, lr: 0.0001, epoch: 2/25, step: 52/80\n",
      "loss: 0.1609, last_20: 0.1436, lr: 0.0001, epoch: 2/25, step: 53/80\n",
      "loss: 0.006, last_20: 0.1437, lr: 0.0001, epoch: 2/25, step: 54/80\n",
      "loss: 0.4272, last_20: 0.1452, lr: 0.0001, epoch: 2/25, step: 55/80\n",
      "loss: 0.0176, last_20: 0.1457, lr: 0.0001, epoch: 2/25, step: 56/80\n",
      "loss: 0.0038, last_20: 0.1379, lr: 0.0001, epoch: 2/25, step: 57/80\n",
      "loss: 0.5293, last_20: 0.1624, lr: 0.0001, epoch: 2/25, step: 58/80\n",
      "loss: 0.086, last_20: 0.1642, lr: 0.0001, epoch: 2/25, step: 59/80\n",
      "loss: 0.2158, last_20: 0.1729, lr: 0.0001, epoch: 2/25, step: 60/80\n",
      "loss: 0.036, last_20: 0.1567, lr: 0.0001, epoch: 2/25, step: 61/80\n",
      "loss: 0.0698, last_20: 0.1594, lr: 0.0001, epoch: 2/25, step: 62/80\n",
      "loss: 0.0025, last_20: 0.1589, lr: 0.0001, epoch: 2/25, step: 63/80\n",
      "loss: 0.0305, last_20: 0.1596, lr: 0.0001, epoch: 2/25, step: 64/80\n",
      "loss: 0.0733, last_20: 0.1598, lr: 0.0001, epoch: 2/25, step: 65/80\n",
      "loss: 0.0133, last_20: 0.1601, lr: 0.0001, epoch: 2/25, step: 66/80\n",
      "loss: 0.02, last_20: 0.1335, lr: 0.0001, epoch: 2/25, step: 67/80\n",
      "loss: 0.0314, last_20: 0.1349, lr: 0.0001, epoch: 2/25, step: 68/80\n",
      "loss: 0.132, last_20: 0.123, lr: 0.0001, epoch: 2/25, step: 69/80\n",
      "loss: 0.0234, last_20: 0.1108, lr: 0.0001, epoch: 2/25, step: 70/80\n",
      "loss: 0.076, last_20: 0.0982, lr: 0.0001, epoch: 2/25, step: 71/80\n",
      "loss: 0.2012, last_20: 0.1078, lr: 0.0001, epoch: 2/25, step: 72/80\n",
      "loss: 0.6758, last_20: 0.1335, lr: 0.0001, epoch: 2/25, step: 73/80\n",
      "loss: 0.2681, last_20: 0.1467, lr: 0.0001, epoch: 2/25, step: 74/80\n",
      "loss: 0.0569, last_20: 0.1281, lr: 0.0001, epoch: 2/25, step: 75/80\n",
      "loss: 0.0099, last_20: 0.1278, lr: 0.0001, epoch: 2/25, step: 76/80\n",
      "loss: 0.0707, last_20: 0.1311, lr: 0.0001, epoch: 2/25, step: 77/80\n",
      "loss: 0.1595, last_20: 0.1126, lr: 0.0001, epoch: 2/25, step: 78/80\n",
      "loss: 0.0172, last_20: 0.1092, lr: 0.0001, epoch: 2/25, step: 79/80\n",
      "loss: 0.2294, last_20: 0.1098, lr: 0.0001, epoch: 2/25, step: 80/80\n",
      "loss: 0.4468, last_20: 0.1304, lr: 0.0001, epoch: 3/25, step: 1/80\n",
      "loss: 0.0123, last_20: 0.1275, lr: 0.0001, epoch: 3/25, step: 2/80\n",
      "loss: 0.2839, last_20: 0.1416, lr: 0.0001, epoch: 3/25, step: 3/80\n",
      "loss: 0.0372, last_20: 0.1419, lr: 0.0001, epoch: 3/25, step: 4/80\n",
      "loss: 0.2076, last_20: 0.1486, lr: 0.0001, epoch: 3/25, step: 5/80\n",
      "loss: 0.0156, last_20: 0.1487, lr: 0.0001, epoch: 3/25, step: 6/80\n",
      "loss: 0.1151, last_20: 0.1535, lr: 0.0001, epoch: 3/25, step: 7/80\n",
      "loss: 0.3845, last_20: 0.1712, lr: 0.0001, epoch: 3/25, step: 8/80\n",
      "loss: 0.4624, last_20: 0.1877, lr: 0.0001, epoch: 3/25, step: 9/80\n",
      "loss: 0.0033, last_20: 0.1867, lr: 0.0001, epoch: 3/25, step: 10/80\n",
      "loss: 0.0138, last_20: 0.1836, lr: 0.0001, epoch: 3/25, step: 11/80\n",
      "loss: 0.0162, last_20: 0.1743, lr: 0.0001, epoch: 3/25, step: 12/80\n",
      "loss: 0.6377, last_20: 0.1724, lr: 0.0001, epoch: 3/25, step: 13/80\n",
      "loss: 0.4312, last_20: 0.1806, lr: 0.0001, epoch: 3/25, step: 14/80\n",
      "loss: 0.0239, last_20: 0.1789, lr: 0.0001, epoch: 3/25, step: 15/80\n",
      "loss: 0.4951, last_20: 0.2032, lr: 0.0001, epoch: 3/25, step: 16/80\n",
      "loss: 0.0122, last_20: 0.2002, lr: 0.0001, epoch: 3/25, step: 17/80\n",
      "loss: 0.3513, last_20: 0.2098, lr: 0.0001, epoch: 3/25, step: 18/80\n",
      "loss: 0.1521, last_20: 0.2166, lr: 0.0001, epoch: 3/25, step: 19/80\n",
      "loss: 0.4802, last_20: 0.2291, lr: 0.0001, epoch: 3/25, step: 20/80\n",
      "loss: 0.1757, last_20: 0.2156, lr: 0.0001, epoch: 3/25, step: 21/80\n",
      "loss: 0.0803, last_20: 0.219, lr: 0.0001, epoch: 3/25, step: 22/80\n",
      "loss: 0.4697, last_20: 0.2283, lr: 0.0001, epoch: 3/25, step: 23/80\n",
      "loss: 0.1231, last_20: 0.2326, lr: 0.0001, epoch: 3/25, step: 24/80\n",
      "loss: 0.003, last_20: 0.2223, lr: 0.0001, epoch: 3/25, step: 25/80\n",
      "loss: 0.1794, last_20: 0.2305, lr: 0.0001, epoch: 3/25, step: 26/80\n",
      "loss: 0.0652, last_20: 0.228, lr: 0.0001, epoch: 3/25, step: 27/80\n",
      "loss: 0.0135, last_20: 0.2095, lr: 0.0001, epoch: 3/25, step: 28/80\n",
      "loss: 0.0878, last_20: 0.1907, lr: 0.0001, epoch: 3/25, step: 29/80\n",
      "loss: 0.0026, last_20: 0.1907, lr: 0.0001, epoch: 3/25, step: 30/80\n",
      "loss: 0.0224, last_20: 0.1911, lr: 0.0001, epoch: 3/25, step: 31/80\n",
      "loss: 0.0126, last_20: 0.191, lr: 0.0001, epoch: 3/25, step: 32/80\n",
      "loss: 0.0462, last_20: 0.1614, lr: 0.0001, epoch: 3/25, step: 33/80\n",
      "loss: 0.0979, last_20: 0.1447, lr: 0.0001, epoch: 3/25, step: 34/80\n",
      "loss: 0.7197, last_20: 0.1795, lr: 0.0001, epoch: 3/25, step: 35/80\n",
      "loss: 0.2461, last_20: 0.1671, lr: 0.0001, epoch: 3/25, step: 36/80\n",
      "loss: 0.1129, last_20: 0.1721, lr: 0.0001, epoch: 3/25, step: 37/80\n",
      "loss: 0.6748, last_20: 0.1883, lr: 0.0001, epoch: 3/25, step: 38/80\n",
      "loss: 0.0124, last_20: 0.1813, lr: 0.0001, epoch: 3/25, step: 39/80\n",
      "loss: 0.2386, last_20: 0.1692, lr: 0.0001, epoch: 3/25, step: 40/80\n",
      "loss: 0.0268, last_20: 0.1618, lr: 0.0001, epoch: 3/25, step: 41/80\n",
      "loss: 0.4231, last_20: 0.1789, lr: 0.0001, epoch: 3/25, step: 42/80\n",
      "loss: 0.0097, last_20: 0.1559, lr: 0.0001, epoch: 3/25, step: 43/80\n",
      "loss: 0.0193, last_20: 0.1507, lr: 0.0001, epoch: 3/25, step: 44/80\n",
      "loss: 0.0026, last_20: 0.1507, lr: 0.0001, epoch: 3/25, step: 45/80\n",
      "loss: 0.3752, last_20: 0.1605, lr: 0.0001, epoch: 3/25, step: 46/80\n",
      "loss: 0.8735, last_20: 0.2009, lr: 0.0001, epoch: 3/25, step: 47/80\n",
      "loss: 0.035, last_20: 0.202, lr: 0.0001, epoch: 3/25, step: 48/80\n",
      "loss: 0.3054, last_20: 0.2128, lr: 0.0001, epoch: 3/25, step: 49/80\n",
      "loss: 0.2559, last_20: 0.2255, lr: 0.0001, epoch: 3/25, step: 50/80\n",
      "loss: 0.0444, last_20: 0.2266, lr: 0.0001, epoch: 3/25, step: 51/80\n",
      "loss: 0.0043, last_20: 0.2262, lr: 0.0001, epoch: 3/25, step: 52/80\n",
      "loss: 0.0333, last_20: 0.2255, lr: 0.0001, epoch: 3/25, step: 53/80\n",
      "loss: 0.5796, last_20: 0.2496, lr: 0.0001, epoch: 3/25, step: 54/80\n",
      "loss: 0.0062, last_20: 0.214, lr: 0.0001, epoch: 3/25, step: 55/80\n",
      "loss: 0.1113, last_20: 0.2072, lr: 0.0001, epoch: 3/25, step: 56/80\n",
      "loss: 0.0691, last_20: 0.205, lr: 0.0001, epoch: 3/25, step: 57/80\n",
      "loss: 0.0211, last_20: 0.1723, lr: 0.0001, epoch: 3/25, step: 58/80\n",
      "loss: 0.7568, last_20: 0.2096, lr: 0.0001, epoch: 3/25, step: 59/80\n",
      "loss: 0.0183, last_20: 0.1985, lr: 0.0001, epoch: 3/25, step: 60/80\n",
      "loss: 0.1562, last_20: 0.205, lr: 0.0001, epoch: 3/25, step: 61/80\n",
      "loss: 0.0365, last_20: 0.1857, lr: 0.0001, epoch: 3/25, step: 62/80\n",
      "loss: 0.0415, last_20: 0.1873, lr: 0.0001, epoch: 3/25, step: 63/80\n",
      "loss: 0.0385, last_20: 0.1882, lr: 0.0001, epoch: 3/25, step: 64/80\n",
      "loss: 0.4072, last_20: 0.2085, lr: 0.0001, epoch: 3/25, step: 65/80\n",
      "loss: 0.0037, last_20: 0.1899, lr: 0.0001, epoch: 3/25, step: 66/80\n",
      "loss: 0.3984, last_20: 0.1661, lr: 0.0001, epoch: 3/25, step: 67/80\n",
      "loss: 0.0513, last_20: 0.1669, lr: 0.0001, epoch: 3/25, step: 68/80\n",
      "loss: 0.0964, last_20: 0.1565, lr: 0.0001, epoch: 3/25, step: 69/80\n",
      "loss: 0.0067, last_20: 0.144, lr: 0.0001, epoch: 3/25, step: 70/80\n",
      "loss: 0.1167, last_20: 0.1477, lr: 0.0001, epoch: 3/25, step: 71/80\n",
      "loss: 0.0396, last_20: 0.1494, lr: 0.0001, epoch: 3/25, step: 72/80\n",
      "loss: 0.0173, last_20: 0.1486, lr: 0.0001, epoch: 3/25, step: 73/80\n",
      "loss: 0.0045, last_20: 0.1199, lr: 0.0001, epoch: 3/25, step: 74/80\n",
      "loss: 0.1105, last_20: 0.1251, lr: 0.0001, epoch: 3/25, step: 75/80\n",
      "loss: 0.0138, last_20: 0.1202, lr: 0.0001, epoch: 3/25, step: 76/80\n",
      "loss: 0.0134, last_20: 0.1174, lr: 0.0001, epoch: 3/25, step: 77/80\n",
      "loss: 0.4187, last_20: 0.1373, lr: 0.0001, epoch: 3/25, step: 78/80\n",
      "loss: 0.0269, last_20: 0.1008, lr: 0.0001, epoch: 3/25, step: 79/80\n",
      "loss: 0.1025, last_20: 0.105, lr: 0.0001, epoch: 3/25, step: 80/80\n",
      "loss: 0.0043, last_20: 0.0974, lr: 0.0001, epoch: 4/25, step: 1/80\n",
      "loss: 0.5952, last_20: 0.1254, lr: 0.0001, epoch: 4/25, step: 2/80\n",
      "loss: 0.4714, last_20: 0.1469, lr: 0.0001, epoch: 4/25, step: 3/80\n",
      "loss: 0.0606, last_20: 0.148, lr: 0.0001, epoch: 4/25, step: 4/80\n",
      "loss: 0.3218, last_20: 0.1437, lr: 0.0001, epoch: 4/25, step: 5/80\n",
      "loss: 0.0781, last_20: 0.1474, lr: 0.0001, epoch: 4/25, step: 6/80\n",
      "loss: 0.1556, last_20: 0.1353, lr: 0.0001, epoch: 4/25, step: 7/80\n",
      "loss: 0.0926, last_20: 0.1373, lr: 0.0001, epoch: 4/25, step: 8/80\n",
      "loss: 0.3398, last_20: 0.1495, lr: 0.0001, epoch: 4/25, step: 9/80\n",
      "loss: 0.0317, last_20: 0.1507, lr: 0.0001, epoch: 4/25, step: 10/80\n",
      "loss: 0.3914, last_20: 0.1645, lr: 0.0001, epoch: 4/25, step: 11/80\n",
      "loss: 0.0186, last_20: 0.1634, lr: 0.0001, epoch: 4/25, step: 12/80\n",
      "loss: 0.624, last_20: 0.1938, lr: 0.0001, epoch: 4/25, step: 13/80\n",
      "loss: 0.0021, last_20: 0.1937, lr: 0.0001, epoch: 4/25, step: 14/80\n",
      "loss: 0.3186, last_20: 0.2041, lr: 0.0001, epoch: 4/25, step: 15/80\n",
      "loss: 0.071, last_20: 0.2069, lr: 0.0001, epoch: 4/25, step: 16/80\n",
      "loss: 0.0686, last_20: 0.2097, lr: 0.0001, epoch: 4/25, step: 17/80\n",
      "loss: 0.1395, last_20: 0.1957, lr: 0.0001, epoch: 4/25, step: 18/80\n",
      "loss: 0.0576, last_20: 0.1973, lr: 0.0001, epoch: 4/25, step: 19/80\n",
      "loss: 0.2158, last_20: 0.2029, lr: 0.0001, epoch: 4/25, step: 20/80\n",
      "loss: 0.0792, last_20: 0.2067, lr: 0.0001, epoch: 4/25, step: 21/80\n",
      "loss: 0.003, last_20: 0.1771, lr: 0.0001, epoch: 4/25, step: 22/80\n",
      "loss: 0.0288, last_20: 0.1549, lr: 0.0001, epoch: 4/25, step: 23/80\n",
      "loss: 0.1707, last_20: 0.1604, lr: 0.0001, epoch: 4/25, step: 24/80\n",
      "loss: 0.203, last_20: 0.1545, lr: 0.0001, epoch: 4/25, step: 25/80\n",
      "loss: 0.2751, last_20: 0.1643, lr: 0.0001, epoch: 4/25, step: 26/80\n",
      "loss: 0.1039, last_20: 0.1618, lr: 0.0001, epoch: 4/25, step: 27/80\n",
      "loss: 0.2876, last_20: 0.1715, lr: 0.0001, epoch: 4/25, step: 28/80\n",
      "loss: 0.0107, last_20: 0.155, lr: 0.0001, epoch: 4/25, step: 29/80\n",
      "loss: 0.5708, last_20: 0.182, lr: 0.0001, epoch: 4/25, step: 30/80\n",
      "loss: 0.0384, last_20: 0.1643, lr: 0.0001, epoch: 4/25, step: 31/80\n",
      "loss: 0.0226, last_20: 0.1646, lr: 0.0001, epoch: 4/25, step: 32/80\n",
      "loss: 0.0264, last_20: 0.1347, lr: 0.0001, epoch: 4/25, step: 33/80\n",
      "loss: 0.0724, last_20: 0.1382, lr: 0.0001, epoch: 4/25, step: 34/80\n",
      "loss: 0.0082, last_20: 0.1227, lr: 0.0001, epoch: 4/25, step: 35/80\n",
      "loss: 0.7764, last_20: 0.1579, lr: 0.0001, epoch: 4/25, step: 36/80\n",
      "loss: 0.2605, last_20: 0.1675, lr: 0.0001, epoch: 4/25, step: 37/80\n",
      "loss: 0.5303, last_20: 0.1871, lr: 0.0001, epoch: 4/25, step: 38/80\n",
      "loss: 0.0102, last_20: 0.1847, lr: 0.0001, epoch: 4/25, step: 39/80\n",
      "loss: 0.038, last_20: 0.1758, lr: 0.0001, epoch: 4/25, step: 40/80\n",
      "loss: 0.2749, last_20: 0.1856, lr: 0.0001, epoch: 4/25, step: 41/80\n",
      "loss: 0.0671, last_20: 0.1888, lr: 0.0001, epoch: 4/25, step: 42/80\n",
      "loss: 0.3411, last_20: 0.2044, lr: 0.0001, epoch: 4/25, step: 43/80\n",
      "loss: 0.3142, last_20: 0.2116, lr: 0.0001, epoch: 4/25, step: 44/80\n",
      "loss: 0.0384, last_20: 0.2034, lr: 0.0001, epoch: 4/25, step: 45/80\n",
      "loss: 0.16, last_20: 0.1976, lr: 0.0001, epoch: 4/25, step: 46/80\n",
      "loss: 0.6235, last_20: 0.2236, lr: 0.0001, epoch: 4/25, step: 47/80\n",
      "loss: 0.0058, last_20: 0.2095, lr: 0.0001, epoch: 4/25, step: 48/80\n",
      "loss: 0.0157, last_20: 0.2097, lr: 0.0001, epoch: 4/25, step: 49/80\n",
      "loss: 0.4624, last_20: 0.2043, lr: 0.0001, epoch: 4/25, step: 50/80\n",
      "loss: 0.3787, last_20: 0.2213, lr: 0.0001, epoch: 4/25, step: 51/80\n",
      "loss: 0.2402, last_20: 0.2322, lr: 0.0001, epoch: 4/25, step: 52/80\n",
      "loss: 0.2341, last_20: 0.2426, lr: 0.0001, epoch: 4/25, step: 53/80\n",
      "loss: 0.029, last_20: 0.2404, lr: 0.0001, epoch: 4/25, step: 54/80\n",
      "loss: 0.0853, last_20: 0.2443, lr: 0.0001, epoch: 4/25, step: 55/80\n",
      "loss: 0.0044, last_20: 0.2057, lr: 0.0001, epoch: 4/25, step: 56/80\n",
      "loss: 0.0153, last_20: 0.1934, lr: 0.0001, epoch: 4/25, step: 57/80\n",
      "loss: 0.017, last_20: 0.1678, lr: 0.0001, epoch: 4/25, step: 58/80\n",
      "loss: 0.2627, last_20: 0.1804, lr: 0.0001, epoch: 4/25, step: 59/80\n",
      "loss: 0.3081, last_20: 0.1939, lr: 0.0001, epoch: 4/25, step: 60/80\n",
      "loss: 0.6201, last_20: 0.2112, lr: 0.0001, epoch: 4/25, step: 61/80\n",
      "loss: 0.2184, last_20: 0.2187, lr: 0.0001, epoch: 4/25, step: 62/80\n",
      "loss: 0.0209, last_20: 0.2027, lr: 0.0001, epoch: 4/25, step: 63/80\n",
      "loss: 0.5845, last_20: 0.2162, lr: 0.0001, epoch: 4/25, step: 64/80\n",
      "loss: 0.6841, last_20: 0.2485, lr: 0.0001, epoch: 4/25, step: 65/80\n",
      "loss: 0.3171, last_20: 0.2564, lr: 0.0001, epoch: 4/25, step: 66/80\n",
      "loss: 0.0818, last_20: 0.2293, lr: 0.0001, epoch: 4/25, step: 67/80\n",
      "loss: 0.4683, last_20: 0.2524, lr: 0.0001, epoch: 4/25, step: 68/80\n",
      "loss: 0.0789, last_20: 0.2556, lr: 0.0001, epoch: 4/25, step: 69/80\n",
      "loss: 0.0131, last_20: 0.2331, lr: 0.0001, epoch: 4/25, step: 70/80\n",
      "loss: 0.0042, last_20: 0.2144, lr: 0.0001, epoch: 4/25, step: 71/80\n",
      "loss: 0.1251, last_20: 0.2086, lr: 0.0001, epoch: 4/25, step: 72/80\n",
      "loss: 0.006, last_20: 0.1972, lr: 0.0001, epoch: 4/25, step: 73/80\n",
      "loss: 0.0692, last_20: 0.1992, lr: 0.0001, epoch: 4/25, step: 74/80\n",
      "loss: 0.4231, last_20: 0.2161, lr: 0.0001, epoch: 4/25, step: 75/80\n",
      "loss: 0.1497, last_20: 0.2234, lr: 0.0001, epoch: 4/25, step: 76/80\n",
      "loss: 0.6318, last_20: 0.2542, lr: 0.0001, epoch: 4/25, step: 77/80\n",
      "loss: 0.0485, last_20: 0.2558, lr: 0.0001, epoch: 4/25, step: 78/80\n",
      "loss: 0.5967, last_20: 0.2725, lr: 0.0001, epoch: 4/25, step: 79/80\n",
      "loss: 0.0704, last_20: 0.2606, lr: 0.0001, epoch: 4/25, step: 80/80\n",
      "loss: 0.207, last_20: 0.2399, lr: 0.0001, epoch: 5/25, step: 1/80\n",
      "loss: 0.6187, last_20: 0.26, lr: 0.0001, epoch: 5/25, step: 2/80\n",
      "loss: 0.3013, last_20: 0.274, lr: 0.0001, epoch: 5/25, step: 3/80\n",
      "loss: 0.1182, last_20: 0.2507, lr: 0.0001, epoch: 5/25, step: 4/80\n",
      "loss: 0.0031, last_20: 0.2166, lr: 0.0001, epoch: 5/25, step: 5/80\n",
      "loss: 0.0402, last_20: 0.2028, lr: 0.0001, epoch: 5/25, step: 6/80\n",
      "loss: 0.0064, last_20: 0.199, lr: 0.0001, epoch: 5/25, step: 7/80\n",
      "loss: 0.2952, last_20: 0.1903, lr: 0.0001, epoch: 5/25, step: 8/80\n",
      "loss: 0.0723, last_20: 0.19, lr: 0.0001, epoch: 5/25, step: 9/80\n",
      "loss: 0.5449, last_20: 0.2166, lr: 0.0001, epoch: 5/25, step: 10/80\n",
      "loss: 0.0645, last_20: 0.2196, lr: 0.0001, epoch: 5/25, step: 11/80\n",
      "loss: 0.3716, last_20: 0.2319, lr: 0.0001, epoch: 5/25, step: 12/80\n",
      "loss: 0.0067, last_20: 0.232, lr: 0.0001, epoch: 5/25, step: 13/80\n",
      "loss: 0.1532, last_20: 0.2362, lr: 0.0001, epoch: 5/25, step: 14/80\n",
      "loss: 0.4307, last_20: 0.2366, lr: 0.0001, epoch: 5/25, step: 15/80\n",
      "loss: 0.4407, last_20: 0.2511, lr: 0.0001, epoch: 5/25, step: 16/80\n",
      "loss: 0.0962, last_20: 0.2243, lr: 0.0001, epoch: 5/25, step: 17/80\n",
      "loss: 0.4055, last_20: 0.2422, lr: 0.0001, epoch: 5/25, step: 18/80\n",
      "loss: 0.0065, last_20: 0.2127, lr: 0.0001, epoch: 5/25, step: 19/80\n",
      "loss: 0.0154, last_20: 0.2099, lr: 0.0001, epoch: 5/25, step: 20/80\n",
      "loss: 0.0024, last_20: 0.1997, lr: 0.0001, epoch: 5/25, step: 21/80\n",
      "loss: 0.5151, last_20: 0.1945, lr: 0.0001, epoch: 5/25, step: 22/80\n",
      "loss: 0.2695, last_20: 0.1929, lr: 0.0001, epoch: 5/25, step: 23/80\n",
      "loss: 0.0628, last_20: 0.1901, lr: 0.0001, epoch: 5/25, step: 24/80\n",
      "loss: 0.3198, last_20: 0.206, lr: 0.0001, epoch: 5/25, step: 25/80\n",
      "loss: 0.0057, last_20: 0.2043, lr: 0.0001, epoch: 5/25, step: 26/80\n",
      "loss: 0.4077, last_20: 0.2243, lr: 0.0001, epoch: 5/25, step: 27/80\n",
      "loss: 0.0764, last_20: 0.2134, lr: 0.0001, epoch: 5/25, step: 28/80\n",
      "loss: 0.0069, last_20: 0.2101, lr: 0.0001, epoch: 5/25, step: 29/80\n",
      "loss: 0.0122, last_20: 0.1835, lr: 0.0001, epoch: 5/25, step: 30/80\n",
      "loss: 0.0038, last_20: 0.1804, lr: 0.0001, epoch: 5/25, step: 31/80\n",
      "loss: 0.0149, last_20: 0.1626, lr: 0.0001, epoch: 5/25, step: 32/80\n",
      "loss: 0.0135, last_20: 0.1629, lr: 0.0001, epoch: 5/25, step: 33/80\n",
      "loss: 0.1786, last_20: 0.1642, lr: 0.0001, epoch: 5/25, step: 34/80\n",
      "loss: 0.3098, last_20: 0.1582, lr: 0.0001, epoch: 5/25, step: 35/80\n",
      "loss: 0.2476, last_20: 0.1485, lr: 0.0001, epoch: 5/25, step: 36/80\n",
      "loss: 0.0517, last_20: 0.1463, lr: 0.0001, epoch: 5/25, step: 37/80\n",
      "loss: 0.3677, last_20: 0.1444, lr: 0.0001, epoch: 5/25, step: 38/80\n",
      "loss: 0.111, last_20: 0.1496, lr: 0.0001, epoch: 5/25, step: 39/80\n",
      "loss: 0.0342, last_20: 0.1506, lr: 0.0001, epoch: 5/25, step: 40/80\n",
      "loss: 0.1788, last_20: 0.1594, lr: 0.0001, epoch: 5/25, step: 41/80\n",
      "loss: 0.0699, last_20: 0.1371, lr: 0.0001, epoch: 5/25, step: 42/80\n",
      "loss: 0.0494, last_20: 0.1261, lr: 0.0001, epoch: 5/25, step: 43/80\n",
      "loss: 0.0094, last_20: 0.1234, lr: 0.0001, epoch: 5/25, step: 44/80\n",
      "loss: 0.0355, last_20: 0.1092, lr: 0.0001, epoch: 5/25, step: 45/80\n",
      "loss: 0.0024, last_20: 0.1091, lr: 0.0001, epoch: 5/25, step: 46/80\n",
      "loss: 0.1953, last_20: 0.0985, lr: 0.0001, epoch: 5/25, step: 47/80\n",
      "loss: 0.0035, last_20: 0.0948, lr: 0.0001, epoch: 5/25, step: 48/80\n",
      "loss: 0.0383, last_20: 0.0964, lr: 0.0001, epoch: 5/25, step: 49/80\n",
      "loss: 0.6445, last_20: 0.128, lr: 0.0001, epoch: 5/25, step: 50/80\n",
      "loss: 0.1022, last_20: 0.1329, lr: 0.0001, epoch: 5/25, step: 51/80\n",
      "loss: 0.1202, last_20: 0.1382, lr: 0.0001, epoch: 5/25, step: 52/80\n",
      "loss: 0.0085, last_20: 0.1379, lr: 0.0001, epoch: 5/25, step: 53/80\n",
      "loss: 0.4172, last_20: 0.1499, lr: 0.0001, epoch: 5/25, step: 54/80\n",
      "loss: 0.02, last_20: 0.1354, lr: 0.0001, epoch: 5/25, step: 55/80\n",
      "loss: 0.7222, last_20: 0.1591, lr: 0.0001, epoch: 5/25, step: 56/80\n",
      "loss: 0.8682, last_20: 0.1999, lr: 0.0001, epoch: 5/25, step: 57/80\n",
      "loss: 0.3567, last_20: 0.1994, lr: 0.0001, epoch: 5/25, step: 58/80\n",
      "loss: 0.042, last_20: 0.1959, lr: 0.0001, epoch: 5/25, step: 59/80\n",
      "loss: 0.874, last_20: 0.2379, lr: 0.0001, epoch: 5/25, step: 60/80\n",
      "loss: 0.2423, last_20: 0.2411, lr: 0.0001, epoch: 5/25, step: 61/80\n",
      "loss: 0.0217, last_20: 0.2387, lr: 0.0001, epoch: 5/25, step: 62/80\n",
      "loss: 0.0081, last_20: 0.2366, lr: 0.0001, epoch: 5/25, step: 63/80\n",
      "loss: 0.3171, last_20: 0.252, lr: 0.0001, epoch: 5/25, step: 64/80\n",
      "loss: 0.0597, last_20: 0.2532, lr: 0.0001, epoch: 5/25, step: 65/80\n",
      "loss: 0.0047, last_20: 0.2533, lr: 0.0001, epoch: 5/25, step: 66/80\n",
      "loss: 0.2996, last_20: 0.2585, lr: 0.0001, epoch: 5/25, step: 67/80\n",
      "loss: 0.0666, last_20: 0.2617, lr: 0.0001, epoch: 5/25, step: 68/80\n",
      "loss: 0.028, last_20: 0.2612, lr: 0.0001, epoch: 5/25, step: 69/80\n",
      "loss: 0.2451, last_20: 0.2412, lr: 0.0001, epoch: 5/25, step: 70/80\n",
      "loss: 0.2561, last_20: 0.2489, lr: 0.0001, epoch: 5/25, step: 71/80\n",
      "loss: 0.1416, last_20: 0.25, lr: 0.0001, epoch: 5/25, step: 72/80\n",
      "loss: 0.0057, last_20: 0.2498, lr: 0.0001, epoch: 5/25, step: 73/80\n",
      "loss: 0.0123, last_20: 0.2296, lr: 0.0001, epoch: 5/25, step: 74/80\n",
      "loss: 0.0026, last_20: 0.2287, lr: 0.0001, epoch: 5/25, step: 75/80\n",
      "loss: 0.0503, last_20: 0.1951, lr: 0.0001, epoch: 5/25, step: 76/80\n",
      "loss: 0.0512, last_20: 0.1543, lr: 0.0001, epoch: 5/25, step: 77/80\n",
      "loss: 0.0031, last_20: 0.1366, lr: 0.0001, epoch: 5/25, step: 78/80\n",
      "loss: 0.1086, last_20: 0.1399, lr: 0.0001, epoch: 5/25, step: 79/80\n",
      "loss: 0.0071, last_20: 0.0966, lr: 0.0001, epoch: 5/25, step: 80/80\n",
      "loss: 0.1086, last_20: 0.0899, lr: 0.0001, epoch: 6/25, step: 1/80\n",
      "loss: 0.3796, last_20: 0.1078, lr: 0.0001, epoch: 6/25, step: 2/80\n",
      "loss: 0.0061, last_20: 0.1077, lr: 0.0001, epoch: 6/25, step: 3/80\n",
      "loss: 0.5952, last_20: 0.1216, lr: 0.0001, epoch: 6/25, step: 4/80\n",
      "loss: 0.1393, last_20: 0.1256, lr: 0.0001, epoch: 6/25, step: 5/80\n",
      "loss: 0.0601, last_20: 0.1283, lr: 0.0001, epoch: 6/25, step: 6/80\n",
      "loss: 0.0809, last_20: 0.1174, lr: 0.0001, epoch: 6/25, step: 7/80\n",
      "loss: 0.1372, last_20: 0.1209, lr: 0.0001, epoch: 6/25, step: 8/80\n",
      "loss: 0.1395, last_20: 0.1265, lr: 0.0001, epoch: 6/25, step: 9/80\n",
      "loss: 0.1444, last_20: 0.1215, lr: 0.0001, epoch: 6/25, step: 10/80\n",
      "loss: 0.0064, last_20: 0.109, lr: 0.0001, epoch: 6/25, step: 11/80\n",
      "loss: 0.2297, last_20: 0.1134, lr: 0.0001, epoch: 6/25, step: 12/80\n",
      "loss: 0.0094, last_20: 0.1136, lr: 0.0001, epoch: 6/25, step: 13/80\n",
      "loss: 0.1929, last_20: 0.1226, lr: 0.0001, epoch: 6/25, step: 14/80\n",
      "loss: 0.2252, last_20: 0.1337, lr: 0.0001, epoch: 6/25, step: 15/80\n",
      "loss: 0.0712, last_20: 0.1348, lr: 0.0001, epoch: 6/25, step: 16/80\n",
      "loss: 0.0891, last_20: 0.1367, lr: 0.0001, epoch: 6/25, step: 17/80\n",
      "loss: 0.0358, last_20: 0.1383, lr: 0.0001, epoch: 6/25, step: 18/80\n",
      "loss: 0.1895, last_20: 0.1424, lr: 0.0001, epoch: 6/25, step: 19/80\n",
      "loss: 0.0314, last_20: 0.1436, lr: 0.0001, epoch: 6/25, step: 20/80\n",
      "loss: 0.3623, last_20: 0.1563, lr: 0.0001, epoch: 6/25, step: 21/80\n",
      "loss: 0.0135, last_20: 0.138, lr: 0.0001, epoch: 6/25, step: 22/80\n",
      "loss: 0.217, last_20: 0.1485, lr: 0.0001, epoch: 6/25, step: 23/80\n",
      "loss: 0.1324, last_20: 0.1254, lr: 0.0001, epoch: 6/25, step: 24/80\n",
      "loss: 0.3467, last_20: 0.1357, lr: 0.0001, epoch: 6/25, step: 25/80\n",
      "loss: 0.0226, last_20: 0.1339, lr: 0.0001, epoch: 6/25, step: 26/80\n",
      "loss: 0.5166, last_20: 0.1556, lr: 0.0001, epoch: 6/25, step: 27/80\n",
      "loss: 0.0184, last_20: 0.1497, lr: 0.0001, epoch: 6/25, step: 28/80\n",
      "loss: 0.0509, last_20: 0.1453, lr: 0.0001, epoch: 6/25, step: 29/80\n",
      "loss: 0.1549, last_20: 0.1458, lr: 0.0001, epoch: 6/25, step: 30/80\n",
      "loss: 0.0503, last_20: 0.148, lr: 0.0001, epoch: 6/25, step: 31/80\n",
      "loss: 0.7114, last_20: 0.1721, lr: 0.0001, epoch: 6/25, step: 32/80\n",
      "loss: 0.3862, last_20: 0.1909, lr: 0.0001, epoch: 6/25, step: 33/80\n",
      "loss: 0.0308, last_20: 0.1828, lr: 0.0001, epoch: 6/25, step: 34/80\n",
      "loss: 0.0353, last_20: 0.1733, lr: 0.0001, epoch: 6/25, step: 35/80\n",
      "loss: 0.0517, last_20: 0.1723, lr: 0.0001, epoch: 6/25, step: 36/80\n",
      "loss: 0.9165, last_20: 0.2137, lr: 0.0001, epoch: 6/25, step: 37/80\n",
      "loss: 0.6646, last_20: 0.2451, lr: 0.0001, epoch: 6/25, step: 38/80\n",
      "loss: 0.4272, last_20: 0.257, lr: 0.0001, epoch: 6/25, step: 39/80\n",
      "loss: 0.0367, last_20: 0.2573, lr: 0.0001, epoch: 6/25, step: 40/80\n",
      "loss: 0.0679, last_20: 0.2426, lr: 0.0001, epoch: 6/25, step: 41/80\n",
      "loss: 0.0667, last_20: 0.2452, lr: 0.0001, epoch: 6/25, step: 42/80\n",
      "loss: 0.3723, last_20: 0.253, lr: 0.0001, epoch: 6/25, step: 43/80\n",
      "loss: 0.2355, last_20: 0.2582, lr: 0.0001, epoch: 6/25, step: 44/80\n",
      "loss: 0.6636, last_20: 0.274, lr: 0.0001, epoch: 6/25, step: 45/80\n",
      "loss: 0.1501, last_20: 0.2804, lr: 0.0001, epoch: 6/25, step: 46/80\n",
      "loss: 0.0025, last_20: 0.2547, lr: 0.0001, epoch: 6/25, step: 47/80\n",
      "loss: 0.2732, last_20: 0.2674, lr: 0.0001, epoch: 6/25, step: 48/80\n",
      "loss: 0.034, last_20: 0.2666, lr: 0.0001, epoch: 6/25, step: 49/80\n",
      "loss: 0.2198, last_20: 0.2698, lr: 0.0001, epoch: 6/25, step: 50/80\n",
      "loss: 0.2756, last_20: 0.2811, lr: 0.0001, epoch: 6/25, step: 51/80\n",
      "loss: 0.2028, last_20: 0.2557, lr: 0.0001, epoch: 6/25, step: 52/80\n",
      "loss: 0.2993, last_20: 0.2513, lr: 0.0001, epoch: 6/25, step: 53/80\n",
      "loss: 0.0097, last_20: 0.2502, lr: 0.0001, epoch: 6/25, step: 54/80\n",
      "loss: 0.3831, last_20: 0.2676, lr: 0.0001, epoch: 6/25, step: 55/80\n",
      "loss: 0.4966, last_20: 0.2899, lr: 0.0001, epoch: 6/25, step: 56/80\n",
      "loss: 0.1121, last_20: 0.2497, lr: 0.0001, epoch: 6/25, step: 57/80\n",
      "loss: 0.2461, last_20: 0.2287, lr: 0.0001, epoch: 6/25, step: 58/80\n",
      "loss: 0.3792, last_20: 0.2263, lr: 0.0001, epoch: 6/25, step: 59/80\n",
      "loss: 0.6211, last_20: 0.2556, lr: 0.0001, epoch: 6/25, step: 60/80\n",
      "loss: 0.4663, last_20: 0.2755, lr: 0.0001, epoch: 6/25, step: 61/80\n",
      "loss: 0.6479, last_20: 0.3045, lr: 0.0001, epoch: 6/25, step: 62/80\n",
      "loss: 0.0324, last_20: 0.2875, lr: 0.0001, epoch: 6/25, step: 63/80\n",
      "loss: 0.1135, last_20: 0.2814, lr: 0.0001, epoch: 6/25, step: 64/80\n",
      "loss: 0.0291, last_20: 0.2497, lr: 0.0001, epoch: 6/25, step: 65/80\n",
      "loss: 0.0803, last_20: 0.2462, lr: 0.0001, epoch: 6/25, step: 66/80\n",
      "loss: 0.3467, last_20: 0.2634, lr: 0.0001, epoch: 6/25, step: 67/80\n",
      "loss: 0.0267, last_20: 0.2511, lr: 0.0001, epoch: 6/25, step: 68/80\n",
      "loss: 0.2294, last_20: 0.2609, lr: 0.0001, epoch: 6/25, step: 69/80\n",
      "loss: 0.3015, last_20: 0.265, lr: 0.0001, epoch: 6/25, step: 70/80\n",
      "loss: 0.1949, last_20: 0.2609, lr: 0.0001, epoch: 6/25, step: 71/80\n",
      "loss: 0.0149, last_20: 0.2515, lr: 0.0001, epoch: 6/25, step: 72/80\n",
      "loss: 0.042, last_20: 0.2387, lr: 0.0001, epoch: 6/25, step: 73/80\n",
      "loss: 0.2013, last_20: 0.2483, lr: 0.0001, epoch: 6/25, step: 74/80\n",
      "loss: 0.0098, last_20: 0.2296, lr: 0.0001, epoch: 6/25, step: 75/80\n",
      "loss: 0.1827, last_20: 0.2139, lr: 0.0001, epoch: 6/25, step: 76/80\n",
      "loss: 0.2925, last_20: 0.2229, lr: 0.0001, epoch: 6/25, step: 77/80\n",
      "loss: 0.366, last_20: 0.2289, lr: 0.0001, epoch: 6/25, step: 78/80\n",
      "loss: 0.303, last_20: 0.2251, lr: 0.0001, epoch: 6/25, step: 79/80\n",
      "loss: 0.2625, last_20: 0.2072, lr: 0.0001, epoch: 6/25, step: 80/80\n",
      "loss: 0.457, last_20: 0.2067, lr: 0.0001, epoch: 7/25, step: 1/80\n",
      "loss: 0.1487, last_20: 0.1817, lr: 0.0001, epoch: 7/25, step: 2/80\n",
      "loss: 0.1199, last_20: 0.1861, lr: 0.0001, epoch: 7/25, step: 3/80\n",
      "loss: 0.0194, last_20: 0.1814, lr: 0.0001, epoch: 7/25, step: 4/80\n",
      "loss: 0.0106, last_20: 0.1805, lr: 0.0001, epoch: 7/25, step: 5/80\n",
      "loss: 0.2925, last_20: 0.1911, lr: 0.0001, epoch: 7/25, step: 6/80\n",
      "loss: 0.0025, last_20: 0.1739, lr: 0.0001, epoch: 7/25, step: 7/80\n",
      "loss: 0.0867, last_20: 0.1769, lr: 0.0001, epoch: 7/25, step: 8/80\n",
      "loss: 0.0256, last_20: 0.1667, lr: 0.0001, epoch: 7/25, step: 9/80\n",
      "loss: 0.2942, last_20: 0.1663, lr: 0.0001, epoch: 7/25, step: 10/80\n",
      "loss: 0.0409, last_20: 0.1586, lr: 0.0001, epoch: 7/25, step: 11/80\n",
      "loss: 0.0063, last_20: 0.1582, lr: 0.0001, epoch: 7/25, step: 12/80\n",
      "loss: 0.1294, last_20: 0.1626, lr: 0.0001, epoch: 7/25, step: 13/80\n",
      "loss: 0.0185, last_20: 0.1534, lr: 0.0001, epoch: 7/25, step: 14/80\n",
      "loss: 0.4253, last_20: 0.1742, lr: 0.0001, epoch: 7/25, step: 15/80\n",
      "loss: 0.1027, last_20: 0.1702, lr: 0.0001, epoch: 7/25, step: 16/80\n",
      "loss: 0.0084, last_20: 0.156, lr: 0.0001, epoch: 7/25, step: 17/80\n",
      "loss: 0.0073, last_20: 0.1381, lr: 0.0001, epoch: 7/25, step: 18/80\n",
      "loss: 0.0069, last_20: 0.1233, lr: 0.0001, epoch: 7/25, step: 19/80\n",
      "loss: 0.0157, last_20: 0.1109, lr: 0.0001, epoch: 7/25, step: 20/80\n",
      "loss: 0.0173, last_20: 0.0889, lr: 0.0001, epoch: 7/25, step: 21/80\n",
      "loss: 0.0107, last_20: 0.082, lr: 0.0001, epoch: 7/25, step: 22/80\n",
      "loss: 0.005, last_20: 0.0763, lr: 0.0001, epoch: 7/25, step: 23/80\n",
      "loss: 0.0119, last_20: 0.0759, lr: 0.0001, epoch: 7/25, step: 24/80\n",
      "loss: 0.4043, last_20: 0.0956, lr: 0.0001, epoch: 7/25, step: 25/80\n",
      "loss: 0.0055, last_20: 0.0813, lr: 0.0001, epoch: 7/25, step: 26/80\n",
      "loss: 0.3179, last_20: 0.097, lr: 0.0001, epoch: 7/25, step: 27/80\n",
      "loss: 0.022, last_20: 0.0938, lr: 0.0001, epoch: 7/25, step: 28/80\n",
      "loss: 0.1025, last_20: 0.0976, lr: 0.0001, epoch: 7/25, step: 29/80\n",
      "loss: 0.0091, last_20: 0.0834, lr: 0.0001, epoch: 7/25, step: 30/80\n",
      "loss: 0.0195, last_20: 0.0823, lr: 0.0001, epoch: 7/25, step: 31/80\n",
      "loss: 0.666, last_20: 0.1153, lr: 0.0001, epoch: 7/25, step: 32/80\n",
      "loss: 0.0131, last_20: 0.1095, lr: 0.0001, epoch: 7/25, step: 33/80\n",
      "loss: 0.0023, last_20: 0.1087, lr: 0.0001, epoch: 7/25, step: 34/80\n",
      "loss: 0.2798, last_20: 0.1014, lr: 0.0001, epoch: 7/25, step: 35/80\n",
      "loss: 0.032, last_20: 0.0979, lr: 0.0001, epoch: 7/25, step: 36/80\n",
      "loss: 0.0284, last_20: 0.0989, lr: 0.0001, epoch: 7/25, step: 37/80\n",
      "loss: 0.5088, last_20: 0.1239, lr: 0.0001, epoch: 7/25, step: 38/80\n",
      "loss: 0.229, last_20: 0.135, lr: 0.0001, epoch: 7/25, step: 39/80\n",
      "loss: 0.0177, last_20: 0.1351, lr: 0.0001, epoch: 7/25, step: 40/80\n",
      "loss: 0.479, last_20: 0.1582, lr: 0.0001, epoch: 7/25, step: 41/80\n",
      "loss: 0.408, last_20: 0.1781, lr: 0.0001, epoch: 7/25, step: 42/80\n",
      "loss: 0.1512, last_20: 0.1854, lr: 0.0001, epoch: 7/25, step: 43/80\n",
      "loss: 0.0049, last_20: 0.1851, lr: 0.0001, epoch: 7/25, step: 44/80\n",
      "loss: 0.106, last_20: 0.1701, lr: 0.0001, epoch: 7/25, step: 45/80\n",
      "loss: 0.0037, last_20: 0.17, lr: 0.0001, epoch: 7/25, step: 46/80\n",
      "loss: 0.4512, last_20: 0.1767, lr: 0.0001, epoch: 7/25, step: 47/80\n",
      "loss: 0.9468, last_20: 0.223, lr: 0.0001, epoch: 7/25, step: 48/80\n",
      "loss: 0.5317, last_20: 0.2444, lr: 0.0001, epoch: 7/25, step: 49/80\n",
      "loss: 0.0451, last_20: 0.2462, lr: 0.0001, epoch: 7/25, step: 50/80\n",
      "loss: 0.0351, last_20: 0.247, lr: 0.0001, epoch: 7/25, step: 51/80\n",
      "loss: 0.0489, last_20: 0.2161, lr: 0.0001, epoch: 7/25, step: 52/80\n",
      "loss: 0.2654, last_20: 0.2287, lr: 0.0001, epoch: 7/25, step: 53/80\n",
      "loss: 0.0067, last_20: 0.229, lr: 0.0001, epoch: 7/25, step: 54/80\n",
      "loss: 0.097, last_20: 0.2198, lr: 0.0001, epoch: 7/25, step: 55/80\n",
      "loss: 0.0895, last_20: 0.2227, lr: 0.0001, epoch: 7/25, step: 56/80\n",
      "loss: 0.0579, last_20: 0.2242, lr: 0.0001, epoch: 7/25, step: 57/80\n",
      "loss: 0.5161, last_20: 0.2245, lr: 0.0001, epoch: 7/25, step: 58/80\n",
      "loss: 0.7744, last_20: 0.2518, lr: 0.0001, epoch: 7/25, step: 59/80\n",
      "loss: 0.028, last_20: 0.2523, lr: 0.0001, epoch: 7/25, step: 60/80\n",
      "loss: 0.4761, last_20: 0.2522, lr: 0.0001, epoch: 7/25, step: 61/80\n",
      "loss: 0.0666, last_20: 0.2351, lr: 0.0001, epoch: 7/25, step: 62/80\n",
      "loss: 0.1171, last_20: 0.2334, lr: 0.0001, epoch: 7/25, step: 63/80\n",
      "loss: 0.0972, last_20: 0.238, lr: 0.0001, epoch: 7/25, step: 64/80\n",
      "loss: 0.2505, last_20: 0.2453, lr: 0.0001, epoch: 7/25, step: 65/80\n",
      "loss: 0.2305, last_20: 0.2566, lr: 0.0001, epoch: 7/25, step: 66/80\n",
      "loss: 0.2686, last_20: 0.2475, lr: 0.0001, epoch: 7/25, step: 67/80\n",
      "loss: 0.5801, last_20: 0.2291, lr: 0.0001, epoch: 7/25, step: 68/80\n",
      "loss: 0.068, last_20: 0.2059, lr: 0.0001, epoch: 7/25, step: 69/80\n",
      "loss: 0.3445, last_20: 0.2209, lr: 0.0001, epoch: 7/25, step: 70/80\n",
      "loss: 0.0819, last_20: 0.2233, lr: 0.0001, epoch: 7/25, step: 71/80\n",
      "loss: 0.9785, last_20: 0.2697, lr: 0.0001, epoch: 7/25, step: 72/80\n",
      "loss: 0.0373, last_20: 0.2583, lr: 0.0001, epoch: 7/25, step: 73/80\n",
      "loss: 0.0142, last_20: 0.2587, lr: 0.0001, epoch: 7/25, step: 74/80\n",
      "loss: 0.038, last_20: 0.2558, lr: 0.0001, epoch: 7/25, step: 75/80\n",
      "loss: 0.01, last_20: 0.2518, lr: 0.0001, epoch: 7/25, step: 76/80\n",
      "loss: 0.1493, last_20: 0.2563, lr: 0.0001, epoch: 7/25, step: 77/80\n",
      "loss: 0.5039, last_20: 0.2557, lr: 0.0001, epoch: 7/25, step: 78/80\n",
      "loss: 0.4158, last_20: 0.2378, lr: 0.0001, epoch: 7/25, step: 79/80\n",
      "loss: 0.1627, last_20: 0.2445, lr: 0.0001, epoch: 7/25, step: 80/80\n",
      "loss: 0.6421, last_20: 0.2528, lr: 0.0001, epoch: 8/25, step: 1/80\n",
      "loss: 0.065, last_20: 0.2528, lr: 0.0001, epoch: 8/25, step: 2/80\n",
      "loss: 0.0358, last_20: 0.2487, lr: 0.0001, epoch: 8/25, step: 3/80\n",
      "loss: 0.1954, last_20: 0.2536, lr: 0.0001, epoch: 8/25, step: 4/80\n",
      "loss: 0.0027, last_20: 0.2412, lr: 0.0001, epoch: 8/25, step: 5/80\n",
      "loss: 0.3384, last_20: 0.2466, lr: 0.0001, epoch: 8/25, step: 6/80\n",
      "loss: 0.0269, last_20: 0.2345, lr: 0.0001, epoch: 8/25, step: 7/80\n",
      "loss: 0.153, last_20: 0.2132, lr: 0.0001, epoch: 8/25, step: 8/80\n",
      "loss: 0.0081, last_20: 0.2102, lr: 0.0001, epoch: 8/25, step: 9/80\n",
      "loss: 0.1377, last_20: 0.1998, lr: 0.0001, epoch: 8/25, step: 10/80\n",
      "loss: 0.0462, last_20: 0.1981, lr: 0.0001, epoch: 8/25, step: 11/80\n",
      "loss: 0.0045, last_20: 0.1494, lr: 0.0001, epoch: 8/25, step: 12/80\n",
      "loss: 0.0669, last_20: 0.1508, lr: 0.0001, epoch: 8/25, step: 13/80\n",
      "loss: 0.2874, last_20: 0.1645, lr: 0.0001, epoch: 8/25, step: 14/80\n",
      "loss: 0.0332, last_20: 0.1642, lr: 0.0001, epoch: 8/25, step: 15/80\n",
      "loss: 0.0404, last_20: 0.1658, lr: 0.0001, epoch: 8/25, step: 16/80\n",
      "loss: 0.0702, last_20: 0.1618, lr: 0.0001, epoch: 8/25, step: 17/80\n",
      "loss: 0.1886, last_20: 0.146, lr: 0.0001, epoch: 8/25, step: 18/80\n",
      "loss: 0.0392, last_20: 0.1272, lr: 0.0001, epoch: 8/25, step: 19/80\n",
      "loss: 0.0513, last_20: 0.1216, lr: 0.0001, epoch: 8/25, step: 20/80\n",
      "loss: 0.0932, last_20: 0.0942, lr: 0.0001, epoch: 8/25, step: 21/80\n",
      "loss: 0.3208, last_20: 0.107, lr: 0.0001, epoch: 8/25, step: 22/80\n",
      "loss: 0.7983, last_20: 0.1451, lr: 0.0001, epoch: 8/25, step: 23/80\n",
      "loss: 0.4558, last_20: 0.1581, lr: 0.0001, epoch: 8/25, step: 24/80\n",
      "loss: 0.3477, last_20: 0.1754, lr: 0.0001, epoch: 8/25, step: 25/80\n",
      "loss: 0.3093, last_20: 0.1739, lr: 0.0001, epoch: 8/25, step: 26/80\n",
      "loss: 0.1079, last_20: 0.178, lr: 0.0001, epoch: 8/25, step: 27/80\n",
      "loss: 0.199, last_20: 0.1803, lr: 0.0001, epoch: 8/25, step: 28/80\n",
      "loss: 0.3225, last_20: 0.196, lr: 0.0001, epoch: 8/25, step: 29/80\n",
      "loss: 0.0068, last_20: 0.1895, lr: 0.0001, epoch: 8/25, step: 30/80\n",
      "loss: 0.2262, last_20: 0.1985, lr: 0.0001, epoch: 8/25, step: 31/80\n",
      "loss: 0.1298, last_20: 0.2047, lr: 0.0001, epoch: 8/25, step: 32/80\n",
      "loss: 0.332, last_20: 0.218, lr: 0.0001, epoch: 8/25, step: 33/80\n",
      "loss: 0.1785, last_20: 0.2125, lr: 0.0001, epoch: 8/25, step: 34/80\n",
      "loss: 0.5791, last_20: 0.2398, lr: 0.0001, epoch: 8/25, step: 35/80\n",
      "loss: 0.0975, last_20: 0.2427, lr: 0.0001, epoch: 8/25, step: 36/80\n",
      "loss: 0.1567, last_20: 0.247, lr: 0.0001, epoch: 8/25, step: 37/80\n",
      "loss: 0.0085, last_20: 0.238, lr: 0.0001, epoch: 8/25, step: 38/80\n",
      "loss: 0.0873, last_20: 0.2404, lr: 0.0001, epoch: 8/25, step: 39/80\n",
      "loss: 0.0075, last_20: 0.2382, lr: 0.0001, epoch: 8/25, step: 40/80\n",
      "loss: 0.1393, last_20: 0.2405, lr: 0.0001, epoch: 8/25, step: 41/80\n",
      "loss: 0.1959, last_20: 0.2343, lr: 0.0001, epoch: 8/25, step: 42/80\n",
      "loss: 0.0032, last_20: 0.1945, lr: 0.0001, epoch: 8/25, step: 43/80\n",
      "loss: 0.4707, last_20: 0.1953, lr: 0.0001, epoch: 8/25, step: 44/80\n",
      "loss: 0.1398, last_20: 0.1849, lr: 0.0001, epoch: 8/25, step: 45/80\n",
      "loss: 0.0933, last_20: 0.1741, lr: 0.0001, epoch: 8/25, step: 46/80\n",
      "loss: 0.0583, last_20: 0.1716, lr: 0.0001, epoch: 8/25, step: 47/80\n",
      "loss: 0.0186, last_20: 0.1626, lr: 0.0001, epoch: 8/25, step: 48/80\n",
      "loss: 0.0097, last_20: 0.1469, lr: 0.0001, epoch: 8/25, step: 49/80\n",
      "loss: 0.0176, last_20: 0.1475, lr: 0.0001, epoch: 8/25, step: 50/80\n",
      "loss: 0.1327, last_20: 0.1428, lr: 0.0001, epoch: 8/25, step: 51/80\n",
      "loss: 0.0508, last_20: 0.1389, lr: 0.0001, epoch: 8/25, step: 52/80\n",
      "loss: 0.0031, last_20: 0.1224, lr: 0.0001, epoch: 8/25, step: 53/80\n",
      "loss: 0.0142, last_20: 0.1142, lr: 0.0001, epoch: 8/25, step: 54/80\n",
      "loss: 0.0057, last_20: 0.0855, lr: 0.0001, epoch: 8/25, step: 55/80\n",
      "loss: 0.085, last_20: 0.0849, lr: 0.0001, epoch: 8/25, step: 56/80\n",
      "loss: 0.4727, last_20: 0.1007, lr: 0.0001, epoch: 8/25, step: 57/80\n",
      "loss: 0.0503, last_20: 0.1028, lr: 0.0001, epoch: 8/25, step: 58/80\n",
      "loss: 0.0528, last_20: 0.1011, lr: 0.0001, epoch: 8/25, step: 59/80\n",
      "loss: 0.013, last_20: 0.1013, lr: 0.0001, epoch: 8/25, step: 60/80\n",
      "loss: 0.3708, last_20: 0.1129, lr: 0.0001, epoch: 8/25, step: 61/80\n",
      "loss: 0.2137, last_20: 0.1138, lr: 0.0001, epoch: 8/25, step: 62/80\n",
      "loss: 0.0039, last_20: 0.1138, lr: 0.0001, epoch: 8/25, step: 63/80\n",
      "loss: 0.8501, last_20: 0.1328, lr: 0.0001, epoch: 8/25, step: 64/80\n",
      "loss: 0.0404, last_20: 0.1278, lr: 0.0001, epoch: 8/25, step: 65/80\n",
      "loss: 0.4709, last_20: 0.1467, lr: 0.0001, epoch: 8/25, step: 66/80\n",
      "loss: 0.323, last_20: 0.1599, lr: 0.0001, epoch: 8/25, step: 67/80\n",
      "loss: 0.1484, last_20: 0.1664, lr: 0.0001, epoch: 8/25, step: 68/80\n",
      "loss: 0.1304, last_20: 0.1725, lr: 0.0001, epoch: 8/25, step: 69/80\n",
      "loss: 0.0292, last_20: 0.1731, lr: 0.0001, epoch: 8/25, step: 70/80\n",
      "loss: 0.0352, last_20: 0.1682, lr: 0.0001, epoch: 8/25, step: 71/80\n",
      "loss: 0.0417, last_20: 0.1677, lr: 0.0001, epoch: 8/25, step: 72/80\n",
      "loss: 0.044, last_20: 0.1698, lr: 0.0001, epoch: 8/25, step: 73/80\n",
      "loss: 0.0851, last_20: 0.1733, lr: 0.0001, epoch: 8/25, step: 74/80\n",
      "loss: 0.3594, last_20: 0.191, lr: 0.0001, epoch: 8/25, step: 75/80\n",
      "loss: 0.015, last_20: 0.1875, lr: 0.0001, epoch: 8/25, step: 76/80\n",
      "loss: 0.0104, last_20: 0.1644, lr: 0.0001, epoch: 8/25, step: 77/80\n",
      "loss: 0.0101, last_20: 0.1624, lr: 0.0001, epoch: 8/25, step: 78/80\n",
      "loss: 0.1982, last_20: 0.1696, lr: 0.0001, epoch: 8/25, step: 79/80\n",
      "loss: 0.0718, last_20: 0.1726, lr: 0.0001, epoch: 8/25, step: 80/80\n",
      "loss: 0.5361, last_20: 0.1809, lr: 0.0001, epoch: 9/25, step: 1/80\n",
      "loss: 0.0151, last_20: 0.1709, lr: 0.0001, epoch: 9/25, step: 2/80\n",
      "loss: 0.1031, last_20: 0.1759, lr: 0.0001, epoch: 9/25, step: 3/80\n",
      "loss: 0.3865, last_20: 0.1527, lr: 0.0001, epoch: 9/25, step: 4/80\n",
      "loss: 0.0103, last_20: 0.1512, lr: 0.0001, epoch: 9/25, step: 5/80\n",
      "loss: 0.3445, last_20: 0.1449, lr: 0.0001, epoch: 9/25, step: 6/80\n",
      "loss: 0.0927, last_20: 0.1334, lr: 0.0001, epoch: 9/25, step: 7/80\n",
      "loss: 0.0042, last_20: 0.1261, lr: 0.0001, epoch: 9/25, step: 8/80\n",
      "loss: 0.4624, last_20: 0.1427, lr: 0.0001, epoch: 9/25, step: 9/80\n",
      "loss: 0.3696, last_20: 0.1598, lr: 0.0001, epoch: 9/25, step: 10/80\n",
      "loss: 0.8262, last_20: 0.1993, lr: 0.0001, epoch: 9/25, step: 11/80\n",
      "loss: 0.5625, last_20: 0.2254, lr: 0.0001, epoch: 9/25, step: 12/80\n",
      "loss: 0.1763, last_20: 0.232, lr: 0.0001, epoch: 9/25, step: 13/80\n",
      "loss: 0.1837, last_20: 0.2369, lr: 0.0001, epoch: 9/25, step: 14/80\n",
      "loss: 0.0141, last_20: 0.2196, lr: 0.0001, epoch: 9/25, step: 15/80\n",
      "loss: 0.2426, last_20: 0.231, lr: 0.0001, epoch: 9/25, step: 16/80\n",
      "loss: 0.5815, last_20: 0.2596, lr: 0.0001, epoch: 9/25, step: 17/80\n",
      "loss: 0.0211, last_20: 0.2601, lr: 0.0001, epoch: 9/25, step: 18/80\n",
      "loss: 0.2034, last_20: 0.2604, lr: 0.0001, epoch: 9/25, step: 19/80\n",
      "loss: 0.0891, last_20: 0.2613, lr: 0.0001, epoch: 9/25, step: 20/80\n",
      "loss: 0.1268, last_20: 0.2408, lr: 0.0001, epoch: 9/25, step: 21/80\n",
      "loss: 0.0491, last_20: 0.2425, lr: 0.0001, epoch: 9/25, step: 22/80\n",
      "loss: 0.271, last_20: 0.2509, lr: 0.0001, epoch: 9/25, step: 23/80\n",
      "loss: 0.0528, last_20: 0.2342, lr: 0.0001, epoch: 9/25, step: 24/80\n",
      "loss: 0.132, last_20: 0.2403, lr: 0.0001, epoch: 9/25, step: 25/80\n",
      "loss: 0.3608, last_20: 0.2411, lr: 0.0001, epoch: 9/25, step: 26/80\n",
      "loss: 0.5952, last_20: 0.2662, lr: 0.0001, epoch: 9/25, step: 27/80\n",
      "loss: 0.5796, last_20: 0.295, lr: 0.0001, epoch: 9/25, step: 28/80\n",
      "loss: 0.3459, last_20: 0.2892, lr: 0.0001, epoch: 9/25, step: 29/80\n",
      "loss: 0.005, last_20: 0.2709, lr: 0.0001, epoch: 9/25, step: 30/80\n",
      "loss: 0.0087, last_20: 0.2301, lr: 0.0001, epoch: 9/25, step: 31/80\n",
      "loss: 0.092, last_20: 0.2065, lr: 0.0001, epoch: 9/25, step: 32/80\n",
      "loss: 0.2024, last_20: 0.2078, lr: 0.0001, epoch: 9/25, step: 33/80\n",
      "loss: 0.1206, last_20: 0.2047, lr: 0.0001, epoch: 9/25, step: 34/80\n",
      "loss: 0.0143, last_20: 0.2047, lr: 0.0001, epoch: 9/25, step: 35/80\n",
      "loss: 0.1759, last_20: 0.2014, lr: 0.0001, epoch: 9/25, step: 36/80\n",
      "loss: 0.025, last_20: 0.1735, lr: 0.0001, epoch: 9/25, step: 37/80\n",
      "loss: 0.0787, last_20: 0.1764, lr: 0.0001, epoch: 9/25, step: 38/80\n",
      "loss: 0.0947, last_20: 0.171, lr: 0.0001, epoch: 9/25, step: 39/80\n",
      "loss: 0.022, last_20: 0.1676, lr: 0.0001, epoch: 9/25, step: 40/80\n",
      "loss: 0.0023, last_20: 0.1614, lr: 0.0001, epoch: 9/25, step: 41/80\n",
      "loss: 0.345, last_20: 0.1762, lr: 0.0001, epoch: 9/25, step: 42/80\n",
      "loss: 0.084, last_20: 0.1668, lr: 0.0001, epoch: 9/25, step: 43/80\n",
      "loss: 0.4153, last_20: 0.185, lr: 0.0001, epoch: 9/25, step: 44/80\n",
      "loss: 0.0918, last_20: 0.183, lr: 0.0001, epoch: 9/25, step: 45/80\n",
      "loss: 0.0201, last_20: 0.1659, lr: 0.0001, epoch: 9/25, step: 46/80\n",
      "loss: 0.0029, last_20: 0.1363, lr: 0.0001, epoch: 9/25, step: 47/80\n",
      "loss: 0.1099, last_20: 0.1128, lr: 0.0001, epoch: 9/25, step: 48/80\n",
      "loss: 0.1766, last_20: 0.1044, lr: 0.0001, epoch: 9/25, step: 49/80\n",
      "loss: 0.0075, last_20: 0.1045, lr: 0.0001, epoch: 9/25, step: 50/80\n",
      "loss: 0.124, last_20: 0.1103, lr: 0.0001, epoch: 9/25, step: 51/80\n",
      "loss: 0.2551, last_20: 0.1184, lr: 0.0001, epoch: 9/25, step: 52/80\n",
      "loss: 0.0277, last_20: 0.1097, lr: 0.0001, epoch: 9/25, step: 53/80\n",
      "loss: 0.2327, last_20: 0.1153, lr: 0.0001, epoch: 9/25, step: 54/80\n",
      "loss: 0.4612, last_20: 0.1376, lr: 0.0001, epoch: 9/25, step: 55/80\n",
      "loss: 0.0048, last_20: 0.1291, lr: 0.0001, epoch: 9/25, step: 56/80\n",
      "loss: 0.9702, last_20: 0.1763, lr: 0.0001, epoch: 9/25, step: 57/80\n",
      "loss: 0.3928, last_20: 0.192, lr: 0.0001, epoch: 9/25, step: 58/80\n",
      "loss: 0.0227, last_20: 0.1884, lr: 0.0001, epoch: 9/25, step: 59/80\n",
      "loss: 0.0199, last_20: 0.1883, lr: 0.0001, epoch: 9/25, step: 60/80\n",
      "loss: 0.0092, last_20: 0.1887, lr: 0.0001, epoch: 9/25, step: 61/80\n",
      "loss: 0.7212, last_20: 0.2075, lr: 0.0001, epoch: 9/25, step: 62/80\n",
      "loss: 0.3484, last_20: 0.2207, lr: 0.0001, epoch: 9/25, step: 63/80\n",
      "loss: 0.0034, last_20: 0.2001, lr: 0.0001, epoch: 9/25, step: 64/80\n",
      "loss: 0.3279, last_20: 0.2119, lr: 0.0001, epoch: 9/25, step: 65/80\n",
      "loss: 0.0028, last_20: 0.211, lr: 0.0001, epoch: 9/25, step: 66/80\n",
      "loss: 0.0183, last_20: 0.2118, lr: 0.0001, epoch: 9/25, step: 67/80\n",
      "loss: 0.0609, last_20: 0.2094, lr: 0.0001, epoch: 9/25, step: 68/80\n",
      "loss: 0.3213, last_20: 0.2166, lr: 0.0001, epoch: 9/25, step: 69/80\n",
      "loss: 0.0851, last_20: 0.2205, lr: 0.0001, epoch: 9/25, step: 70/80\n",
      "loss: 0.0827, last_20: 0.2184, lr: 0.0001, epoch: 9/25, step: 71/80\n",
      "loss: 0.005, last_20: 0.2059, lr: 0.0001, epoch: 9/25, step: 72/80\n",
      "loss: 0.1065, last_20: 0.2098, lr: 0.0001, epoch: 9/25, step: 73/80\n",
      "loss: 0.2612, last_20: 0.2113, lr: 0.0001, epoch: 9/25, step: 74/80\n",
      "loss: 0.0676, last_20: 0.1916, lr: 0.0001, epoch: 9/25, step: 75/80\n",
      "loss: 0.2374, last_20: 0.2032, lr: 0.0001, epoch: 9/25, step: 76/80\n",
      "loss: 0.8745, last_20: 0.1984, lr: 0.0001, epoch: 9/25, step: 77/80\n",
      "loss: 0.0034, last_20: 0.179, lr: 0.0001, epoch: 9/25, step: 78/80\n",
      "loss: 0.0094, last_20: 0.1783, lr: 0.0001, epoch: 9/25, step: 79/80\n",
      "loss: 0.0142, last_20: 0.178, lr: 0.0001, epoch: 9/25, step: 80/80\n",
      "loss: 0.4734, last_20: 0.2012, lr: 0.0001, epoch: 10/25, step: 1/80\n",
      "loss: 0.0081, last_20: 0.1656, lr: 0.0001, epoch: 10/25, step: 2/80\n",
      "loss: 0.3066, last_20: 0.1635, lr: 0.0001, epoch: 10/25, step: 3/80\n",
      "loss: 0.408, last_20: 0.1837, lr: 0.0001, epoch: 10/25, step: 4/80\n",
      "loss: 0.0393, last_20: 0.1693, lr: 0.0001, epoch: 10/25, step: 5/80\n",
      "loss: 0.0492, last_20: 0.1716, lr: 0.0001, epoch: 10/25, step: 6/80\n",
      "loss: 0.042, last_20: 0.1728, lr: 0.0001, epoch: 10/25, step: 7/80\n",
      "loss: 0.0923, last_20: 0.1744, lr: 0.0001, epoch: 10/25, step: 8/80\n",
      "loss: 0.0043, last_20: 0.1585, lr: 0.0001, epoch: 10/25, step: 9/80\n",
      "loss: 0.054, last_20: 0.157, lr: 0.0001, epoch: 10/25, step: 10/80\n",
      "loss: 0.0238, last_20: 0.154, lr: 0.0001, epoch: 10/25, step: 11/80\n",
      "loss: 0.2231, last_20: 0.1649, lr: 0.0001, epoch: 10/25, step: 12/80\n",
      "loss: 0.151, last_20: 0.1671, lr: 0.0001, epoch: 10/25, step: 13/80\n",
      "loss: 0.01, last_20: 0.1546, lr: 0.0001, epoch: 10/25, step: 14/80\n",
      "loss: 0.025, last_20: 0.1524, lr: 0.0001, epoch: 10/25, step: 15/80\n",
      "loss: 0.5674, last_20: 0.1689, lr: 0.0001, epoch: 10/25, step: 16/80\n",
      "loss: 0.0481, last_20: 0.1276, lr: 0.0001, epoch: 10/25, step: 17/80\n",
      "loss: 0.0597, last_20: 0.1304, lr: 0.0001, epoch: 10/25, step: 18/80\n",
      "loss: 0.0065, last_20: 0.1303, lr: 0.0001, epoch: 10/25, step: 19/80\n",
      "loss: 0.0451, last_20: 0.1318, lr: 0.0001, epoch: 10/25, step: 20/80\n",
      "loss: 0.395, last_20: 0.1279, lr: 0.0001, epoch: 10/25, step: 21/80\n",
      "loss: 0.1192, last_20: 0.1335, lr: 0.0001, epoch: 10/25, step: 22/80\n",
      "loss: 0.0142, last_20: 0.1189, lr: 0.0001, epoch: 10/25, step: 23/80\n",
      "loss: 0.0059, last_20: 0.0988, lr: 0.0001, epoch: 10/25, step: 24/80\n",
      "loss: 0.0206, last_20: 0.0978, lr: 0.0001, epoch: 10/25, step: 25/80\n",
      "loss: 0.4348, last_20: 0.1171, lr: 0.0001, epoch: 10/25, step: 26/80\n",
      "loss: 0.07, last_20: 0.1185, lr: 0.0001, epoch: 10/25, step: 27/80\n",
      "loss: 0.1594, last_20: 0.1219, lr: 0.0001, epoch: 10/25, step: 28/80\n",
      "loss: 0.2681, last_20: 0.135, lr: 0.0001, epoch: 10/25, step: 29/80\n",
      "loss: 0.0533, last_20: 0.135, lr: 0.0001, epoch: 10/25, step: 30/80\n",
      "loss: 0.0091, last_20: 0.1343, lr: 0.0001, epoch: 10/25, step: 31/80\n",
      "loss: 0.3047, last_20: 0.1384, lr: 0.0001, epoch: 10/25, step: 32/80\n",
      "loss: 0.281, last_20: 0.1449, lr: 0.0001, epoch: 10/25, step: 33/80\n",
      "loss: 0.0103, last_20: 0.1449, lr: 0.0001, epoch: 10/25, step: 34/80\n",
      "loss: 0.0268, last_20: 0.145, lr: 0.0001, epoch: 10/25, step: 35/80\n",
      "loss: 0.1868, last_20: 0.1259, lr: 0.0001, epoch: 10/25, step: 36/80\n",
      "loss: 0.397, last_20: 0.1434, lr: 0.0001, epoch: 10/25, step: 37/80\n",
      "loss: 0.2942, last_20: 0.1551, lr: 0.0001, epoch: 10/25, step: 38/80\n",
      "loss: 0.0244, last_20: 0.156, lr: 0.0001, epoch: 10/25, step: 39/80\n",
      "loss: 0.0657, last_20: 0.157, lr: 0.0001, epoch: 10/25, step: 40/80\n",
      "loss: 0.0041, last_20: 0.1375, lr: 0.0001, epoch: 10/25, step: 41/80\n",
      "loss: 0.3357, last_20: 0.1483, lr: 0.0001, epoch: 10/25, step: 42/80\n",
      "loss: 0.4773, last_20: 0.1715, lr: 0.0001, epoch: 10/25, step: 43/80\n",
      "loss: 0.012, last_20: 0.1718, lr: 0.0001, epoch: 10/25, step: 44/80\n",
      "loss: 0.0078, last_20: 0.1711, lr: 0.0001, epoch: 10/25, step: 45/80\n",
      "loss: 0.0066, last_20: 0.1497, lr: 0.0001, epoch: 10/25, step: 46/80\n",
      "loss: 0.0658, last_20: 0.1495, lr: 0.0001, epoch: 10/25, step: 47/80\n",
      "loss: 0.4932, last_20: 0.1662, lr: 0.0001, epoch: 10/25, step: 48/80\n",
      "loss: 0.5737, last_20: 0.1815, lr: 0.0001, epoch: 10/25, step: 49/80\n",
      "loss: 0.8193, last_20: 0.2198, lr: 0.0001, epoch: 10/25, step: 50/80\n",
      "loss: 0.332, last_20: 0.2359, lr: 0.0001, epoch: 10/25, step: 51/80\n",
      "loss: 0.1718, last_20: 0.2293, lr: 0.0001, epoch: 10/25, step: 52/80\n",
      "loss: 0.2498, last_20: 0.2277, lr: 0.0001, epoch: 10/25, step: 53/80\n",
      "loss: 0.1945, last_20: 0.2369, lr: 0.0001, epoch: 10/25, step: 54/80\n",
      "loss: 0.2566, last_20: 0.2484, lr: 0.0001, epoch: 10/25, step: 55/80\n",
      "loss: 0.0059, last_20: 0.2394, lr: 0.0001, epoch: 10/25, step: 56/80\n",
      "loss: 0.0197, last_20: 0.2205, lr: 0.0001, epoch: 10/25, step: 57/80\n",
      "loss: 0.1063, last_20: 0.2111, lr: 0.0001, epoch: 10/25, step: 58/80\n",
      "loss: 0.0174, last_20: 0.2108, lr: 0.0001, epoch: 10/25, step: 59/80\n",
      "loss: 0.0134, last_20: 0.2081, lr: 0.0001, epoch: 10/25, step: 60/80\n",
      "loss: 0.5762, last_20: 0.2368, lr: 0.0001, epoch: 10/25, step: 61/80\n",
      "loss: 0.0163, last_20: 0.2208, lr: 0.0001, epoch: 10/25, step: 62/80\n",
      "loss: 0.3464, last_20: 0.2142, lr: 0.0001, epoch: 10/25, step: 63/80\n",
      "loss: 0.325, last_20: 0.2299, lr: 0.0001, epoch: 10/25, step: 64/80\n",
      "loss: 0.1664, last_20: 0.2378, lr: 0.0001, epoch: 10/25, step: 65/80\n",
      "loss: 0.0356, last_20: 0.2393, lr: 0.0001, epoch: 10/25, step: 66/80\n",
      "loss: 0.0239, last_20: 0.2372, lr: 0.0001, epoch: 10/25, step: 67/80\n",
      "loss: 0.0495, last_20: 0.215, lr: 0.0001, epoch: 10/25, step: 68/80\n",
      "loss: 0.052, last_20: 0.1889, lr: 0.0001, epoch: 10/25, step: 69/80\n",
      "loss: 0.0875, last_20: 0.1523, lr: 0.0001, epoch: 10/25, step: 70/80\n",
      "loss: 0.0261, last_20: 0.137, lr: 0.0001, epoch: 10/25, step: 71/80\n",
      "loss: 0.3577, last_20: 0.1463, lr: 0.0001, epoch: 10/25, step: 72/80\n",
      "loss: 0.2456, last_20: 0.1461, lr: 0.0001, epoch: 10/25, step: 73/80\n",
      "loss: 0.2957, last_20: 0.1512, lr: 0.0001, epoch: 10/25, step: 74/80\n",
      "loss: 0.0142, last_20: 0.139, lr: 0.0001, epoch: 10/25, step: 75/80\n",
      "loss: 0.6685, last_20: 0.1722, lr: 0.0001, epoch: 10/25, step: 76/80\n",
      "loss: 0.0048, last_20: 0.1714, lr: 0.0001, epoch: 10/25, step: 77/80\n",
      "loss: 0.0245, last_20: 0.1673, lr: 0.0001, epoch: 10/25, step: 78/80\n",
      "loss: 0.0206, last_20: 0.1675, lr: 0.0001, epoch: 10/25, step: 79/80\n",
      "loss: 0.0246, last_20: 0.1681, lr: 0.0001, epoch: 10/25, step: 80/80\n",
      "loss: 0.3718, last_20: 0.1578, lr: 0.0001, epoch: 11/25, step: 1/80\n",
      "loss: 0.103, last_20: 0.1622, lr: 0.0001, epoch: 11/25, step: 2/80\n",
      "loss: 0.0411, last_20: 0.1469, lr: 0.0001, epoch: 11/25, step: 3/80\n",
      "loss: 0.5928, last_20: 0.1603, lr: 0.0001, epoch: 11/25, step: 4/80\n",
      "loss: 0.0275, last_20: 0.1534, lr: 0.0001, epoch: 11/25, step: 5/80\n",
      "loss: 0.0202, last_20: 0.1526, lr: 0.0001, epoch: 11/25, step: 6/80\n",
      "loss: 0.003, last_20: 0.1515, lr: 0.0001, epoch: 11/25, step: 7/80\n",
      "loss: 0.0093, last_20: 0.1495, lr: 0.0001, epoch: 11/25, step: 8/80\n",
      "loss: 0.4661, last_20: 0.1702, lr: 0.0001, epoch: 11/25, step: 9/80\n",
      "loss: 0.0262, last_20: 0.1672, lr: 0.0001, epoch: 11/25, step: 10/80\n",
      "loss: 0.2148, last_20: 0.1766, lr: 0.0001, epoch: 11/25, step: 11/80\n",
      "loss: 0.0032, last_20: 0.1589, lr: 0.0001, epoch: 11/25, step: 12/80\n",
      "loss: 0.2048, last_20: 0.1568, lr: 0.0001, epoch: 11/25, step: 13/80\n",
      "loss: 0.3799, last_20: 0.161, lr: 0.0001, epoch: 11/25, step: 14/80\n",
      "loss: 0.8213, last_20: 0.2014, lr: 0.0001, epoch: 11/25, step: 15/80\n",
      "loss: 0.0699, last_20: 0.1715, lr: 0.0001, epoch: 11/25, step: 16/80\n",
      "loss: 0.2798, last_20: 0.1852, lr: 0.0001, epoch: 11/25, step: 17/80\n",
      "loss: 0.0456, last_20: 0.1863, lr: 0.0001, epoch: 11/25, step: 18/80\n",
      "loss: 0.0042, last_20: 0.1855, lr: 0.0001, epoch: 11/25, step: 19/80\n",
      "loss: 0.0582, last_20: 0.1871, lr: 0.0001, epoch: 11/25, step: 20/80\n",
      "loss: 0.1884, last_20: 0.178, lr: 0.0001, epoch: 11/25, step: 21/80\n",
      "loss: 0.4324, last_20: 0.1944, lr: 0.0001, epoch: 11/25, step: 22/80\n",
      "loss: 0.3225, last_20: 0.2085, lr: 0.0001, epoch: 11/25, step: 23/80\n",
      "loss: 0.0825, last_20: 0.183, lr: 0.0001, epoch: 11/25, step: 24/80\n",
      "loss: 0.0773, last_20: 0.1855, lr: 0.0001, epoch: 11/25, step: 25/80\n",
      "loss: 0.0053, last_20: 0.1847, lr: 0.0001, epoch: 11/25, step: 26/80\n",
      "loss: 0.4688, last_20: 0.208, lr: 0.0001, epoch: 11/25, step: 27/80\n",
      "loss: 0.2089, last_20: 0.218, lr: 0.0001, epoch: 11/25, step: 28/80\n",
      "loss: 0.9434, last_20: 0.2419, lr: 0.0001, epoch: 11/25, step: 29/80\n",
      "loss: 0.0132, last_20: 0.2412, lr: 0.0001, epoch: 11/25, step: 30/80\n",
      "loss: 0.0106, last_20: 0.231, lr: 0.0001, epoch: 11/25, step: 31/80\n",
      "loss: 0.0731, last_20: 0.2345, lr: 0.0001, epoch: 11/25, step: 32/80\n",
      "loss: 0.0831, last_20: 0.2284, lr: 0.0001, epoch: 11/25, step: 33/80\n",
      "loss: 0.0228, last_20: 0.2106, lr: 0.0001, epoch: 11/25, step: 34/80\n",
      "loss: 0.3235, last_20: 0.1857, lr: 0.0001, epoch: 11/25, step: 35/80\n",
      "loss: 0.5547, last_20: 0.2099, lr: 0.0001, epoch: 11/25, step: 36/80\n",
      "loss: 0.2632, last_20: 0.2091, lr: 0.0001, epoch: 11/25, step: 37/80\n",
      "loss: 0.076, last_20: 0.2106, lr: 0.0001, epoch: 11/25, step: 38/80\n",
      "loss: 0.2451, last_20: 0.2227, lr: 0.0001, epoch: 11/25, step: 39/80\n",
      "loss: 0.1301, last_20: 0.2262, lr: 0.0001, epoch: 11/25, step: 40/80\n",
      "loss: 0.707, last_20: 0.2522, lr: 0.0001, epoch: 11/25, step: 41/80\n",
      "loss: 0.584, last_20: 0.2598, lr: 0.0001, epoch: 11/25, step: 42/80\n",
      "loss: 0.1865, last_20: 0.253, lr: 0.0001, epoch: 11/25, step: 43/80\n",
      "loss: 0.405, last_20: 0.2691, lr: 0.0001, epoch: 11/25, step: 44/80\n",
      "loss: 0.2201, last_20: 0.2762, lr: 0.0001, epoch: 11/25, step: 45/80\n",
      "loss: 0.6431, last_20: 0.3081, lr: 0.0001, epoch: 11/25, step: 46/80\n",
      "loss: 0.0276, last_20: 0.2861, lr: 0.0001, epoch: 11/25, step: 47/80\n",
      "loss: 0.6753, last_20: 0.3094, lr: 0.0001, epoch: 11/25, step: 48/80\n",
      "loss: 0.0887, last_20: 0.2666, lr: 0.0001, epoch: 11/25, step: 49/80\n",
      "loss: 0.2085, last_20: 0.2764, lr: 0.0001, epoch: 11/25, step: 50/80\n",
      "loss: 0.1227, last_20: 0.282, lr: 0.0001, epoch: 11/25, step: 51/80\n",
      "loss: 0.8516, last_20: 0.3209, lr: 0.0001, epoch: 11/25, step: 52/80\n",
      "loss: 0.229, last_20: 0.3282, lr: 0.0001, epoch: 11/25, step: 53/80\n",
      "loss: 0.1479, last_20: 0.3345, lr: 0.0001, epoch: 11/25, step: 54/80\n",
      "loss: 0.2527, last_20: 0.3309, lr: 0.0001, epoch: 11/25, step: 55/80\n",
      "loss: 0.5015, last_20: 0.3283, lr: 0.0001, epoch: 11/25, step: 56/80\n",
      "loss: 0.018, last_20: 0.316, lr: 0.0001, epoch: 11/25, step: 57/80\n",
      "loss: 0.0807, last_20: 0.3163, lr: 0.0001, epoch: 11/25, step: 58/80\n",
      "loss: 0.7729, last_20: 0.3426, lr: 0.0001, epoch: 11/25, step: 59/80\n",
      "loss: 0.4075, last_20: 0.3565, lr: 0.0001, epoch: 11/25, step: 60/80\n",
      "loss: 0.0688, last_20: 0.3246, lr: 0.0001, epoch: 11/25, step: 61/80\n",
      "loss: 0.324, last_20: 0.3116, lr: 0.0001, epoch: 11/25, step: 62/80\n",
      "loss: 0.0163, last_20: 0.3031, lr: 0.0001, epoch: 11/25, step: 63/80\n",
      "loss: 0.0061, last_20: 0.2832, lr: 0.0001, epoch: 11/25, step: 64/80\n",
      "loss: 0.1897, last_20: 0.2816, lr: 0.0001, epoch: 11/25, step: 65/80\n",
      "loss: 0.0147, last_20: 0.2502, lr: 0.0001, epoch: 11/25, step: 66/80\n",
      "loss: 0.0154, last_20: 0.2496, lr: 0.0001, epoch: 11/25, step: 67/80\n",
      "loss: 0.0532, last_20: 0.2185, lr: 0.0001, epoch: 11/25, step: 68/80\n",
      "loss: 0.0023, last_20: 0.2142, lr: 0.0001, epoch: 11/25, step: 69/80\n",
      "loss: 0.0023, last_20: 0.2039, lr: 0.0001, epoch: 11/25, step: 70/80\n",
      "loss: 0.0901, last_20: 0.2022, lr: 0.0001, epoch: 11/25, step: 71/80\n",
      "loss: 0.0328, last_20: 0.1613, lr: 0.0001, epoch: 11/25, step: 72/80\n",
      "loss: 0.02, last_20: 0.1508, lr: 0.0001, epoch: 11/25, step: 73/80\n",
      "loss: 0.4702, last_20: 0.167, lr: 0.0001, epoch: 11/25, step: 74/80\n",
      "loss: 0.1365, last_20: 0.1612, lr: 0.0001, epoch: 11/25, step: 75/80\n",
      "loss: 0.0194, last_20: 0.137, lr: 0.0001, epoch: 11/25, step: 76/80\n",
      "loss: 0.0127, last_20: 0.1368, lr: 0.0001, epoch: 11/25, step: 77/80\n",
      "loss: 0.0833, last_20: 0.1369, lr: 0.0001, epoch: 11/25, step: 78/80\n",
      "loss: 0.0616, last_20: 0.1013, lr: 0.0001, epoch: 11/25, step: 79/80\n",
      "loss: 0.0686, last_20: 0.0844, lr: 0.0001, epoch: 11/25, step: 80/80\n",
      "loss: 0.0377, last_20: 0.0828, lr: 0.0001, epoch: 12/25, step: 1/80\n",
      "loss: 0.0423, last_20: 0.0688, lr: 0.0001, epoch: 12/25, step: 2/80\n",
      "loss: 0.2449, last_20: 0.0802, lr: 0.0001, epoch: 12/25, step: 3/80\n",
      "loss: 0.0529, last_20: 0.0825, lr: 0.0001, epoch: 12/25, step: 4/80\n",
      "loss: 0.1923, last_20: 0.0827, lr: 0.0001, epoch: 12/25, step: 5/80\n",
      "loss: 0.0275, last_20: 0.0833, lr: 0.0001, epoch: 12/25, step: 6/80\n",
      "loss: 0.0036, last_20: 0.0827, lr: 0.0001, epoch: 12/25, step: 7/80\n",
      "loss: 0.6768, last_20: 0.1139, lr: 0.0001, epoch: 12/25, step: 8/80\n",
      "loss: 0.4597, last_20: 0.1368, lr: 0.0001, epoch: 12/25, step: 9/80\n",
      "loss: 0.1808, last_20: 0.1457, lr: 0.0001, epoch: 12/25, step: 10/80\n",
      "loss: 0.0142, last_20: 0.1419, lr: 0.0001, epoch: 12/25, step: 11/80\n",
      "loss: 0.0762, last_20: 0.1441, lr: 0.0001, epoch: 12/25, step: 12/80\n",
      "loss: 0.0872, last_20: 0.1474, lr: 0.0001, epoch: 12/25, step: 13/80\n",
      "loss: 0.0292, last_20: 0.1254, lr: 0.0001, epoch: 12/25, step: 14/80\n",
      "loss: 0.0088, last_20: 0.119, lr: 0.0001, epoch: 12/25, step: 15/80\n",
      "loss: 0.1188, last_20: 0.124, lr: 0.0001, epoch: 12/25, step: 16/80\n",
      "loss: 0.7349, last_20: 0.1601, lr: 0.0001, epoch: 12/25, step: 17/80\n",
      "loss: 0.4695, last_20: 0.1794, lr: 0.0001, epoch: 12/25, step: 18/80\n",
      "loss: 0.4329, last_20: 0.1979, lr: 0.0001, epoch: 12/25, step: 19/80\n",
      "loss: 0.3076, last_20: 0.2099, lr: 0.0001, epoch: 12/25, step: 20/80\n",
      "loss: 0.7651, last_20: 0.2463, lr: 0.0001, epoch: 12/25, step: 21/80\n",
      "loss: 0.0406, last_20: 0.2462, lr: 0.0001, epoch: 12/25, step: 22/80\n",
      "loss: 0.3228, last_20: 0.2501, lr: 0.0001, epoch: 12/25, step: 23/80\n",
      "loss: 0.1295, last_20: 0.2539, lr: 0.0001, epoch: 12/25, step: 24/80\n",
      "loss: 0.8291, last_20: 0.2857, lr: 0.0001, epoch: 12/25, step: 25/80\n",
      "loss: 0.0116, last_20: 0.2849, lr: 0.0001, epoch: 12/25, step: 26/80\n",
      "loss: 0.2328, last_20: 0.2964, lr: 0.0001, epoch: 12/25, step: 27/80\n",
      "loss: 0.014, last_20: 0.2633, lr: 0.0001, epoch: 12/25, step: 28/80\n",
      "loss: 0.0154, last_20: 0.241, lr: 0.0001, epoch: 12/25, step: 29/80\n",
      "loss: 0.0032, last_20: 0.2322, lr: 0.0001, epoch: 12/25, step: 30/80\n",
      "loss: 0.0536, last_20: 0.2341, lr: 0.0001, epoch: 12/25, step: 31/80\n",
      "loss: 0.6152, last_20: 0.2611, lr: 0.0001, epoch: 12/25, step: 32/80\n",
      "loss: 0.0049, last_20: 0.257, lr: 0.0001, epoch: 12/25, step: 33/80\n",
      "loss: 0.3906, last_20: 0.275, lr: 0.0001, epoch: 12/25, step: 34/80\n",
      "loss: 0.0026, last_20: 0.2747, lr: 0.0001, epoch: 12/25, step: 35/80\n",
      "loss: 0.1798, last_20: 0.2778, lr: 0.0001, epoch: 12/25, step: 36/80\n",
      "loss: 0.918, last_20: 0.2869, lr: 0.0001, epoch: 12/25, step: 37/80\n",
      "loss: 0.0187, last_20: 0.2644, lr: 0.0001, epoch: 12/25, step: 38/80\n",
      "loss: 0.0046, last_20: 0.243, lr: 0.0001, epoch: 12/25, step: 39/80\n",
      "loss: 0.0029, last_20: 0.2278, lr: 0.0001, epoch: 12/25, step: 40/80\n",
      "loss: 0.0061, last_20: 0.1898, lr: 0.0001, epoch: 12/25, step: 41/80\n",
      "loss: 0.0029, last_20: 0.1879, lr: 0.0001, epoch: 12/25, step: 42/80\n",
      "loss: 0.6401, last_20: 0.2038, lr: 0.0001, epoch: 12/25, step: 43/80\n",
      "loss: 0.469, last_20: 0.2208, lr: 0.0001, epoch: 12/25, step: 44/80\n",
      "loss: 0.3359, last_20: 0.1961, lr: 0.0001, epoch: 12/25, step: 45/80\n",
      "loss: 0.0036, last_20: 0.1957, lr: 0.0001, epoch: 12/25, step: 46/80\n",
      "loss: 0.2654, last_20: 0.1973, lr: 0.0001, epoch: 12/25, step: 47/80\n",
      "loss: 0.2289, last_20: 0.2081, lr: 0.0001, epoch: 12/25, step: 48/80\n",
      "loss: 0.0062, last_20: 0.2076, lr: 0.0001, epoch: 12/25, step: 49/80\n",
      "loss: 0.4832, last_20: 0.2316, lr: 0.0001, epoch: 12/25, step: 50/80\n",
      "loss: 0.449, last_20: 0.2514, lr: 0.0001, epoch: 12/25, step: 51/80\n",
      "loss: 0.8145, last_20: 0.2613, lr: 0.0001, epoch: 12/25, step: 52/80\n",
      "loss: 0.2056, last_20: 0.2714, lr: 0.0001, epoch: 12/25, step: 53/80\n",
      "loss: 0.056, last_20: 0.2546, lr: 0.0001, epoch: 12/25, step: 54/80\n",
      "loss: 0.3279, last_20: 0.2709, lr: 0.0001, epoch: 12/25, step: 55/80\n",
      "loss: 0.3042, last_20: 0.2771, lr: 0.0001, epoch: 12/25, step: 56/80\n",
      "loss: 0.3555, last_20: 0.249, lr: 0.0001, epoch: 12/25, step: 57/80\n",
      "loss: 0.3694, last_20: 0.2665, lr: 0.0001, epoch: 12/25, step: 58/80\n",
      "loss: 0.005, last_20: 0.2666, lr: 0.0001, epoch: 12/25, step: 59/80\n",
      "loss: 0.9126, last_20: 0.312, lr: 0.0001, epoch: 12/25, step: 60/80\n",
      "loss: 0.0334, last_20: 0.3134, lr: 0.0001, epoch: 12/25, step: 61/80\n",
      "loss: 0.05, last_20: 0.3158, lr: 0.0001, epoch: 12/25, step: 62/80\n",
      "loss: 0.0514, last_20: 0.2863, lr: 0.0001, epoch: 12/25, step: 63/80\n",
      "loss: 0.0152, last_20: 0.2636, lr: 0.0001, epoch: 12/25, step: 64/80\n",
      "loss: 0.1271, last_20: 0.2532, lr: 0.0001, epoch: 12/25, step: 65/80\n",
      "loss: 0.0022, last_20: 0.2531, lr: 0.0001, epoch: 12/25, step: 66/80\n",
      "loss: 0.0227, last_20: 0.241, lr: 0.0001, epoch: 12/25, step: 67/80\n",
      "loss: 0.2114, last_20: 0.2401, lr: 0.0001, epoch: 12/25, step: 68/80\n",
      "loss: 0.0206, last_20: 0.2408, lr: 0.0001, epoch: 12/25, step: 69/80\n",
      "loss: 0.1237, last_20: 0.2229, lr: 0.0001, epoch: 12/25, step: 70/80\n",
      "loss: 0.1761, last_20: 0.2092, lr: 0.0001, epoch: 12/25, step: 71/80\n",
      "loss: 0.6333, last_20: 0.2002, lr: 0.0001, epoch: 12/25, step: 72/80\n",
      "loss: 0.0032, last_20: 0.19, lr: 0.0001, epoch: 12/25, step: 73/80\n",
      "loss: 0.4644, last_20: 0.2105, lr: 0.0001, epoch: 12/25, step: 74/80\n",
      "loss: 0.0098, last_20: 0.1946, lr: 0.0001, epoch: 12/25, step: 75/80\n",
      "loss: 0.0498, last_20: 0.1818, lr: 0.0001, epoch: 12/25, step: 76/80\n",
      "loss: 0.0251, last_20: 0.1653, lr: 0.0001, epoch: 12/25, step: 77/80\n",
      "loss: 0.235, last_20: 0.1586, lr: 0.0001, epoch: 12/25, step: 78/80\n",
      "loss: 0.0029, last_20: 0.1585, lr: 0.0001, epoch: 12/25, step: 79/80\n",
      "loss: 0.0242, last_20: 0.1141, lr: 0.0001, epoch: 12/25, step: 80/80\n",
      "loss: 0.0861, last_20: 0.1167, lr: 0.0001, epoch: 13/25, step: 1/80\n",
      "loss: 0.2238, last_20: 0.1254, lr: 0.0001, epoch: 13/25, step: 2/80\n",
      "loss: 0.291, last_20: 0.1374, lr: 0.0001, epoch: 13/25, step: 3/80\n",
      "loss: 0.0059, last_20: 0.1369, lr: 0.0001, epoch: 13/25, step: 4/80\n",
      "loss: 0.0023, last_20: 0.1307, lr: 0.0001, epoch: 13/25, step: 5/80\n",
      "loss: 0.0263, last_20: 0.1319, lr: 0.0001, epoch: 13/25, step: 6/80\n",
      "loss: 0.2673, last_20: 0.1441, lr: 0.0001, epoch: 13/25, step: 7/80\n",
      "loss: 0.16, last_20: 0.1415, lr: 0.0001, epoch: 13/25, step: 8/80\n",
      "loss: 0.207, last_20: 0.1509, lr: 0.0001, epoch: 13/25, step: 9/80\n",
      "loss: 0.0657, last_20: 0.148, lr: 0.0001, epoch: 13/25, step: 10/80\n",
      "loss: 0.0895, last_20: 0.1436, lr: 0.0001, epoch: 13/25, step: 11/80\n",
      "loss: 0.1887, last_20: 0.1214, lr: 0.0001, epoch: 13/25, step: 12/80\n",
      "loss: 0.1401, last_20: 0.1282, lr: 0.0001, epoch: 13/25, step: 13/80\n",
      "loss: 0.0109, last_20: 0.1056, lr: 0.0001, epoch: 13/25, step: 14/80\n",
      "loss: 0.6353, last_20: 0.1368, lr: 0.0001, epoch: 13/25, step: 15/80\n",
      "loss: 0.0141, last_20: 0.1351, lr: 0.0001, epoch: 13/25, step: 16/80\n",
      "loss: 0.1274, last_20: 0.1402, lr: 0.0001, epoch: 13/25, step: 17/80\n",
      "loss: 0.0207, last_20: 0.1295, lr: 0.0001, epoch: 13/25, step: 18/80\n",
      "loss: 0.4863, last_20: 0.1536, lr: 0.0001, epoch: 13/25, step: 19/80\n",
      "loss: 0.0446, last_20: 0.1547, lr: 0.0001, epoch: 13/25, step: 20/80\n",
      "loss: 0.0027, last_20: 0.1505, lr: 0.0001, epoch: 13/25, step: 21/80\n",
      "loss: 0.0212, last_20: 0.1404, lr: 0.0001, epoch: 13/25, step: 22/80\n",
      "loss: 0.244, last_20: 0.138, lr: 0.0001, epoch: 13/25, step: 23/80\n",
      "loss: 0.0265, last_20: 0.139, lr: 0.0001, epoch: 13/25, step: 24/80\n",
      "loss: 0.0518, last_20: 0.1415, lr: 0.0001, epoch: 13/25, step: 25/80\n",
      "loss: 0.1476, last_20: 0.1476, lr: 0.0001, epoch: 13/25, step: 26/80\n",
      "loss: 0.3843, last_20: 0.1534, lr: 0.0001, epoch: 13/25, step: 27/80\n",
      "loss: 0.0119, last_20: 0.146, lr: 0.0001, epoch: 13/25, step: 28/80\n",
      "loss: 0.1805, last_20: 0.1447, lr: 0.0001, epoch: 13/25, step: 29/80\n",
      "loss: 0.0044, last_20: 0.1416, lr: 0.0001, epoch: 13/25, step: 30/80\n",
      "loss: 0.1057, last_20: 0.1424, lr: 0.0001, epoch: 13/25, step: 31/80\n",
      "loss: 0.0992, last_20: 0.138, lr: 0.0001, epoch: 13/25, step: 32/80\n",
      "loss: 0.0028, last_20: 0.1311, lr: 0.0001, epoch: 13/25, step: 33/80\n",
      "loss: 0.0594, last_20: 0.1335, lr: 0.0001, epoch: 13/25, step: 34/80\n",
      "loss: 0.0181, last_20: 0.1027, lr: 0.0001, epoch: 13/25, step: 35/80\n",
      "loss: 0.5981, last_20: 0.1319, lr: 0.0001, epoch: 13/25, step: 36/80\n",
      "loss: 0.0778, last_20: 0.1294, lr: 0.0001, epoch: 13/25, step: 37/80\n",
      "loss: 0.0806, last_20: 0.1324, lr: 0.0001, epoch: 13/25, step: 38/80\n",
      "loss: 0.3533, last_20: 0.1257, lr: 0.0001, epoch: 13/25, step: 39/80\n",
      "loss: 0.0837, last_20: 0.1277, lr: 0.0001, epoch: 13/25, step: 40/80\n",
      "loss: 0.1757, last_20: 0.1363, lr: 0.0001, epoch: 13/25, step: 41/80\n",
      "loss: 0.2986, last_20: 0.1502, lr: 0.0001, epoch: 13/25, step: 42/80\n",
      "loss: 0.0307, last_20: 0.1395, lr: 0.0001, epoch: 13/25, step: 43/80\n",
      "loss: 0.731, last_20: 0.1748, lr: 0.0001, epoch: 13/25, step: 44/80\n",
      "loss: 0.0067, last_20: 0.1725, lr: 0.0001, epoch: 13/25, step: 45/80\n",
      "loss: 0.1241, last_20: 0.1713, lr: 0.0001, epoch: 13/25, step: 46/80\n",
      "loss: 0.0876, last_20: 0.1565, lr: 0.0001, epoch: 13/25, step: 47/80\n",
      "loss: 0.121, last_20: 0.1619, lr: 0.0001, epoch: 13/25, step: 48/80\n",
      "loss: 0.0108, last_20: 0.1535, lr: 0.0001, epoch: 13/25, step: 49/80\n",
      "loss: 0.4216, last_20: 0.1743, lr: 0.0001, epoch: 13/25, step: 50/80\n",
      "loss: 0.1786, last_20: 0.178, lr: 0.0001, epoch: 13/25, step: 51/80\n",
      "loss: 0.6592, last_20: 0.206, lr: 0.0001, epoch: 13/25, step: 52/80\n",
      "loss: 0.6812, last_20: 0.2399, lr: 0.0001, epoch: 13/25, step: 53/80\n",
      "loss: 0.7588, last_20: 0.2749, lr: 0.0001, epoch: 13/25, step: 54/80\n",
      "loss: 0.835, last_20: 0.3157, lr: 0.0001, epoch: 13/25, step: 55/80\n",
      "loss: 0.25, last_20: 0.2983, lr: 0.0001, epoch: 13/25, step: 56/80\n",
      "loss: 0.4087, last_20: 0.3148, lr: 0.0001, epoch: 13/25, step: 57/80\n",
      "loss: 0.0344, last_20: 0.3125, lr: 0.0001, epoch: 13/25, step: 58/80\n",
      "loss: 0.0511, last_20: 0.2974, lr: 0.0001, epoch: 13/25, step: 59/80\n",
      "loss: 0.1554, last_20: 0.301, lr: 0.0001, epoch: 13/25, step: 60/80\n",
      "loss: 0.2009, last_20: 0.3023, lr: 0.0001, epoch: 13/25, step: 61/80\n",
      "loss: 0.209, last_20: 0.2978, lr: 0.0001, epoch: 13/25, step: 62/80\n",
      "loss: 0.1247, last_20: 0.3025, lr: 0.0001, epoch: 13/25, step: 63/80\n",
      "loss: 0.5718, last_20: 0.2945, lr: 0.0001, epoch: 13/25, step: 64/80\n",
      "loss: 0.2925, last_20: 0.3088, lr: 0.0001, epoch: 13/25, step: 65/80\n",
      "loss: 0.0844, last_20: 0.3068, lr: 0.0001, epoch: 13/25, step: 66/80\n",
      "loss: 0.2976, last_20: 0.3173, lr: 0.0001, epoch: 13/25, step: 67/80\n",
      "loss: 0.2278, last_20: 0.3227, lr: 0.0001, epoch: 13/25, step: 68/80\n",
      "loss: 0.1282, last_20: 0.3285, lr: 0.0001, epoch: 13/25, step: 69/80\n",
      "loss: 0.1247, last_20: 0.3137, lr: 0.0001, epoch: 13/25, step: 70/80\n",
      "loss: 0.8931, last_20: 0.3494, lr: 0.0001, epoch: 13/25, step: 71/80\n",
      "loss: 0.4536, last_20: 0.3391, lr: 0.0001, epoch: 13/25, step: 72/80\n",
      "loss: 0.0623, last_20: 0.3082, lr: 0.0001, epoch: 13/25, step: 73/80\n",
      "loss: 0.0039, last_20: 0.2705, lr: 0.0001, epoch: 13/25, step: 74/80\n",
      "loss: 0.0981, last_20: 0.2336, lr: 0.0001, epoch: 13/25, step: 75/80\n",
      "loss: 0.1653, last_20: 0.2294, lr: 0.0001, epoch: 13/25, step: 76/80\n",
      "loss: 0.3508, last_20: 0.2265, lr: 0.0001, epoch: 13/25, step: 77/80\n",
      "loss: 0.0222, last_20: 0.2259, lr: 0.0001, epoch: 13/25, step: 78/80\n",
      "loss: 0.0807, last_20: 0.2274, lr: 0.0001, epoch: 13/25, step: 79/80\n",
      "loss: 0.0583, last_20: 0.2225, lr: 0.0001, epoch: 13/25, step: 80/80\n",
      "loss: 0.4609, last_20: 0.2355, lr: 0.0001, epoch: 14/25, step: 1/80\n",
      "loss: 0.1624, last_20: 0.2332, lr: 0.0001, epoch: 14/25, step: 2/80\n",
      "loss: 0.4355, last_20: 0.2487, lr: 0.0001, epoch: 14/25, step: 3/80\n",
      "loss: 0.3508, last_20: 0.2377, lr: 0.0001, epoch: 14/25, step: 4/80\n",
      "loss: 0.0064, last_20: 0.2233, lr: 0.0001, epoch: 14/25, step: 5/80\n",
      "loss: 0.3958, last_20: 0.2389, lr: 0.0001, epoch: 14/25, step: 6/80\n",
      "loss: 0.0099, last_20: 0.2245, lr: 0.0001, epoch: 14/25, step: 7/80\n",
      "loss: 0.2654, last_20: 0.2264, lr: 0.0001, epoch: 14/25, step: 8/80\n",
      "loss: 0.0538, last_20: 0.2227, lr: 0.0001, epoch: 14/25, step: 9/80\n",
      "loss: 0.4211, last_20: 0.2375, lr: 0.0001, epoch: 14/25, step: 10/80\n",
      "loss: 0.07, last_20: 0.1964, lr: 0.0001, epoch: 14/25, step: 11/80\n",
      "loss: 0.0086, last_20: 0.1741, lr: 0.0001, epoch: 14/25, step: 12/80\n",
      "loss: 0.1183, last_20: 0.1769, lr: 0.0001, epoch: 14/25, step: 13/80\n",
      "loss: 0.2256, last_20: 0.188, lr: 0.0001, epoch: 14/25, step: 14/80\n",
      "loss: 0.0163, last_20: 0.1839, lr: 0.0001, epoch: 14/25, step: 15/80\n",
      "loss: 0.2208, last_20: 0.1867, lr: 0.0001, epoch: 14/25, step: 16/80\n",
      "loss: 0.3425, last_20: 0.1863, lr: 0.0001, epoch: 14/25, step: 17/80\n",
      "loss: 0.1508, last_20: 0.1927, lr: 0.0001, epoch: 14/25, step: 18/80\n",
      "loss: 0.0257, last_20: 0.1899, lr: 0.0001, epoch: 14/25, step: 19/80\n",
      "loss: 0.0523, last_20: 0.1896, lr: 0.0001, epoch: 14/25, step: 20/80\n",
      "loss: 0.0199, last_20: 0.1676, lr: 0.0001, epoch: 14/25, step: 21/80\n",
      "loss: 0.2351, last_20: 0.1712, lr: 0.0001, epoch: 14/25, step: 22/80\n",
      "loss: 0.0352, last_20: 0.1512, lr: 0.0001, epoch: 14/25, step: 23/80\n",
      "loss: 0.0087, last_20: 0.1341, lr: 0.0001, epoch: 14/25, step: 24/80\n",
      "loss: 0.0086, last_20: 0.1342, lr: 0.0001, epoch: 14/25, step: 25/80\n",
      "loss: 0.304, last_20: 0.1296, lr: 0.0001, epoch: 14/25, step: 26/80\n",
      "loss: 0.004, last_20: 0.1293, lr: 0.0001, epoch: 14/25, step: 27/80\n",
      "loss: 0.5752, last_20: 0.1448, lr: 0.0001, epoch: 14/25, step: 28/80\n",
      "loss: 0.1105, last_20: 0.1477, lr: 0.0001, epoch: 14/25, step: 29/80\n",
      "loss: 0.1747, last_20: 0.1353, lr: 0.0001, epoch: 14/25, step: 30/80\n",
      "loss: 0.6133, last_20: 0.1625, lr: 0.0001, epoch: 14/25, step: 31/80\n",
      "loss: 0.3057, last_20: 0.1774, lr: 0.0001, epoch: 14/25, step: 32/80\n",
      "loss: 0.259, last_20: 0.1844, lr: 0.0001, epoch: 14/25, step: 33/80\n",
      "loss: 0.0721, last_20: 0.1767, lr: 0.0001, epoch: 14/25, step: 34/80\n",
      "loss: 0.6265, last_20: 0.2072, lr: 0.0001, epoch: 14/25, step: 35/80\n",
      "loss: 0.1807, last_20: 0.2052, lr: 0.0001, epoch: 14/25, step: 36/80\n",
      "loss: 0.0672, last_20: 0.1915, lr: 0.0001, epoch: 14/25, step: 37/80\n",
      "loss: 0.1322, last_20: 0.1905, lr: 0.0001, epoch: 14/25, step: 38/80\n",
      "loss: 0.4558, last_20: 0.212, lr: 0.0001, epoch: 14/25, step: 39/80\n",
      "loss: 0.2164, last_20: 0.2202, lr: 0.0001, epoch: 14/25, step: 40/80\n",
      "loss: 0.032, last_20: 0.2208, lr: 0.0001, epoch: 14/25, step: 41/80\n",
      "loss: 0.0265, last_20: 0.2104, lr: 0.0001, epoch: 14/25, step: 42/80\n",
      "loss: 0.2183, last_20: 0.2196, lr: 0.0001, epoch: 14/25, step: 43/80\n",
      "loss: 0.046, last_20: 0.2214, lr: 0.0001, epoch: 14/25, step: 44/80\n",
      "loss: 0.3, last_20: 0.236, lr: 0.0001, epoch: 14/25, step: 45/80\n",
      "loss: 0.1252, last_20: 0.2271, lr: 0.0001, epoch: 14/25, step: 46/80\n",
      "loss: 0.2313, last_20: 0.2384, lr: 0.0001, epoch: 14/25, step: 47/80\n",
      "loss: 0.4941, last_20: 0.2344, lr: 0.0001, epoch: 14/25, step: 48/80\n",
      "loss: 0.2159, last_20: 0.2396, lr: 0.0001, epoch: 14/25, step: 49/80\n",
      "loss: 0.2805, last_20: 0.2449, lr: 0.0001, epoch: 14/25, step: 50/80\n",
      "loss: 0.0051, last_20: 0.2145, lr: 0.0001, epoch: 14/25, step: 51/80\n",
      "loss: 0.0116, last_20: 0.1998, lr: 0.0001, epoch: 14/25, step: 52/80\n",
      "loss: 0.0246, last_20: 0.1881, lr: 0.0001, epoch: 14/25, step: 53/80\n",
      "loss: 0.0084, last_20: 0.1849, lr: 0.0001, epoch: 14/25, step: 54/80\n",
      "loss: 0.004, last_20: 0.1538, lr: 0.0001, epoch: 14/25, step: 55/80\n",
      "loss: 0.008, last_20: 0.1452, lr: 0.0001, epoch: 14/25, step: 56/80\n",
      "loss: 0.2034, last_20: 0.152, lr: 0.0001, epoch: 14/25, step: 57/80\n",
      "loss: 0.3813, last_20: 0.1644, lr: 0.0001, epoch: 14/25, step: 58/80\n",
      "loss: 0.1003, last_20: 0.1466, lr: 0.0001, epoch: 14/25, step: 59/80\n",
      "loss: 0.2979, last_20: 0.1507, lr: 0.0001, epoch: 14/25, step: 60/80\n",
      "loss: 0.3125, last_20: 0.1647, lr: 0.0001, epoch: 14/25, step: 61/80\n",
      "loss: 0.3782, last_20: 0.1823, lr: 0.0001, epoch: 14/25, step: 62/80\n",
      "loss: 0.1108, last_20: 0.177, lr: 0.0001, epoch: 14/25, step: 63/80\n",
      "loss: 0.0032, last_20: 0.1748, lr: 0.0001, epoch: 14/25, step: 64/80\n",
      "loss: 0.0669, last_20: 0.1632, lr: 0.0001, epoch: 14/25, step: 65/80\n",
      "loss: 0.6426, last_20: 0.189, lr: 0.0001, epoch: 14/25, step: 66/80\n",
      "loss: 0.0115, last_20: 0.178, lr: 0.0001, epoch: 14/25, step: 67/80\n",
      "loss: 0.0083, last_20: 0.1537, lr: 0.0001, epoch: 14/25, step: 68/80\n",
      "loss: 0.4287, last_20: 0.1644, lr: 0.0001, epoch: 14/25, step: 69/80\n",
      "loss: 0.192, last_20: 0.16, lr: 0.0001, epoch: 14/25, step: 70/80\n",
      "loss: 0.4211, last_20: 0.1808, lr: 0.0001, epoch: 14/25, step: 71/80\n",
      "loss: 0.5327, last_20: 0.2068, lr: 0.0001, epoch: 14/25, step: 72/80\n",
      "loss: 0.4482, last_20: 0.228, lr: 0.0001, epoch: 14/25, step: 73/80\n",
      "loss: 0.0057, last_20: 0.2279, lr: 0.0001, epoch: 14/25, step: 74/80\n",
      "loss: 0.0471, last_20: 0.23, lr: 0.0001, epoch: 14/25, step: 75/80\n",
      "loss: 0.0121, last_20: 0.2302, lr: 0.0001, epoch: 14/25, step: 76/80\n",
      "loss: 0.3628, last_20: 0.2382, lr: 0.0001, epoch: 14/25, step: 77/80\n",
      "loss: 0.1473, last_20: 0.2265, lr: 0.0001, epoch: 14/25, step: 78/80\n",
      "loss: 0.1801, last_20: 0.2305, lr: 0.0001, epoch: 14/25, step: 79/80\n",
      "loss: 0.8652, last_20: 0.2589, lr: 0.0001, epoch: 14/25, step: 80/80\n",
      "loss: 0.016, last_20: 0.244, lr: 0.0001, epoch: 15/25, step: 1/80\n",
      "loss: 0.6177, last_20: 0.256, lr: 0.0001, epoch: 15/25, step: 2/80\n",
      "loss: 0.0052, last_20: 0.2507, lr: 0.0001, epoch: 15/25, step: 3/80\n",
      "loss: 0.0215, last_20: 0.2516, lr: 0.0001, epoch: 15/25, step: 4/80\n",
      "loss: 0.4229, last_20: 0.2694, lr: 0.0001, epoch: 15/25, step: 5/80\n",
      "loss: 0.3386, last_20: 0.2542, lr: 0.0001, epoch: 15/25, step: 6/80\n",
      "loss: 0.4543, last_20: 0.2764, lr: 0.0001, epoch: 15/25, step: 7/80\n",
      "loss: 0.0079, last_20: 0.2764, lr: 0.0001, epoch: 15/25, step: 8/80\n",
      "loss: 0.0023, last_20: 0.255, lr: 0.0001, epoch: 15/25, step: 9/80\n",
      "loss: 0.0499, last_20: 0.2479, lr: 0.0001, epoch: 15/25, step: 10/80\n",
      "loss: 0.0092, last_20: 0.2273, lr: 0.0001, epoch: 15/25, step: 11/80\n",
      "loss: 0.0089, last_20: 0.2011, lr: 0.0001, epoch: 15/25, step: 12/80\n",
      "loss: 0.0059, last_20: 0.179, lr: 0.0001, epoch: 15/25, step: 13/80\n",
      "loss: 0.087, last_20: 0.1831, lr: 0.0001, epoch: 15/25, step: 14/80\n",
      "loss: 0.0263, last_20: 0.1821, lr: 0.0001, epoch: 15/25, step: 15/80\n",
      "loss: 0.1583, last_20: 0.1894, lr: 0.0001, epoch: 15/25, step: 16/80\n",
      "loss: 0.1788, last_20: 0.1802, lr: 0.0001, epoch: 15/25, step: 17/80\n",
      "loss: 0.0149, last_20: 0.1735, lr: 0.0001, epoch: 15/25, step: 18/80\n",
      "loss: 0.0437, last_20: 0.1667, lr: 0.0001, epoch: 15/25, step: 19/80\n",
      "loss: 0.0721, last_20: 0.1271, lr: 0.0001, epoch: 15/25, step: 20/80\n",
      "loss: 0.2573, last_20: 0.1391, lr: 0.0001, epoch: 15/25, step: 21/80\n",
      "loss: 0.1616, last_20: 0.1163, lr: 0.0001, epoch: 15/25, step: 22/80\n",
      "loss: 0.2051, last_20: 0.1263, lr: 0.0001, epoch: 15/25, step: 23/80\n",
      "loss: 0.0148, last_20: 0.126, lr: 0.0001, epoch: 15/25, step: 24/80\n",
      "loss: 0.4041, last_20: 0.1251, lr: 0.0001, epoch: 15/25, step: 25/80\n",
      "loss: 0.4185, last_20: 0.129, lr: 0.0001, epoch: 15/25, step: 26/80\n",
      "loss: 0.0245, last_20: 0.1076, lr: 0.0001, epoch: 15/25, step: 27/80\n",
      "loss: 0.0966, last_20: 0.112, lr: 0.0001, epoch: 15/25, step: 28/80\n",
      "loss: 0.0041, last_20: 0.1121, lr: 0.0001, epoch: 15/25, step: 29/80\n",
      "loss: 0.0777, last_20: 0.1135, lr: 0.0001, epoch: 15/25, step: 30/80\n",
      "loss: 0.0038, last_20: 0.1132, lr: 0.0001, epoch: 15/25, step: 31/80\n",
      "loss: 0.208, last_20: 0.1232, lr: 0.0001, epoch: 15/25, step: 32/80\n",
      "loss: 0.0631, last_20: 0.126, lr: 0.0001, epoch: 15/25, step: 33/80\n",
      "loss: 0.3655, last_20: 0.1399, lr: 0.0001, epoch: 15/25, step: 34/80\n",
      "loss: 0.0487, last_20: 0.1411, lr: 0.0001, epoch: 15/25, step: 35/80\n",
      "loss: 0.2054, last_20: 0.1434, lr: 0.0001, epoch: 15/25, step: 36/80\n",
      "loss: 0.2637, last_20: 0.1477, lr: 0.0001, epoch: 15/25, step: 37/80\n",
      "loss: 0.2025, last_20: 0.157, lr: 0.0001, epoch: 15/25, step: 38/80\n",
      "loss: 0.2399, last_20: 0.1669, lr: 0.0001, epoch: 15/25, step: 39/80\n",
      "loss: 0.647, last_20: 0.1956, lr: 0.0001, epoch: 15/25, step: 40/80\n",
      "loss: 0.016, last_20: 0.1835, lr: 0.0001, epoch: 15/25, step: 41/80\n",
      "loss: 0.0716, last_20: 0.179, lr: 0.0001, epoch: 15/25, step: 42/80\n",
      "loss: 0.0178, last_20: 0.1697, lr: 0.0001, epoch: 15/25, step: 43/80\n",
      "loss: 0.1455, last_20: 0.1762, lr: 0.0001, epoch: 15/25, step: 44/80\n",
      "loss: 0.0674, last_20: 0.1594, lr: 0.0001, epoch: 15/25, step: 45/80\n",
      "loss: 0.1603, last_20: 0.1465, lr: 0.0001, epoch: 15/25, step: 46/80\n",
      "loss: 0.6489, last_20: 0.1777, lr: 0.0001, epoch: 15/25, step: 47/80\n",
      "loss: 0.0254, last_20: 0.1741, lr: 0.0001, epoch: 15/25, step: 48/80\n",
      "loss: 0.0197, last_20: 0.1749, lr: 0.0001, epoch: 15/25, step: 49/80\n",
      "loss: 0.0058, last_20: 0.1713, lr: 0.0001, epoch: 15/25, step: 50/80\n",
      "loss: 0.0284, last_20: 0.1725, lr: 0.0001, epoch: 15/25, step: 51/80\n",
      "loss: 0.085, last_20: 0.1664, lr: 0.0001, epoch: 15/25, step: 52/80\n",
      "loss: 0.0134, last_20: 0.1639, lr: 0.0001, epoch: 15/25, step: 53/80\n",
      "loss: 0.5483, last_20: 0.173, lr: 0.0001, epoch: 15/25, step: 54/80\n",
      "loss: 0.0041, last_20: 0.1708, lr: 0.0001, epoch: 15/25, step: 55/80\n",
      "loss: 0.5635, last_20: 0.1887, lr: 0.0001, epoch: 15/25, step: 56/80\n",
      "loss: 0.1098, last_20: 0.181, lr: 0.0001, epoch: 15/25, step: 57/80\n",
      "loss: 0.0191, last_20: 0.1718, lr: 0.0001, epoch: 15/25, step: 58/80\n",
      "loss: 0.2859, last_20: 0.1741, lr: 0.0001, epoch: 15/25, step: 59/80\n",
      "loss: 0.0624, last_20: 0.1449, lr: 0.0001, epoch: 15/25, step: 60/80\n",
      "loss: 0.0329, last_20: 0.1458, lr: 0.0001, epoch: 15/25, step: 61/80\n",
      "loss: 0.073, last_20: 0.1458, lr: 0.0001, epoch: 15/25, step: 62/80\n",
      "loss: 0.0366, last_20: 0.1468, lr: 0.0001, epoch: 15/25, step: 63/80\n",
      "loss: 0.6182, last_20: 0.1704, lr: 0.0001, epoch: 15/25, step: 64/80\n",
      "loss: 0.0193, last_20: 0.168, lr: 0.0001, epoch: 15/25, step: 65/80\n",
      "loss: 0.0192, last_20: 0.1609, lr: 0.0001, epoch: 15/25, step: 66/80\n",
      "loss: 0.0819, last_20: 0.1326, lr: 0.0001, epoch: 15/25, step: 67/80\n",
      "loss: 0.0097, last_20: 0.1318, lr: 0.0001, epoch: 15/25, step: 68/80\n",
      "loss: 0.3425, last_20: 0.1479, lr: 0.0001, epoch: 15/25, step: 69/80\n",
      "loss: 0.2264, last_20: 0.159, lr: 0.0001, epoch: 15/25, step: 70/80\n",
      "loss: 0.008, last_20: 0.158, lr: 0.0001, epoch: 15/25, step: 71/80\n",
      "loss: 0.2379, last_20: 0.1656, lr: 0.0001, epoch: 15/25, step: 72/80\n",
      "loss: 0.5264, last_20: 0.1913, lr: 0.0001, epoch: 15/25, step: 73/80\n",
      "loss: 0.0187, last_20: 0.1648, lr: 0.0001, epoch: 15/25, step: 74/80\n",
      "loss: 0.2756, last_20: 0.1783, lr: 0.0001, epoch: 15/25, step: 75/80\n",
      "loss: 0.069, last_20: 0.1536, lr: 0.0001, epoch: 15/25, step: 76/80\n",
      "loss: 0.0464, last_20: 0.1505, lr: 0.0001, epoch: 15/25, step: 77/80\n",
      "loss: 0.3755, last_20: 0.1683, lr: 0.0001, epoch: 15/25, step: 78/80\n",
      "loss: 0.0049, last_20: 0.1542, lr: 0.0001, epoch: 15/25, step: 79/80\n",
      "loss: 0.0613, last_20: 0.1542, lr: 0.0001, epoch: 15/25, step: 80/80\n",
      "loss: 0.0312, last_20: 0.1541, lr: 0.0001, epoch: 16/25, step: 1/80\n",
      "loss: 0.5073, last_20: 0.1758, lr: 0.0001, epoch: 16/25, step: 2/80\n",
      "loss: 0.0233, last_20: 0.1751, lr: 0.0001, epoch: 16/25, step: 3/80\n",
      "loss: 0.1375, last_20: 0.1511, lr: 0.0001, epoch: 16/25, step: 4/80\n",
      "loss: 0.0108, last_20: 0.1507, lr: 0.0001, epoch: 16/25, step: 5/80\n",
      "loss: 0.4856, last_20: 0.174, lr: 0.0001, epoch: 16/25, step: 6/80\n",
      "loss: 0.0287, last_20: 0.1713, lr: 0.0001, epoch: 16/25, step: 7/80\n",
      "loss: 0.0291, last_20: 0.1723, lr: 0.0001, epoch: 16/25, step: 8/80\n",
      "loss: 0.0024, last_20: 0.1553, lr: 0.0001, epoch: 16/25, step: 9/80\n",
      "loss: 0.0845, last_20: 0.1482, lr: 0.0001, epoch: 16/25, step: 10/80\n",
      "loss: 0.0129, last_20: 0.1484, lr: 0.0001, epoch: 16/25, step: 11/80\n",
      "loss: 0.0373, last_20: 0.1384, lr: 0.0001, epoch: 16/25, step: 12/80\n",
      "loss: 0.0976, last_20: 0.117, lr: 0.0001, epoch: 16/25, step: 13/80\n",
      "loss: 0.0201, last_20: 0.1171, lr: 0.0001, epoch: 16/25, step: 14/80\n",
      "loss: 0.0082, last_20: 0.1037, lr: 0.0001, epoch: 16/25, step: 15/80\n",
      "loss: 0.0078, last_20: 0.1006, lr: 0.0001, epoch: 16/25, step: 16/80\n",
      "loss: 0.0049, last_20: 0.0985, lr: 0.0001, epoch: 16/25, step: 17/80\n",
      "loss: 0.1591, last_20: 0.0877, lr: 0.0001, epoch: 16/25, step: 18/80\n",
      "loss: 0.0052, last_20: 0.0877, lr: 0.0001, epoch: 16/25, step: 19/80\n",
      "loss: 0.0038, last_20: 0.0849, lr: 0.0001, epoch: 16/25, step: 20/80\n",
      "loss: 0.0189, last_20: 0.0842, lr: 0.0001, epoch: 16/25, step: 21/80\n",
      "loss: 0.6562, last_20: 0.0917, lr: 0.0001, epoch: 16/25, step: 22/80\n",
      "loss: 0.0056, last_20: 0.0908, lr: 0.0001, epoch: 16/25, step: 23/80\n",
      "loss: 0.0136, last_20: 0.0846, lr: 0.0001, epoch: 16/25, step: 24/80\n",
      "loss: 0.153, last_20: 0.0917, lr: 0.0001, epoch: 16/25, step: 25/80\n",
      "loss: 0.1521, last_20: 0.075, lr: 0.0001, epoch: 16/25, step: 26/80\n",
      "loss: 0.3813, last_20: 0.0927, lr: 0.0001, epoch: 16/25, step: 27/80\n",
      "loss: 0.0047, last_20: 0.0915, lr: 0.0001, epoch: 16/25, step: 28/80\n",
      "loss: 0.4163, last_20: 0.1122, lr: 0.0001, epoch: 16/25, step: 29/80\n",
      "loss: 0.1012, last_20: 0.113, lr: 0.0001, epoch: 16/25, step: 30/80\n",
      "loss: 0.1893, last_20: 0.1218, lr: 0.0001, epoch: 16/25, step: 31/80\n",
      "loss: 0.3225, last_20: 0.1361, lr: 0.0001, epoch: 16/25, step: 32/80\n",
      "loss: 0.0106, last_20: 0.1317, lr: 0.0001, epoch: 16/25, step: 33/80\n",
      "loss: 0.0715, last_20: 0.1343, lr: 0.0001, epoch: 16/25, step: 34/80\n",
      "loss: 0.1248, last_20: 0.1401, lr: 0.0001, epoch: 16/25, step: 35/80\n",
      "loss: 0.1243, last_20: 0.1459, lr: 0.0001, epoch: 16/25, step: 36/80\n",
      "loss: 0.2673, last_20: 0.1591, lr: 0.0001, epoch: 16/25, step: 37/80\n",
      "loss: 0.429, last_20: 0.1726, lr: 0.0001, epoch: 16/25, step: 38/80\n",
      "loss: 0.0081, last_20: 0.1727, lr: 0.0001, epoch: 16/25, step: 39/80\n",
      "loss: 0.9565, last_20: 0.2203, lr: 0.0001, epoch: 16/25, step: 40/80\n",
      "loss: 0.0053, last_20: 0.2197, lr: 0.0001, epoch: 16/25, step: 41/80\n",
      "loss: 0.0945, last_20: 0.1916, lr: 0.0001, epoch: 16/25, step: 42/80\n",
      "loss: 0.0179, last_20: 0.1922, lr: 0.0001, epoch: 16/25, step: 43/80\n",
      "loss: 0.0027, last_20: 0.1916, lr: 0.0001, epoch: 16/25, step: 44/80\n",
      "loss: 0.064, last_20: 0.1872, lr: 0.0001, epoch: 16/25, step: 45/80\n",
      "loss: 0.8579, last_20: 0.2225, lr: 0.0001, epoch: 16/25, step: 46/80\n",
      "loss: 0.1593, last_20: 0.2114, lr: 0.0001, epoch: 16/25, step: 47/80\n",
      "loss: 0.2024, last_20: 0.2213, lr: 0.0001, epoch: 16/25, step: 48/80\n",
      "loss: 0.176, last_20: 0.2093, lr: 0.0001, epoch: 16/25, step: 49/80\n",
      "loss: 0.7432, last_20: 0.2414, lr: 0.0001, epoch: 16/25, step: 50/80\n",
      "loss: 0.0026, last_20: 0.232, lr: 0.0001, epoch: 16/25, step: 51/80\n",
      "loss: 0.0915, last_20: 0.2205, lr: 0.0001, epoch: 16/25, step: 52/80\n",
      "loss: 0.0039, last_20: 0.2201, lr: 0.0001, epoch: 16/25, step: 53/80\n",
      "loss: 0.8325, last_20: 0.2582, lr: 0.0001, epoch: 16/25, step: 54/80\n",
      "loss: 0.0026, last_20: 0.2521, lr: 0.0001, epoch: 16/25, step: 55/80\n",
      "loss: 0.7178, last_20: 0.2818, lr: 0.0001, epoch: 16/25, step: 56/80\n",
      "loss: 0.0315, last_20: 0.27, lr: 0.0001, epoch: 16/25, step: 57/80\n",
      "loss: 0.0028, last_20: 0.2486, lr: 0.0001, epoch: 16/25, step: 58/80\n",
      "loss: 0.7212, last_20: 0.2843, lr: 0.0001, epoch: 16/25, step: 59/80\n",
      "loss: 0.0251, last_20: 0.2377, lr: 0.0001, epoch: 16/25, step: 60/80\n",
      "loss: 0.0042, last_20: 0.2377, lr: 0.0001, epoch: 16/25, step: 61/80\n",
      "loss: 0.0153, last_20: 0.2337, lr: 0.0001, epoch: 16/25, step: 62/80\n",
      "loss: 0.6089, last_20: 0.2633, lr: 0.0001, epoch: 16/25, step: 63/80\n",
      "loss: 0.0507, last_20: 0.2657, lr: 0.0001, epoch: 16/25, step: 64/80\n",
      "loss: 0.1368, last_20: 0.2693, lr: 0.0001, epoch: 16/25, step: 65/80\n",
      "loss: 0.3545, last_20: 0.2441, lr: 0.0001, epoch: 16/25, step: 66/80\n",
      "loss: 0.0439, last_20: 0.2384, lr: 0.0001, epoch: 16/25, step: 67/80\n",
      "loss: 0.2861, last_20: 0.2426, lr: 0.0001, epoch: 16/25, step: 68/80\n",
      "loss: 0.4285, last_20: 0.2552, lr: 0.0001, epoch: 16/25, step: 69/80\n",
      "loss: 0.0402, last_20: 0.22, lr: 0.0001, epoch: 16/25, step: 70/80\n",
      "loss: 0.2306, last_20: 0.2314, lr: 0.0001, epoch: 16/25, step: 71/80\n",
      "loss: 0.1526, last_20: 0.2345, lr: 0.0001, epoch: 16/25, step: 72/80\n",
      "loss: 0.0062, last_20: 0.2346, lr: 0.0001, epoch: 16/25, step: 73/80\n",
      "loss: 0.0043, last_20: 0.1932, lr: 0.0001, epoch: 16/25, step: 74/80\n",
      "loss: 0.0125, last_20: 0.1937, lr: 0.0001, epoch: 16/25, step: 75/80\n",
      "loss: 0.0025, last_20: 0.1579, lr: 0.0001, epoch: 16/25, step: 76/80\n",
      "loss: 0.224, last_20: 0.1675, lr: 0.0001, epoch: 16/25, step: 77/80\n",
      "loss: 0.0052, last_20: 0.1677, lr: 0.0001, epoch: 16/25, step: 78/80\n",
      "loss: 0.0077, last_20: 0.132, lr: 0.0001, epoch: 16/25, step: 79/80\n",
      "loss: 0.6064, last_20: 0.1611, lr: 0.0001, epoch: 16/25, step: 80/80\n",
      "loss: 0.0278, last_20: 0.1622, lr: 0.0001, epoch: 17/25, step: 1/80\n",
      "loss: 0.3076, last_20: 0.1769, lr: 0.0001, epoch: 17/25, step: 2/80\n",
      "loss: 0.2142, last_20: 0.1571, lr: 0.0001, epoch: 17/25, step: 3/80\n",
      "loss: 0.1026, last_20: 0.1597, lr: 0.0001, epoch: 17/25, step: 4/80\n",
      "loss: 0.0045, last_20: 0.1531, lr: 0.0001, epoch: 17/25, step: 5/80\n",
      "loss: 0.2502, last_20: 0.1479, lr: 0.0001, epoch: 17/25, step: 6/80\n",
      "loss: 0.3706, last_20: 0.1642, lr: 0.0001, epoch: 17/25, step: 7/80\n",
      "loss: 0.004, last_20: 0.1501, lr: 0.0001, epoch: 17/25, step: 8/80\n",
      "loss: 0.3396, last_20: 0.1457, lr: 0.0001, epoch: 17/25, step: 9/80\n",
      "loss: 0.0621, last_20: 0.1468, lr: 0.0001, epoch: 17/25, step: 10/80\n",
      "loss: 0.0043, last_20: 0.1354, lr: 0.0001, epoch: 17/25, step: 11/80\n",
      "loss: 0.121, last_20: 0.1339, lr: 0.0001, epoch: 17/25, step: 12/80\n",
      "loss: 0.0205, last_20: 0.1346, lr: 0.0001, epoch: 17/25, step: 13/80\n",
      "loss: 0.1202, last_20: 0.1404, lr: 0.0001, epoch: 17/25, step: 14/80\n",
      "loss: 0.0328, last_20: 0.1414, lr: 0.0001, epoch: 17/25, step: 15/80\n",
      "loss: 0.5942, last_20: 0.171, lr: 0.0001, epoch: 17/25, step: 16/80\n",
      "loss: 0.0292, last_20: 0.1612, lr: 0.0001, epoch: 17/25, step: 17/80\n",
      "loss: 0.2832, last_20: 0.1751, lr: 0.0001, epoch: 17/25, step: 18/80\n",
      "loss: 0.0072, last_20: 0.1751, lr: 0.0001, epoch: 17/25, step: 19/80\n",
      "loss: 0.0348, last_20: 0.1465, lr: 0.0001, epoch: 17/25, step: 20/80\n",
      "loss: 0.0249, last_20: 0.1464, lr: 0.0001, epoch: 17/25, step: 21/80\n",
      "loss: 0.0695, last_20: 0.1345, lr: 0.0001, epoch: 17/25, step: 22/80\n",
      "loss: 0.0116, last_20: 0.1244, lr: 0.0001, epoch: 17/25, step: 23/80\n",
      "loss: 0.009, last_20: 0.1197, lr: 0.0001, epoch: 17/25, step: 24/80\n",
      "loss: 0.1029, last_20: 0.1246, lr: 0.0001, epoch: 17/25, step: 25/80\n",
      "loss: 0.0091, last_20: 0.1125, lr: 0.0001, epoch: 17/25, step: 26/80\n",
      "loss: 0.0587, last_20: 0.0969, lr: 0.0001, epoch: 17/25, step: 27/80\n",
      "loss: 0.0459, last_20: 0.099, lr: 0.0001, epoch: 17/25, step: 28/80\n",
      "loss: 0.9673, last_20: 0.1304, lr: 0.0001, epoch: 17/25, step: 29/80\n",
      "loss: 0.0125, last_20: 0.1279, lr: 0.0001, epoch: 17/25, step: 30/80\n",
      "loss: 0.0328, last_20: 0.1294, lr: 0.0001, epoch: 17/25, step: 31/80\n",
      "loss: 0.5342, last_20: 0.15, lr: 0.0001, epoch: 17/25, step: 32/80\n",
      "loss: 0.038, last_20: 0.1509, lr: 0.0001, epoch: 17/25, step: 33/80\n",
      "loss: 0.0341, last_20: 0.1466, lr: 0.0001, epoch: 17/25, step: 34/80\n",
      "loss: 0.479, last_20: 0.1689, lr: 0.0001, epoch: 17/25, step: 35/80\n",
      "loss: 0.0305, last_20: 0.1407, lr: 0.0001, epoch: 17/25, step: 36/80\n",
      "loss: 0.0111, last_20: 0.1398, lr: 0.0001, epoch: 17/25, step: 37/80\n",
      "loss: 0.034, last_20: 0.1274, lr: 0.0001, epoch: 17/25, step: 38/80\n",
      "loss: 0.053, last_20: 0.1296, lr: 0.0001, epoch: 17/25, step: 39/80\n",
      "loss: 0.0913, last_20: 0.1325, lr: 0.0001, epoch: 17/25, step: 40/80\n",
      "loss: 0.5386, last_20: 0.1582, lr: 0.0001, epoch: 17/25, step: 41/80\n",
      "loss: 0.8271, last_20: 0.196, lr: 0.0001, epoch: 17/25, step: 42/80\n",
      "loss: 0.4634, last_20: 0.2186, lr: 0.0001, epoch: 17/25, step: 43/80\n",
      "loss: 0.3496, last_20: 0.2357, lr: 0.0001, epoch: 17/25, step: 44/80\n",
      "loss: 0.3071, last_20: 0.2459, lr: 0.0001, epoch: 17/25, step: 45/80\n",
      "loss: 0.1089, last_20: 0.2509, lr: 0.0001, epoch: 17/25, step: 46/80\n",
      "loss: 0.0446, last_20: 0.2501, lr: 0.0001, epoch: 17/25, step: 47/80\n",
      "loss: 0.0427, last_20: 0.25, lr: 0.0001, epoch: 17/25, step: 48/80\n",
      "loss: 0.0142, last_20: 0.2023, lr: 0.0001, epoch: 17/25, step: 49/80\n",
      "loss: 0.3167, last_20: 0.2175, lr: 0.0001, epoch: 17/25, step: 50/80\n",
      "loss: 0.1697, last_20: 0.2244, lr: 0.0001, epoch: 17/25, step: 51/80\n",
      "loss: 0.259, last_20: 0.2106, lr: 0.0001, epoch: 17/25, step: 52/80\n",
      "loss: 0.0493, last_20: 0.2112, lr: 0.0001, epoch: 17/25, step: 53/80\n",
      "loss: 0.0273, last_20: 0.2109, lr: 0.0001, epoch: 17/25, step: 54/80\n",
      "loss: 0.27, last_20: 0.2004, lr: 0.0001, epoch: 17/25, step: 55/80\n",
      "loss: 0.1322, last_20: 0.2055, lr: 0.0001, epoch: 17/25, step: 56/80\n",
      "loss: 0.3779, last_20: 0.2238, lr: 0.0001, epoch: 17/25, step: 57/80\n",
      "loss: 0.0142, last_20: 0.2228, lr: 0.0001, epoch: 17/25, step: 58/80\n",
      "loss: 0.0948, last_20: 0.2249, lr: 0.0001, epoch: 17/25, step: 59/80\n",
      "loss: 0.5542, last_20: 0.2481, lr: 0.0001, epoch: 17/25, step: 60/80\n",
      "loss: 0.1396, last_20: 0.2281, lr: 0.0001, epoch: 17/25, step: 61/80\n",
      "loss: 0.2048, last_20: 0.197, lr: 0.0001, epoch: 17/25, step: 62/80\n",
      "loss: 0.1467, last_20: 0.1812, lr: 0.0001, epoch: 17/25, step: 63/80\n",
      "loss: 0.0073, last_20: 0.1641, lr: 0.0001, epoch: 17/25, step: 64/80\n",
      "loss: 0.3262, last_20: 0.165, lr: 0.0001, epoch: 17/25, step: 65/80\n",
      "loss: 0.0184, last_20: 0.1605, lr: 0.0001, epoch: 17/25, step: 66/80\n",
      "loss: 0.0067, last_20: 0.1586, lr: 0.0001, epoch: 17/25, step: 67/80\n",
      "loss: 0.0623, last_20: 0.1596, lr: 0.0001, epoch: 17/25, step: 68/80\n",
      "loss: 0.2544, last_20: 0.1716, lr: 0.0001, epoch: 17/25, step: 69/80\n",
      "loss: 0.0116, last_20: 0.1563, lr: 0.0001, epoch: 17/25, step: 70/80\n",
      "loss: 0.3962, last_20: 0.1677, lr: 0.0001, epoch: 17/25, step: 71/80\n",
      "loss: 0.0103, last_20: 0.1552, lr: 0.0001, epoch: 17/25, step: 72/80\n",
      "loss: 0.0311, last_20: 0.1543, lr: 0.0001, epoch: 17/25, step: 73/80\n",
      "loss: 0.8447, last_20: 0.1952, lr: 0.0001, epoch: 17/25, step: 74/80\n",
      "loss: 0.3262, last_20: 0.198, lr: 0.0001, epoch: 17/25, step: 75/80\n",
      "loss: 0.015, last_20: 0.1921, lr: 0.0001, epoch: 17/25, step: 76/80\n",
      "loss: 0.0383, last_20: 0.1752, lr: 0.0001, epoch: 17/25, step: 77/80\n",
      "loss: 0.0047, last_20: 0.1747, lr: 0.0001, epoch: 17/25, step: 78/80\n",
      "loss: 0.0533, last_20: 0.1726, lr: 0.0001, epoch: 17/25, step: 79/80\n",
      "loss: 0.2463, last_20: 0.1572, lr: 0.0001, epoch: 17/25, step: 80/80\n",
      "loss: 0.0985, last_20: 0.1552, lr: 0.0001, epoch: 18/25, step: 1/80\n",
      "loss: 0.3535, last_20: 0.1626, lr: 0.0001, epoch: 18/25, step: 2/80\n",
      "loss: 0.176, last_20: 0.1641, lr: 0.0001, epoch: 18/25, step: 3/80\n",
      "loss: 0.207, last_20: 0.174, lr: 0.0001, epoch: 18/25, step: 4/80\n",
      "loss: 0.5742, last_20: 0.1864, lr: 0.0001, epoch: 18/25, step: 5/80\n",
      "loss: 0.035, last_20: 0.1873, lr: 0.0001, epoch: 18/25, step: 6/80\n",
      "loss: 0.0631, last_20: 0.1901, lr: 0.0001, epoch: 18/25, step: 7/80\n",
      "loss: 0.0483, last_20: 0.1894, lr: 0.0001, epoch: 18/25, step: 8/80\n",
      "loss: 0.0954, last_20: 0.1814, lr: 0.0001, epoch: 18/25, step: 9/80\n",
      "loss: 0.1628, last_20: 0.189, lr: 0.0001, epoch: 18/25, step: 10/80\n",
      "loss: 0.005, last_20: 0.1694, lr: 0.0001, epoch: 18/25, step: 11/80\n",
      "loss: 0.179, last_20: 0.1779, lr: 0.0001, epoch: 18/25, step: 12/80\n",
      "loss: 0.0764, last_20: 0.1801, lr: 0.0001, epoch: 18/25, step: 13/80\n",
      "loss: 0.0242, last_20: 0.1391, lr: 0.0001, epoch: 18/25, step: 14/80\n",
      "loss: 0.6309, last_20: 0.1543, lr: 0.0001, epoch: 18/25, step: 15/80\n",
      "loss: 0.2391, last_20: 0.1655, lr: 0.0001, epoch: 18/25, step: 16/80\n",
      "loss: 0.1416, last_20: 0.1707, lr: 0.0001, epoch: 18/25, step: 17/80\n",
      "loss: 0.0945, last_20: 0.1752, lr: 0.0001, epoch: 18/25, step: 18/80\n",
      "loss: 0.0082, last_20: 0.1729, lr: 0.0001, epoch: 18/25, step: 19/80\n",
      "loss: 0.0426, last_20: 0.1628, lr: 0.0001, epoch: 18/25, step: 20/80\n",
      "loss: 0.0903, last_20: 0.1624, lr: 0.0001, epoch: 18/25, step: 21/80\n",
      "loss: 0.6187, last_20: 0.1756, lr: 0.0001, epoch: 18/25, step: 22/80\n",
      "loss: 0.425, last_20: 0.1881, lr: 0.0001, epoch: 18/25, step: 23/80\n",
      "loss: 0.5503, last_20: 0.2052, lr: 0.0001, epoch: 18/25, step: 24/80\n",
      "loss: 0.3677, last_20: 0.1949, lr: 0.0001, epoch: 18/25, step: 25/80\n",
      "loss: 0.4006, last_20: 0.2132, lr: 0.0001, epoch: 18/25, step: 26/80\n",
      "loss: 0.0101, last_20: 0.2105, lr: 0.0001, epoch: 18/25, step: 27/80\n",
      "loss: 0.1, last_20: 0.2131, lr: 0.0001, epoch: 18/25, step: 28/80\n",
      "loss: 0.0085, last_20: 0.2088, lr: 0.0001, epoch: 18/25, step: 29/80\n",
      "loss: 0.2164, last_20: 0.2115, lr: 0.0001, epoch: 18/25, step: 30/80\n",
      "loss: 0.3411, last_20: 0.2283, lr: 0.0001, epoch: 18/25, step: 31/80\n",
      "loss: 0.1404, last_20: 0.2263, lr: 0.0001, epoch: 18/25, step: 32/80\n",
      "loss: 0.0241, last_20: 0.2237, lr: 0.0001, epoch: 18/25, step: 33/80\n",
      "loss: 0.2734, last_20: 0.2362, lr: 0.0001, epoch: 18/25, step: 34/80\n",
      "loss: 0.0482, last_20: 0.207, lr: 0.0001, epoch: 18/25, step: 35/80\n",
      "loss: 0.6768, last_20: 0.2289, lr: 0.0001, epoch: 18/25, step: 36/80\n",
      "loss: 0.0125, last_20: 0.2225, lr: 0.0001, epoch: 18/25, step: 37/80\n",
      "loss: 0.0401, last_20: 0.2198, lr: 0.0001, epoch: 18/25, step: 38/80\n",
      "loss: 0.0602, last_20: 0.2223, lr: 0.0001, epoch: 18/25, step: 39/80\n",
      "loss: 0.0196, last_20: 0.2212, lr: 0.0001, epoch: 18/25, step: 40/80\n",
      "loss: 0.0117, last_20: 0.2173, lr: 0.0001, epoch: 18/25, step: 41/80\n",
      "loss: 0.3962, last_20: 0.2061, lr: 0.0001, epoch: 18/25, step: 42/80\n",
      "loss: 0.3625, last_20: 0.203, lr: 0.0001, epoch: 18/25, step: 43/80\n",
      "loss: 0.5259, last_20: 0.2018, lr: 0.0001, epoch: 18/25, step: 44/80\n",
      "loss: 0.1301, last_20: 0.1899, lr: 0.0001, epoch: 18/25, step: 45/80\n",
      "loss: 0.0027, last_20: 0.17, lr: 0.0001, epoch: 18/25, step: 46/80\n",
      "loss: 0.043, last_20: 0.1717, lr: 0.0001, epoch: 18/25, step: 47/80\n",
      "loss: 0.0584, last_20: 0.1696, lr: 0.0001, epoch: 18/25, step: 48/80\n",
      "loss: 0.0151, last_20: 0.1699, lr: 0.0001, epoch: 18/25, step: 49/80\n",
      "loss: 0.0077, last_20: 0.1595, lr: 0.0001, epoch: 18/25, step: 50/80\n",
      "loss: 0.0706, last_20: 0.146, lr: 0.0001, epoch: 18/25, step: 51/80\n",
      "loss: 0.0041, last_20: 0.1391, lr: 0.0001, epoch: 18/25, step: 52/80\n",
      "loss: 0.5933, last_20: 0.1676, lr: 0.0001, epoch: 18/25, step: 53/80\n",
      "loss: 0.0381, last_20: 0.1558, lr: 0.0001, epoch: 18/25, step: 54/80\n",
      "loss: 0.1115, last_20: 0.159, lr: 0.0001, epoch: 18/25, step: 55/80\n",
      "loss: 0.6216, last_20: 0.1562, lr: 0.0001, epoch: 18/25, step: 56/80\n",
      "loss: 0.1554, last_20: 0.1634, lr: 0.0001, epoch: 18/25, step: 57/80\n",
      "loss: 0.0317, last_20: 0.163, lr: 0.0001, epoch: 18/25, step: 58/80\n",
      "loss: 0.0068, last_20: 0.1603, lr: 0.0001, epoch: 18/25, step: 59/80\n",
      "loss: 0.0032, last_20: 0.1595, lr: 0.0001, epoch: 18/25, step: 60/80\n",
      "loss: 0.5806, last_20: 0.1879, lr: 0.0001, epoch: 18/25, step: 61/80\n",
      "loss: 0.1062, last_20: 0.1734, lr: 0.0001, epoch: 18/25, step: 62/80\n",
      "loss: 0.5503, last_20: 0.1828, lr: 0.0001, epoch: 18/25, step: 63/80\n",
      "loss: 0.6108, last_20: 0.1871, lr: 0.0001, epoch: 18/25, step: 64/80\n",
      "loss: 0.6309, last_20: 0.2121, lr: 0.0001, epoch: 18/25, step: 65/80\n",
      "loss: 0.0107, last_20: 0.2125, lr: 0.0001, epoch: 18/25, step: 66/80\n",
      "loss: 0.0485, last_20: 0.2128, lr: 0.0001, epoch: 18/25, step: 67/80\n",
      "loss: 0.1428, last_20: 0.217, lr: 0.0001, epoch: 18/25, step: 68/80\n",
      "loss: 0.5796, last_20: 0.2452, lr: 0.0001, epoch: 18/25, step: 69/80\n",
      "loss: 0.0039, last_20: 0.245, lr: 0.0001, epoch: 18/25, step: 70/80\n",
      "loss: 0.0753, last_20: 0.2453, lr: 0.0001, epoch: 18/25, step: 71/80\n",
      "loss: 0.1143, last_20: 0.2508, lr: 0.0001, epoch: 18/25, step: 72/80\n",
      "loss: 0.4438, last_20: 0.2433, lr: 0.0001, epoch: 18/25, step: 73/80\n",
      "loss: 0.1791, last_20: 0.2503, lr: 0.0001, epoch: 18/25, step: 74/80\n",
      "loss: 0.5928, last_20: 0.2744, lr: 0.0001, epoch: 18/25, step: 75/80\n",
      "loss: 0.4014, last_20: 0.2634, lr: 0.0001, epoch: 18/25, step: 76/80\n",
      "loss: 0.3, last_20: 0.2706, lr: 0.0001, epoch: 18/25, step: 77/80\n",
      "loss: 0.0699, last_20: 0.2725, lr: 0.0001, epoch: 18/25, step: 78/80\n",
      "loss: 0.0042, last_20: 0.2724, lr: 0.0001, epoch: 18/25, step: 79/80\n",
      "loss: 0.2725, last_20: 0.2859, lr: 0.0001, epoch: 18/25, step: 80/80\n",
      "loss: 0.0034, last_20: 0.257, lr: 0.0001, epoch: 19/25, step: 1/80\n",
      "loss: 0.415, last_20: 0.2725, lr: 0.0001, epoch: 19/25, step: 2/80\n",
      "loss: 0.3293, last_20: 0.2614, lr: 0.0001, epoch: 19/25, step: 3/80\n",
      "loss: 0.3354, last_20: 0.2476, lr: 0.0001, epoch: 19/25, step: 4/80\n",
      "loss: 0.0259, last_20: 0.2174, lr: 0.0001, epoch: 19/25, step: 5/80\n",
      "loss: 0.0175, last_20: 0.2177, lr: 0.0001, epoch: 19/25, step: 6/80\n",
      "loss: 0.771, last_20: 0.2539, lr: 0.0001, epoch: 19/25, step: 7/80\n",
      "loss: 0.2141, last_20: 0.2574, lr: 0.0001, epoch: 19/25, step: 8/80\n",
      "loss: 0.1263, last_20: 0.2348, lr: 0.0001, epoch: 19/25, step: 9/80\n",
      "loss: 0.0064, last_20: 0.2349, lr: 0.0001, epoch: 19/25, step: 10/80\n",
      "loss: 0.0386, last_20: 0.233, lr: 0.0001, epoch: 19/25, step: 11/80\n",
      "loss: 0.021, last_20: 0.2284, lr: 0.0001, epoch: 19/25, step: 12/80\n",
      "loss: 0.3274, last_20: 0.2226, lr: 0.0001, epoch: 19/25, step: 13/80\n",
      "loss: 0.1506, last_20: 0.2211, lr: 0.0001, epoch: 19/25, step: 14/80\n",
      "loss: 0.1207, last_20: 0.1975, lr: 0.0001, epoch: 19/25, step: 15/80\n",
      "loss: 0.0197, last_20: 0.1784, lr: 0.0001, epoch: 19/25, step: 16/80\n",
      "loss: 0.0927, last_20: 0.1681, lr: 0.0001, epoch: 19/25, step: 17/80\n",
      "loss: 0.0027, last_20: 0.1647, lr: 0.0001, epoch: 19/25, step: 18/80\n",
      "loss: 0.0482, last_20: 0.1669, lr: 0.0001, epoch: 19/25, step: 19/80\n",
      "loss: 0.0287, last_20: 0.1547, lr: 0.0001, epoch: 19/25, step: 20/80\n",
      "loss: 0.2216, last_20: 0.1656, lr: 0.0001, epoch: 19/25, step: 21/80\n",
      "loss: 0.0894, last_20: 0.1494, lr: 0.0001, epoch: 19/25, step: 22/80\n",
      "loss: 0.6479, last_20: 0.1653, lr: 0.0001, epoch: 19/25, step: 23/80\n",
      "loss: 0.005, last_20: 0.1488, lr: 0.0001, epoch: 19/25, step: 24/80\n",
      "loss: 0.2079, last_20: 0.1579, lr: 0.0001, epoch: 19/25, step: 25/80\n",
      "loss: 0.0207, last_20: 0.158, lr: 0.0001, epoch: 19/25, step: 26/80\n",
      "loss: 0.0095, last_20: 0.12, lr: 0.0001, epoch: 19/25, step: 27/80\n",
      "loss: 0.2961, last_20: 0.1241, lr: 0.0001, epoch: 19/25, step: 28/80\n",
      "loss: 0.1002, last_20: 0.1227, lr: 0.0001, epoch: 19/25, step: 29/80\n",
      "loss: 0.2607, last_20: 0.1355, lr: 0.0001, epoch: 19/25, step: 30/80\n",
      "loss: 0.0233, last_20: 0.1347, lr: 0.0001, epoch: 19/25, step: 31/80\n",
      "loss: 0.0127, last_20: 0.1343, lr: 0.0001, epoch: 19/25, step: 32/80\n",
      "loss: 0.0664, last_20: 0.1212, lr: 0.0001, epoch: 19/25, step: 33/80\n",
      "loss: 0.0173, last_20: 0.1146, lr: 0.0001, epoch: 19/25, step: 34/80\n",
      "loss: 0.0323, last_20: 0.1102, lr: 0.0001, epoch: 19/25, step: 35/80\n",
      "loss: 0.6182, last_20: 0.1401, lr: 0.0001, epoch: 19/25, step: 36/80\n",
      "loss: 0.2117, last_20: 0.146, lr: 0.0001, epoch: 19/25, step: 37/80\n",
      "loss: 0.4856, last_20: 0.1702, lr: 0.0001, epoch: 19/25, step: 38/80\n",
      "loss: 0.062, last_20: 0.1709, lr: 0.0001, epoch: 19/25, step: 39/80\n",
      "loss: 0.6665, last_20: 0.2027, lr: 0.0001, epoch: 19/25, step: 40/80\n",
      "loss: 0.0098, last_20: 0.1922, lr: 0.0001, epoch: 19/25, step: 41/80\n",
      "loss: 0.191, last_20: 0.1972, lr: 0.0001, epoch: 19/25, step: 42/80\n",
      "loss: 0.0228, last_20: 0.166, lr: 0.0001, epoch: 19/25, step: 43/80\n",
      "loss: 0.311, last_20: 0.1813, lr: 0.0001, epoch: 19/25, step: 44/80\n",
      "loss: 0.0047, last_20: 0.1711, lr: 0.0001, epoch: 19/25, step: 45/80\n",
      "loss: 0.0032, last_20: 0.1702, lr: 0.0001, epoch: 19/25, step: 46/80\n",
      "loss: 0.4231, last_20: 0.1909, lr: 0.0001, epoch: 19/25, step: 47/80\n",
      "loss: 0.1041, last_20: 0.1813, lr: 0.0001, epoch: 19/25, step: 48/80\n",
      "loss: 0.2966, last_20: 0.1911, lr: 0.0001, epoch: 19/25, step: 49/80\n",
      "loss: 0.0086, last_20: 0.1785, lr: 0.0001, epoch: 19/25, step: 50/80\n",
      "loss: 0.4646, last_20: 0.2006, lr: 0.0001, epoch: 19/25, step: 51/80\n",
      "loss: 0.0141, last_20: 0.2007, lr: 0.0001, epoch: 19/25, step: 52/80\n",
      "loss: 0.3425, last_20: 0.2145, lr: 0.0001, epoch: 19/25, step: 53/80\n",
      "loss: 0.0117, last_20: 0.2142, lr: 0.0001, epoch: 19/25, step: 54/80\n",
      "loss: 0.0109, last_20: 0.2131, lr: 0.0001, epoch: 19/25, step: 55/80\n",
      "loss: 0.003, last_20: 0.1824, lr: 0.0001, epoch: 19/25, step: 56/80\n",
      "loss: 0.0625, last_20: 0.1749, lr: 0.0001, epoch: 19/25, step: 57/80\n",
      "loss: 0.1246, last_20: 0.1569, lr: 0.0001, epoch: 19/25, step: 58/80\n",
      "loss: 0.2837, last_20: 0.1679, lr: 0.0001, epoch: 19/25, step: 59/80\n",
      "loss: 0.4971, last_20: 0.1595, lr: 0.0001, epoch: 19/25, step: 60/80\n",
      "loss: 0.1398, last_20: 0.166, lr: 0.0001, epoch: 19/25, step: 61/80\n",
      "loss: 0.016, last_20: 0.1572, lr: 0.0001, epoch: 19/25, step: 62/80\n",
      "loss: 0.6519, last_20: 0.1887, lr: 0.0001, epoch: 19/25, step: 63/80\n",
      "loss: 0.0459, last_20: 0.1754, lr: 0.0001, epoch: 19/25, step: 64/80\n",
      "loss: 0.0107, last_20: 0.1757, lr: 0.0001, epoch: 19/25, step: 65/80\n",
      "loss: 0.6309, last_20: 0.2071, lr: 0.0001, epoch: 19/25, step: 66/80\n",
      "loss: 0.0223, last_20: 0.1871, lr: 0.0001, epoch: 19/25, step: 67/80\n",
      "loss: 0.2173, last_20: 0.1927, lr: 0.0001, epoch: 19/25, step: 68/80\n",
      "loss: 0.0407, last_20: 0.1799, lr: 0.0001, epoch: 19/25, step: 69/80\n",
      "loss: 0.0813, last_20: 0.1836, lr: 0.0001, epoch: 19/25, step: 70/80\n",
      "loss: 0.006, last_20: 0.1606, lr: 0.0001, epoch: 19/25, step: 71/80\n",
      "loss: 0.364, last_20: 0.1781, lr: 0.0001, epoch: 19/25, step: 72/80\n",
      "loss: 0.502, last_20: 0.1861, lr: 0.0001, epoch: 19/25, step: 73/80\n",
      "loss: 0.0931, last_20: 0.1902, lr: 0.0001, epoch: 19/25, step: 74/80\n",
      "loss: 0.0065, last_20: 0.19, lr: 0.0001, epoch: 19/25, step: 75/80\n",
      "loss: 0.3123, last_20: 0.2054, lr: 0.0001, epoch: 19/25, step: 76/80\n",
      "loss: 0.3088, last_20: 0.2177, lr: 0.0001, epoch: 19/25, step: 77/80\n",
      "loss: 0.283, last_20: 0.2257, lr: 0.0001, epoch: 19/25, step: 78/80\n",
      "loss: 0.0567, last_20: 0.2143, lr: 0.0001, epoch: 19/25, step: 79/80\n",
      "loss: 0.1934, last_20: 0.1991, lr: 0.0001, epoch: 19/25, step: 80/80\n",
      "loss: 0.0382, last_20: 0.1941, lr: 0.0001, epoch: 20/25, step: 1/80\n",
      "loss: 0.0388, last_20: 0.1952, lr: 0.0001, epoch: 20/25, step: 2/80\n",
      "loss: 0.1688, last_20: 0.171, lr: 0.0001, epoch: 20/25, step: 3/80\n",
      "loss: 0.0518, last_20: 0.1713, lr: 0.0001, epoch: 20/25, step: 4/80\n",
      "loss: 0.0074, last_20: 0.1712, lr: 0.0001, epoch: 20/25, step: 5/80\n",
      "loss: 0.4285, last_20: 0.161, lr: 0.0001, epoch: 20/25, step: 6/80\n",
      "loss: 0.0916, last_20: 0.1645, lr: 0.0001, epoch: 20/25, step: 7/80\n",
      "loss: 0.032, last_20: 0.1552, lr: 0.0001, epoch: 20/25, step: 8/80\n",
      "loss: 0.0583, last_20: 0.1561, lr: 0.0001, epoch: 20/25, step: 9/80\n",
      "loss: 0.0031, last_20: 0.1522, lr: 0.0001, epoch: 20/25, step: 10/80\n",
      "loss: 0.0963, last_20: 0.1567, lr: 0.0001, epoch: 20/25, step: 11/80\n",
      "loss: 0.2966, last_20: 0.1534, lr: 0.0001, epoch: 20/25, step: 12/80\n",
      "loss: 0.3118, last_20: 0.1438, lr: 0.0001, epoch: 20/25, step: 13/80\n",
      "loss: 0.5269, last_20: 0.1655, lr: 0.0001, epoch: 20/25, step: 14/80\n",
      "loss: 0.0101, last_20: 0.1657, lr: 0.0001, epoch: 20/25, step: 15/80\n",
      "loss: 0.2179, last_20: 0.161, lr: 0.0001, epoch: 20/25, step: 16/80\n",
      "loss: 0.0088, last_20: 0.146, lr: 0.0001, epoch: 20/25, step: 17/80\n",
      "loss: 0.3691, last_20: 0.1503, lr: 0.0001, epoch: 20/25, step: 18/80\n",
      "loss: 0.1237, last_20: 0.1537, lr: 0.0001, epoch: 20/25, step: 19/80\n",
      "loss: 0.4321, last_20: 0.1656, lr: 0.0001, epoch: 20/25, step: 20/80\n",
      "loss: 0.0087, last_20: 0.1641, lr: 0.0001, epoch: 20/25, step: 21/80\n",
      "loss: 0.3313, last_20: 0.1787, lr: 0.0001, epoch: 20/25, step: 22/80\n",
      "loss: 0.0055, last_20: 0.1706, lr: 0.0001, epoch: 20/25, step: 23/80\n",
      "loss: 0.4001, last_20: 0.188, lr: 0.0001, epoch: 20/25, step: 24/80\n",
      "loss: 0.501, last_20: 0.2127, lr: 0.0001, epoch: 20/25, step: 25/80\n",
      "loss: 0.0101, last_20: 0.1918, lr: 0.0001, epoch: 20/25, step: 26/80\n",
      "loss: 0.0044, last_20: 0.1874, lr: 0.0001, epoch: 20/25, step: 27/80\n",
      "loss: 0.0065, last_20: 0.1861, lr: 0.0001, epoch: 20/25, step: 28/80\n",
      "loss: 0.7363, last_20: 0.22, lr: 0.0001, epoch: 20/25, step: 29/80\n",
      "loss: 0.0154, last_20: 0.2206, lr: 0.0001, epoch: 20/25, step: 30/80\n",
      "loss: 0.0146, last_20: 0.2165, lr: 0.0001, epoch: 20/25, step: 31/80\n",
      "loss: 0.1054, last_20: 0.207, lr: 0.0001, epoch: 20/25, step: 32/80\n",
      "loss: 0.0955, last_20: 0.1962, lr: 0.0001, epoch: 20/25, step: 33/80\n",
      "loss: 0.2957, last_20: 0.1846, lr: 0.0001, epoch: 20/25, step: 34/80\n",
      "loss: 0.0417, last_20: 0.1862, lr: 0.0001, epoch: 20/25, step: 35/80\n",
      "loss: 0.5752, last_20: 0.2041, lr: 0.0001, epoch: 20/25, step: 36/80\n",
      "loss: 0.4226, last_20: 0.2247, lr: 0.0001, epoch: 20/25, step: 37/80\n",
      "loss: 0.0086, last_20: 0.2067, lr: 0.0001, epoch: 20/25, step: 38/80\n",
      "loss: 0.0757, last_20: 0.2043, lr: 0.0001, epoch: 20/25, step: 39/80\n",
      "loss: 0.0356, last_20: 0.1845, lr: 0.0001, epoch: 20/25, step: 40/80\n",
      "loss: 0.0029, last_20: 0.1842, lr: 0.0001, epoch: 20/25, step: 41/80\n",
      "loss: 0.0161, last_20: 0.1684, lr: 0.0001, epoch: 20/25, step: 42/80\n",
      "loss: 0.0408, last_20: 0.1702, lr: 0.0001, epoch: 20/25, step: 43/80\n",
      "loss: 0.5669, last_20: 0.1785, lr: 0.0001, epoch: 20/25, step: 44/80\n",
      "loss: 0.0064, last_20: 0.1538, lr: 0.0001, epoch: 20/25, step: 45/80\n",
      "loss: 0.1841, last_20: 0.1625, lr: 0.0001, epoch: 20/25, step: 46/80\n",
      "loss: 0.0286, last_20: 0.1637, lr: 0.0001, epoch: 20/25, step: 47/80\n",
      "loss: 0.4429, last_20: 0.1855, lr: 0.0001, epoch: 20/25, step: 48/80\n",
      "loss: 0.1667, last_20: 0.1571, lr: 0.0001, epoch: 20/25, step: 49/80\n",
      "loss: 0.0136, last_20: 0.157, lr: 0.0001, epoch: 20/25, step: 50/80\n",
      "loss: 0.0056, last_20: 0.1565, lr: 0.0001, epoch: 20/25, step: 51/80\n",
      "loss: 0.7422, last_20: 0.1884, lr: 0.0001, epoch: 20/25, step: 52/80\n",
      "loss: 0.0606, last_20: 0.1866, lr: 0.0001, epoch: 20/25, step: 53/80\n",
      "loss: 0.4138, last_20: 0.1925, lr: 0.0001, epoch: 20/25, step: 54/80\n",
      "loss: 0.1016, last_20: 0.1955, lr: 0.0001, epoch: 20/25, step: 55/80\n",
      "loss: 0.0955, last_20: 0.1715, lr: 0.0001, epoch: 20/25, step: 56/80\n",
      "loss: 0.4214, last_20: 0.1715, lr: 0.0001, epoch: 20/25, step: 57/80\n",
      "loss: 0.1372, last_20: 0.1779, lr: 0.0001, epoch: 20/25, step: 58/80\n",
      "loss: 0.0104, last_20: 0.1746, lr: 0.0001, epoch: 20/25, step: 59/80\n",
      "loss: 0.4199, last_20: 0.1939, lr: 0.0001, epoch: 20/25, step: 60/80\n",
      "loss: 0.3716, last_20: 0.2123, lr: 0.0001, epoch: 20/25, step: 61/80\n",
      "loss: 0.106, last_20: 0.2168, lr: 0.0001, epoch: 20/25, step: 62/80\n",
      "loss: 0.0076, last_20: 0.2151, lr: 0.0001, epoch: 20/25, step: 63/80\n",
      "loss: 0.1716, last_20: 0.1954, lr: 0.0001, epoch: 20/25, step: 64/80\n",
      "loss: 0.0399, last_20: 0.197, lr: 0.0001, epoch: 20/25, step: 65/80\n",
      "loss: 0.0025, last_20: 0.188, lr: 0.0001, epoch: 20/25, step: 66/80\n",
      "loss: 0.0555, last_20: 0.1893, lr: 0.0001, epoch: 20/25, step: 67/80\n",
      "loss: 0.0561, last_20: 0.17, lr: 0.0001, epoch: 20/25, step: 68/80\n",
      "loss: 0.075, last_20: 0.1654, lr: 0.0001, epoch: 20/25, step: 69/80\n",
      "loss: 0.0217, last_20: 0.1658, lr: 0.0001, epoch: 20/25, step: 70/80\n",
      "loss: 0.0484, last_20: 0.1679, lr: 0.0001, epoch: 20/25, step: 71/80\n",
      "loss: 0.0068, last_20: 0.1312, lr: 0.0001, epoch: 20/25, step: 72/80\n",
      "loss: 0.5962, last_20: 0.1579, lr: 0.0001, epoch: 20/25, step: 73/80\n",
      "loss: 0.9492, last_20: 0.1847, lr: 0.0001, epoch: 20/25, step: 74/80\n",
      "loss: 0.4868, last_20: 0.204, lr: 0.0001, epoch: 20/25, step: 75/80\n",
      "loss: 0.0606, last_20: 0.2022, lr: 0.0001, epoch: 20/25, step: 76/80\n",
      "loss: 0.4399, last_20: 0.2031, lr: 0.0001, epoch: 20/25, step: 77/80\n",
      "loss: 0.0454, last_20: 0.1986, lr: 0.0001, epoch: 20/25, step: 78/80\n",
      "loss: 0.0515, last_20: 0.2006, lr: 0.0001, epoch: 20/25, step: 79/80\n",
      "loss: 0.0915, last_20: 0.1842, lr: 0.0001, epoch: 20/25, step: 80/80\n",
      "loss: 0.5918, last_20: 0.1952, lr: 0.0001, epoch: 21/25, step: 1/80\n",
      "loss: 0.01, last_20: 0.1904, lr: 0.0001, epoch: 21/25, step: 2/80\n",
      "loss: 0.1943, last_20: 0.1997, lr: 0.0001, epoch: 21/25, step: 3/80\n",
      "loss: 0.0176, last_20: 0.192, lr: 0.0001, epoch: 21/25, step: 4/80\n",
      "loss: 0.0056, last_20: 0.1903, lr: 0.0001, epoch: 21/25, step: 5/80\n",
      "loss: 0.0059, last_20: 0.1905, lr: 0.0001, epoch: 21/25, step: 6/80\n",
      "loss: 0.2186, last_20: 0.1986, lr: 0.0001, epoch: 21/25, step: 7/80\n",
      "loss: 0.1597, last_20: 0.2038, lr: 0.0001, epoch: 21/25, step: 8/80\n",
      "loss: 0.2474, last_20: 0.2124, lr: 0.0001, epoch: 21/25, step: 9/80\n",
      "loss: 0.0175, last_20: 0.2122, lr: 0.0001, epoch: 21/25, step: 10/80\n",
      "loss: 0.157, last_20: 0.2177, lr: 0.0001, epoch: 21/25, step: 11/80\n",
      "loss: 0.052, last_20: 0.2199, lr: 0.0001, epoch: 21/25, step: 12/80\n",
      "loss: 0.0119, last_20: 0.1907, lr: 0.0001, epoch: 21/25, step: 13/80\n",
      "loss: 0.0334, last_20: 0.1449, lr: 0.0001, epoch: 21/25, step: 14/80\n",
      "loss: 0.1213, last_20: 0.1266, lr: 0.0001, epoch: 21/25, step: 15/80\n",
      "loss: 0.0173, last_20: 0.1245, lr: 0.0001, epoch: 21/25, step: 16/80\n",
      "loss: 0.2065, last_20: 0.1128, lr: 0.0001, epoch: 21/25, step: 17/80\n",
      "loss: 0.0389, last_20: 0.1125, lr: 0.0001, epoch: 21/25, step: 18/80\n",
      "loss: 0.0463, last_20: 0.1122, lr: 0.0001, epoch: 21/25, step: 19/80\n",
      "loss: 0.0205, last_20: 0.1087, lr: 0.0001, epoch: 21/25, step: 20/80\n",
      "loss: 0.0492, last_20: 0.0815, lr: 0.0001, epoch: 21/25, step: 21/80\n",
      "loss: 0.0552, last_20: 0.0838, lr: 0.0001, epoch: 21/25, step: 22/80\n",
      "loss: 0.0329, last_20: 0.0757, lr: 0.0001, epoch: 21/25, step: 23/80\n",
      "loss: 0.0242, last_20: 0.0761, lr: 0.0001, epoch: 21/25, step: 24/80\n",
      "loss: 0.2534, last_20: 0.0885, lr: 0.0001, epoch: 21/25, step: 25/80\n",
      "loss: 0.0074, last_20: 0.0885, lr: 0.0001, epoch: 21/25, step: 26/80\n",
      "loss: 0.005, last_20: 0.0778, lr: 0.0001, epoch: 21/25, step: 27/80\n",
      "loss: 0.0714, last_20: 0.0734, lr: 0.0001, epoch: 21/25, step: 28/80\n",
      "loss: 0.023, last_20: 0.0622, lr: 0.0001, epoch: 21/25, step: 29/80\n",
      "loss: 0.032, last_20: 0.0629, lr: 0.0001, epoch: 21/25, step: 30/80\n",
      "loss: 0.5132, last_20: 0.0807, lr: 0.0001, epoch: 21/25, step: 31/80\n",
      "loss: 0.0573, last_20: 0.081, lr: 0.0001, epoch: 21/25, step: 32/80\n",
      "loss: 0.5435, last_20: 0.1076, lr: 0.0001, epoch: 21/25, step: 33/80\n",
      "loss: 0.0519, last_20: 0.1085, lr: 0.0001, epoch: 21/25, step: 34/80\n",
      "loss: 0.0127, last_20: 0.1031, lr: 0.0001, epoch: 21/25, step: 35/80\n",
      "loss: 0.3914, last_20: 0.1218, lr: 0.0001, epoch: 21/25, step: 36/80\n",
      "loss: 0.7456, last_20: 0.1487, lr: 0.0001, epoch: 21/25, step: 37/80\n",
      "loss: 0.0098, last_20: 0.1473, lr: 0.0001, epoch: 21/25, step: 38/80\n",
      "loss: 0.0114, last_20: 0.1456, lr: 0.0001, epoch: 21/25, step: 39/80\n",
      "loss: 0.5205, last_20: 0.1705, lr: 0.0001, epoch: 21/25, step: 40/80\n",
      "loss: 0.0044, last_20: 0.1683, lr: 0.0001, epoch: 21/25, step: 41/80\n",
      "loss: 0.2015, last_20: 0.1756, lr: 0.0001, epoch: 21/25, step: 42/80\n",
      "loss: 0.0494, last_20: 0.1764, lr: 0.0001, epoch: 21/25, step: 43/80\n",
      "loss: 0.6289, last_20: 0.2067, lr: 0.0001, epoch: 21/25, step: 44/80\n",
      "loss: 0.3923, last_20: 0.2136, lr: 0.0001, epoch: 21/25, step: 45/80\n",
      "loss: 0.0069, last_20: 0.2136, lr: 0.0001, epoch: 21/25, step: 46/80\n",
      "loss: 0.4287, last_20: 0.2348, lr: 0.0001, epoch: 21/25, step: 47/80\n",
      "loss: 0.3765, last_20: 0.25, lr: 0.0001, epoch: 21/25, step: 48/80\n",
      "loss: 0.1967, last_20: 0.2587, lr: 0.0001, epoch: 21/25, step: 49/80\n",
      "loss: 0.0166, last_20: 0.258, lr: 0.0001, epoch: 21/25, step: 50/80\n",
      "loss: 0.0122, last_20: 0.2329, lr: 0.0001, epoch: 21/25, step: 51/80\n",
      "loss: 0.7671, last_20: 0.2684, lr: 0.0001, epoch: 21/25, step: 52/80\n",
      "loss: 0.0047, last_20: 0.2415, lr: 0.0001, epoch: 21/25, step: 53/80\n",
      "loss: 0.5747, last_20: 0.2676, lr: 0.0001, epoch: 21/25, step: 54/80\n",
      "loss: 0.5225, last_20: 0.2931, lr: 0.0001, epoch: 21/25, step: 55/80\n",
      "loss: 0.0046, last_20: 0.2737, lr: 0.0001, epoch: 21/25, step: 56/80\n",
      "loss: 0.149, last_20: 0.2439, lr: 0.0001, epoch: 21/25, step: 57/80\n",
      "loss: 0.0252, last_20: 0.2447, lr: 0.0001, epoch: 21/25, step: 58/80\n",
      "loss: 0.0257, last_20: 0.2454, lr: 0.0001, epoch: 21/25, step: 59/80\n",
      "loss: 0.0565, last_20: 0.2222, lr: 0.0001, epoch: 21/25, step: 60/80\n",
      "loss: 0.0081, last_20: 0.2224, lr: 0.0001, epoch: 21/25, step: 61/80\n",
      "loss: 0.8418, last_20: 0.2544, lr: 0.0001, epoch: 21/25, step: 62/80\n",
      "loss: 0.0708, last_20: 0.2555, lr: 0.0001, epoch: 21/25, step: 63/80\n",
      "loss: 0.667, last_20: 0.2574, lr: 0.0001, epoch: 21/25, step: 64/80\n",
      "loss: 0.0389, last_20: 0.2397, lr: 0.0001, epoch: 21/25, step: 65/80\n",
      "loss: 0.1731, last_20: 0.248, lr: 0.0001, epoch: 21/25, step: 66/80\n",
      "loss: 0.0315, last_20: 0.2282, lr: 0.0001, epoch: 21/25, step: 67/80\n",
      "loss: 0.3098, last_20: 0.2248, lr: 0.0001, epoch: 21/25, step: 68/80\n",
      "loss: 0.0561, last_20: 0.2178, lr: 0.0001, epoch: 21/25, step: 69/80\n",
      "loss: 0.0908, last_20: 0.2215, lr: 0.0001, epoch: 21/25, step: 70/80\n",
      "loss: 0.0676, last_20: 0.2243, lr: 0.0001, epoch: 21/25, step: 71/80\n",
      "loss: 0.2661, last_20: 0.1992, lr: 0.0001, epoch: 21/25, step: 72/80\n",
      "loss: 0.0039, last_20: 0.1992, lr: 0.0001, epoch: 21/25, step: 73/80\n",
      "loss: 0.0053, last_20: 0.1707, lr: 0.0001, epoch: 21/25, step: 74/80\n",
      "loss: 0.006, last_20: 0.1449, lr: 0.0001, epoch: 21/25, step: 75/80\n",
      "loss: 0.0453, last_20: 0.1469, lr: 0.0001, epoch: 21/25, step: 76/80\n",
      "loss: 0.4451, last_20: 0.1617, lr: 0.0001, epoch: 21/25, step: 77/80\n",
      "loss: 0.0152, last_20: 0.1612, lr: 0.0001, epoch: 21/25, step: 78/80\n",
      "loss: 0.0167, last_20: 0.1608, lr: 0.0001, epoch: 21/25, step: 79/80\n",
      "loss: 0.543, last_20: 0.1851, lr: 0.0001, epoch: 21/25, step: 80/80\n",
      "loss: 0.49, last_20: 0.2092, lr: 0.0001, epoch: 22/25, step: 1/80\n",
      "loss: 0.0551, last_20: 0.1699, lr: 0.0001, epoch: 22/25, step: 2/80\n",
      "loss: 0.6528, last_20: 0.199, lr: 0.0001, epoch: 22/25, step: 3/80\n",
      "loss: 0.4026, last_20: 0.1857, lr: 0.0001, epoch: 22/25, step: 4/80\n",
      "loss: 0.5547, last_20: 0.2115, lr: 0.0001, epoch: 22/25, step: 5/80\n",
      "loss: 0.0149, last_20: 0.2036, lr: 0.0001, epoch: 22/25, step: 6/80\n",
      "loss: 0.0229, last_20: 0.2032, lr: 0.0001, epoch: 22/25, step: 7/80\n",
      "loss: 0.3313, last_20: 0.2043, lr: 0.0001, epoch: 22/25, step: 8/80\n",
      "loss: 0.7354, last_20: 0.2382, lr: 0.0001, epoch: 22/25, step: 9/80\n",
      "loss: 0.5083, last_20: 0.2591, lr: 0.0001, epoch: 22/25, step: 10/80\n",
      "loss: 0.0755, last_20: 0.2595, lr: 0.0001, epoch: 22/25, step: 11/80\n",
      "loss: 0.2024, last_20: 0.2563, lr: 0.0001, epoch: 22/25, step: 12/80\n",
      "loss: 0.0031, last_20: 0.2563, lr: 0.0001, epoch: 22/25, step: 13/80\n",
      "loss: 0.4836, last_20: 0.2802, lr: 0.0001, epoch: 22/25, step: 14/80\n",
      "loss: 0.0868, last_20: 0.2842, lr: 0.0001, epoch: 22/25, step: 15/80\n",
      "loss: 0.0041, last_20: 0.2822, lr: 0.0001, epoch: 22/25, step: 16/80\n",
      "loss: 0.0092, last_20: 0.2604, lr: 0.0001, epoch: 22/25, step: 17/80\n",
      "loss: 0.6968, last_20: 0.2945, lr: 0.0001, epoch: 22/25, step: 18/80\n",
      "loss: 0.0489, last_20: 0.2961, lr: 0.0001, epoch: 22/25, step: 19/80\n",
      "loss: 0.2651, last_20: 0.2822, lr: 0.0001, epoch: 22/25, step: 20/80\n",
      "loss: 0.0089, last_20: 0.2581, lr: 0.0001, epoch: 22/25, step: 21/80\n",
      "loss: 0.0668, last_20: 0.2587, lr: 0.0001, epoch: 22/25, step: 22/80\n",
      "loss: 0.022, last_20: 0.2272, lr: 0.0001, epoch: 22/25, step: 23/80\n",
      "loss: 0.0185, last_20: 0.208, lr: 0.0001, epoch: 22/25, step: 24/80\n",
      "loss: 0.0039, last_20: 0.1804, lr: 0.0001, epoch: 22/25, step: 25/80\n",
      "loss: 0.0327, last_20: 0.1813, lr: 0.0001, epoch: 22/25, step: 26/80\n",
      "loss: 0.4739, last_20: 0.2039, lr: 0.0001, epoch: 22/25, step: 27/80\n",
      "loss: 0.0241, last_20: 0.1885, lr: 0.0001, epoch: 22/25, step: 28/80\n",
      "loss: 0.0104, last_20: 0.1522, lr: 0.0001, epoch: 22/25, step: 29/80\n",
      "loss: 0.1948, last_20: 0.1366, lr: 0.0001, epoch: 22/25, step: 30/80\n",
      "loss: 0.2935, last_20: 0.1475, lr: 0.0001, epoch: 22/25, step: 31/80\n",
      "loss: 0.0296, last_20: 0.1388, lr: 0.0001, epoch: 22/25, step: 32/80\n",
      "loss: 0.1155, last_20: 0.1445, lr: 0.0001, epoch: 22/25, step: 33/80\n",
      "loss: 0.0047, last_20: 0.1205, lr: 0.0001, epoch: 22/25, step: 34/80\n",
      "loss: 0.0086, last_20: 0.1166, lr: 0.0001, epoch: 22/25, step: 35/80\n",
      "loss: 0.2593, last_20: 0.1294, lr: 0.0001, epoch: 22/25, step: 36/80\n",
      "loss: 0.2991, last_20: 0.1439, lr: 0.0001, epoch: 22/25, step: 37/80\n",
      "loss: 0.1614, last_20: 0.1171, lr: 0.0001, epoch: 22/25, step: 38/80\n",
      "loss: 0.543, last_20: 0.1418, lr: 0.0001, epoch: 22/25, step: 39/80\n",
      "loss: 0.4932, last_20: 0.1532, lr: 0.0001, epoch: 22/25, step: 40/80\n",
      "loss: 0.4958, last_20: 0.1775, lr: 0.0001, epoch: 22/25, step: 41/80\n",
      "loss: 0.0542, last_20: 0.1769, lr: 0.0001, epoch: 22/25, step: 42/80\n",
      "loss: 0.0206, last_20: 0.1768, lr: 0.0001, epoch: 22/25, step: 43/80\n",
      "loss: 0.1126, last_20: 0.1815, lr: 0.0001, epoch: 22/25, step: 44/80\n",
      "loss: 0.0027, last_20: 0.1815, lr: 0.0001, epoch: 22/25, step: 45/80\n",
      "loss: 0.014, last_20: 0.1805, lr: 0.0001, epoch: 22/25, step: 46/80\n",
      "loss: 0.3625, last_20: 0.175, lr: 0.0001, epoch: 22/25, step: 47/80\n",
      "loss: 0.1656, last_20: 0.1821, lr: 0.0001, epoch: 22/25, step: 48/80\n",
      "loss: 0.0558, last_20: 0.1843, lr: 0.0001, epoch: 22/25, step: 49/80\n",
      "loss: 0.7842, last_20: 0.2138, lr: 0.0001, epoch: 22/25, step: 50/80\n",
      "loss: 0.0061, last_20: 0.1994, lr: 0.0001, epoch: 22/25, step: 51/80\n",
      "loss: 0.1392, last_20: 0.2049, lr: 0.0001, epoch: 22/25, step: 52/80\n",
      "loss: 0.519, last_20: 0.2251, lr: 0.0001, epoch: 22/25, step: 53/80\n",
      "loss: 0.0869, last_20: 0.2292, lr: 0.0001, epoch: 22/25, step: 54/80\n",
      "loss: 0.4707, last_20: 0.2523, lr: 0.0001, epoch: 22/25, step: 55/80\n",
      "loss: 0.3425, last_20: 0.2565, lr: 0.0001, epoch: 22/25, step: 56/80\n",
      "loss: 0.2378, last_20: 0.2534, lr: 0.0001, epoch: 22/25, step: 57/80\n",
      "loss: 0.0207, last_20: 0.2464, lr: 0.0001, epoch: 22/25, step: 58/80\n",
      "loss: 0.8286, last_20: 0.2606, lr: 0.0001, epoch: 22/25, step: 59/80\n",
      "loss: 0.0298, last_20: 0.2375, lr: 0.0001, epoch: 22/25, step: 60/80\n",
      "loss: 0.0891, last_20: 0.2171, lr: 0.0001, epoch: 22/25, step: 61/80\n",
      "loss: 0.5107, last_20: 0.24, lr: 0.0001, epoch: 22/25, step: 62/80\n",
      "loss: 0.1759, last_20: 0.2477, lr: 0.0001, epoch: 22/25, step: 63/80\n",
      "loss: 0.7759, last_20: 0.2809, lr: 0.0001, epoch: 22/25, step: 64/80\n",
      "loss: 0.2668, last_20: 0.2941, lr: 0.0001, epoch: 22/25, step: 65/80\n",
      "loss: 0.1245, last_20: 0.2996, lr: 0.0001, epoch: 22/25, step: 66/80\n",
      "loss: 0.0722, last_20: 0.2851, lr: 0.0001, epoch: 22/25, step: 67/80\n",
      "loss: 0.0032, last_20: 0.277, lr: 0.0001, epoch: 22/25, step: 68/80\n",
      "loss: 0.0171, last_20: 0.275, lr: 0.0001, epoch: 22/25, step: 69/80\n",
      "loss: 0.0717, last_20: 0.2394, lr: 0.0001, epoch: 22/25, step: 70/80\n",
      "loss: 0.2617, last_20: 0.2522, lr: 0.0001, epoch: 22/25, step: 71/80\n",
      "loss: 0.0202, last_20: 0.2462, lr: 0.0001, epoch: 22/25, step: 72/80\n",
      "loss: 0.024, last_20: 0.2215, lr: 0.0001, epoch: 22/25, step: 73/80\n",
      "loss: 0.6953, last_20: 0.2519, lr: 0.0001, epoch: 22/25, step: 74/80\n",
      "loss: 0.0327, last_20: 0.23, lr: 0.0001, epoch: 22/25, step: 75/80\n",
      "loss: 0.0561, last_20: 0.2157, lr: 0.0001, epoch: 22/25, step: 76/80\n",
      "loss: 0.2498, last_20: 0.2163, lr: 0.0001, epoch: 22/25, step: 77/80\n",
      "loss: 0.0714, last_20: 0.2188, lr: 0.0001, epoch: 22/25, step: 78/80\n",
      "loss: 0.0058, last_20: 0.1777, lr: 0.0001, epoch: 22/25, step: 79/80\n",
      "loss: 0.3364, last_20: 0.193, lr: 0.0001, epoch: 22/25, step: 80/80\n",
      "loss: 0.4319, last_20: 0.2102, lr: 0.0001, epoch: 23/25, step: 1/80\n",
      "loss: 0.0784, last_20: 0.1885, lr: 0.0001, epoch: 23/25, step: 2/80\n",
      "loss: 0.017, last_20: 0.1806, lr: 0.0001, epoch: 23/25, step: 3/80\n",
      "loss: 0.2788, last_20: 0.1557, lr: 0.0001, epoch: 23/25, step: 4/80\n",
      "loss: 0.0102, last_20: 0.1429, lr: 0.0001, epoch: 23/25, step: 5/80\n",
      "loss: 0.1288, last_20: 0.1431, lr: 0.0001, epoch: 23/25, step: 6/80\n",
      "loss: 0.0194, last_20: 0.1405, lr: 0.0001, epoch: 23/25, step: 7/80\n",
      "loss: 0.2751, last_20: 0.1541, lr: 0.0001, epoch: 23/25, step: 8/80\n",
      "loss: 0.4668, last_20: 0.1766, lr: 0.0001, epoch: 23/25, step: 9/80\n",
      "loss: 0.0656, last_20: 0.1763, lr: 0.0001, epoch: 23/25, step: 10/80\n",
      "loss: 0.0981, last_20: 0.1681, lr: 0.0001, epoch: 23/25, step: 11/80\n",
      "loss: 0.1461, last_20: 0.1744, lr: 0.0001, epoch: 23/25, step: 12/80\n",
      "loss: 0.0499, last_20: 0.1757, lr: 0.0001, epoch: 23/25, step: 13/80\n",
      "loss: 0.6772, last_20: 0.1748, lr: 0.0001, epoch: 23/25, step: 14/80\n",
      "loss: 0.0219, last_20: 0.1742, lr: 0.0001, epoch: 23/25, step: 15/80\n",
      "loss: 0.0403, last_20: 0.1734, lr: 0.0001, epoch: 23/25, step: 16/80\n",
      "loss: 0.0455, last_20: 0.1632, lr: 0.0001, epoch: 23/25, step: 17/80\n",
      "loss: 0.2576, last_20: 0.1725, lr: 0.0001, epoch: 23/25, step: 18/80\n",
      "loss: 0.0322, last_20: 0.1739, lr: 0.0001, epoch: 23/25, step: 19/80\n",
      "loss: 0.1814, last_20: 0.1661, lr: 0.0001, epoch: 23/25, step: 20/80\n",
      "loss: 0.0039, last_20: 0.1447, lr: 0.0001, epoch: 23/25, step: 21/80\n",
      "loss: 0.0029, last_20: 0.1409, lr: 0.0001, epoch: 23/25, step: 22/80\n",
      "loss: 0.0495, last_20: 0.1426, lr: 0.0001, epoch: 23/25, step: 23/80\n",
      "loss: 0.5112, last_20: 0.1542, lr: 0.0001, epoch: 23/25, step: 24/80\n",
      "loss: 0.025, last_20: 0.1549, lr: 0.0001, epoch: 23/25, step: 25/80\n",
      "loss: 0.0185, last_20: 0.1494, lr: 0.0001, epoch: 23/25, step: 26/80\n",
      "loss: 0.5352, last_20: 0.1752, lr: 0.0001, epoch: 23/25, step: 27/80\n",
      "loss: 0.0028, last_20: 0.1616, lr: 0.0001, epoch: 23/25, step: 28/80\n",
      "loss: 0.0075, last_20: 0.1386, lr: 0.0001, epoch: 23/25, step: 29/80\n",
      "loss: 0.1827, last_20: 0.1445, lr: 0.0001, epoch: 23/25, step: 30/80\n",
      "loss: 0.0113, last_20: 0.1401, lr: 0.0001, epoch: 23/25, step: 31/80\n",
      "loss: 0.0396, last_20: 0.1348, lr: 0.0001, epoch: 23/25, step: 32/80\n",
      "loss: 0.0072, last_20: 0.1327, lr: 0.0001, epoch: 23/25, step: 33/80\n",
      "loss: 0.0368, last_20: 0.1007, lr: 0.0001, epoch: 23/25, step: 34/80\n",
      "loss: 0.5576, last_20: 0.1274, lr: 0.0001, epoch: 23/25, step: 35/80\n",
      "loss: 0.4978, last_20: 0.1503, lr: 0.0001, epoch: 23/25, step: 36/80\n",
      "loss: 0.0133, last_20: 0.1487, lr: 0.0001, epoch: 23/25, step: 37/80\n",
      "loss: 0.008, last_20: 0.1362, lr: 0.0001, epoch: 23/25, step: 38/80\n",
      "loss: 0.0045, last_20: 0.1348, lr: 0.0001, epoch: 23/25, step: 39/80\n",
      "loss: 0.0221, last_20: 0.1269, lr: 0.0001, epoch: 23/25, step: 40/80\n",
      "loss: 0.0872, last_20: 0.131, lr: 0.0001, epoch: 23/25, step: 41/80\n",
      "loss: 0.0064, last_20: 0.1312, lr: 0.0001, epoch: 23/25, step: 42/80\n",
      "loss: 0.1191, last_20: 0.1347, lr: 0.0001, epoch: 23/25, step: 43/80\n",
      "loss: 0.0363, last_20: 0.1109, lr: 0.0001, epoch: 23/25, step: 44/80\n",
      "loss: 0.0151, last_20: 0.1105, lr: 0.0001, epoch: 23/25, step: 45/80\n",
      "loss: 0.004, last_20: 0.1097, lr: 0.0001, epoch: 23/25, step: 46/80\n",
      "loss: 0.0358, last_20: 0.0848, lr: 0.0001, epoch: 23/25, step: 47/80\n",
      "loss: 0.0163, last_20: 0.0854, lr: 0.0001, epoch: 23/25, step: 48/80\n",
      "loss: 0.2106, last_20: 0.0956, lr: 0.0001, epoch: 23/25, step: 49/80\n",
      "loss: 0.0053, last_20: 0.0867, lr: 0.0001, epoch: 23/25, step: 50/80\n",
      "loss: 0.2166, last_20: 0.097, lr: 0.0001, epoch: 23/25, step: 51/80\n",
      "loss: 0.5278, last_20: 0.1214, lr: 0.0001, epoch: 23/25, step: 52/80\n",
      "loss: 0.0046, last_20: 0.1213, lr: 0.0001, epoch: 23/25, step: 53/80\n",
      "loss: 0.0711, last_20: 0.123, lr: 0.0001, epoch: 23/25, step: 54/80\n",
      "loss: 0.0066, last_20: 0.0954, lr: 0.0001, epoch: 23/25, step: 55/80\n",
      "loss: 0.5815, last_20: 0.0996, lr: 0.0001, epoch: 23/25, step: 56/80\n",
      "loss: 0.0023, last_20: 0.0991, lr: 0.0001, epoch: 23/25, step: 57/80\n",
      "loss: 0.1226, last_20: 0.1048, lr: 0.0001, epoch: 23/25, step: 58/80\n",
      "loss: 0.0383, last_20: 0.1065, lr: 0.0001, epoch: 23/25, step: 59/80\n",
      "loss: 0.015, last_20: 0.1061, lr: 0.0001, epoch: 23/25, step: 60/80\n",
      "loss: 0.959, last_20: 0.1497, lr: 0.0001, epoch: 23/25, step: 61/80\n",
      "loss: 0.0594, last_20: 0.1524, lr: 0.0001, epoch: 23/25, step: 62/80\n",
      "loss: 0.1332, last_20: 0.1531, lr: 0.0001, epoch: 23/25, step: 63/80\n",
      "loss: 0.0422, last_20: 0.1534, lr: 0.0001, epoch: 23/25, step: 64/80\n",
      "loss: 0.4436, last_20: 0.1748, lr: 0.0001, epoch: 23/25, step: 65/80\n",
      "loss: 0.0024, last_20: 0.1747, lr: 0.0001, epoch: 23/25, step: 66/80\n",
      "loss: 0.3745, last_20: 0.1916, lr: 0.0001, epoch: 23/25, step: 67/80\n",
      "loss: 0.4102, last_20: 0.2113, lr: 0.0001, epoch: 23/25, step: 68/80\n",
      "loss: 0.0088, last_20: 0.2012, lr: 0.0001, epoch: 23/25, step: 69/80\n",
      "loss: 0.1681, last_20: 0.2094, lr: 0.0001, epoch: 23/25, step: 70/80\n",
      "loss: 0.2859, last_20: 0.2129, lr: 0.0001, epoch: 23/25, step: 71/80\n",
      "loss: 0.0454, last_20: 0.1887, lr: 0.0001, epoch: 23/25, step: 72/80\n",
      "loss: 0.2235, last_20: 0.1997, lr: 0.0001, epoch: 23/25, step: 73/80\n",
      "loss: 0.0145, last_20: 0.1968, lr: 0.0001, epoch: 23/25, step: 74/80\n",
      "loss: 0.1085, last_20: 0.2019, lr: 0.0001, epoch: 23/25, step: 75/80\n",
      "loss: 0.0337, last_20: 0.1746, lr: 0.0001, epoch: 23/25, step: 76/80\n",
      "loss: 0.1497, last_20: 0.1819, lr: 0.0001, epoch: 23/25, step: 77/80\n",
      "loss: 0.1088, last_20: 0.1812, lr: 0.0001, epoch: 23/25, step: 78/80\n",
      "loss: 0.0253, last_20: 0.1806, lr: 0.0001, epoch: 23/25, step: 79/80\n",
      "loss: 0.4827, last_20: 0.204, lr: 0.0001, epoch: 23/25, step: 80/80\n",
      "loss: 0.3174, last_20: 0.1719, lr: 0.0001, epoch: 24/25, step: 1/80\n",
      "loss: 0.3853, last_20: 0.1882, lr: 0.0001, epoch: 24/25, step: 2/80\n",
      "loss: 0.47, last_20: 0.205, lr: 0.0001, epoch: 24/25, step: 3/80\n",
      "loss: 0.0197, last_20: 0.2039, lr: 0.0001, epoch: 24/25, step: 4/80\n",
      "loss: 0.0439, last_20: 0.1839, lr: 0.0001, epoch: 24/25, step: 5/80\n",
      "loss: 0.323, last_20: 0.1999, lr: 0.0001, epoch: 24/25, step: 6/80\n",
      "loss: 0.0676, last_20: 0.1846, lr: 0.0001, epoch: 24/25, step: 7/80\n",
      "loss: 0.0032, last_20: 0.1643, lr: 0.0001, epoch: 24/25, step: 8/80\n",
      "loss: 0.0089, last_20: 0.1643, lr: 0.0001, epoch: 24/25, step: 9/80\n",
      "loss: 0.0263, last_20: 0.1572, lr: 0.0001, epoch: 24/25, step: 10/80\n",
      "loss: 0.0028, last_20: 0.143, lr: 0.0001, epoch: 24/25, step: 11/80\n",
      "loss: 0.1914, last_20: 0.1503, lr: 0.0001, epoch: 24/25, step: 12/80\n",
      "loss: 0.6406, last_20: 0.1712, lr: 0.0001, epoch: 24/25, step: 13/80\n",
      "loss: 0.3604, last_20: 0.1885, lr: 0.0001, epoch: 24/25, step: 14/80\n",
      "loss: 0.0551, last_20: 0.1858, lr: 0.0001, epoch: 24/25, step: 15/80\n",
      "loss: 0.2229, last_20: 0.1952, lr: 0.0001, epoch: 24/25, step: 16/80\n",
      "loss: 0.0286, last_20: 0.1892, lr: 0.0001, epoch: 24/25, step: 17/80\n",
      "loss: 0.3022, last_20: 0.1989, lr: 0.0001, epoch: 24/25, step: 18/80\n",
      "loss: 0.0077, last_20: 0.198, lr: 0.0001, epoch: 24/25, step: 19/80\n",
      "loss: 0.3, last_20: 0.1888, lr: 0.0001, epoch: 24/25, step: 20/80\n",
      "loss: 0.0797, last_20: 0.177, lr: 0.0001, epoch: 24/25, step: 21/80\n",
      "loss: 0.0059, last_20: 0.158, lr: 0.0001, epoch: 24/25, step: 22/80\n",
      "loss: 0.0188, last_20: 0.1354, lr: 0.0001, epoch: 24/25, step: 23/80\n",
      "loss: 0.3401, last_20: 0.1515, lr: 0.0001, epoch: 24/25, step: 24/80\n",
      "loss: 0.0252, last_20: 0.1505, lr: 0.0001, epoch: 24/25, step: 25/80\n",
      "loss: 0.0196, last_20: 0.1353, lr: 0.0001, epoch: 24/25, step: 26/80\n",
      "loss: 0.0685, last_20: 0.1354, lr: 0.0001, epoch: 24/25, step: 27/80\n",
      "loss: 0.1168, last_20: 0.1411, lr: 0.0001, epoch: 24/25, step: 28/80\n",
      "loss: 0.0098, last_20: 0.1411, lr: 0.0001, epoch: 24/25, step: 29/80\n",
      "loss: 0.0278, last_20: 0.1412, lr: 0.0001, epoch: 24/25, step: 30/80\n",
      "loss: 0.0195, last_20: 0.142, lr: 0.0001, epoch: 24/25, step: 31/80\n",
      "loss: 0.3916, last_20: 0.152, lr: 0.0001, epoch: 24/25, step: 32/80\n",
      "loss: 0.0144, last_20: 0.1207, lr: 0.0001, epoch: 24/25, step: 33/80\n",
      "loss: 0.0187, last_20: 0.1036, lr: 0.0001, epoch: 24/25, step: 34/80\n",
      "loss: 0.5732, last_20: 0.1295, lr: 0.0001, epoch: 24/25, step: 35/80\n",
      "loss: 0.004, last_20: 0.1186, lr: 0.0001, epoch: 24/25, step: 36/80\n",
      "loss: 0.0376, last_20: 0.1191, lr: 0.0001, epoch: 24/25, step: 37/80\n",
      "loss: 0.0023, last_20: 0.1041, lr: 0.0001, epoch: 24/25, step: 38/80\n",
      "loss: 0.6094, last_20: 0.1341, lr: 0.0001, epoch: 24/25, step: 39/80\n",
      "loss: 0.0744, last_20: 0.1229, lr: 0.0001, epoch: 24/25, step: 40/80\n",
      "loss: 0.2231, last_20: 0.13, lr: 0.0001, epoch: 24/25, step: 41/80\n",
      "loss: 0.0802, last_20: 0.1338, lr: 0.0001, epoch: 24/25, step: 42/80\n",
      "loss: 0.0602, last_20: 0.1358, lr: 0.0001, epoch: 24/25, step: 43/80\n",
      "loss: 0.0321, last_20: 0.1204, lr: 0.0001, epoch: 24/25, step: 44/80\n",
      "loss: 0.6514, last_20: 0.1517, lr: 0.0001, epoch: 24/25, step: 45/80\n",
      "loss: 0.1135, last_20: 0.1564, lr: 0.0001, epoch: 24/25, step: 46/80\n",
      "loss: 0.5557, last_20: 0.1808, lr: 0.0001, epoch: 24/25, step: 47/80\n",
      "loss: 0.3337, last_20: 0.1916, lr: 0.0001, epoch: 24/25, step: 48/80\n",
      "loss: 0.117, last_20: 0.197, lr: 0.0001, epoch: 24/25, step: 49/80\n",
      "loss: 0.3113, last_20: 0.2112, lr: 0.0001, epoch: 24/25, step: 50/80\n",
      "loss: 0.0069, last_20: 0.2105, lr: 0.0001, epoch: 24/25, step: 51/80\n",
      "loss: 0.2228, last_20: 0.2021, lr: 0.0001, epoch: 24/25, step: 52/80\n",
      "loss: 0.0061, last_20: 0.2017, lr: 0.0001, epoch: 24/25, step: 53/80\n",
      "loss: 0.1371, last_20: 0.2076, lr: 0.0001, epoch: 24/25, step: 54/80\n",
      "loss: 0.1215, last_20: 0.185, lr: 0.0001, epoch: 24/25, step: 55/80\n",
      "loss: 0.4893, last_20: 0.2093, lr: 0.0001, epoch: 24/25, step: 56/80\n",
      "loss: 0.6235, last_20: 0.2386, lr: 0.0001, epoch: 24/25, step: 57/80\n",
      "loss: 0.0323, last_20: 0.2401, lr: 0.0001, epoch: 24/25, step: 58/80\n",
      "loss: 0.0039, last_20: 0.2098, lr: 0.0001, epoch: 24/25, step: 59/80\n",
      "loss: 0.1188, last_20: 0.212, lr: 0.0001, epoch: 24/25, step: 60/80\n",
      "loss: 0.0298, last_20: 0.2024, lr: 0.0001, epoch: 24/25, step: 61/80\n",
      "loss: 0.0262, last_20: 0.1997, lr: 0.0001, epoch: 24/25, step: 62/80\n",
      "loss: 0.6367, last_20: 0.2285, lr: 0.0001, epoch: 24/25, step: 63/80\n",
      "loss: 0.0119, last_20: 0.2275, lr: 0.0001, epoch: 24/25, step: 64/80\n",
      "loss: 0.1877, last_20: 0.2043, lr: 0.0001, epoch: 24/25, step: 65/80\n",
      "loss: 0.0154, last_20: 0.1994, lr: 0.0001, epoch: 24/25, step: 66/80\n",
      "loss: 0.4539, last_20: 0.1943, lr: 0.0001, epoch: 24/25, step: 67/80\n",
      "loss: 0.24, last_20: 0.1896, lr: 0.0001, epoch: 24/25, step: 68/80\n",
      "loss: 0.6904, last_20: 0.2183, lr: 0.0001, epoch: 24/25, step: 69/80\n",
      "loss: 0.0186, last_20: 0.2036, lr: 0.0001, epoch: 24/25, step: 70/80\n",
      "loss: 0.1522, last_20: 0.2109, lr: 0.0001, epoch: 24/25, step: 71/80\n",
      "loss: 0.0079, last_20: 0.2002, lr: 0.0001, epoch: 24/25, step: 72/80\n",
      "loss: 0.0622, last_20: 0.203, lr: 0.0001, epoch: 24/25, step: 73/80\n",
      "loss: 0.3389, last_20: 0.2131, lr: 0.0001, epoch: 24/25, step: 74/80\n",
      "loss: 0.1677, last_20: 0.2154, lr: 0.0001, epoch: 24/25, step: 75/80\n",
      "loss: 0.4551, last_20: 0.2137, lr: 0.0001, epoch: 24/25, step: 76/80\n",
      "loss: 0.2292, last_20: 0.1939, lr: 0.0001, epoch: 24/25, step: 77/80\n",
      "loss: 0.0186, last_20: 0.1933, lr: 0.0001, epoch: 24/25, step: 78/80\n",
      "loss: 0.125, last_20: 0.1993, lr: 0.0001, epoch: 24/25, step: 79/80\n",
      "loss: 0.3376, last_20: 0.2102, lr: 0.0001, epoch: 24/25, step: 80/80\n",
      "loss: 0.4387, last_20: 0.2307, lr: 0.0001, epoch: 25/25, step: 1/80\n",
      "loss: 0.0153, last_20: 0.2301, lr: 0.0001, epoch: 25/25, step: 2/80\n",
      "loss: 0.0328, last_20: 0.2, lr: 0.0001, epoch: 25/25, step: 3/80\n",
      "loss: 0.007, last_20: 0.1997, lr: 0.0001, epoch: 25/25, step: 4/80\n",
      "loss: 0.0854, last_20: 0.1946, lr: 0.0001, epoch: 25/25, step: 5/80\n",
      "loss: 0.4292, last_20: 0.2153, lr: 0.0001, epoch: 25/25, step: 6/80\n",
      "loss: 0.1415, last_20: 0.1997, lr: 0.0001, epoch: 25/25, step: 7/80\n",
      "loss: 0.0027, last_20: 0.1878, lr: 0.0001, epoch: 25/25, step: 8/80\n",
      "loss: 0.5386, last_20: 0.1802, lr: 0.0001, epoch: 25/25, step: 9/80\n",
      "loss: 0.4209, last_20: 0.2003, lr: 0.0001, epoch: 25/25, step: 10/80\n",
      "loss: 0.179, last_20: 0.2017, lr: 0.0001, epoch: 25/25, step: 11/80\n",
      "loss: 0.3672, last_20: 0.2196, lr: 0.0001, epoch: 25/25, step: 12/80\n",
      "loss: 0.1008, last_20: 0.2216, lr: 0.0001, epoch: 25/25, step: 13/80\n",
      "loss: 0.0105, last_20: 0.2051, lr: 0.0001, epoch: 25/25, step: 14/80\n",
      "loss: 0.0042, last_20: 0.197, lr: 0.0001, epoch: 25/25, step: 15/80\n",
      "loss: 0.0132, last_20: 0.1749, lr: 0.0001, epoch: 25/25, step: 16/80\n",
      "loss: 0.1379, last_20: 0.1703, lr: 0.0001, epoch: 25/25, step: 17/80\n",
      "loss: 0.4507, last_20: 0.1919, lr: 0.0001, epoch: 25/25, step: 18/80\n",
      "loss: 0.0404, last_20: 0.1877, lr: 0.0001, epoch: 25/25, step: 19/80\n",
      "loss: 0.0106, last_20: 0.1713, lr: 0.0001, epoch: 25/25, step: 20/80\n",
      "loss: 0.0836, last_20: 0.1536, lr: 0.0001, epoch: 25/25, step: 21/80\n",
      "loss: 0.0626, last_20: 0.1559, lr: 0.0001, epoch: 25/25, step: 22/80\n",
      "loss: 0.248, last_20: 0.1667, lr: 0.0001, epoch: 25/25, step: 23/80\n",
      "loss: 0.1387, last_20: 0.1733, lr: 0.0001, epoch: 25/25, step: 24/80\n",
      "loss: 0.2717, last_20: 0.1826, lr: 0.0001, epoch: 25/25, step: 25/80\n",
      "loss: 0.6465, last_20: 0.1935, lr: 0.0001, epoch: 25/25, step: 26/80\n",
      "loss: 0.0453, last_20: 0.1887, lr: 0.0001, epoch: 25/25, step: 27/80\n",
      "loss: 0.0975, last_20: 0.1934, lr: 0.0001, epoch: 25/25, step: 28/80\n",
      "loss: 0.7969, last_20: 0.2063, lr: 0.0001, epoch: 25/25, step: 29/80\n",
      "loss: 0.4072, last_20: 0.2056, lr: 0.0001, epoch: 25/25, step: 30/80\n",
      "loss: 0.0637, last_20: 0.1999, lr: 0.0001, epoch: 25/25, step: 31/80\n",
      "loss: 0.0072, last_20: 0.1819, lr: 0.0001, epoch: 25/25, step: 32/80\n",
      "loss: 0.4089, last_20: 0.1973, lr: 0.0001, epoch: 25/25, step: 33/80\n",
      "loss: 0.132, last_20: 0.2033, lr: 0.0001, epoch: 25/25, step: 34/80\n",
      "loss: 0.6289, last_20: 0.2346, lr: 0.0001, epoch: 25/25, step: 35/80\n",
      "loss: 0.0318, last_20: 0.2355, lr: 0.0001, epoch: 25/25, step: 36/80\n",
      "loss: 0.0667, last_20: 0.2319, lr: 0.0001, epoch: 25/25, step: 37/80\n",
      "loss: 0.1855, last_20: 0.2187, lr: 0.0001, epoch: 25/25, step: 38/80\n",
      "loss: 0.0137, last_20: 0.2173, lr: 0.0001, epoch: 25/25, step: 39/80\n",
      "loss: 0.1685, last_20: 0.2252, lr: 0.0001, epoch: 25/25, step: 40/80\n",
      "loss: 0.05, last_20: 0.2236, lr: 0.0001, epoch: 25/25, step: 41/80\n",
      "loss: 0.0034, last_20: 0.2206, lr: 0.0001, epoch: 25/25, step: 42/80\n",
      "loss: 0.0066, last_20: 0.2085, lr: 0.0001, epoch: 25/25, step: 43/80\n",
      "loss: 0.3223, last_20: 0.2177, lr: 0.0001, epoch: 25/25, step: 44/80\n",
      "loss: 0.0155, last_20: 0.2049, lr: 0.0001, epoch: 25/25, step: 45/80\n",
      "loss: 0.0096, last_20: 0.1731, lr: 0.0001, epoch: 25/25, step: 46/80\n",
      "loss: 0.0036, last_20: 0.171, lr: 0.0001, epoch: 25/25, step: 47/80\n",
      "loss: 0.0992, last_20: 0.1711, lr: 0.0001, epoch: 25/25, step: 48/80\n",
      "loss: 0.1177, last_20: 0.1371, lr: 0.0001, epoch: 25/25, step: 49/80\n",
      "loss: 0.1324, last_20: 0.1234, lr: 0.0001, epoch: 25/25, step: 50/80\n",
      "loss: 0.7676, last_20: 0.1586, lr: 0.0001, epoch: 25/25, step: 51/80\n",
      "loss: 0.0052, last_20: 0.1585, lr: 0.0001, epoch: 25/25, step: 52/80\n",
      "loss: 0.2451, last_20: 0.1503, lr: 0.0001, epoch: 25/25, step: 53/80\n",
      "loss: 0.0134, last_20: 0.1443, lr: 0.0001, epoch: 25/25, step: 54/80\n",
      "loss: 0.2341, last_20: 0.1246, lr: 0.0001, epoch: 25/25, step: 55/80\n",
      "loss: 0.0151, last_20: 0.1238, lr: 0.0001, epoch: 25/25, step: 56/80\n",
      "loss: 0.0275, last_20: 0.1218, lr: 0.0001, epoch: 25/25, step: 57/80\n",
      "loss: 0.5039, last_20: 0.1377, lr: 0.0001, epoch: 25/25, step: 58/80\n",
      "loss: 0.0092, last_20: 0.1375, lr: 0.0001, epoch: 25/25, step: 59/80\n",
      "loss: 0.0702, last_20: 0.1326, lr: 0.0001, epoch: 25/25, step: 60/80\n",
      "loss: 0.0396, last_20: 0.1321, lr: 0.0001, epoch: 25/25, step: 61/80\n",
      "loss: 0.5264, last_20: 0.1582, lr: 0.0001, epoch: 25/25, step: 62/80\n",
      "loss: 0.3628, last_20: 0.176, lr: 0.0001, epoch: 25/25, step: 63/80\n",
      "loss: 0.0144, last_20: 0.1606, lr: 0.0001, epoch: 25/25, step: 64/80\n",
      "loss: 0.2457, last_20: 0.1721, lr: 0.0001, epoch: 25/25, step: 65/80\n",
      "loss: 0.3899, last_20: 0.1911, lr: 0.0001, epoch: 25/25, step: 66/80\n",
      "loss: 0.0256, last_20: 0.1922, lr: 0.0001, epoch: 25/25, step: 67/80\n",
      "loss: 0.4109, last_20: 0.2078, lr: 0.0001, epoch: 25/25, step: 68/80\n",
      "loss: 0.8154, last_20: 0.2427, lr: 0.0001, epoch: 25/25, step: 69/80\n",
      "loss: 0.384, last_20: 0.2553, lr: 0.0001, epoch: 25/25, step: 70/80\n",
      "loss: 0.2637, last_20: 0.2301, lr: 0.0001, epoch: 25/25, step: 71/80\n",
      "loss: 0.0055, last_20: 0.2301, lr: 0.0001, epoch: 25/25, step: 72/80\n",
      "loss: 0.5303, last_20: 0.2444, lr: 0.0001, epoch: 25/25, step: 73/80\n",
      "loss: 0.0515, last_20: 0.2463, lr: 0.0001, epoch: 25/25, step: 74/80\n",
      "loss: 0.1886, last_20: 0.244, lr: 0.0001, epoch: 25/25, step: 75/80\n",
      "loss: 0.6304, last_20: 0.2748, lr: 0.0001, epoch: 25/25, step: 76/80\n",
      "loss: 0.0481, last_20: 0.2758, lr: 0.0001, epoch: 25/25, step: 77/80\n",
      "loss: 0.0357, last_20: 0.2524, lr: 0.0001, epoch: 25/25, step: 78/80\n",
      "loss: 0.6328, last_20: 0.2836, lr: 0.0001, epoch: 25/25, step: 79/80\n",
      "loss: 0.0598, last_20: 0.2831, lr: 0.0001, epoch: 25/25, step: 80/80\n",
      "***** Training Completed *****\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(text_encoder.get_input_embeddings().parameters(), lr=1e-4, eps=1e-7)\n",
    "#optimizer = torch.optim.RMSprop(text_encoder.get_input_embeddings().parameters(), lr=1e-3, eps=1e-7)\n",
    "\n",
    "# Training\n",
    "data_folder = f'../data/{property_name}'\n",
    "train_model(property_name, data_folder, optimizer, num_train_epochs=30)\n",
    "\n",
    "# Save final model\n",
    "save_model(f'saved_models/textual_inversion/{property_name}', f'{property_name}_final.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1 (tags/v3.8.1:1b293b6, Dec 18 2019, 23:11:46) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cc8010bf3f78e9c10d4febe712c77abe75f8df416c09ebdb6a9b39023fa5c08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
