{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, DDPMScheduler\n",
    "from itertools import chain\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, logging\n",
    "\n",
    "# Setup\n",
    "diffusion_model_id = 'runwayml/stable-diffusion-v1-5'\n",
    "text_encoder_model_id = 'openai/clip-vit-large-patch14'\n",
    "device = 'cuda'\n",
    "seed = 1024\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Textual inversion settings\n",
    "property_name = 'skypiea'  # Name of property to learn\n",
    "property_type = 'location'  # Type of property to learn (object, style)\n",
    "placeholder_token = '<skypiea>'  # Token that represents new property\n",
    "initializer_token = 'sky'  # Initial embedding for new property\n",
    "\n",
    "# Hugging Face access token\n",
    "token = ''\n",
    "with open('hugging_face_token.txt', 'r') as secret:\n",
    "    token = secret.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model components\n",
    "\n",
    "# Text Encoder + Tokenizer\n",
    "tokenizer = CLIPTokenizer.from_pretrained(text_encoder_model_id)\n",
    "text_encoder = CLIPTextModel.from_pretrained(text_encoder_model_id, torch_dtype=torch.float16)\n",
    "text_encoder.to(device)\n",
    "\n",
    "# Variational Autoencoder\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    diffusion_model_id, subfolder='vae', torch_dtype=torch.float16,\n",
    "    revision='fp16', use_auth_token=token)\n",
    "vae.to(device)\n",
    "\n",
    "# U-Net Model\n",
    "u_net = UNet2DConditionModel.from_pretrained(\n",
    "    diffusion_model_id, subfolder='unet', torch_dtype=torch.float16,\n",
    "    revision='fp16', use_auth_token=token)\n",
    "u_net.to(device)\n",
    "\n",
    "# Noise Scheduler\n",
    "noise_scheduler = DDPMScheduler.from_config(diffusion_model_id, subfolder='scheduler', use_auth_token=token)\n",
    "\n",
    "# Freeze parameters for a model\n",
    "def freeze_params(params):\n",
    "    for param in params:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Freeze all pre-trained models except for token embeddings in the text encoder\n",
    "freeze_params(vae.parameters())\n",
    "freeze_params(u_net.parameters())\n",
    "encoder_params_to_freeze = itertools.chain(\n",
    "        text_encoder.text_model.encoder.parameters(),\n",
    "        text_encoder.text_model.final_layer_norm.parameters(),\n",
    "        text_encoder.text_model.embeddings.position_embedding.parameters(),\n",
    ")\n",
    "freeze_params(encoder_params_to_freeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tokenizer and text encoder\n",
    "\n",
    "# Add the placeholder token in tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(placeholder_token)\n",
    "\n",
    "# Convert the initializer_token, placeholder_token to ids\n",
    "token_ids = tokenizer.encode(initializer_token, add_special_tokens=False)\n",
    "initializer_token_id = token_ids[0]\n",
    "placeholder_token_id = tokenizer.convert_tokens_to_ids(placeholder_token)\n",
    "\n",
    "# Resize the token embeddings as we are adding new special tokens to the tokenizer\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Initialise the newly added placeholder token with the embeddings of the initializer token\n",
    "token_embeds = text_encoder.get_input_embeddings().weight.data\n",
    "token_embeds[placeholder_token_id] = token_embeds[initializer_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt base templates\n",
    "\n",
    "# Object\n",
    "object_templates = [\n",
    "    'a photo of a {}',\n",
    "    'a rendering of a {}',\n",
    "    'a cropped photo of the {}',\n",
    "    'the photo of a {}',\n",
    "    'a photo of a clean {}',\n",
    "    'a photo of a dirty {}',\n",
    "    'a dark photo of the {}',\n",
    "    'a photo of my {}',\n",
    "    'a photo of the cool {}',\n",
    "    'a close-up photo of a {}',\n",
    "    'a bright photo of the {}',\n",
    "    'a cropped photo of a {}',\n",
    "    'a photo of the {}',\n",
    "    'a good photo of the {}',\n",
    "    'a photo of one {}',\n",
    "    'a close-up photo of the {}',\n",
    "    'a rendition of the {}',\n",
    "    'a photo of the clean {}',\n",
    "    'a rendition of a {}',\n",
    "    'a photo of a nice {}',\n",
    "    'a good photo of a {}',\n",
    "    'a photo of the nice {}',\n",
    "    'a photo of the small {}',\n",
    "    'a photo of the weird {}',\n",
    "    'a photo of the large {}',\n",
    "    'a photo of a cool {}',\n",
    "    'a photo of a small {}',\n",
    "]\n",
    "\n",
    "# Style\n",
    "style_templates = [\n",
    "    'a painting in the style of {}',\n",
    "    'a rendering in the style of {}',\n",
    "    'a cropped painting in the style of {}',\n",
    "    'the painting in the style of {}',\n",
    "    'a clean painting in the style of {}',\n",
    "    'a dirty painting in the style of {}',\n",
    "    'a dark painting in the style of {}',\n",
    "    'a picture in the style of {}',\n",
    "    'a cool painting in the style of {}',\n",
    "    'a close-up painting in the style of {}',\n",
    "    'a bright painting in the style of {}',\n",
    "    'a cropped painting in the style of {}',\n",
    "    'a good painting in the style of {}',\n",
    "    'a close-up painting in the style of {}',\n",
    "    'a rendition in the style of {}',\n",
    "    'a nice painting in the style of {}',\n",
    "    'a small painting in the style of {}',\n",
    "    'a weird painting in the style of {}',\n",
    "    'a large painting in the style of {}',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended prompt templates\n",
    "\n",
    "selected_templates = [p.format(placeholder_token) for p in object_templates]  # Object\n",
    "if property_type == 'style':  # Style\n",
    "    selected_templates = [p.format(placeholder_token) for p in style_templates]\n",
    "elif property_type == 'location':  # Location\n",
    "    #data_folder = f'../data/{property_name}/'\n",
    "    selected_templates = [p.format(f'location of {placeholder_token}') for p in object_templates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class TextualInversionDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root,\n",
    "        templates,\n",
    "        placeholder_token,\n",
    "        repeats=10,  # 100\n",
    "        flip_p=0.5,\n",
    "    ):\n",
    "        self.data_root = data_root\n",
    "        self.placeholder_token = placeholder_token\n",
    "        self.flip_p = flip_p\n",
    "        self.flip_transform = RandomHorizontalFlip(p=self.flip_p)\n",
    "\n",
    "        # Data settings\n",
    "        self.image_paths = [os.path.join(self.data_root, file_path) for file_path in os.listdir(self.data_root)]\n",
    "        self.num_images = len(self.image_paths)\n",
    "        self._length = self.num_images * repeats\n",
    "        self.templates = templates\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Get and prepare image\n",
    "        image = Image.open(self.image_paths[i % self.num_images])\n",
    "        image = self.flip_transform(image)\n",
    "        image = np.array(image).astype(np.uint8)\n",
    "        image = (image / 127.5 - 1.0).astype(np.float16)\n",
    "\n",
    "        # Get text prompt\n",
    "        text = random.choice(self.templates)\n",
    "\n",
    "        # Create example\n",
    "        example = {}\n",
    "        example['input_prompt'] = text\n",
    "        example['pixel_values'] = torch.from_numpy(image).permute(2, 0, 1).to(device)\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "# Encode input prompt\n",
    "def encode_prompt(prompt):\n",
    "    text_inputs = tokenizer(\n",
    "        prompt, padding='max_length', max_length=tokenizer.model_max_length,\n",
    "        truncation=True, return_tensors='pt')\n",
    "    text_embeddings = text_encoder(text_inputs.input_ids.to(device))[0]\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to a pytorch file\n",
    "def save_model(path_dir, filename):\n",
    "    if not os.path.isdir(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    learned_embeddings = text_encoder.get_input_embeddings().weight[placeholder_token_id]\n",
    "    torch.save({placeholder_token: learned_embeddings.detach().cpu()}, os.path.join(path_dir, filename))\n",
    "\n",
    "# Model training\n",
    "def train_model(property, data_root, optimizer, num_train_epochs=50, batch_size=1):\n",
    "    # Initialize dataset\n",
    "    train_dataset = TextualInversionDataset(data_root, selected_templates, placeholder_token)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    max_train_steps = num_train_epochs * len(train_dataloader)\n",
    "    lr_scheduler = LambdaLR(optimizer, lambda _: 1)\n",
    "\n",
    "    # Training loop\n",
    "    print('***** Running Training *****')\n",
    "    print(f'  Num. Examples = {len(train_dataset)}')\n",
    "    print(f'  Num. Epochs = {num_train_epochs}')\n",
    "    loss_queue = deque(maxlen=20)\n",
    "    for epoch in range(num_train_epochs):\n",
    "        # Save current model\n",
    "        if not (epoch % 10):\n",
    "            save_model(f'saved_models/{property}', f'{property}_{epoch // 10}.pt')\n",
    "\n",
    "        # Train for another epoch\n",
    "        text_encoder.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Convert images to latent space\n",
    "            latents = vae.encode(batch['pixel_values']).latent_dist.sample()\n",
    "            latents *= 0.18215\n",
    "\n",
    "            # Sample noise that we'll add to the latents\n",
    "            noise = torch.randn(latents.shape, dtype=torch.float16).to(latents.device)\n",
    "            bsz = latents.shape[0]\n",
    "\n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(\n",
    "                0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device\n",
    "            ).long()\n",
    "\n",
    "            # Add noise to the latents according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "\n",
    "            # Get the text embedding for conditioning\n",
    "            encoder_hidden_states = encode_prompt(batch['input_prompt'])\n",
    "\n",
    "            # Predict the noise residual\n",
    "            noise_pred = u_net(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "\n",
    "            # Backwards pass\n",
    "            loss = F.mse_loss(noise_pred, noise, reduction='none').mean([1, 2, 3]).mean()\n",
    "            loss.backward()\n",
    "\n",
    "            # Zero out the gradients for all token embeddings except the placeholder token\n",
    "            grads = text_encoder.get_input_embeddings().weight.grad\n",
    "            index_grads_to_zero = torch.arange(len(tokenizer)) != placeholder_token_id\n",
    "            grads.data[index_grads_to_zero, :] = grads.data[index_grads_to_zero, :].fill_(0)\n",
    "\n",
    "            # Optimizer pass\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Print logs\n",
    "            current_loss = round(loss.detach().item(), 4)\n",
    "            loss_queue.append(current_loss)\n",
    "            recent_loss = round(sum(loss_queue) / len(loss_queue), 4)\n",
    "            print(f'loss: {current_loss}, last_20: {recent_loss}, lr: {lr_scheduler.get_last_lr()[0]}, '\n",
    "                  f'epoch: {epoch + 1}/{num_train_epochs}, step: {step + 1}/{len(train_dataloader)}')\n",
    "    print('***** Training Completed *****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Running Training *****\n",
      "  Num. Examples = 30\n",
      "  Num. Epochs = 20\n",
      "loss: 0.0359, last_20: 0.0359, lr: 0.0001, epoch: 1/20, step: 1/30\n",
      "loss: 0.0202, last_20: 0.028, lr: 0.0001, epoch: 1/20, step: 2/30\n",
      "loss: 0.2218, last_20: 0.0926, lr: 0.0001, epoch: 1/20, step: 3/30\n",
      "loss: 0.0135, last_20: 0.0728, lr: 0.0001, epoch: 1/20, step: 4/30\n",
      "loss: 0.0065, last_20: 0.0596, lr: 0.0001, epoch: 1/20, step: 5/30\n",
      "loss: 0.0544, last_20: 0.0587, lr: 0.0001, epoch: 1/20, step: 6/30\n",
      "loss: 0.3582, last_20: 0.1015, lr: 0.0001, epoch: 1/20, step: 7/30\n",
      "loss: 0.4363, last_20: 0.1434, lr: 0.0001, epoch: 1/20, step: 8/30\n",
      "loss: 0.2361, last_20: 0.1537, lr: 0.0001, epoch: 1/20, step: 9/30\n",
      "loss: 0.002, last_20: 0.1385, lr: 0.0001, epoch: 1/20, step: 10/30\n",
      "loss: 0.363, last_20: 0.1589, lr: 0.0001, epoch: 1/20, step: 11/30\n",
      "loss: 0.0035, last_20: 0.1459, lr: 0.0001, epoch: 1/20, step: 12/30\n",
      "loss: 0.0302, last_20: 0.137, lr: 0.0001, epoch: 1/20, step: 13/30\n",
      "loss: 0.0347, last_20: 0.1297, lr: 0.0001, epoch: 1/20, step: 14/30\n",
      "loss: 0.6611, last_20: 0.1652, lr: 0.0001, epoch: 1/20, step: 15/30\n",
      "loss: 0.0038, last_20: 0.1551, lr: 0.0001, epoch: 1/20, step: 16/30\n",
      "loss: 0.2373, last_20: 0.1599, lr: 0.0001, epoch: 1/20, step: 17/30\n",
      "loss: 0.0319, last_20: 0.1528, lr: 0.0001, epoch: 1/20, step: 18/30\n",
      "loss: 0.0042, last_20: 0.145, lr: 0.0001, epoch: 1/20, step: 19/30\n",
      "loss: 0.165, last_20: 0.146, lr: 0.0001, epoch: 1/20, step: 20/30\n",
      "loss: 0.1366, last_20: 0.151, lr: 0.0001, epoch: 1/20, step: 21/30\n",
      "loss: 0.0049, last_20: 0.1502, lr: 0.0001, epoch: 1/20, step: 22/30\n",
      "loss: 0.0734, last_20: 0.1428, lr: 0.0001, epoch: 1/20, step: 23/30\n",
      "loss: 0.2966, last_20: 0.157, lr: 0.0001, epoch: 1/20, step: 24/30\n",
      "loss: 0.0222, last_20: 0.1578, lr: 0.0001, epoch: 1/20, step: 25/30\n",
      "loss: 0.0603, last_20: 0.1581, lr: 0.0001, epoch: 1/20, step: 26/30\n",
      "loss: 0.0644, last_20: 0.1434, lr: 0.0001, epoch: 1/20, step: 27/30\n",
      "loss: 0.0589, last_20: 0.1245, lr: 0.0001, epoch: 1/20, step: 28/30\n",
      "loss: 0.023, last_20: 0.1139, lr: 0.0001, epoch: 1/20, step: 29/30\n",
      "loss: 0.0065, last_20: 0.1141, lr: 0.0001, epoch: 1/20, step: 30/30\n",
      "loss: 0.4202, last_20: 0.1169, lr: 0.0001, epoch: 2/20, step: 1/30\n",
      "loss: 0.0023, last_20: 0.1169, lr: 0.0001, epoch: 2/20, step: 2/30\n",
      "loss: 0.2454, last_20: 0.1276, lr: 0.0001, epoch: 2/20, step: 3/30\n",
      "loss: 0.1814, last_20: 0.135, lr: 0.0001, epoch: 2/20, step: 4/30\n",
      "loss: 0.0018, last_20: 0.102, lr: 0.0001, epoch: 2/20, step: 5/30\n",
      "loss: 0.1344, last_20: 0.1085, lr: 0.0001, epoch: 2/20, step: 6/30\n",
      "loss: 0.0668, last_20: 0.1, lr: 0.0001, epoch: 2/20, step: 7/30\n",
      "loss: 0.4897, last_20: 0.1229, lr: 0.0001, epoch: 2/20, step: 8/30\n",
      "loss: 0.0133, last_20: 0.1234, lr: 0.0001, epoch: 2/20, step: 9/30\n",
      "loss: 0.4985, last_20: 0.14, lr: 0.0001, epoch: 2/20, step: 10/30\n",
      "loss: 0.2202, last_20: 0.1442, lr: 0.0001, epoch: 2/20, step: 11/30\n",
      "loss: 0.3979, last_20: 0.1639, lr: 0.0001, epoch: 2/20, step: 12/30\n",
      "loss: 0.521, last_20: 0.1862, lr: 0.0001, epoch: 2/20, step: 13/30\n",
      "loss: 0.2893, last_20: 0.1859, lr: 0.0001, epoch: 2/20, step: 14/30\n",
      "loss: 0.2778, last_20: 0.1987, lr: 0.0001, epoch: 2/20, step: 15/30\n",
      "loss: 0.0085, last_20: 0.1961, lr: 0.0001, epoch: 2/20, step: 16/30\n",
      "loss: 0.0043, last_20: 0.1931, lr: 0.0001, epoch: 2/20, step: 17/30\n",
      "loss: 0.4182, last_20: 0.211, lr: 0.0001, epoch: 2/20, step: 18/30\n",
      "loss: 0.1708, last_20: 0.2184, lr: 0.0001, epoch: 2/20, step: 19/30\n",
      "loss: 0.0065, last_20: 0.2184, lr: 0.0001, epoch: 2/20, step: 20/30\n",
      "loss: 0.0316, last_20: 0.199, lr: 0.0001, epoch: 2/20, step: 21/30\n",
      "loss: 0.2991, last_20: 0.2138, lr: 0.0001, epoch: 2/20, step: 22/30\n",
      "loss: 0.0765, last_20: 0.2054, lr: 0.0001, epoch: 2/20, step: 23/30\n",
      "loss: 0.1048, last_20: 0.2016, lr: 0.0001, epoch: 2/20, step: 24/30\n",
      "loss: 0.0121, last_20: 0.2021, lr: 0.0001, epoch: 2/20, step: 25/30\n",
      "loss: 0.5161, last_20: 0.2212, lr: 0.0001, epoch: 2/20, step: 26/30\n",
      "loss: 0.0608, last_20: 0.2209, lr: 0.0001, epoch: 2/20, step: 27/30\n",
      "loss: 0.0024, last_20: 0.1965, lr: 0.0001, epoch: 2/20, step: 28/30\n",
      "loss: 0.3315, last_20: 0.2124, lr: 0.0001, epoch: 2/20, step: 29/30\n",
      "loss: 0.0472, last_20: 0.1898, lr: 0.0001, epoch: 2/20, step: 30/30\n",
      "loss: 0.5659, last_20: 0.2071, lr: 0.0001, epoch: 3/20, step: 1/30\n",
      "loss: 0.3533, last_20: 0.2049, lr: 0.0001, epoch: 3/20, step: 2/30\n",
      "loss: 0.0257, last_20: 0.1801, lr: 0.0001, epoch: 3/20, step: 3/30\n",
      "loss: 0.2484, last_20: 0.1781, lr: 0.0001, epoch: 3/20, step: 4/30\n",
      "loss: 0.0204, last_20: 0.1652, lr: 0.0001, epoch: 3/20, step: 5/30\n",
      "loss: 0.1023, last_20: 0.1699, lr: 0.0001, epoch: 3/20, step: 6/30\n",
      "loss: 0.0383, last_20: 0.1716, lr: 0.0001, epoch: 3/20, step: 7/30\n",
      "loss: 0.0044, last_20: 0.1509, lr: 0.0001, epoch: 3/20, step: 8/30\n",
      "loss: 0.3142, last_20: 0.1581, lr: 0.0001, epoch: 3/20, step: 9/30\n",
      "loss: 0.0178, last_20: 0.1586, lr: 0.0001, epoch: 3/20, step: 10/30\n",
      "loss: 0.2407, last_20: 0.1691, lr: 0.0001, epoch: 3/20, step: 11/30\n",
      "loss: 0.4795, last_20: 0.1781, lr: 0.0001, epoch: 3/20, step: 12/30\n",
      "loss: 0.0515, last_20: 0.1769, lr: 0.0001, epoch: 3/20, step: 13/30\n",
      "loss: 0.0651, last_20: 0.1749, lr: 0.0001, epoch: 3/20, step: 14/30\n",
      "loss: 0.2406, last_20: 0.1863, lr: 0.0001, epoch: 3/20, step: 15/30\n",
      "loss: 0.2715, last_20: 0.1741, lr: 0.0001, epoch: 3/20, step: 16/30\n",
      "loss: 0.0803, last_20: 0.175, lr: 0.0001, epoch: 3/20, step: 17/30\n",
      "loss: 0.3672, last_20: 0.1933, lr: 0.0001, epoch: 3/20, step: 18/30\n",
      "loss: 0.0585, last_20: 0.1796, lr: 0.0001, epoch: 3/20, step: 19/30\n",
      "loss: 0.0251, last_20: 0.1785, lr: 0.0001, epoch: 3/20, step: 20/30\n",
      "loss: 0.0084, last_20: 0.1507, lr: 0.0001, epoch: 3/20, step: 21/30\n",
      "loss: 0.0167, last_20: 0.1338, lr: 0.0001, epoch: 3/20, step: 22/30\n",
      "loss: 0.2019, last_20: 0.1426, lr: 0.0001, epoch: 3/20, step: 23/30\n",
      "loss: 0.0087, last_20: 0.1307, lr: 0.0001, epoch: 3/20, step: 24/30\n",
      "loss: 0.3064, last_20: 0.145, lr: 0.0001, epoch: 3/20, step: 25/30\n",
      "loss: 0.1215, last_20: 0.1459, lr: 0.0001, epoch: 3/20, step: 26/30\n",
      "loss: 0.3337, last_20: 0.1607, lr: 0.0001, epoch: 3/20, step: 27/30\n",
      "loss: 0.012, last_20: 0.1611, lr: 0.0001, epoch: 3/20, step: 28/30\n",
      "loss: 0.0314, last_20: 0.1469, lr: 0.0001, epoch: 3/20, step: 29/30\n",
      "loss: 0.0021, last_20: 0.1461, lr: 0.0001, epoch: 3/20, step: 30/30\n",
      "loss: 0.14, last_20: 0.1411, lr: 0.0001, epoch: 4/20, step: 1/30\n",
      "loss: 0.057, last_20: 0.12, lr: 0.0001, epoch: 4/20, step: 2/30\n",
      "loss: 0.088, last_20: 0.1218, lr: 0.0001, epoch: 4/20, step: 3/30\n",
      "loss: 0.095, last_20: 0.1233, lr: 0.0001, epoch: 4/20, step: 4/30\n",
      "loss: 0.0573, last_20: 0.1141, lr: 0.0001, epoch: 4/20, step: 5/30\n",
      "loss: 0.016, last_20: 0.1014, lr: 0.0001, epoch: 4/20, step: 6/30\n",
      "loss: 0.2465, last_20: 0.1097, lr: 0.0001, epoch: 4/20, step: 7/30\n",
      "loss: 0.243, last_20: 0.1035, lr: 0.0001, epoch: 4/20, step: 8/30\n",
      "loss: 0.0095, last_20: 0.101, lr: 0.0001, epoch: 4/20, step: 9/30\n",
      "loss: 0.0902, last_20: 0.1043, lr: 0.0001, epoch: 4/20, step: 10/30\n",
      "loss: 0.4226, last_20: 0.125, lr: 0.0001, epoch: 4/20, step: 11/30\n",
      "loss: 0.1829, last_20: 0.1333, lr: 0.0001, epoch: 4/20, step: 12/30\n",
      "loss: 0.4937, last_20: 0.1479, lr: 0.0001, epoch: 4/20, step: 13/30\n",
      "loss: 0.3711, last_20: 0.166, lr: 0.0001, epoch: 4/20, step: 14/30\n",
      "loss: 0.1396, last_20: 0.1577, lr: 0.0001, epoch: 4/20, step: 15/30\n",
      "loss: 0.107, last_20: 0.1569, lr: 0.0001, epoch: 4/20, step: 16/30\n",
      "loss: 0.3921, last_20: 0.1599, lr: 0.0001, epoch: 4/20, step: 17/30\n",
      "loss: 0.3318, last_20: 0.1758, lr: 0.0001, epoch: 4/20, step: 18/30\n",
      "loss: 0.0387, last_20: 0.1762, lr: 0.0001, epoch: 4/20, step: 19/30\n",
      "loss: 0.2109, last_20: 0.1866, lr: 0.0001, epoch: 4/20, step: 20/30\n",
      "loss: 0.2018, last_20: 0.1897, lr: 0.0001, epoch: 4/20, step: 21/30\n",
      "loss: 0.0809, last_20: 0.1909, lr: 0.0001, epoch: 4/20, step: 22/30\n",
      "loss: 0.1321, last_20: 0.1931, lr: 0.0001, epoch: 4/20, step: 23/30\n",
      "loss: 0.0233, last_20: 0.1895, lr: 0.0001, epoch: 4/20, step: 24/30\n",
      "loss: 0.2773, last_20: 0.2006, lr: 0.0001, epoch: 4/20, step: 25/30\n",
      "loss: 0.4565, last_20: 0.2226, lr: 0.0001, epoch: 4/20, step: 26/30\n",
      "loss: 0.0864, last_20: 0.2146, lr: 0.0001, epoch: 4/20, step: 27/30\n",
      "loss: 0.0024, last_20: 0.2025, lr: 0.0001, epoch: 4/20, step: 28/30\n",
      "loss: 0.1002, last_20: 0.2071, lr: 0.0001, epoch: 4/20, step: 29/30\n",
      "loss: 0.0135, last_20: 0.2032, lr: 0.0001, epoch: 4/20, step: 30/30\n",
      "loss: 0.2849, last_20: 0.1964, lr: 0.0001, epoch: 5/20, step: 1/30\n",
      "loss: 0.0145, last_20: 0.1879, lr: 0.0001, epoch: 5/20, step: 2/30\n",
      "loss: 0.0686, last_20: 0.1667, lr: 0.0001, epoch: 5/20, step: 3/30\n",
      "loss: 0.1376, last_20: 0.155, lr: 0.0001, epoch: 5/20, step: 4/30\n",
      "loss: 0.1103, last_20: 0.1535, lr: 0.0001, epoch: 5/20, step: 5/30\n",
      "loss: 0.2328, last_20: 0.1598, lr: 0.0001, epoch: 5/20, step: 6/30\n",
      "loss: 0.0226, last_20: 0.1414, lr: 0.0001, epoch: 5/20, step: 7/30\n",
      "loss: 0.2365, last_20: 0.1366, lr: 0.0001, epoch: 5/20, step: 8/30\n",
      "loss: 0.0566, last_20: 0.1375, lr: 0.0001, epoch: 5/20, step: 9/30\n",
      "loss: 0.0583, last_20: 0.1299, lr: 0.0001, epoch: 5/20, step: 10/30\n",
      "loss: 0.2472, last_20: 0.1321, lr: 0.0001, epoch: 5/20, step: 11/30\n",
      "loss: 0.0511, last_20: 0.1306, lr: 0.0001, epoch: 5/20, step: 12/30\n",
      "loss: 0.0149, last_20: 0.1248, lr: 0.0001, epoch: 5/20, step: 13/30\n",
      "loss: 0.0064, last_20: 0.1239, lr: 0.0001, epoch: 5/20, step: 14/30\n",
      "loss: 0.333, last_20: 0.1267, lr: 0.0001, epoch: 5/20, step: 15/30\n",
      "loss: 0.5552, last_20: 0.1316, lr: 0.0001, epoch: 5/20, step: 16/30\n",
      "loss: 0.1158, last_20: 0.1331, lr: 0.0001, epoch: 5/20, step: 17/30\n",
      "loss: 0.0135, last_20: 0.1337, lr: 0.0001, epoch: 5/20, step: 18/30\n",
      "loss: 0.0254, last_20: 0.1299, lr: 0.0001, epoch: 5/20, step: 19/30\n",
      "loss: 0.2844, last_20: 0.1435, lr: 0.0001, epoch: 5/20, step: 20/30\n",
      "loss: 0.2014, last_20: 0.1393, lr: 0.0001, epoch: 5/20, step: 21/30\n",
      "loss: 0.2532, last_20: 0.1512, lr: 0.0001, epoch: 5/20, step: 22/30\n",
      "loss: 0.0506, last_20: 0.1503, lr: 0.0001, epoch: 5/20, step: 23/30\n",
      "loss: 0.2822, last_20: 0.1576, lr: 0.0001, epoch: 5/20, step: 24/30\n",
      "loss: 0.6172, last_20: 0.1829, lr: 0.0001, epoch: 5/20, step: 25/30\n",
      "loss: 0.2491, last_20: 0.1837, lr: 0.0001, epoch: 5/20, step: 26/30\n",
      "loss: 0.059, last_20: 0.1856, lr: 0.0001, epoch: 5/20, step: 27/30\n",
      "loss: 0.0228, last_20: 0.1749, lr: 0.0001, epoch: 5/20, step: 28/30\n",
      "loss: 0.0883, last_20: 0.1765, lr: 0.0001, epoch: 5/20, step: 29/30\n",
      "loss: 0.0916, last_20: 0.1781, lr: 0.0001, epoch: 5/20, step: 30/30\n",
      "loss: 0.3176, last_20: 0.1816, lr: 0.0001, epoch: 6/20, step: 1/30\n",
      "loss: 0.1698, last_20: 0.1876, lr: 0.0001, epoch: 6/20, step: 2/30\n",
      "loss: 0.0148, last_20: 0.1876, lr: 0.0001, epoch: 6/20, step: 3/30\n",
      "loss: 0.0033, last_20: 0.1874, lr: 0.0001, epoch: 6/20, step: 4/30\n",
      "loss: 0.0047, last_20: 0.171, lr: 0.0001, epoch: 6/20, step: 5/30\n",
      "loss: 0.0453, last_20: 0.1455, lr: 0.0001, epoch: 6/20, step: 6/30\n",
      "loss: 0.2426, last_20: 0.1518, lr: 0.0001, epoch: 6/20, step: 7/30\n",
      "loss: 0.3562, last_20: 0.169, lr: 0.0001, epoch: 6/20, step: 8/30\n",
      "loss: 0.158, last_20: 0.1756, lr: 0.0001, epoch: 6/20, step: 9/30\n",
      "loss: 0.0997, last_20: 0.1664, lr: 0.0001, epoch: 6/20, step: 10/30\n",
      "loss: 0.0183, last_20: 0.1572, lr: 0.0001, epoch: 6/20, step: 11/30\n",
      "loss: 0.2296, last_20: 0.156, lr: 0.0001, epoch: 6/20, step: 12/30\n",
      "loss: 0.0172, last_20: 0.1544, lr: 0.0001, epoch: 6/20, step: 13/30\n",
      "loss: 0.0053, last_20: 0.1405, lr: 0.0001, epoch: 6/20, step: 14/30\n",
      "loss: 0.0053, last_20: 0.1099, lr: 0.0001, epoch: 6/20, step: 15/30\n",
      "loss: 0.1741, last_20: 0.1062, lr: 0.0001, epoch: 6/20, step: 16/30\n",
      "loss: 0.0834, last_20: 0.1074, lr: 0.0001, epoch: 6/20, step: 17/30\n",
      "loss: 0.3821, last_20: 0.1254, lr: 0.0001, epoch: 6/20, step: 18/30\n",
      "loss: 0.3242, last_20: 0.1372, lr: 0.0001, epoch: 6/20, step: 19/30\n",
      "loss: 0.5615, last_20: 0.1607, lr: 0.0001, epoch: 6/20, step: 20/30\n",
      "loss: 0.023, last_20: 0.1459, lr: 0.0001, epoch: 6/20, step: 21/30\n",
      "loss: 0.1976, last_20: 0.1473, lr: 0.0001, epoch: 6/20, step: 22/30\n",
      "loss: 0.006, last_20: 0.1469, lr: 0.0001, epoch: 6/20, step: 23/30\n",
      "loss: 0.4214, last_20: 0.1678, lr: 0.0001, epoch: 6/20, step: 24/30\n",
      "loss: 0.3892, last_20: 0.187, lr: 0.0001, epoch: 6/20, step: 25/30\n",
      "loss: 0.0146, last_20: 0.1855, lr: 0.0001, epoch: 6/20, step: 26/30\n",
      "loss: 0.1669, last_20: 0.1817, lr: 0.0001, epoch: 6/20, step: 27/30\n",
      "loss: 0.271, last_20: 0.1774, lr: 0.0001, epoch: 6/20, step: 28/30\n",
      "loss: 0.0499, last_20: 0.172, lr: 0.0001, epoch: 6/20, step: 29/30\n",
      "loss: 0.375, last_20: 0.1858, lr: 0.0001, epoch: 6/20, step: 30/30\n",
      "loss: 0.0021, last_20: 0.185, lr: 0.0001, epoch: 7/20, step: 1/30\n",
      "loss: 0.1022, last_20: 0.1786, lr: 0.0001, epoch: 7/20, step: 2/30\n",
      "loss: 0.4456, last_20: 0.2, lr: 0.0001, epoch: 7/20, step: 3/30\n",
      "loss: 0.0333, last_20: 0.2014, lr: 0.0001, epoch: 7/20, step: 4/30\n",
      "loss: 0.6533, last_20: 0.2338, lr: 0.0001, epoch: 7/20, step: 5/30\n",
      "loss: 0.1692, last_20: 0.2336, lr: 0.0001, epoch: 7/20, step: 6/30\n",
      "loss: 0.0026, last_20: 0.2295, lr: 0.0001, epoch: 7/20, step: 7/30\n",
      "loss: 0.0059, last_20: 0.2107, lr: 0.0001, epoch: 7/20, step: 8/30\n",
      "loss: 0.0614, last_20: 0.1976, lr: 0.0001, epoch: 7/20, step: 9/30\n",
      "loss: 0.0031, last_20: 0.1697, lr: 0.0001, epoch: 7/20, step: 10/30\n",
      "loss: 0.1135, last_20: 0.1742, lr: 0.0001, epoch: 7/20, step: 11/30\n",
      "loss: 0.0031, last_20: 0.1645, lr: 0.0001, epoch: 7/20, step: 12/30\n",
      "loss: 0.224, last_20: 0.1754, lr: 0.0001, epoch: 7/20, step: 13/30\n",
      "loss: 0.3669, last_20: 0.1726, lr: 0.0001, epoch: 7/20, step: 14/30\n",
      "loss: 0.0103, last_20: 0.1537, lr: 0.0001, epoch: 7/20, step: 15/30\n",
      "loss: 0.0278, last_20: 0.1544, lr: 0.0001, epoch: 7/20, step: 16/30\n",
      "loss: 0.1802, last_20: 0.155, lr: 0.0001, epoch: 7/20, step: 17/30\n",
      "loss: 0.2101, last_20: 0.152, lr: 0.0001, epoch: 7/20, step: 18/30\n",
      "loss: 0.4314, last_20: 0.1711, lr: 0.0001, epoch: 7/20, step: 19/30\n",
      "loss: 0.0096, last_20: 0.1528, lr: 0.0001, epoch: 7/20, step: 20/30\n",
      "loss: 0.105, last_20: 0.1579, lr: 0.0001, epoch: 7/20, step: 21/30\n",
      "loss: 0.4348, last_20: 0.1746, lr: 0.0001, epoch: 7/20, step: 22/30\n",
      "loss: 0.0984, last_20: 0.1572, lr: 0.0001, epoch: 7/20, step: 23/30\n",
      "loss: 0.1726, last_20: 0.1642, lr: 0.0001, epoch: 7/20, step: 24/30\n",
      "loss: 0.0033, last_20: 0.1317, lr: 0.0001, epoch: 7/20, step: 25/30\n",
      "loss: 0.1389, last_20: 0.1301, lr: 0.0001, epoch: 7/20, step: 26/30\n",
      "loss: 0.0512, last_20: 0.1326, lr: 0.0001, epoch: 7/20, step: 27/30\n",
      "loss: 0.0579, last_20: 0.1352, lr: 0.0001, epoch: 7/20, step: 28/30\n",
      "loss: 0.4189, last_20: 0.153, lr: 0.0001, epoch: 7/20, step: 29/30\n",
      "loss: 0.5918, last_20: 0.1825, lr: 0.0001, epoch: 7/20, step: 30/30\n",
      "loss: 0.2371, last_20: 0.1887, lr: 0.0001, epoch: 8/20, step: 1/30\n",
      "loss: 0.0093, last_20: 0.189, lr: 0.0001, epoch: 8/20, step: 2/30\n",
      "loss: 0.0115, last_20: 0.1783, lr: 0.0001, epoch: 8/20, step: 3/30\n",
      "loss: 0.4998, last_20: 0.185, lr: 0.0001, epoch: 8/20, step: 4/30\n",
      "loss: 0.1333, last_20: 0.1911, lr: 0.0001, epoch: 8/20, step: 5/30\n",
      "loss: 0.0565, last_20: 0.1926, lr: 0.0001, epoch: 8/20, step: 6/30\n",
      "loss: 0.0983, last_20: 0.1885, lr: 0.0001, epoch: 8/20, step: 7/30\n",
      "loss: 0.2281, last_20: 0.1894, lr: 0.0001, epoch: 8/20, step: 8/30\n",
      "loss: 0.1256, last_20: 0.1741, lr: 0.0001, epoch: 8/20, step: 9/30\n",
      "loss: 0.012, last_20: 0.1742, lr: 0.0001, epoch: 8/20, step: 10/30\n",
      "loss: 0.0469, last_20: 0.1713, lr: 0.0001, epoch: 8/20, step: 11/30\n",
      "loss: 0.0058, last_20: 0.1499, lr: 0.0001, epoch: 8/20, step: 12/30\n",
      "loss: 0.5229, last_20: 0.1711, lr: 0.0001, epoch: 8/20, step: 13/30\n",
      "loss: 0.0321, last_20: 0.1641, lr: 0.0001, epoch: 8/20, step: 14/30\n",
      "loss: 0.6685, last_20: 0.1973, lr: 0.0001, epoch: 8/20, step: 15/30\n",
      "loss: 0.2739, last_20: 0.2041, lr: 0.0001, epoch: 8/20, step: 16/30\n",
      "loss: 0.2644, last_20: 0.2147, lr: 0.0001, epoch: 8/20, step: 17/30\n",
      "loss: 0.7676, last_20: 0.2502, lr: 0.0001, epoch: 8/20, step: 18/30\n",
      "loss: 0.3862, last_20: 0.2486, lr: 0.0001, epoch: 8/20, step: 19/30\n",
      "loss: 0.0336, last_20: 0.2207, lr: 0.0001, epoch: 8/20, step: 20/30\n",
      "loss: 0.0111, last_20: 0.2094, lr: 0.0001, epoch: 8/20, step: 21/30\n",
      "loss: 0.0153, last_20: 0.2097, lr: 0.0001, epoch: 8/20, step: 22/30\n",
      "loss: 0.5054, last_20: 0.2344, lr: 0.0001, epoch: 8/20, step: 23/30\n",
      "loss: 0.2366, last_20: 0.2212, lr: 0.0001, epoch: 8/20, step: 24/30\n",
      "loss: 0.2024, last_20: 0.2247, lr: 0.0001, epoch: 8/20, step: 25/30\n",
      "loss: 0.1785, last_20: 0.2308, lr: 0.0001, epoch: 8/20, step: 26/30\n",
      "loss: 0.1998, last_20: 0.2358, lr: 0.0001, epoch: 8/20, step: 27/30\n",
      "loss: 0.1129, last_20: 0.2301, lr: 0.0001, epoch: 8/20, step: 28/30\n",
      "loss: 0.0306, last_20: 0.2253, lr: 0.0001, epoch: 8/20, step: 29/30\n",
      "loss: 0.0226, last_20: 0.2259, lr: 0.0001, epoch: 8/20, step: 30/30\n",
      "loss: 0.1737, last_20: 0.2322, lr: 0.0001, epoch: 9/20, step: 1/30\n",
      "loss: 0.7002, last_20: 0.2669, lr: 0.0001, epoch: 9/20, step: 2/30\n",
      "loss: 0.2512, last_20: 0.2533, lr: 0.0001, epoch: 9/20, step: 3/30\n",
      "loss: 0.2695, last_20: 0.2652, lr: 0.0001, epoch: 9/20, step: 4/30\n",
      "loss: 0.0254, last_20: 0.233, lr: 0.0001, epoch: 9/20, step: 5/30\n",
      "loss: 0.1338, last_20: 0.226, lr: 0.0001, epoch: 9/20, step: 6/30\n",
      "loss: 0.1113, last_20: 0.2184, lr: 0.0001, epoch: 9/20, step: 7/30\n",
      "loss: 0.064, last_20: 0.1832, lr: 0.0001, epoch: 9/20, step: 8/30\n",
      "loss: 0.0875, last_20: 0.1683, lr: 0.0001, epoch: 9/20, step: 9/30\n",
      "loss: 0.5044, last_20: 0.1918, lr: 0.0001, epoch: 9/20, step: 10/30\n",
      "loss: 0.201, last_20: 0.2013, lr: 0.0001, epoch: 9/20, step: 11/30\n",
      "loss: 0.0925, last_20: 0.2052, lr: 0.0001, epoch: 9/20, step: 12/30\n",
      "loss: 0.7827, last_20: 0.219, lr: 0.0001, epoch: 9/20, step: 13/30\n",
      "loss: 0.4014, last_20: 0.2273, lr: 0.0001, epoch: 9/20, step: 14/30\n",
      "loss: 0.2474, last_20: 0.2295, lr: 0.0001, epoch: 9/20, step: 15/30\n",
      "loss: 0.0589, last_20: 0.2235, lr: 0.0001, epoch: 9/20, step: 16/30\n",
      "loss: 0.0182, last_20: 0.2145, lr: 0.0001, epoch: 9/20, step: 17/30\n",
      "loss: 0.0236, last_20: 0.21, lr: 0.0001, epoch: 9/20, step: 18/30\n",
      "loss: 0.053, last_20: 0.2111, lr: 0.0001, epoch: 9/20, step: 19/30\n",
      "loss: 0.2411, last_20: 0.222, lr: 0.0001, epoch: 9/20, step: 20/30\n",
      "loss: 0.0676, last_20: 0.2167, lr: 0.0001, epoch: 9/20, step: 21/30\n",
      "loss: 0.4412, last_20: 0.2038, lr: 0.0001, epoch: 9/20, step: 22/30\n",
      "loss: 0.3108, last_20: 0.2068, lr: 0.0001, epoch: 9/20, step: 23/30\n",
      "loss: 0.0966, last_20: 0.1981, lr: 0.0001, epoch: 9/20, step: 24/30\n",
      "loss: 0.0347, last_20: 0.1986, lr: 0.0001, epoch: 9/20, step: 25/30\n",
      "loss: 0.065, last_20: 0.1951, lr: 0.0001, epoch: 9/20, step: 26/30\n",
      "loss: 0.0085, last_20: 0.19, lr: 0.0001, epoch: 9/20, step: 27/30\n",
      "loss: 0.356, last_20: 0.2046, lr: 0.0001, epoch: 9/20, step: 28/30\n",
      "loss: 0.1698, last_20: 0.2087, lr: 0.0001, epoch: 9/20, step: 29/30\n",
      "loss: 0.1447, last_20: 0.1907, lr: 0.0001, epoch: 9/20, step: 30/30\n",
      "loss: 0.0555, last_20: 0.1835, lr: 0.0001, epoch: 10/20, step: 1/30\n",
      "loss: 0.2715, last_20: 0.1924, lr: 0.0001, epoch: 10/20, step: 2/30\n",
      "loss: 0.2527, last_20: 0.1659, lr: 0.0001, epoch: 10/20, step: 3/30\n",
      "loss: 0.0025, last_20: 0.146, lr: 0.0001, epoch: 10/20, step: 4/30\n",
      "loss: 0.1469, last_20: 0.1409, lr: 0.0001, epoch: 10/20, step: 5/30\n",
      "loss: 0.1083, last_20: 0.1434, lr: 0.0001, epoch: 10/20, step: 6/30\n",
      "loss: 0.0081, last_20: 0.1429, lr: 0.0001, epoch: 10/20, step: 7/30\n",
      "loss: 0.2725, last_20: 0.1553, lr: 0.0001, epoch: 10/20, step: 8/30\n",
      "loss: 0.3105, last_20: 0.1682, lr: 0.0001, epoch: 10/20, step: 9/30\n",
      "loss: 0.0019, last_20: 0.1563, lr: 0.0001, epoch: 10/20, step: 10/30\n",
      "loss: 0.014, last_20: 0.1536, lr: 0.0001, epoch: 10/20, step: 11/30\n",
      "loss: 0.002, last_20: 0.1316, lr: 0.0001, epoch: 10/20, step: 12/30\n",
      "loss: 0.0698, last_20: 0.1196, lr: 0.0001, epoch: 10/20, step: 13/30\n",
      "loss: 0.5615, last_20: 0.1428, lr: 0.0001, epoch: 10/20, step: 14/30\n",
      "loss: 0.1351, last_20: 0.1478, lr: 0.0001, epoch: 10/20, step: 15/30\n",
      "loss: 0.4768, last_20: 0.1684, lr: 0.0001, epoch: 10/20, step: 16/30\n",
      "loss: 0.0181, last_20: 0.1689, lr: 0.0001, epoch: 10/20, step: 17/30\n",
      "loss: 0.3389, last_20: 0.1681, lr: 0.0001, epoch: 10/20, step: 18/30\n",
      "loss: 0.5303, last_20: 0.1861, lr: 0.0001, epoch: 10/20, step: 19/30\n",
      "loss: 0.0432, last_20: 0.181, lr: 0.0001, epoch: 10/20, step: 20/30\n",
      "loss: 0.4453, last_20: 0.2005, lr: 0.0001, epoch: 10/20, step: 21/30\n",
      "loss: 0.0195, last_20: 0.1879, lr: 0.0001, epoch: 10/20, step: 22/30\n",
      "loss: 0.3843, last_20: 0.1945, lr: 0.0001, epoch: 10/20, step: 23/30\n",
      "loss: 0.1465, last_20: 0.2017, lr: 0.0001, epoch: 10/20, step: 24/30\n",
      "loss: 0.0289, last_20: 0.1958, lr: 0.0001, epoch: 10/20, step: 25/30\n",
      "loss: 0.0123, last_20: 0.191, lr: 0.0001, epoch: 10/20, step: 26/30\n",
      "loss: 0.0218, last_20: 0.1917, lr: 0.0001, epoch: 10/20, step: 27/30\n",
      "loss: 0.2174, last_20: 0.1889, lr: 0.0001, epoch: 10/20, step: 28/30\n",
      "loss: 0.4966, last_20: 0.1982, lr: 0.0001, epoch: 10/20, step: 29/30\n",
      "loss: 0.0073, last_20: 0.1985, lr: 0.0001, epoch: 10/20, step: 30/30\n",
      "loss: 0.6938, last_20: 0.2325, lr: 0.0001, epoch: 11/20, step: 1/30\n",
      "loss: 0.0566, last_20: 0.2352, lr: 0.0001, epoch: 11/20, step: 2/30\n",
      "loss: 0.0062, last_20: 0.232, lr: 0.0001, epoch: 11/20, step: 3/30\n",
      "loss: 0.0166, last_20: 0.2048, lr: 0.0001, epoch: 11/20, step: 4/30\n",
      "loss: 0.1636, last_20: 0.2062, lr: 0.0001, epoch: 11/20, step: 5/30\n",
      "loss: 0.0889, last_20: 0.1868, lr: 0.0001, epoch: 11/20, step: 6/30\n",
      "loss: 0.0103, last_20: 0.1864, lr: 0.0001, epoch: 11/20, step: 7/30\n",
      "loss: 0.0286, last_20: 0.1709, lr: 0.0001, epoch: 11/20, step: 8/30\n",
      "loss: 0.4128, last_20: 0.165, lr: 0.0001, epoch: 11/20, step: 9/30\n",
      "loss: 0.0027, last_20: 0.163, lr: 0.0001, epoch: 11/20, step: 10/30\n",
      "loss: 0.014, last_20: 0.1414, lr: 0.0001, epoch: 11/20, step: 11/30\n",
      "loss: 0.039, last_20: 0.1424, lr: 0.0001, epoch: 11/20, step: 12/30\n",
      "loss: 0.3589, last_20: 0.1411, lr: 0.0001, epoch: 11/20, step: 13/30\n",
      "loss: 0.3425, last_20: 0.1509, lr: 0.0001, epoch: 11/20, step: 14/30\n",
      "loss: 0.052, last_20: 0.1521, lr: 0.0001, epoch: 11/20, step: 15/30\n",
      "loss: 0.2642, last_20: 0.1647, lr: 0.0001, epoch: 11/20, step: 16/30\n",
      "loss: 0.003, last_20: 0.1638, lr: 0.0001, epoch: 11/20, step: 17/30\n",
      "loss: 0.0336, last_20: 0.1546, lr: 0.0001, epoch: 11/20, step: 18/30\n",
      "loss: 0.2939, last_20: 0.1444, lr: 0.0001, epoch: 11/20, step: 19/30\n",
      "loss: 0.002, last_20: 0.1442, lr: 0.0001, epoch: 11/20, step: 20/30\n",
      "loss: 0.0926, last_20: 0.1141, lr: 0.0001, epoch: 11/20, step: 21/30\n",
      "loss: 0.0345, last_20: 0.113, lr: 0.0001, epoch: 11/20, step: 22/30\n",
      "loss: 0.1462, last_20: 0.12, lr: 0.0001, epoch: 11/20, step: 23/30\n",
      "loss: 0.2542, last_20: 0.1319, lr: 0.0001, epoch: 11/20, step: 24/30\n",
      "loss: 0.2117, last_20: 0.1343, lr: 0.0001, epoch: 11/20, step: 25/30\n",
      "loss: 0.521, last_20: 0.1559, lr: 0.0001, epoch: 11/20, step: 26/30\n",
      "loss: 0.0061, last_20: 0.1557, lr: 0.0001, epoch: 11/20, step: 27/30\n",
      "loss: 0.0136, last_20: 0.1549, lr: 0.0001, epoch: 11/20, step: 28/30\n",
      "loss: 0.2242, last_20: 0.1455, lr: 0.0001, epoch: 11/20, step: 29/30\n",
      "loss: 0.0077, last_20: 0.1457, lr: 0.0001, epoch: 11/20, step: 30/30\n",
      "loss: 0.0062, last_20: 0.1454, lr: 0.0001, epoch: 12/20, step: 1/30\n",
      "loss: 0.2375, last_20: 0.1553, lr: 0.0001, epoch: 12/20, step: 2/30\n",
      "loss: 0.0078, last_20: 0.1377, lr: 0.0001, epoch: 12/20, step: 3/30\n",
      "loss: 0.0944, last_20: 0.1253, lr: 0.0001, epoch: 12/20, step: 4/30\n",
      "loss: 0.0207, last_20: 0.1238, lr: 0.0001, epoch: 12/20, step: 5/30\n",
      "loss: 0.6567, last_20: 0.1434, lr: 0.0001, epoch: 12/20, step: 6/30\n",
      "loss: 0.0216, last_20: 0.1443, lr: 0.0001, epoch: 12/20, step: 7/30\n",
      "loss: 0.3799, last_20: 0.1616, lr: 0.0001, epoch: 12/20, step: 8/30\n",
      "loss: 0.0049, last_20: 0.1472, lr: 0.0001, epoch: 12/20, step: 9/30\n",
      "loss: 0.4941, last_20: 0.1718, lr: 0.0001, epoch: 12/20, step: 10/30\n",
      "loss: 0.6831, last_20: 0.2013, lr: 0.0001, epoch: 12/20, step: 11/30\n",
      "loss: 0.1204, last_20: 0.2056, lr: 0.0001, epoch: 12/20, step: 12/30\n",
      "loss: 0.1997, last_20: 0.2083, lr: 0.0001, epoch: 12/20, step: 13/30\n",
      "loss: 0.1009, last_20: 0.2006, lr: 0.0001, epoch: 12/20, step: 14/30\n",
      "loss: 0.0043, last_20: 0.1902, lr: 0.0001, epoch: 12/20, step: 15/30\n",
      "loss: 0.0041, last_20: 0.1644, lr: 0.0001, epoch: 12/20, step: 16/30\n",
      "loss: 0.0194, last_20: 0.1651, lr: 0.0001, epoch: 12/20, step: 17/30\n",
      "loss: 0.234, last_20: 0.1761, lr: 0.0001, epoch: 12/20, step: 18/30\n",
      "loss: 0.007, last_20: 0.1652, lr: 0.0001, epoch: 12/20, step: 19/30\n",
      "loss: 0.0743, last_20: 0.1686, lr: 0.0001, epoch: 12/20, step: 20/30\n",
      "loss: 0.373, last_20: 0.1869, lr: 0.0001, epoch: 12/20, step: 21/30\n",
      "loss: 0.2246, last_20: 0.1862, lr: 0.0001, epoch: 12/20, step: 22/30\n",
      "loss: 0.0715, last_20: 0.1894, lr: 0.0001, epoch: 12/20, step: 23/30\n",
      "loss: 0.7607, last_20: 0.2227, lr: 0.0001, epoch: 12/20, step: 24/30\n",
      "loss: 0.0132, last_20: 0.2224, lr: 0.0001, epoch: 12/20, step: 25/30\n",
      "loss: 0.0369, last_20: 0.1914, lr: 0.0001, epoch: 12/20, step: 26/30\n",
      "loss: 0.0298, last_20: 0.1918, lr: 0.0001, epoch: 12/20, step: 27/30\n",
      "loss: 0.2944, last_20: 0.1875, lr: 0.0001, epoch: 12/20, step: 28/30\n",
      "loss: 0.022, last_20: 0.1884, lr: 0.0001, epoch: 12/20, step: 29/30\n",
      "loss: 0.1464, last_20: 0.171, lr: 0.0001, epoch: 12/20, step: 30/30\n",
      "loss: 0.0027, last_20: 0.137, lr: 0.0001, epoch: 13/20, step: 1/30\n",
      "loss: 0.333, last_20: 0.1476, lr: 0.0001, epoch: 13/20, step: 2/30\n",
      "loss: 0.5532, last_20: 0.1653, lr: 0.0001, epoch: 13/20, step: 3/30\n",
      "loss: 0.0754, last_20: 0.164, lr: 0.0001, epoch: 13/20, step: 4/30\n",
      "loss: 0.0558, last_20: 0.1666, lr: 0.0001, epoch: 13/20, step: 5/30\n",
      "loss: 0.2668, last_20: 0.1797, lr: 0.0001, epoch: 13/20, step: 6/30\n",
      "loss: 0.0026, last_20: 0.1789, lr: 0.0001, epoch: 13/20, step: 7/30\n",
      "loss: 0.7002, last_20: 0.2022, lr: 0.0001, epoch: 13/20, step: 8/30\n",
      "loss: 0.1058, last_20: 0.2071, lr: 0.0001, epoch: 13/20, step: 9/30\n",
      "loss: 0.0027, last_20: 0.2035, lr: 0.0001, epoch: 13/20, step: 10/30\n",
      "loss: 0.0433, last_20: 0.187, lr: 0.0001, epoch: 13/20, step: 11/30\n",
      "loss: 0.1417, last_20: 0.1829, lr: 0.0001, epoch: 13/20, step: 12/30\n",
      "loss: 0.0228, last_20: 0.1805, lr: 0.0001, epoch: 13/20, step: 13/30\n",
      "loss: 0.0593, last_20: 0.1454, lr: 0.0001, epoch: 13/20, step: 14/30\n",
      "loss: 0.0237, last_20: 0.1459, lr: 0.0001, epoch: 13/20, step: 15/30\n",
      "loss: 0.0039, last_20: 0.1443, lr: 0.0001, epoch: 13/20, step: 16/30\n",
      "loss: 0.008, last_20: 0.1432, lr: 0.0001, epoch: 13/20, step: 17/30\n",
      "loss: 0.8184, last_20: 0.1694, lr: 0.0001, epoch: 13/20, step: 18/30\n",
      "loss: 0.6094, last_20: 0.1988, lr: 0.0001, epoch: 13/20, step: 19/30\n",
      "loss: 0.2162, last_20: 0.2022, lr: 0.0001, epoch: 13/20, step: 20/30\n",
      "loss: 0.0061, last_20: 0.2024, lr: 0.0001, epoch: 13/20, step: 21/30\n",
      "loss: 0.0244, last_20: 0.187, lr: 0.0001, epoch: 13/20, step: 22/30\n",
      "loss: 0.198, last_20: 0.1692, lr: 0.0001, epoch: 13/20, step: 23/30\n",
      "loss: 0.0256, last_20: 0.1667, lr: 0.0001, epoch: 13/20, step: 24/30\n",
      "loss: 0.0064, last_20: 0.1643, lr: 0.0001, epoch: 13/20, step: 25/30\n",
      "loss: 0.1361, last_20: 0.1577, lr: 0.0001, epoch: 13/20, step: 26/30\n",
      "loss: 0.3618, last_20: 0.1757, lr: 0.0001, epoch: 13/20, step: 27/30\n",
      "loss: 0.4717, last_20: 0.1643, lr: 0.0001, epoch: 13/20, step: 28/30\n",
      "loss: 0.2358, last_20: 0.1708, lr: 0.0001, epoch: 13/20, step: 29/30\n",
      "loss: 0.4204, last_20: 0.1917, lr: 0.0001, epoch: 13/20, step: 30/30\n",
      "loss: 0.0264, last_20: 0.1908, lr: 0.0001, epoch: 14/20, step: 1/30\n",
      "loss: 0.4648, last_20: 0.207, lr: 0.0001, epoch: 14/20, step: 2/30\n",
      "loss: 0.0065, last_20: 0.2061, lr: 0.0001, epoch: 14/20, step: 3/30\n",
      "loss: 0.0038, last_20: 0.2034, lr: 0.0001, epoch: 14/20, step: 4/30\n",
      "loss: 0.0102, last_20: 0.2027, lr: 0.0001, epoch: 14/20, step: 5/30\n",
      "loss: 0.1309, last_20: 0.209, lr: 0.0001, epoch: 14/20, step: 6/30\n",
      "loss: 0.0045, last_20: 0.2089, lr: 0.0001, epoch: 14/20, step: 7/30\n",
      "loss: 0.0104, last_20: 0.1685, lr: 0.0001, epoch: 14/20, step: 8/30\n",
      "loss: 0.3752, last_20: 0.1568, lr: 0.0001, epoch: 14/20, step: 9/30\n",
      "loss: 0.2003, last_20: 0.156, lr: 0.0001, epoch: 14/20, step: 10/30\n",
      "loss: 0.0113, last_20: 0.1562, lr: 0.0001, epoch: 14/20, step: 11/30\n",
      "loss: 0.2695, last_20: 0.1685, lr: 0.0001, epoch: 14/20, step: 12/30\n",
      "loss: 0.0502, last_20: 0.1611, lr: 0.0001, epoch: 14/20, step: 13/30\n",
      "loss: 0.0977, last_20: 0.1647, lr: 0.0001, epoch: 14/20, step: 14/30\n",
      "loss: 0.1957, last_20: 0.1742, lr: 0.0001, epoch: 14/20, step: 15/30\n",
      "loss: 0.0023, last_20: 0.1675, lr: 0.0001, epoch: 14/20, step: 16/30\n",
      "loss: 0.011, last_20: 0.1499, lr: 0.0001, epoch: 14/20, step: 17/30\n",
      "loss: 0.1003, last_20: 0.1314, lr: 0.0001, epoch: 14/20, step: 18/30\n",
      "loss: 0.0026, last_20: 0.1197, lr: 0.0001, epoch: 14/20, step: 19/30\n",
      "loss: 0.023, last_20: 0.0998, lr: 0.0001, epoch: 14/20, step: 20/30\n",
      "loss: 0.1617, last_20: 0.1066, lr: 0.0001, epoch: 14/20, step: 21/30\n",
      "loss: 0.0259, last_20: 0.0846, lr: 0.0001, epoch: 14/20, step: 22/30\n",
      "loss: 0.0023, last_20: 0.0844, lr: 0.0001, epoch: 14/20, step: 23/30\n",
      "loss: 0.2104, last_20: 0.0948, lr: 0.0001, epoch: 14/20, step: 24/30\n",
      "loss: 0.0423, last_20: 0.0964, lr: 0.0001, epoch: 14/20, step: 25/30\n",
      "loss: 0.0188, last_20: 0.0908, lr: 0.0001, epoch: 14/20, step: 26/30\n",
      "loss: 0.0524, last_20: 0.0932, lr: 0.0001, epoch: 14/20, step: 27/30\n",
      "loss: 0.0022, last_20: 0.0928, lr: 0.0001, epoch: 14/20, step: 28/30\n",
      "loss: 0.0989, last_20: 0.0789, lr: 0.0001, epoch: 14/20, step: 29/30\n",
      "loss: 0.0057, last_20: 0.0692, lr: 0.0001, epoch: 14/20, step: 30/30\n",
      "loss: 0.7012, last_20: 0.1037, lr: 0.0001, epoch: 15/20, step: 1/30\n",
      "loss: 0.5356, last_20: 0.117, lr: 0.0001, epoch: 15/20, step: 2/30\n",
      "loss: 0.0311, last_20: 0.1161, lr: 0.0001, epoch: 15/20, step: 3/30\n",
      "loss: 0.1512, last_20: 0.1187, lr: 0.0001, epoch: 15/20, step: 4/30\n",
      "loss: 0.0183, last_20: 0.1099, lr: 0.0001, epoch: 15/20, step: 5/30\n",
      "loss: 0.1951, last_20: 0.1195, lr: 0.0001, epoch: 15/20, step: 6/30\n",
      "loss: 0.3279, last_20: 0.1353, lr: 0.0001, epoch: 15/20, step: 7/30\n",
      "loss: 0.0763, last_20: 0.1341, lr: 0.0001, epoch: 15/20, step: 8/30\n",
      "loss: 0.0084, last_20: 0.1344, lr: 0.0001, epoch: 15/20, step: 9/30\n",
      "loss: 0.0204, last_20: 0.1343, lr: 0.0001, epoch: 15/20, step: 10/30\n",
      "loss: 0.5488, last_20: 0.1537, lr: 0.0001, epoch: 15/20, step: 11/30\n",
      "loss: 0.1425, last_20: 0.1595, lr: 0.0001, epoch: 15/20, step: 12/30\n",
      "loss: 0.018, last_20: 0.1603, lr: 0.0001, epoch: 15/20, step: 13/30\n",
      "loss: 0.0712, last_20: 0.1533, lr: 0.0001, epoch: 15/20, step: 14/30\n",
      "loss: 0.6138, last_20: 0.1819, lr: 0.0001, epoch: 15/20, step: 15/30\n",
      "loss: 0.3213, last_20: 0.197, lr: 0.0001, epoch: 15/20, step: 16/30\n",
      "loss: 0.0216, last_20: 0.1955, lr: 0.0001, epoch: 15/20, step: 17/30\n",
      "loss: 0.2058, last_20: 0.2057, lr: 0.0001, epoch: 15/20, step: 18/30\n",
      "loss: 0.0775, last_20: 0.2046, lr: 0.0001, epoch: 15/20, step: 19/30\n",
      "loss: 0.3667, last_20: 0.2226, lr: 0.0001, epoch: 15/20, step: 20/30\n",
      "loss: 0.201, last_20: 0.1976, lr: 0.0001, epoch: 15/20, step: 21/30\n",
      "loss: 0.2372, last_20: 0.1827, lr: 0.0001, epoch: 15/20, step: 22/30\n",
      "loss: 0.0859, last_20: 0.1854, lr: 0.0001, epoch: 15/20, step: 23/30\n",
      "loss: 0.0129, last_20: 0.1785, lr: 0.0001, epoch: 15/20, step: 24/30\n",
      "loss: 0.0608, last_20: 0.1807, lr: 0.0001, epoch: 15/20, step: 25/30\n",
      "loss: 0.0313, last_20: 0.1725, lr: 0.0001, epoch: 15/20, step: 26/30\n",
      "loss: 0.3481, last_20: 0.1735, lr: 0.0001, epoch: 15/20, step: 27/30\n",
      "loss: 0.0253, last_20: 0.1709, lr: 0.0001, epoch: 15/20, step: 28/30\n",
      "loss: 0.0033, last_20: 0.1707, lr: 0.0001, epoch: 15/20, step: 29/30\n",
      "loss: 0.0186, last_20: 0.1706, lr: 0.0001, epoch: 15/20, step: 30/30\n",
      "loss: 0.01, last_20: 0.1436, lr: 0.0001, epoch: 16/20, step: 1/30\n",
      "loss: 0.0062, last_20: 0.1368, lr: 0.0001, epoch: 16/20, step: 2/30\n",
      "loss: 0.0247, last_20: 0.1372, lr: 0.0001, epoch: 16/20, step: 3/30\n",
      "loss: 0.0267, last_20: 0.1349, lr: 0.0001, epoch: 16/20, step: 4/30\n",
      "loss: 0.0462, last_20: 0.1066, lr: 0.0001, epoch: 16/20, step: 5/30\n",
      "loss: 0.0665, last_20: 0.0938, lr: 0.0001, epoch: 16/20, step: 6/30\n",
      "loss: 0.3069, last_20: 0.1081, lr: 0.0001, epoch: 16/20, step: 7/30\n",
      "loss: 0.0281, last_20: 0.0992, lr: 0.0001, epoch: 16/20, step: 8/30\n",
      "loss: 0.0793, last_20: 0.0993, lr: 0.0001, epoch: 16/20, step: 9/30\n",
      "loss: 0.0037, last_20: 0.0811, lr: 0.0001, epoch: 16/20, step: 10/30\n",
      "loss: 0.0098, last_20: 0.0716, lr: 0.0001, epoch: 16/20, step: 11/30\n",
      "loss: 0.0129, last_20: 0.0604, lr: 0.0001, epoch: 16/20, step: 12/30\n",
      "loss: 0.3101, last_20: 0.0716, lr: 0.0001, epoch: 16/20, step: 13/30\n",
      "loss: 0.0319, last_20: 0.0725, lr: 0.0001, epoch: 16/20, step: 14/30\n",
      "loss: 0.3606, last_20: 0.0875, lr: 0.0001, epoch: 16/20, step: 15/30\n",
      "loss: 0.223, last_20: 0.0971, lr: 0.0001, epoch: 16/20, step: 16/30\n",
      "loss: 0.2294, last_20: 0.0912, lr: 0.0001, epoch: 16/20, step: 17/30\n",
      "loss: 0.4683, last_20: 0.1133, lr: 0.0001, epoch: 16/20, step: 18/30\n",
      "loss: 0.3176, last_20: 0.129, lr: 0.0001, epoch: 16/20, step: 19/30\n",
      "loss: 0.2167, last_20: 0.1389, lr: 0.0001, epoch: 16/20, step: 20/30\n",
      "loss: 0.0016, last_20: 0.1385, lr: 0.0001, epoch: 16/20, step: 21/30\n",
      "loss: 0.2379, last_20: 0.1501, lr: 0.0001, epoch: 16/20, step: 22/30\n",
      "loss: 0.4026, last_20: 0.169, lr: 0.0001, epoch: 16/20, step: 23/30\n",
      "loss: 0.0035, last_20: 0.1678, lr: 0.0001, epoch: 16/20, step: 24/30\n",
      "loss: 0.0052, last_20: 0.1658, lr: 0.0001, epoch: 16/20, step: 25/30\n",
      "loss: 0.0542, last_20: 0.1652, lr: 0.0001, epoch: 16/20, step: 26/30\n",
      "loss: 0.0395, last_20: 0.1518, lr: 0.0001, epoch: 16/20, step: 27/30\n",
      "loss: 0.2384, last_20: 0.1623, lr: 0.0001, epoch: 16/20, step: 28/30\n",
      "loss: 0.212, last_20: 0.1689, lr: 0.0001, epoch: 16/20, step: 29/30\n",
      "loss: 0.0122, last_20: 0.1694, lr: 0.0001, epoch: 16/20, step: 30/30\n",
      "loss: 0.4275, last_20: 0.1903, lr: 0.0001, epoch: 17/20, step: 1/30\n",
      "loss: 0.301, last_20: 0.2047, lr: 0.0001, epoch: 17/20, step: 2/30\n",
      "loss: 0.3293, last_20: 0.2056, lr: 0.0001, epoch: 17/20, step: 3/30\n",
      "loss: 0.0032, last_20: 0.2042, lr: 0.0001, epoch: 17/20, step: 4/30\n",
      "loss: 0.0101, last_20: 0.1867, lr: 0.0001, epoch: 17/20, step: 5/30\n",
      "loss: 0.0044, last_20: 0.1757, lr: 0.0001, epoch: 17/20, step: 6/30\n",
      "loss: 0.1626, last_20: 0.1724, lr: 0.0001, epoch: 17/20, step: 7/30\n",
      "loss: 0.0051, last_20: 0.1492, lr: 0.0001, epoch: 17/20, step: 8/30\n",
      "loss: 0.2418, last_20: 0.1454, lr: 0.0001, epoch: 17/20, step: 9/30\n",
      "loss: 0.0504, last_20: 0.1371, lr: 0.0001, epoch: 17/20, step: 10/30\n",
      "loss: 0.0172, last_20: 0.1379, lr: 0.0001, epoch: 17/20, step: 11/30\n",
      "loss: 0.6201, last_20: 0.157, lr: 0.0001, epoch: 17/20, step: 12/30\n",
      "loss: 0.4629, last_20: 0.16, lr: 0.0001, epoch: 17/20, step: 13/30\n",
      "loss: 0.2372, last_20: 0.1717, lr: 0.0001, epoch: 17/20, step: 14/30\n",
      "loss: 0.2576, last_20: 0.1843, lr: 0.0001, epoch: 17/20, step: 15/30\n",
      "loss: 0.0161, last_20: 0.1824, lr: 0.0001, epoch: 17/20, step: 16/30\n",
      "loss: 0.0155, last_20: 0.1812, lr: 0.0001, epoch: 17/20, step: 17/30\n",
      "loss: 0.093, last_20: 0.174, lr: 0.0001, epoch: 17/20, step: 18/30\n",
      "loss: 0.026, last_20: 0.1647, lr: 0.0001, epoch: 17/20, step: 19/30\n",
      "loss: 0.6221, last_20: 0.1952, lr: 0.0001, epoch: 17/20, step: 20/30\n",
      "loss: 0.0023, last_20: 0.1739, lr: 0.0001, epoch: 17/20, step: 21/30\n",
      "loss: 0.0393, last_20: 0.1608, lr: 0.0001, epoch: 17/20, step: 22/30\n",
      "loss: 0.3884, last_20: 0.1638, lr: 0.0001, epoch: 17/20, step: 23/30\n",
      "loss: 0.022, last_20: 0.1647, lr: 0.0001, epoch: 17/20, step: 24/30\n",
      "loss: 0.2103, last_20: 0.1747, lr: 0.0001, epoch: 17/20, step: 25/30\n",
      "loss: 0.0048, last_20: 0.1747, lr: 0.0001, epoch: 17/20, step: 26/30\n",
      "loss: 0.1166, last_20: 0.1724, lr: 0.0001, epoch: 17/20, step: 27/30\n",
      "loss: 0.2896, last_20: 0.1867, lr: 0.0001, epoch: 17/20, step: 28/30\n",
      "loss: 0.087, last_20: 0.1789, lr: 0.0001, epoch: 17/20, step: 29/30\n",
      "loss: 0.004, last_20: 0.1766, lr: 0.0001, epoch: 17/20, step: 30/30\n",
      "loss: 0.0999, last_20: 0.1807, lr: 0.0001, epoch: 18/20, step: 1/30\n",
      "loss: 0.2041, last_20: 0.1599, lr: 0.0001, epoch: 18/20, step: 2/30\n",
      "loss: 0.3611, last_20: 0.1548, lr: 0.0001, epoch: 18/20, step: 3/30\n",
      "loss: 0.0089, last_20: 0.1434, lr: 0.0001, epoch: 18/20, step: 4/30\n",
      "loss: 0.2659, last_20: 0.1438, lr: 0.0001, epoch: 18/20, step: 5/30\n",
      "loss: 0.0692, last_20: 0.1465, lr: 0.0001, epoch: 18/20, step: 6/30\n",
      "loss: 0.1969, last_20: 0.1556, lr: 0.0001, epoch: 18/20, step: 7/30\n",
      "loss: 0.0445, last_20: 0.1531, lr: 0.0001, epoch: 18/20, step: 8/30\n",
      "loss: 0.0033, last_20: 0.152, lr: 0.0001, epoch: 18/20, step: 9/30\n",
      "loss: 0.1538, last_20: 0.1286, lr: 0.0001, epoch: 18/20, step: 10/30\n",
      "loss: 0.2225, last_20: 0.1396, lr: 0.0001, epoch: 18/20, step: 11/30\n",
      "loss: 0.0365, last_20: 0.1395, lr: 0.0001, epoch: 18/20, step: 12/30\n",
      "loss: 0.0868, last_20: 0.1244, lr: 0.0001, epoch: 18/20, step: 13/30\n",
      "loss: 0.0917, last_20: 0.1279, lr: 0.0001, epoch: 18/20, step: 14/30\n",
      "loss: 0.0564, last_20: 0.1202, lr: 0.0001, epoch: 18/20, step: 15/30\n",
      "loss: 0.0053, last_20: 0.1202, lr: 0.0001, epoch: 18/20, step: 16/30\n",
      "loss: 0.0791, last_20: 0.1183, lr: 0.0001, epoch: 18/20, step: 17/30\n",
      "loss: 0.0526, last_20: 0.1065, lr: 0.0001, epoch: 18/20, step: 18/30\n",
      "loss: 0.0161, last_20: 0.1029, lr: 0.0001, epoch: 18/20, step: 19/30\n",
      "loss: 0.0097, last_20: 0.1032, lr: 0.0001, epoch: 18/20, step: 20/30\n",
      "loss: 0.7729, last_20: 0.1369, lr: 0.0001, epoch: 18/20, step: 21/30\n",
      "loss: 0.2134, last_20: 0.1373, lr: 0.0001, epoch: 18/20, step: 22/30\n",
      "loss: 0.0687, last_20: 0.1227, lr: 0.0001, epoch: 18/20, step: 23/30\n",
      "loss: 0.0192, last_20: 0.1232, lr: 0.0001, epoch: 18/20, step: 24/30\n",
      "loss: 0.1428, last_20: 0.1171, lr: 0.0001, epoch: 18/20, step: 25/30\n",
      "loss: 0.028, last_20: 0.115, lr: 0.0001, epoch: 18/20, step: 26/30\n",
      "loss: 0.6709, last_20: 0.1387, lr: 0.0001, epoch: 18/20, step: 27/30\n",
      "loss: 0.3835, last_20: 0.1557, lr: 0.0001, epoch: 18/20, step: 28/30\n",
      "loss: 0.2485, last_20: 0.1679, lr: 0.0001, epoch: 18/20, step: 29/30\n",
      "loss: 0.0201, last_20: 0.1612, lr: 0.0001, epoch: 18/20, step: 30/30\n",
      "loss: 0.2551, last_20: 0.1629, lr: 0.0001, epoch: 19/20, step: 1/30\n",
      "loss: 0.4004, last_20: 0.1811, lr: 0.0001, epoch: 19/20, step: 2/30\n",
      "loss: 0.6992, last_20: 0.2117, lr: 0.0001, epoch: 19/20, step: 3/30\n",
      "loss: 0.0983, last_20: 0.212, lr: 0.0001, epoch: 19/20, step: 4/30\n",
      "loss: 0.0078, last_20: 0.2096, lr: 0.0001, epoch: 19/20, step: 5/30\n",
      "loss: 0.2539, last_20: 0.222, lr: 0.0001, epoch: 19/20, step: 6/30\n",
      "loss: 0.1312, last_20: 0.2246, lr: 0.0001, epoch: 19/20, step: 7/30\n",
      "loss: 0.0077, last_20: 0.2224, lr: 0.0001, epoch: 19/20, step: 8/30\n",
      "loss: 0.0495, last_20: 0.224, lr: 0.0001, epoch: 19/20, step: 9/30\n",
      "loss: 0.0547, last_20: 0.2263, lr: 0.0001, epoch: 19/20, step: 10/30\n",
      "loss: 0.0429, last_20: 0.1898, lr: 0.0001, epoch: 19/20, step: 11/30\n",
      "loss: 0.1033, last_20: 0.1843, lr: 0.0001, epoch: 19/20, step: 12/30\n",
      "loss: 0.0249, last_20: 0.1821, lr: 0.0001, epoch: 19/20, step: 13/30\n",
      "loss: 0.0024, last_20: 0.1813, lr: 0.0001, epoch: 19/20, step: 14/30\n",
      "loss: 0.0252, last_20: 0.1754, lr: 0.0001, epoch: 19/20, step: 15/30\n",
      "loss: 0.0068, last_20: 0.1743, lr: 0.0001, epoch: 19/20, step: 16/30\n",
      "loss: 0.0192, last_20: 0.1417, lr: 0.0001, epoch: 19/20, step: 17/30\n",
      "loss: 0.0954, last_20: 0.1273, lr: 0.0001, epoch: 19/20, step: 18/30\n",
      "loss: 0.4578, last_20: 0.1378, lr: 0.0001, epoch: 19/20, step: 19/30\n",
      "loss: 0.2365, last_20: 0.1486, lr: 0.0001, epoch: 19/20, step: 20/30\n",
      "loss: 0.4243, last_20: 0.1571, lr: 0.0001, epoch: 19/20, step: 21/30\n",
      "loss: 0.1261, last_20: 0.1434, lr: 0.0001, epoch: 19/20, step: 22/30\n",
      "loss: 0.3022, last_20: 0.1235, lr: 0.0001, epoch: 19/20, step: 23/30\n",
      "loss: 0.0163, last_20: 0.1194, lr: 0.0001, epoch: 19/20, step: 24/30\n",
      "loss: 0.0062, last_20: 0.1193, lr: 0.0001, epoch: 19/20, step: 25/30\n",
      "loss: 0.2308, last_20: 0.1182, lr: 0.0001, epoch: 19/20, step: 26/30\n",
      "loss: 0.003, last_20: 0.1118, lr: 0.0001, epoch: 19/20, step: 27/30\n",
      "loss: 0.0218, last_20: 0.1125, lr: 0.0001, epoch: 19/20, step: 28/30\n",
      "loss: 0.0071, last_20: 0.1103, lr: 0.0001, epoch: 19/20, step: 29/30\n",
      "loss: 0.0348, last_20: 0.1093, lr: 0.0001, epoch: 19/20, step: 30/30\n",
      "loss: 0.6279, last_20: 0.1386, lr: 0.0001, epoch: 20/20, step: 1/30\n",
      "loss: 0.2357, last_20: 0.1452, lr: 0.0001, epoch: 20/20, step: 2/30\n",
      "loss: 0.0895, last_20: 0.1484, lr: 0.0001, epoch: 20/20, step: 3/30\n",
      "loss: 0.2598, last_20: 0.1613, lr: 0.0001, epoch: 20/20, step: 4/30\n",
      "loss: 0.384, last_20: 0.1793, lr: 0.0001, epoch: 20/20, step: 5/30\n",
      "loss: 0.1927, last_20: 0.1886, lr: 0.0001, epoch: 20/20, step: 6/30\n",
      "loss: 0.5054, last_20: 0.2129, lr: 0.0001, epoch: 20/20, step: 7/30\n",
      "loss: 0.251, last_20: 0.2206, lr: 0.0001, epoch: 20/20, step: 8/30\n",
      "loss: 0.1211, last_20: 0.2038, lr: 0.0001, epoch: 20/20, step: 9/30\n",
      "loss: 0.4641, last_20: 0.2152, lr: 0.0001, epoch: 20/20, step: 10/30\n",
      "loss: 0.049, last_20: 0.1964, lr: 0.0001, epoch: 20/20, step: 11/30\n",
      "loss: 0.0055, last_20: 0.1904, lr: 0.0001, epoch: 20/20, step: 12/30\n",
      "loss: 0.0058, last_20: 0.1756, lr: 0.0001, epoch: 20/20, step: 13/30\n",
      "loss: 0.312, last_20: 0.1904, lr: 0.0001, epoch: 20/20, step: 14/30\n",
      "loss: 0.0017, last_20: 0.1901, lr: 0.0001, epoch: 20/20, step: 15/30\n",
      "loss: 0.181, last_20: 0.1876, lr: 0.0001, epoch: 20/20, step: 16/30\n",
      "loss: 0.1095, last_20: 0.193, lr: 0.0001, epoch: 20/20, step: 17/30\n",
      "loss: 0.0831, last_20: 0.196, lr: 0.0001, epoch: 20/20, step: 18/30\n",
      "loss: 0.0197, last_20: 0.1967, lr: 0.0001, epoch: 20/20, step: 19/30\n",
      "loss: 0.0078, last_20: 0.1953, lr: 0.0001, epoch: 20/20, step: 20/30\n",
      "loss: 0.004, last_20: 0.1641, lr: 0.0001, epoch: 20/20, step: 21/30\n",
      "loss: 0.4231, last_20: 0.1735, lr: 0.0001, epoch: 20/20, step: 22/30\n",
      "loss: 0.1053, last_20: 0.1743, lr: 0.0001, epoch: 20/20, step: 23/30\n",
      "loss: 0.2295, last_20: 0.1728, lr: 0.0001, epoch: 20/20, step: 24/30\n",
      "loss: 0.0555, last_20: 0.1563, lr: 0.0001, epoch: 20/20, step: 25/30\n",
      "loss: 0.3101, last_20: 0.1622, lr: 0.0001, epoch: 20/20, step: 26/30\n",
      "loss: 0.0455, last_20: 0.1392, lr: 0.0001, epoch: 20/20, step: 27/30\n",
      "loss: 0.0389, last_20: 0.1286, lr: 0.0001, epoch: 20/20, step: 28/30\n",
      "loss: 0.0319, last_20: 0.1241, lr: 0.0001, epoch: 20/20, step: 29/30\n",
      "loss: 0.0175, last_20: 0.1018, lr: 0.0001, epoch: 20/20, step: 30/30\n",
      "***** Training Completed *****\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(text_encoder.get_input_embeddings().parameters(), lr=1e-4, eps=1e-7)\n",
    "#optimizer = torch.optim.RMSprop(text_encoder.get_input_embeddings().parameters(), lr=1e-3, eps=1e-7)\n",
    "\n",
    "# Training\n",
    "data_folder = f'../data/{property_name}'\n",
    "train_model(property_name, data_folder, optimizer, num_train_epochs=20)\n",
    "\n",
    "# Save final model\n",
    "save_model(f'saved_models/{property_name}', f'{property_name}_final.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cc8010bf3f78e9c10d4febe712c77abe75f8df416c09ebdb6a9b39023fa5c08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
